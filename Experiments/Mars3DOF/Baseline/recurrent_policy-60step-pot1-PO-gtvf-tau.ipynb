{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RNN Policy  with Engine Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/Users/briangaudet/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/Experiments/Mars3DOF/Baseline\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('../../../RL_lib/Agents/PPO')\n",
    "sys.path.append('../../../RL_lib/Utils')\n",
    "sys.path.append('../../../Mars3dof_env')\n",
    "\n",
    "%load_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib nbagg\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:1000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:1000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-dof dynamics model\n",
      "lander model apf\n",
      "queue fixed\n",
      "Flat Constraint\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"800\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"800\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"800\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABkAAAAJYCAYAAAA6xipCAAAgAElEQVR4nOzdd3RUdfoG8JciICgqCitFEQUbu6CgLqhrwfYDWcV1FcSyFkSsqAu6KOill1BCryEhSIDQQm9SAgSSkExCekJIQnqZ9EySmWTm+f0R5jKTAjOI5o48n3Oec8y931tmXpMzc1/u/YoQERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERHRpZw4ceLGoKCge0NCQu5nGIZhGIZhGKZuAgMDe/j6+rZo7M/uRERERERE5ABFUZqGhISM1+l0CWFhYclhYWEpDMMwDMMwDMPUm2SdThd88uTJzo39OZ6IiIiIiIguIyQkZHx4eHhGdnZ2cmlpaXRZWVkUwzAMwzAMwzB1U1JSEh0TE5MdGhrqoShK08b+LE9EREREREQNCAwMbKvT6RKys7OTAYQwDMMwDMMwDHPp5OfnJ+h0usRjx461b+zP80RERERERNSAoKCge8PCwpJLS0ujG/uLJMMwDMMwDMO4QkpLS6PCwsJSgoKC7m3sz/NERERERETUgJCQkPvDwsJSysrKohr7iyTDMAzDMAzDuELKysqiwsLCUkJCQu5v7M/zRERERERE1AA2QBiGYRiGYRjGubABQkRERERE5ALYAGn8FBcX61544YXC1q1bm0UEubm5YY19TgzDMI7Ezc0tpUOHDqYmTZpg4sSJqY19PgzDMFcrOp0uqlevXmXXXXed5d577y2vvZ4NECIiIiIiIhfgyg2Q1157TS8iGDduXLrt8jVr1iSKCBr7/BzNjBkzzt98881VQUFBUSkpKeFms7nRz4lhGNdIenp6+FtvvZV7++23G5s3b25p165d1eOPP168b9++WAAhnTp1MooIRAQtWrSwdOrUyThw4MACPz+/+N96bL1er2vWrJll6tSp55OTk88UFxfrGvv9YBjGNWL9DDds2LDc2uveeeedXBHBa6+9pm/Mcxw0aFBBv379SuLi4iIyMzPr/OMUNkCIiIiIiIhcgKs3QFq0aGG54YYbqnNyctQvpr+1AVJeXh76R5y/9TgjRozI7tu3b2ljv58Mw7he+vTpU9qrV6+y7du3x8fFxUUcOnQo5n//+1/62rVrzwI1DZAxY8ZkpKSkhMfHx0fs2bMnbtiwYXlNmjTB2LFj06/kmGazOcRkMoUEBQVFiQhiY2MjGvt9YBjGtfLaa6/pb7/9dmObNm2qS0tL1c9dZWVloTfccEN1x44djY3VALF+PuvZs6fh66+/zmxoHBsgRERERERELsDVGyDPPvts0V133VUxcuTIbOvy2g0QT0/PxLvvvruiefPmlk6dOhl/+umnNNv9WC8QDhkyRN+6dWvza6+9po+NjY0QEaxcufLcww8/XNqiRQtLz549DeHh4ZFHjx6N6dmzp6FVq1bmJ598sjg9PT3c0fMdMGBA4dixY9Nvu+02U6dOnYyPPPJIqVz419kigkceeYSNEIZhHEpubm6YiGDnzp1xDY3p1KmTsb5HU3399deZTZs2RXh4eOTljrNz5854EcGGDRsSHnzwQUOzZs0s7u7uybZ/u4SNEIZhnIj1M1H37t3LFy9enGRdvmTJkqQePXqUDxgwoNDaANm0aVPCww8/XNqmTZvqtm3bVj/zzDNFkZGR6t+uBQsWJLdq1cp85swZddnw4cNzu3btWuHInWn1fQ6s/fetvkYIGyBEREREREQuoE4DxGwOQVGRrlHi5KOfrF+evby8Elu0aGFJTEw8A9g3QPz9/WOaNm2KMWPGZISHh0e6u7snt2zZ0uzu7p5s+8W3TZs21T/99FNa5AXWBshdd91VsXnz5oSQkJCoXr16lfXs2dPw2GOPlezbty/2+PHj0XfeeWflW2+9VefxDQ2d7/XXX28eMmSIPjg4OCo4ODgqOzs7bNiwYXm9e/cuS0lJCc/Ozub8HwyjkRQVQVdUBJ3ZfHFZeTlCi4qgMxgQWt/YqqqLyyora8aWlTk21tnzM5lMIddff735gw8+yDEYDPVu31ADJDs7O6xJkyb44Ycf0i53HGsDpEePHuVbtmxJiIyMjDx37tyZbdu2xYsIjh49GpOSkhJuMpkavWYMwyCkqLJIV1RZpDNbLn6uKjeVhxZVFukMRvu/FdaxVeYqdVmlqTK0qLJIV2Ysc2jslZyj9TOcoiip/fv3L7Eu79+/f8nEiRNTbRsgnp6eiV5eXokRERGRJ06ciH722WeLunfvXl5VdfE8Bg4cWPDXv/7VYDKZQtavX3+2WbNmFn9//xhHzqW+z4EpKSnh99xzT8WIESOyU1JSwgsLC+s0UtgAISIiIiIicgF1GiBFRTqIoFFSVOTU8+OtX54BhPTq1avsjTfeyAPsGyCDBw/O79+/f7HtdiNHjsy+++67K2y/+D733HOFtmOsDZA5c+akWJctW7bsnIjA9tn548aNS+/atWuFo+fbrl27qtqP2Hr//fdzeOcHw2gv1j9N6elQ7/IaOxbpIsDQocizHduyJcwiQGws1LsgJk5EqggweDDybcfedBOqRIDgYKh33rm5IeVKztHT0zPxxhtvrG7RooXloYceKvvss8+yAgMDo63rG2qAAAhp165d1fDhwy/bwLU2QLy9vRNtl584cSJaeOcHw2guoghEEaSXXLxDdeyBsemiCIb6DrX/2zW5pVkUQWzuxd/jiUcnpooiGOwz2P5v1/SbqkQRBGcEX/zbFeB2RX+7rJ/h0tPTw6+77jpLXFxcRFxcXESLFi0sGRkZ4bYNkNrJyMgIFxEEBQWp55GTkxPWoUMH0/Dhw3PbtWtX9f333zv8iL/6PgcCCLn33nvL+QgsIiIiIiIiF/dnaYDs2bMnrlmzZggJCYmybYA88MADhm+//TbDdjtvb+/EZs2aWaz/WrlTp07G2s/CtzZAjh49qv7rwe3bt8eLCGwfeTVv3rzkG2+8sdrR8+3Xr19x7eVsgDCMNuMKDRCg5pn5W7ZsSRgzZkxG7969y5o1awbrXW6XaoDccsstVe+8847DDZBz586dsV3OBgjDaDOu1AABEPLCCy8Ufvvttxlff/115ksvvVQAIMS2AXLmzJnIl19+Ob9z587G1q1bm1u1amWWmsfynbXd5+bNmxNEBA899FCZ7d0hl0t9nwMBNkCIiIiIiIj+FP4Mj8Cy/vz0008XDRgwoPBKGiC1LxBaGyAnTpxQ/yW19SJgbm6u+pgqd3f35DZt2jjcALE9X2vYAGEYbUbrj8BqKG+++WZex44djUDDDZDMzMywJk2aYMKECQ4/Asv2bx/ABgjDaDWu9AgsACHr168/26lTJ2OnTp2M1qaGbQOka9euFY8//njxtm3b4kNCQqKCg4OjRARr1qyxuyvtyy+/zGzWrBk6d+5sLCgocPgf1TT0d5INECIiIiIioj8BV58E3bahEBgYGN20aVOMGjUqSy7zCKx77rnH7hFYbIAwDPNnyc8//5x20003VQENX9gbPXp0ZrNmzRAREeHwJOhsgDAMc7Vi+5nIZDKF3Hbbbab27dubrP84xdoAyczMDBMR7N27N8667d69e+OkVgNk//79sU2bNrVs2LAhoXv37uVDhgzRO3oubIAQERERERH9if2ZGiAAQoYMGaJv0aKFRS40QI4dO2Y3Cfr8+fPrnQSdDRCGYVwtmZmZYX//+99LFi1alBQYGBgdGxsb4eHhca5du3ZV1jmROnXqZBwzZkxGSkpKeEJCwpk9e/bEDRs2LO/CBOgOPSOfDRCGYa52an8m0uv1Or1er961YW2AVFVVhdx0001Vr776an5ERESkn59f/F//+leD2DRACgoKdF26dKn86KOPsoGafxBz3XXXWTw8PM45ci5sgBAREREREf2J/dkaILGxsRHNmzdXGyBAzSTBd999d0WzZs0sHTt2NNZ+5AsbIAzDuGIMBkPoZ599lvXggw8a2rRpU92yZUtz165dK7766qvM0tLSUKDm75uIQETQvHlzS8eOHY2DBg0q2L59e7yjx2EDhGGYq52GPhNZY/sIrK1bt8Z369at4rrrrrP06NGjfOfOnXZ3gLz++uv67t27lxsMFx/v9fPPP6e1bdu2uvbcRfWFDRAiIiIiIqI/MVdugDAMwzAMwzBMY4QNECIiIiIiIhfABgjDMAzDMAzDOBc2QIiIiIiIiFwAGyBXL61atTI3FNvJOxmGYbSUYcOG5Tb0t2vYsGG5jX1+DMMwV5q9e/fGXerz2W/ZNxsgRERERERELoANkKuXiIiIyIZifR4/wzCM1pKWlhbe0N+utLS08MY+P4ZhmCtNaWlp6KU+n/2WfbMBQkRERERE5ALYAGEYhmEYhmEY58IGCBERERERkQsICgq6NywsLLm0tDS6sb9IMgzDMAzDMIwrpLS0NCosLCwlKCjo3sb+PE9EREREREQNCAwMbKvT6RKys7OTG/uLJMMwDMMwDMO4QvLz8xN0Ol3isWPH2jf253kiIiIiIiK6hJCQkPHh4eEZ2dnZyaWlpdFlZWVRDMMwDMMwDMPUTUlJSXRMTEx2SEjIKkVRmjb2Z3kiIiIiIiK6BEVRmoaEhIzX6XQJYWFhyWFhYSkMwzAMwzAMw9SbZJ1OF3zy5MnOjf05noiIiIiIiBx04sSJG4OCgu4NCQm5n2EYhmEYhmGYujl58mR3X1/fFo392Z2IiIiIiIiIiIiIiIiIiIiIiIiuknEiclpESkUkV0T8ROS+WmOOighqZVmtMXeKyG4RKb+wHzcRaV5rzDMiohMRo4gkisj7Tp5rExHpLCJtGYZhGIZhGIZxOJ2l5rM0ERERERHRNWWf1DQieopIb6lpYpwXkTY2Y46KyAoRud0mbW3WNxORSBE5KCIPichAEckTkWk2Y7qJiEFE5ojIAyLyhYhUi8hLTpxrZ6nbiGEYhmEYhmEY5vLhPCBERERERHTNay81X5Cesll2VETcL7HNQBExi8hfbJaNEpFiEbE+c3imiETV2m6D1DRgHNVWRJCWlobi4uI/PHq9Hj4+PtDr9Y1yfIZ1caWwLtoM66LNsC7aDOuizbAuzictLc3aAGl7mc/aREREREREf3rdpeYL0l9tlh2Vmjs69FLTxJguIq1t1k8SkfBa++l2YT8PX/j5mNRtonwgNU0SR7UVERQXF6MxmEwm+Pn5wWQyNcrxqX6sizaxLtrEumgT66JNrIs2sS7OKy4uZgOEiIiIiIhIRJqKyC4ROVFr+UipeVTV30TkbRFJF5GtNutXiMj+Wtu0lpovWgMv/JwgNfON2Bp0Ycz1DZxPS6n77GLo9XqYTKY/PAaDAX5+fjAYDI1yfIZ1caWwLtoM66LNsC7aDOuizbAuzkev17MBQkREREREJCJLRSRFRLpcZtwAqfkSdc+Fn3+vBogi9Ty/2MfHB35+fgzDMAzDMAzDXCY+Pj5sgBARERER0TVvkYikSc2jqy6njdR8ibJOYP57PQKLd4AwrIuLhnXRZlgXbYZ10WZYF22GdXE+vAOEiIiIiIiuZU2kpvmRISI9HNzmCan5EtXrws/WSdA72IwZKTXNjZYXfp4pIpG19uMjVzAJOucAIVusizaxLtrEumgT66JNrIs2sS7O4xwgRERERER0LVsiIkUi8rSI3G4T62Op7hGRCSLSV0TuEpFXROSciPjb7KOZ1DQ39otIb6m5MyRXRKbZjOkmIgYRmSUi94vIZyJSLRfvInEEGyBUR0N1sVgsMFYbG+msiL8v2sS6aBProk2sizaxLs5jA4SIiIiIiK5ldebYuJD3L6y/Q2qaHfkiUikiZ6WmiVH7C1RXEdkjIuUikicis0Wkea0xz4hImIgYpaaJ8r44hw0QqqOhujzh8QS6zO2CclN5I53ZtY2/L9rEumgT66JNrIs2sS7OYwOEiIiIiIjINbABQnXUVxeLxQJRBKIIgtODG/Hsrl38fdEm1kWbWBdtYl20iXVxHhsgREREREREroENEKqjobpsidmCjVEbUWosbaQzu7bx90WbWBdtYl20iXXRJtbFeWyAEBERERERuQY2QKgO1kWbWBdtYl20iXXRJtZFm1gX57EBQkRERERE5BrYAKE66qvLuF/H4bNdnyGtOK0Rz+zaxt8XbWJdtIl10SbWRZtYF+exAUJEREREROQa2AChOuqry+2zb4cogiXBSzgJeiPh74s2sS7axLpoE+uiTayL89gAISIiIiIicg1sgFAd9dXFLcBNnQQ9QZ/QiGd37eLvizaxLtrEumgT66JNrIvz2AAhIiIiIiJyDWyAUB0N1eWhZQ/hnvn3IKkgqZHO7NrG3xdtYl20iXXRJtZFm1gX57EBQkRERERE5BrYAKE6WBdtYl20iXXRJtZFm1gXbWJdnMcGCBERERERkWtgA4TqqK8uRRVFKKwoRLW5uhHP7NrG3xdtYl20iXXRJtZFm1gX57EBQkRERERE5BrYAPkDmKpNKDOWNfZpOKy+utw26zaIIojKiWrEM7u2XSu/L66GddEm1kWbWBdtYl2cxwYIERERERGRa2AD5A/w0tqXcDjpMMwWc73rE/MTNTWvxqUaIF3ndUVqUWojnt2161r5fXE1rIs2sS7axLpoE+viPDZAiIiIiIiIXAMbIH+ATnM64V8b/4VjKceQoE+wayBE5kRCFMHYA2Mb8Qzt1VcXU7UJN0y7AaIIYvNiG/Hsrl3Xyu+Lq2FdtIl10SbWRZtYF+exAUJEREREROQa2AD5Azzh8QTumX8PJh2dBFEEz3g9o67bELkBoghEkUY8Q3sN1eWXM79gtW41CisKG+nMrm3Xyu+Lq2FdtIl10SbWRZtYF+exAUJEREREROQa2AD5A22L3Ya209ti0LpB6jJTtQnZpdnIKMloxDOzd63VxVWwLtrEumgT66JNrIs2sS7OYwOEiIiIiIjINfypGiB6gx5bY7ZelX39kSwWC44kH8HhpMMwVhsb+3TqrctPh3/CmP1jkFOW04hndm3jBSptYl20iXXRJtZFm1gX57EBQkRERERE5Br+VA2Ql9e9jJum34QyY9lV2Z+tVaGr0GVuF3y550sAwGrdajy28jF8vffr37xvi8WiPgYrtyy33jHGaiMsFstvPpYj6qvLzTNuhiiCjVEbUVFV8YecB9njBSptYl20iXXRJtZFm1gX57EBQkRERERE5Br+VA2Q3kt7QxTBvrP7rsr+bM0OmK02KR5e9jCm+E+BKII+y/ugoLygwe0sFgteXPsiBq0bVO/cGcoRBd/u+xaiCHou7gm9QV/vfnos6IEmShOcOH/iqr2mhtRXlwmHJ6ivPyon6nc/B6qLF6i0iXXRJtZFm1gXbWJdnMcGCBERERERkWv4UzVACsoLkF2ajeD0YLy87mV8uuvTq7JfAMgpy8HuhN0QRdBEaYIEfQIOJB647F0ZVeYqtXFwJPkI/rPtP/j5yM8AAO9wb9y38D6IIlgZuvKS++kytwtEEXSd1xVeYV4OnXNhRSF6Lu6Jvsv7orKq0qFtgIbr8tclf0XH2R0Rmxdrt3xT9CZ8uefLBu9eoauDF6i0iXXRJtZFm1gXbWJdnMcGCBERERERkWv4UzVArI4kH4EoggcWPWC3fGXoSvzv4P+wMWrjFe3XWG3EvrP7cCjpkF3jIzwrHEM2DMH4Q+PrbFNtroZ3uDc8dB7YFrsNoggeWfEI/FP88d2B7/DF7i/gF+sHU/Wl34PiymK8s/UdiCIYs3+MQ+e7NWYrhm8ZjkVBi5yaW8TZury87mUM9hmMuSfnOnwMch4vUGkT66JNrIs2sS7axLo4jw0QIiIiIiIi1/CnbIBklmRitW51nQnRn1vzHG6ffTue8HgCRRVFV7TviqoKDPYZjGGbh6l3VWyJ2aLe5RGaGdrgtucKzmHmiZlYE74Gn+/+HKIIfjr8k8PHPpl6EktPL8XJ1JMOjd+TsAePezyOL3Z/4fAxgPrrYqo2wVRtqveOl4+2f4TbZt2G2QGznToOOYcXqLSJddEm1kWbWBdtYl2cxwYIERERERGRa/hTNUAWBS3C1GNTkV6cXu/6xcGLMTtgNswWs9P7Ds0MhXe4N/ad3ac2O15a+xKe8HgC/in+6rLtcdsd2t+KkBV4fePr6t0og30G47k1zyGrNMvpc7va6qvLjdNuhCiCxPzERjyzaxsvUGkT66JNrIs2sS7axLo4jw0QIiIiIiIi1/CnaoDc5X4XRBEEpgU6NP4fq/+B6yZdh13xu9RlZosZSQVJdcZ+f/B7dQ6Of/r8E24Bbrh5xs0QRRCXFwefCB+4n3Kv0yAwVhtxOuM0zmSfueS5tJ7aGqJIvceurKrEhMMTMP349Ms+Kqs273BvzA+c71Rjpb663DDtBnXS95TCFKfOga4OXqDSJtZFm1gXbWJdtIl1cR4bIERERERERK7BJRogZovZobs2/nfwf/ho+0eIyolCeFY4onKiAABZpVmYe3IuVutWAwAisiOwPnI9Wk5uCVEEfrF+6j62xGzBu1vfrTNp+MrQlXhx7YvqnR6ZJZnwi/XDu1vfxcwTMxu8MyI4PVjdprKqEhklGcguza4zbn3keqyLWIdSY2mddXmGPHUfkTmRDjUzlp5ein+s/oe6naOPzQLqr0thRSFaTWkFUaROM6ft9LZoMbkFzhedd/gY5DxeoNIm1kWbWBdtYl20iXVxHhsgRERERERErsElGiDRudHosaAHyk3lDu03KD1IvVsDAALTAiGK4C73uzBgzQC1KTBkwxCkFafhdMZpvL7xdby95W2M3jsaj654FGMPjK133/1X9Ue/Vf3UJoa1ybApelO941frVqvHs07O/uDiBx16HVZFFUX4bNdn6n6+2vPVZbcZe2CsOn7opqGIy4tz+HgN1cVD54GFQQuRZ8izW249zoqQFQ4fg5zHC1TaxLpoE+uiTayLNrEuzmMDhIiIiIiIyDW4RAPk7S1vQxRBRHaEusw/xR/7zu6rd3x4Vjhun307HlnxCADgbP5ZDN8yHF/t+Qo3Tb8Jogg6z+mM+YHzAQA743ei3cx2EEXQe2lvPLriUYw/NB7Pez+Pj3d8jKzSLBRWFAKouRvjTPYZ5JblAgDGHxqPf238F3bE7UBSQRKKK+3fy2/3fQtRBCO2j4B/ij+aT2qOvy35G97Z+g46z+mMDZEbHH6/pvhPQbuZ7fC/g/+77NiI7Ahsit6E8Kxwh/dv5eyFEOudMZP9Jzt9LHIcL1BpE+uiTayLNrEu2sS6OI8NECIiIiIiIteg2QbIat1qPLriUUw7Ng0D1gzAw8seRoI+QV3/tyV/w/cHv0dmSaZTx9x7di92xu+s86ipsKwwhGaGoqSyBOsi1qlzcljz2MrHAACrQldBFMHL615GcHowjiYfRUllCQb7DIYoAg+dBwwmA4ZtHoa3Nr+FksqSeuftsDYNvMO91eMHpQfBYDI49Xp+D/XVZYr/FPx85Ge1EWRre9x2TDw6EcfPH/8jT/OawwtU2sS6aBProk2sizaxLs5jA4SIiIiIiMg1aLYBMvHoRIgi+GTnJ/VuW9+E5x1nd0Trqa0Rr4936Pibojdh1olZiM6Ntls+9+RctfHxb99/q/9938L78PeVf0cHtw740O9D3DnvTogiCE4Pxhu+b6D11Nbw0HmgsKJQ3aahScuTCpKgy9RBb9ADAG6bdRtEEXXeEltn889iT8Keetf9Huqri3X+j1/P/YqKqoo/5DzIHi9QaRProk2sizaxLtrEujiPDRAiIiIiIrqWjROR0yJSKiK5IuInIvfVGtNKRBaLSL6IlInIFhH5S60xd4rIbhEpv7AfNxFpXmvMMyKiExGjiCSKyPtOnqtmGyAJ+gTsjN/Z4COcTmecxu6E3YjXx6uPnWo7vS1EEbs7RS7lBe8X1EZFWFaYuvxcwTnsiNuB0MxQmC1mVJmrMHzLcLu7QaJzozFgzQDcv+j+OudYWFGIZ7yegVuAm0OTtwNAn+V9cJf7XYjNi62zbrL/ZIgi+HjHxw7tCwDi9fE4lnIMDyx6AB3cOuBI8hGHt62vLqP3jlZfvy5TZzd+dsBszA6YjTJjmcPHIOfxApU2sS7axLpoE+uiTayL89gAISIiIiKia9k+qWlE9BSR3lLTxDgvIm1sxiwVkVQRGSAifUXklIgE2KxvJiKRInJQRB4SkYEikici02zGdBMRg4jMEZEHROQLEakWkZecOFfNNkAc8c2+byCK4PuD3wMAUotSca7gHJIKkvDmpjfxod+HAIDDSYdx68xbMWDNAPin+KP7gu7o5t4NT3g8oV7Un358OtwC3NBzcU/0X9Ufv5771e5YcXlxOJp8FM0nNYcogpOpJwEAz3g9gy5zuyAgNUAdm6BPgCgC3yhfu32kFKbgs12fYeyBsTiZehLGaqPd+vf93sd7297Di2tfxD99/qlOXL4ydCX6LO+DPsv74O0tb8MzzPOy782I7SPsHuG1J2GPw+9rQ3W5b+F9aDu9bZ2Gj/UYyYXJDh+DnMcLVNrEumgT66JNrIs2sS7OYwOEiIiIiIjoovZS8wXpqQs/3yQiJhH5t82Y+y+M6Xfh54EiYhb7u0JGiUixiLS48PNMEYmqdawNUtOAcZRLNED+7ftvPOHxBGJyY+yWj9k/Bk0nNsV3B76zWx6TGwNRBLfOvBUAsCdhD0QR9FneR33UlHX+DV2mDgGpAXh367t2DYPDSYcRlxeH1KJUu33vT9yPHXE7kF+eD6CmKSCKwD/F3+58RREsDFpot+3pjNPq/nsv7Q2vMC9kl2ar62+YdoPdOZxKO2W3/Vei2K8AACAASURBVE+Hf4Iogk93fXrJ9wsAfvj1B/RY0APf7vsWR5OP4inPp/C89/OX3Q5w/kKI9XzHHhjr0Hi6MrxApU2sizaxLtrEumgT6+I8NkCIiIiIiIgu6i41X5D+euHnARd+vrnWuPMi8s2F/54kIuG11ne7sN3DF34+JiLutcZ8IDVNEkdppgFitphhMBnUycmjc6NxIPEAkgqS0HVeV4giCEoPUrfdHrcdW2K2oLiyGD4RPrhz3p1YELgAAFBQXoCFQQuxKnQVAKDUWIro3GiczT+Lpz2fhiiCZaeX2U2g7hXmhXe3vgsPnQdEEXy15yuIImgztQ2+3fct3ALc6n0NMbkxCMkIweLgxXhn6zvwifBBYFoglp5eimMpx+zGZpRkqE0MUQQd3Dqoj42yWCzwCvPCjOMzsFq3GitDVyKnLMdu+4DUAMwOmI2D5w469T5vit6kHtMRzl4I+XjHxxBFMNl/slPnRc7hBSptYl20iXXRJtZFm1gX57EBQkREREREVKOpiOwSkRM2y4ZLzZwdtQVLzV0dIiIrRGR/rfWtpeaL1sALPydIzXwjtgZdGHN9A+fTUmq+qFnTWUSg1+thMpn+8BgMBvj5+cFgMOBY0jGIIrhn/j0wmUwYuX0kRBFMODQBO2J3YGPERmQXZ6vb3jLjFogiOJN5Bi95v6Re4J9zYg4KywrtjrM3fi9OnT/l2DlVGKAcVuzuxLDGN9IXiXmJ6thRO0bh+TXPIyg1CB/5faSOe3DRgxBF0GJyC4ffi4/8PsLgdYMRnR2tLisoK8AIvxH4yO8j5JXkXfH7XGQoQnhGOLx0Xk7Xxbrs+inXo/mk5kjOT64zvqKyAuWV5ag0VjbK/0fXSuqrC9P4YV20GdZFm2FdtBnWxfno9Xo2QIiIiIiIiKRmro8UEelis6wxGyDKhfV28fHxgZ+f3x+exRsWY9SqUXh2/rN4edHLEEXQfmp7+Pn5Yfiy4bhrxl34dNWn9W7bd25fPOD2AFb6rsT6Levh5uOmNiC8Nnmp41b4rlCX197Hs/OfhSiCh+Y8BJ8tF9+D77y+w50z7sTLi17G0o1L8dqS19R9jF49Wh3XbWY3iCL42ftnjPcej/ZT20MUQfeZ3dFqUivcOPlGh9+LDtM6QBTBrHWz1GVjPMfg7pl3QxRBu6ntMHLVSKff4wneE/C5x+dYtnHZb6pVM6VZzaO75vTG8o3LG+X/F4ZhGIZhGC3Ex8eHDRAiIiIiIrrmLRKRNKl5dJWtxnwElqbuAFketNzuDosDCQdQWl7q8Pa743bjs52fYU3YGlQaK/HWprfwpu+byCnOQUx2DKKzoxGTHXOxARJT83iHg2cPYmv0VvzD4x/quqisKPz464/4YNsHCEoNqnOsM5lnIIpgb/xeddm26G0Y9MsgTPWfipziHBiNRpSUl+B48nFsj9mOmOwYu31UVFZgceBijDs4DpFZkXbrPEI98O3eb3E8+Tiis6MRmh6KTZGb8KTHk+o5frz9YyTmJSKrKOuy781Ph36yuzPml/Bf8N99/8ULa17AwbMHL7ltff8SNDk/GU0nNq2Zm8TmbhpDhQE3z7gZt8y4BXkleTAajcgpzmn0f5n5Zwz/ha42w7poM6yLNsO6aDOsi/PhHSBERERERHQtayI1zY8MEelRz3rrJOiv2yy7T+qfBL2DzZiRUtPcaHnh55kiEllr3z7iQpOgH0o8hH7z+kEUwUtrX8LZ/LP1jjudcRpHk4+isKLQbvm0Y9MgiuBDvw8RnhWOr/Z8hTkn5yClMAWiCFpNaQUA8InwgSiCAWsG4PWNr6tNgZWhK9FjQQ/0XtpbncdCFMHes3vrnEOZsQy74nfBbDHbLW8/q+auj6icKHXZR9trHoc19dhUu7HRudEXH6cV5Wu37lzBOYgiuGHaDbh34b0QRdQ5RCKyI7AlZgve3PQmRBGM2D7isu/tq+tfhSiC22bdhjvm3oEhG4aox14fuf6S25pM9T8LfEnwEsw8MdNu7pTKqkq712T9eXnI8sueIzmnobpQ42JdtIl10SbWRZtYF+dxDhAiIiIiIrqWLRGRIhF5WkRut4ntY6mWSs0dH8+KSF8ROXkhVs2kprmxX0R6i8hLIpIrItNsxnQTEYOIzBKR+0XkMxGpvjDWUZqZBP1S7lt4H0QR+Kf42y33T/HH+EPj8bTn03hydc2dEv1W9UN6cTraTm+LDm4dYLFY4Bfrh1fXv4rxh8aj4+yO6vwcgWmB6r6+P/i9eiE/tSgVAakB+M+2/8AtwA0VVRWoqKqo99ze3PQmXlz7IuLy4nAm+wzi9fGY7D8ZfZf3hYfOw25sTO7Fu1GC04Pt1iXmJ+KWGbegy9wu6L+qP9rPao9TaaeQU5aDs/lnUVBegBnHZ6Dl5JYYtXPUZd/bw0mH4RXmhXh9PBYELoAogptn3AzvcG8kFyZfcltnLoSYLWYMWDOgZr6WwxOw7PQyiCL4wO+Dy25LzuEFKm1iXbSJddEm1kWbWBfnsQFCRERERETXsjpzbFzI+zZjWonIYhEpkJomxlapaZLY6ioie0SkXETyRGS2iDSvNeYZEQmTmjlFztU6hiM00wDJL8/Hj4d+xITDEwAA434dh2e8nsGu+F0YtG4Q7l90v13ToM/yPuizvA9yy3Jx26zbIIrg1fWvYkXICrtjjNk/BpuiN+F80XkAwPa47dgYtREF5QV243LKchCXF4fcslwcSjqkNipunHZjg3eGxOvjEZwejPzyfEw4PKFmPpFlD8Enwgcf+n2I0XtH2403W8wwVhthqq57geFs/llE5kSi1FgKAEgrToNyRMGLa1+EKAL3U+5X+C4D+87uw/AtwzE/cL667FTaKazWrYYuU1dnfH0XQmadmIVZJ2ahzFhWZ/zWmK347sB3OJB4AKczTmN+4HwcSDxwxedL9eMFKm1iXbSJddEm1kWbWBfnsQFCRERERETkGjTTAEkuTIYoguunXA8AGLRuEESROndRAIDFYlGbEjllORi9d7T6yKf2s9rDWG1Ux94842Z1bG2Hkw5jSfAShGaG2i1fH7le3ebrvV9fnFw9zMtu3FOeT6mPforKicLTnk/jac+n4Rvlqz5+ylEPLn4QogiOJB8BAIzeO9pufpQ3fN9QmzhXw6e7Pq2ZwP3Iz3XW1XchxHoeukyd3ftLfxxeoNIm1kWbWBdtYl20iXVxHhsgRERERERErqFRGyCB5wNx29Sauzf+4vYXvL3lbYw9MBYAcPz8cWyI3IBzBefqbGexWLA/cT92xO2A3qBHmbEMeoNevUhfba5Wx/10+Cd1ucVisdvPB34fqOvyDHlIKkjC+aLzSC5MxvrI9TiSfARV5irsit+F1brVSCpIstv+Dd83cMfcO7Ajbofd8tyyXEw/Ph3zTs1z+L14cvWTaD+rvd28H7MDZmPkjpF4e8vbEEUw6egkh/cXlxeH0MxQDN00FN3cu2F95Hok6BPgFeaFVlNaQRTBoHWD8MuZX+psW9+FkP9s+4/6XgWlB10cW23C4uDFWBK8BNml2Ri2eRje2fqOw+dJjuMFKm1iXbSJddEm1kWbWBfnsQFCRERERETkGhq1AXIy5aTdXQ61H0t1OUtPL4UogiEbhsBUbcLpjNM4fv44SipL8L7f+3hv23swmAx4bOVjEEXwyc5PEJIRgptn3Iyei3vii91fqMfeGrNV/e/6HvPUkHsX3ov7Ft6H3LJcddnCoIV43ONxLA5ebDe2oLxAPUZAaoDdusT8RLy79V2M2T8GYw+MxbDNw9SJ1SccnoD7Ft6HIRuGYOSOkfAM87TbtrKqEqlFqUgvTleXWe9OsWbZ6WV4wfsF9ecuc7s0+JoauhDSfUF3NJ/U3K4BUlJZou7Tdo6TnLIcx95AchgvUGkT66JNrIs2sS7axLo4jw0QIiIiIiIi19CoDZDCskLMWjcLK0+vhH+KP6rMVfWO+3TXp3jB+wWczjhtt9zaALE2FKyPncovz1eX/3ruVywKWgRRBP/2/TfunHen3eOcDiUdwoHEA3aPuqqoqkBJZQnSi9NRWFHY4PnbPorLtgHy3/3/hSiCMfvH2I1PKUxRx584f8Ju3cnUmmbQ3fPvRs/FPSGK4FDSIbsxM47PgCiC/2z7j90+H1j0AEQRdHPvpi7/18Z/ofOczph7ci4G+wxWj3vrzFsx/tB4nMk+0+DrcuZCiMFkUPf9+e7PccfcOyCK4L1t7112W3IOL1BpE+uiTayLNrEu2sS6OI8NECIiIiIiItegmTlAgJqGQrW5GhaLBaczTuNU2ikUVxbj4WUP201CXmWuwu6E3XZzdURkR6iTlldUVajLV4SsQE5ZDoLSg5CgT8DTnk+rj5Mqrrz4ujdFb8LrG1/H0tNLUVBegDd834Aogme9nsWQDUMwZMMQ5Bny7M7fYrHgxPkT8E/xt5vYPDQzFEuCl8A/xd9ufGFFId7wfQP/2vgvGEwGu3UZJRmYHTAby0OWY+2ZtfjQ70OsCl2FGcdn4H2/97E5ejMCUgMw6egkbI/brm4XkhGivtZ7F95b7/v8/cHvIYrgm33fXFFdLsd6J82EwxPgfsodbaa2wcc7PnZoW3IcL1BpE+uiTayLNrEu2sS6OI8NECIiIiIiItegmQaI7Z0EZcYy3L/ofnVS8J3xO7H2zFpklGTUfOmsLFbHhmSEICQjBNXmapQZy9S7SLbFbsOsE7MQnhWOs/lnkaBPgNlidui8dsTtUPffe2lv9b99o3ztxs04PgOvbXgNBxIP2C0PSg+CKIK73O9y+L2YcHgC3tr8FnSZOgDA0E1DIYqgidIEogjG/Tqu3u2ySrMw88TMOo/bspVTloOonCj1/QOAyf6Tcc/8ezDn5Jw642tfCKk2V+Om6Tfhpuk3QW/Q1xlfbipHcWUxKqoqHH695DxeoNIm1kWbWBdtYl20iXVxHhsgRERERERErqFRGyAl5SX4dNWn6LWkF3yjfNVGQ1FFEZ73fh53ud+lNgTstqssQd/lffHwsoft7ryoj22zpNxUbrfuh19/gCiCJ1c/adccOZx0GHfPvxtDNgxBWnGaur31DhSrV9e/ij7L+2B5yHK75afSTqGJ0gR3z7/b4ffCOk/JzvidAIDvDnyHh5Y9hBHbR6Dt9LZoNaUV/GL9HNrXiO0jMGrnKCQVJCEwLRDrI9cjJjcGAJBdmg2vMC90ndcVogh++PWHOtvX1wCxvgdDNw2td2J6oGZC9HMF5+pMFk9XBy9QaRProk2sizaxLtrEujiPDRAiIiIiIiLX0KgNkNLyUrSe1BqiCB5c/CByynKQX57v8J0aEdkR+P7g91h6eqndcovFgoySDKQXp9tN0n0k+QgA4OC5gziUdAjDNg+zm7R7xPYR+GL3Fw6f/6ido7AwaCGKKorslqcUpuBI8hHE5sXWOa/FwYvhfsq9zoTvq3Wr8d/9/0VQehDSi9NxruCc+pgs6+O4Zp2YhTxDHkoqSxo8J7PFjGe9noUoggR9At7d+i5EEbgFuGGy/2TcOvNWiCJoMbkFAlIDcL7ofJ191PdosgR9gvpenUw9qY7NL89H5zmd0WVuFyTmJ0IUQeuprR1+D8lxvEClTayLNrEu2sS6aBPr4jw2QIiIiIiIiFxDoz8Cy3OTJ/Yn7L/kZONxeXE4nXG6TtNgechy9aK8Lds5QHLKcjDFfwpEEXy0/SOM2D5CXXcg8QBaTG6BznM6Y9yv4+rd16UUVhTibP7ZOssnHp0IUQSf7PzEbnluWa56jHh9vN26XfG7IIrg0RWP4qFlD0EUwb6z+wAAx1KOwTvcGyN3jIQoguFbhqvbVVZVIjg9GK9vfB1j9o9R5yW5ffbtqDJXYcbxGWiiNMGANQPQaU4n9fgjto9o8HU1dCFk3ql5+OnwT0gtSq33Na0MXWk39wpdXbxApU2sizaxLtrEumgT6+I8NkCIiIiIiIhcQ6M3QBz5wt1vVT+IInUeAbVat7repoWx2qguXxexDusi1uEF7xcw9+Rc3DP/HnWd7XwWPx/52W5ffrF++HTXp9gcvdnp17UkeAkeWPQAfj7ys91yvUGvHsN2Pg4A2Bm/E9dNug5PeDyBxz0eR5upbXDw3EGUGcuQWZKJgvICzD05V22AeIZ5YsLhCVgYtFDd543TboSx2oiC8gK7/b/v9z5EETzl+RSWnV6GuLy4S56/MxdCTNUm/GP1P9R5SmzPka4uXqDSJtZFm1gXbWJdtIl1cR4bIERERERERK5BUw0QtwA3TDw6EblluXje+3n80+efKDWWYsiGIbhj7h3qHBzZpdl43ONxdJ7TGa+sfwUf+H1QZ9+PrXwMzSc1rzNB+aboTVitW43s0my75dml2QjNDEVyYTIisiPUpsKgdYPU/z6dcdqh1xWvj8eXe77EzBMz7ZabLWYUVhSiqKIIFovFbl1WaRaSCpJQaiwFUDMHyFOeT6H/qv7q3SRmixnV5mqYLWY8ufpJiCJ2j/GyJqs0y27f8wPn45X1r2BLzBZ1WVhWGDZEbkB4Vnid869vDpBFQYuwKGgRKqsq64zfFL0Jn+/+HNvjtiMoPQjTjk1zeL4SchwvUGkT66JNrIs2sS7axLo4jw0QIiIiIiIi16CpBkjb6W0hiiA0M1S9mG+dB8NWcmEyRBFcP+X6yx6jylyF9/3ex3+2/afOvsKywuAV5oVTaafslh9NPqoef37g/AYnQW/IwXMHIYqg19JeDo0HgGe8noEogo1RGwEA//fL/0EUwX0L74Mogr7L+9rdsfLoikchiuC2WbcBqJmnw/axX5fz7b5vIYrguwPf1VlXuy6VVZXqvs8XnUeVucrh10VXDy9QaRProk2sizaxLtrEujiPDRAiIiIiIiLXoKkGyFd7vsInOz9BZkkmzmSfUe96qK3MWIatMVuxNWbr5Y9RbVIv3teeQ8R2PhBTtQk5ZTkoKC9AZkkmVoWuwubozagyV2FFyArMOD4DacVpDr2us/ln8eOhH7EgcIFD4wFg4C8D0WZqG2yK3gQAOH7+OHyjfJFcmKw2Q7zCvNTx3uHeEEXwgvcLAGoaIMWVxSgoL2hwEvnUolQsPb0U7We1hyiCpz2fxrLTy+qMs61LXF4conKi8G/ff6vv1fHzx9WxBpMBXmFeWHtmLXLKcvCh34dOTSRPjuMFKm1iXbSJddEm1kWbWBfnsQFCRERERETkGjTVALmavtzzJT7d9SkKygtw++zbIYpgwuEJOJp8FDdOuxFPez5tN+/HxqiNTk+C3pBtsdvwvPfzmOI/xW65wWRQj5FnyLNbdzL1JEbtHIXFwYsxxX8KPvT7EGeyzwAA3tn6DrrM7YJv9n2Db/Z9gzXha2CxWNTHaFWbq5Ffnm93h0h9BvsMVo//2MrHAABrwtfgm33f2I2z1qWkvAQLAhegy9wuAIB7F95bpwGSVpwGUQTNJzVHgj5B3f+lJrWnK8MLVNrEumgT66JNrIs2sS7OYwOEiIiIiIjINbhEA+Snwz9hyIYhdhfeL8d6IT4oPQjjfh0HUQSj945G80nN1XVlxjLsiNuBXfG78MnOT+waIMWVxSisKISp2vmLAQsCF0AUwZub3rRbbjs5e+3HcXnoPCCK4OV1L6uPt9oZv9NujHXC8zd831CXRedGq3eItJna5pLnNXzLcDRRmuCTnZ9Al6kDUNMUecbrGRw8d1AdtzhwMT5Z9QkiMiPQdGJTNJ/UXD1/Y7XR7g6TPEOe+ppG7hiJjrM7QhTB0E1DnXjHyBG8QKVNrIs2sS7axLpoE+viPDZAiIiIiIiIXINLNEAGrBkAUQTrI9cDAEqNpTiSfKTO3B22rBflA1IDkFSQhCPJR5CgT0Cf5X0gitS562Hf2X14ce2LGH9oPAwmA3os6AFRBNOOTcN7297DO1vfUScov5zInEgsPb3UrqlgFZEdod7ZYUuXqYNyRMG6iHXwDPPE0E1D4RnmiW2x2/D57s+xImQFAlID8P3B77EuYh36LO+DZhOb4eu9X9tNgK4cUZxq2ry1+S3cMO0G9b0FgJaTW0IUwZnMM1gcvLjex2TZsp1PZGHQQjRRmrAB8jvgBSptYl20iXXRJtZFm1gX57EBQkRERERE5BpcogGyI24Hlp1ehrP5ZwEA4VnhEEXwF7e/NLjNnJNz8PORn5Fblous0ixklGSg2lzt0HmdzjitNhTGHxqv/rd/ir9D22+L3QZRBI97PO7Q+Po8ufpJdY4PUQRf7/3abr31nO5beB8mHJ6Aqcemqssqqyovu3/3U+7otbQX3ALcEJoZimnHpqlzqgz1HYr+8/ojqygLQM2juzrN6YROczrVOyl9cWUxMksyUVzZOP8fXSt4gUqbWBdtYl20iXXRJtbFeWyAEBERERERuQaXaIDUFpMbg/sX3Y8nVz/p0PgmShOIIsgsyXRo/JnsM+jg1gF/W/I3ZJdmq42FwLRAh7bfErMFoojD51efYZuHofuC7ph4dCKaT2peZ06NFSErIIqg7/K+AGqaFJ/v/hyf7vr0ko2e1KJU+Eb54nGPx9U7YRYFLbJ7tFbtupQZy9T34PPdn+Ncwbl6911lrkJ2aTZyy3Kv+HVTw3iBSptYF21iXbSJddEm1sV5bIAQERERERG5BpdsgDjLevH+4LmDyC/Px/HzxxGVE2U3Ji4vDqP3joZbgNtvPl5OWQ6OpRxDeFb4FW1fUF6A7NJsVFRVAAD0Bj2qzdWoMleh3FSOyqpKROVEYdyv4y77eCpb807NU+dA6TK3Cw4kHkC8Ph6Hkg7hQ78PsSR4CYCLdSmvLEdcXhyic6Ohy9Sp7+PR5KPqPlOLUtFjQQ88vOxhxObFQhRBu5ntruh106XxApU2sS7axLpoE+uiTayL89gAISIiIiIicg0u0QBJLUpFdG50nbsgHGWdJ2Pcr+Nw/6L7IYqg5eSWdmNG7x1tNwn6b+EZ5glRBAN/GXhF21vvzrA+kspq2ellEEXw2obX1GXGaiPSitMwaueoOvOa1DZkwxD1NY7eOxoAMO7XcRi+Zbhds8Zal4zCDHW82WLGrBOzMGb/GCTmJ6pjz+afVccsCV6i/reHzuOKXjs1jBeotIl10SbWRZtYF21iXZzHBggREREREZFrcIkGyKB1gyCKYLVu9RUdx/2UO/qv6o+lp5eqF+hvmXGL3ZjJ/pPtGiAzjs/At/u+RYI+wenjbY7ejDvn3Yn3tr13Ref7hMcTl2yADNkwBIuCFmHG8Rnq46scad74xfphzsk5ds2Oh5Y9BFEE+87uAwBUm6vRcXZH3Dr1VsTmxOLmGTfjlhm3NPhYrXJTOfqv6g9RBP/d/18sDl4MUQSvb3z9il47NYwXqLSJddEm1kWbWBdtYl2cxwYIERERERGRa3CJBsiwzcNw68xbsS5iHQAgIjsCL3i/gI93fOz0MddHrseioEU4X3TebnluWS6OpRxDRHYEskqz0HZ6WzRRmsA3yldtLtje+fB7+2zXZxj4y0CEZoaqy4zVRpRUlqDcVI6Oszuqd3LYNkBumHaDQ/uPy4vDzvid+OHXHzD35FykFKYAAEzVJnVfuSW56nE9wzzhGeZZbyPEN8oXH/h9gA2RGxCYFogfD/0Inwifq/AukC1eoNIm1kWbWBdtYl20iXVxHhsgRERERERErsElGiC1HUk+AlEEDy5+0KHx3+z7Bp/t+gx6g96h8WaLGW9veRuvrH8FqUWpakMgJCPEqfP8Lf625G/qvCX16bm4p3oni7HaiHh9PEQRXD/leof2P/7QeIgi+GL3F/DQeeCGaTfgrc1vwWwxIzgtGHN95qKismYOksKKQvU9KDOWwWwxX7XXSY7jBSptYl20iXXRJtZFm1gX57EBQkRERERE5BpcsgGSVZqFtWfWwi/Wz6Hxrae2hiiC5MJkp8+x2lyNCYcn4Jt93yC3LNfp7a/U9rjt8AzzREZJRr3r9yfuhyiC3kt7q+eZWZKJ9OL0BveZZ8iD+yl3dF/QHddPuR6PrngUbgFudo/WAurWpdRYioG/DFSbIIeSDqn7LK4sxqboTdgRtwOZJZn4cs+XGPfruKv1NpANXqDSJtZFm1gXbWJdtIl1cR4bIERERERERK7BJRsgzrI2QNwC3OAd7o3uC7rj671f/67H/C0WBC7Al3u+hC5TZ7c8NDMUPx76Ed7h3qgyV6HUWIpyUzksFgsqqipgMBlgsVga3O/rG19XmxivrH8FAJBcmIyI7AjE5sUiqzQLwMW6FBuK8e7Wd/Hu1ndhrDaqd53YNkCic6MhiuDWmbciMidSvQul3FT+O7wz1zZeoNIm1kWbWBdtYl20iXVxHhsgRERERERErsElGiDzA+fj7S1vN/g4qMv5eMfHEEUwxX+KwxOGN6anPZ+GKIKNURvtlnvoPCCK4OV1L6vLQjNDMWrnKPU1XarxMHzLcIgieG3Da+rcIta5RMKywgDUzPexKmQVvlr9FXJLcu32W1RRhILyApiqL9YrqSBJHfOB3wdoP6u93d0kdPXwApU2sS7axLpoE+uiTayL89gAISIiIiIicg0u0QCx3rmwOHgxAKCgvADB6cGIy4tz6DgR2RHYFb8LCfoE3DnvTogi+GbfNw5ta6w24qs9X+GL3V/8YXc1rApdhSEbhsA73BtlxjJ1+am0U/hi9xdYdnoZbpt1G26cdiMm+0+2a+rMOjHLqWN1c++GVlNaITo3GoD9fB+FZYWYdWIW3ALc7JoetY37dZw6IfvykOVsgPxOeIFKm1gXbWJdtIl10SbWxXlsgBARERER0bXuKRHZKSKZUvPlaEit9V4XlttmX60x7URknYiUiEiRiHiIyA21xvQSkeMiUikiaSLynZPn6RINkB1xOzDn5Bz1LgW/WD+IIui3qp9DxymuLEZhRSGqzdVOn2NJZYnaELAe/4/Qzb0bRBGcSjtV73rrOT3l+RT+u/+/eHfruxBF0MGt57873wAAIABJREFUg0P799B5oN+qfph5Yiaic6MxP3A+dsTtQEllCQauHYg+c/rYTYLefUF39FjQo973MM+Qh7P5Z5FnyEOVuQrlpnJUVlVe+YunevEClTaxLtrEumgT66JNrIvz2AAhIiIiIqJr3UARmSIir0nDDZC9InK7TW6pNWaviISLyN9F5EkROSsiPjbr24pItoj8IiI9RWSYiJSLyEgnztMlGiC17Tu7D3fOu9PhuwxumXELRBHE5sU6fY4VVRVqsyEqJ8rp7a9Uv1X90GlOpzrzgFitPbMWogi6uXcDAKQWpeIDvw8weu/oS+43qSAJexL24F8b/wVRBJ/s/ASrQldBFMFgn8EA6tYlz5Cnvgc/Hf4JifmJ9e672lyNksoSu7tW6OrhBSptYl20iXXRJtZFm1gX57EBQkREREREdFFDDRC/S2zzwIXtHrFZ9n8iYhGRThd+/lRECkSkhc2YGSIS58S5uWQDxFnWi/f7zu6D3qBHWFYYkgqSftdj/hblpnKUVJZc8rFT5wrO4as9X2GK/xSH97siZIX6XvRd3hfbYrchLCsMh5MOY+imoZh5YiaAi3UxGo1IK07DuYJzOJZyTN32QOIBdZ9xeXF4aNlDeGntSwjLCoMogo6zO175i6cG8QKVNrEu2sS6aBProk2si/PYACEiIiIiIrqooQZIkYjkiki8iCwVkVtt1n8oIoW1tmkuItVSc1eJiIi31G2iPHvheLXvJmmISzRA9AY9zhedR3HllZ2ndQ6R2QGz1UdLdZ7T+Yr29Ud43vt5iCL45cwvdsvXnlmLJkoT/N8v/6cuqzZXo7KqEj8e+hHjD42HwWRocL9DNw1VmxjjD40HADy4+EF8vONju/fWWpeyirKL84FUFGKK/xR8uutTxOTGqGNDM0PVMe6n3NX/XhO+5mq9HXQBL1BpE+uiTayLNrEu2sS6OI8NECIiIiIioovqa4AME5FXRORvF9bFiEiwiDS7sP4HqWmM1JYrNXd+iIgcEJHltdY/eOF4DzRwLi2l5ouaNZ1FBHq9HiaT6Q+PwWCAn58fDAbDJce9temtmgm+j8+6ouN8d+A79FrSC6tDV6sX6G+aflOjvGZH8pzXcxBF4KXzsltuPf9+K/th4pGJWBWyCosCF9lNgp5ZlNngfjdEbMDPh39GQEoATCYTjEYjmk9qDlEEOcU5MJlMSCtIwz3u9+COGXeguLQY1026Di0mt1DX146+VI9HVzwKUQSjdoyC+8maJsigXwY1+vv4Z4ujvy8M68KwLloN66LNsC7OR6/XswFCRERERER0QX0NkNruvjDuuQs//14NEEXqTr4OHx8f+Pn5aTbPLXgOLSa2wEcrP4Kfnx8mr52Mv8/7O4YvG+70vr5e/TXeW/4elmxc4tD4zds2q82F5RuX/yGvd/2W9RBF8Njcx7DSd6W6fOPWjfDc5Ikpv0yBKIK2k9ti5KqRdg2QztM7O3SMFb4rMHntZPSd29fufVzpuxKiCK6beJ26zHerL8Z6jcVYr7H17muM5xg84f4EvvD4ArPWzcIri1/B5x6fN/r/NwzDMAzDML9HfHx82AAhIiIiIiL6f/buOzyKan8D+BdRL4igcEXQqwhYEAtF/FlAUSxYELlWUAGlWLCgggWlOEQgCIQivRNKqIHQayC0AAmEFEJJQkjvvWeT7Pv7Y5LZLGm7EMzJ5f08zzxuZs6cmdkv+SPn9cwpZksAIiKSKCJfFn++Vq/AqpUzQC7fFnrrg/Svr3jdpvZjD4zFsF3DEJYcZvc95uTlGOHCqahT/8j3cijUst5GdGp0meOBcYFoP7c9RBPc8dcdiE+Px6bATRBN0GZmm0r7nn18Nvxj/OFwwAGiCT7b9BlW+a7CnZPuxIfrPkRmTibcg9zhuNLRqEtESgREE9TR6tTY/2nJjf+Hrqob66LmxrqoubEuam6si/0bZ4AQERERERFZ2BKA3CP6AudvF/9csgh6p1Jtukv5i6DfVKrNBPkfXgT9YspFPDL7EawJWIP5J+dje9B2m8672+luiCY4HXva7ns0m83ov6k/+m7si9TcVLvPvxL5hfmISIvA/tD9FbYpWXD8bqe7AegLpwcnB1e6uPvFlIsQTVB/XH08tfAptJreCj/t/glLTy/VA6XitUUur0tyTjJeWPqCPjPE4SbsDtlt9Jmam4rtQdvhcckDUelRGLF3BBwPO1bH10CXsff3hf4ZrIuaWBc1sS5qYl3sxzVAiIiIiIjoeneriHQo3iAiPxZ/blF8bLKIPCMiLUV/7dUpEQkSfYZGiZ0i4iMiT4lIl+LjLqWO3yYicaLPBHlURHqLSLaIfGHHfdaqAGTG8RkQTTDWY6xd1ymZTTHHaw5W+q1E58WdMeHQhCu55X/E0tNLMWLvCJyMPmm1PzAhEA0nNMSDfz+I2MxYxGfFIyk7yeZ+X13+qvFdJGYnGut/BMQHwD/O3whPStdlyLYh+HLrl0jPS0fHeR0hmmBX8C6jz2ORxyCaoNX0VvCO9jYWmC8yF1XPl0EGDlCpiXVRE+uiJtZFTayL/RiAEBERERHR9e5FKWetDRFZJiL1RWS36Ot5mEQkTEQWiEizy/poInrgkSki6SKyRPTwpLR2InJYRPJEJEpEfrXzPmtFALLcdzm+2PIFvt72Nd5yeQt/HfnLruv8d81/9TU8Ts43AoAbxt5wNbd+Tb2+8nWIJlh6eqnV/tUBq437D04OBgB4RnhCO6AZr6gKSw2rsN9PXD+BaIKpnlMBAHXH1oVogqj0KKNNRl4GVvmuwm/Ov8FkMqGOVgeiCeIy4xCXGYeo9CjkFuQa7f3i/Ix7+tj1YzSe2BiiCd5Y+UY1fiMEcIBKVayLmlgXNbEuamJd7McAhIiIiIiIqHao0QBk6dIC/OtfBXj77cpnC3y+5XO0mt7KmLWRlJ2EwIRARGdE23SdoxFHse7MOoQkh+COSXdANMHgzYOv+v6vlRF7R0A0wVdbv7LafyLqhBE2JGQlAACmHJ1itQj6tGPTKuy3yFyEInMRzGYzACAzPxMZeRlWszXOJZ6DaIJb/7wVJpMJYz3GQjugISMvo8J+SwKYIduGGK/TYgBS/ThApSbWRU2si5pYFzWxLvZjAEJERERERFQ71HgAIgK8+mrlAcjo/aPx5dYvkZabhhV+K1BvXD2IJvhow0c2XaewqBCmQlOteS3T7pDdEE3Qfm77CtskZSdh/KHxeH3l6xiybYgRgMw6Mcuma6w9sxYvO7+MiYcnIiQ5BItOLcKOoB0ISw3DC0tewJNTnzQGQuKz4tF+bnt0mt+p3L7iMuPgF+eHyPRI5BbkIjE7Eel5NfNv6n8ZB6jUxLqoiXVRE+uiJtbFfgxAiIiIiIiIaocaDUCSk02YP38PoqMr/4M7Kz/LWMC81+pexmD/F1u+sOk6raa3gmiCY5HHrvqe/wkB8QEY6DYQY/aPqbDNhaQLEE1w+8TbAeivwlrlvwpBSUEVnhOWGoYW01rg0dmPYtKRSRBN0H9Tf6zyXwXRBC87vwyg7EBIZHqk8Z1POjIJF1Multu/2Ww2ZplQ9eMAlZpYFzWxLmpiXdTEutiPAQgREREREVHtUCvWAClt0alF+GHnDzgacdTmc0oG7zef34zknGQEJQUhLjPuSm75H1ESJJS8qqo8cZlxGLR5EIbuGGpzvw4eDsZ3EZgQiFbTW+Fl55exPWg73nJ5CyPdRwKwrktqbiqiM6KxM3ince72oO1Gn6djT6PL4i74xPUTHI88biyITtWPA1RqYl3UxLqoiXVRE+tiPwYgREREREREtYMyAYjJBBw8CBQWVv91nl74NEQTLPFZgnum3gPRBI/MfqT6L1RNerr0hGiChacWWu13O+dmhBCxmbFWx2Ycn4EJhyYgMTuxwn57r+8N0QQfrv8QReYio6+k7CSrdqXr8q8//wXRBGGpYfjjwB/ov6k/fGN9jbYHLh0w+im9HslKv5XV8E1QaRygUhProibWRU2si5pYF/sxACEiIiIiIqodajQAuXjRhEGD/HHXXWaIACLAb79Vfo7ZbMYAtwFYE7DG5usMcBuAB/5+wCpAuM3xtqu8+2unJABZcHKB1f4NgRuM+4/PigcAfLP9G6tF0E9Gn6yw33Vn1mHE3hE4GHYQReYifLfjO3y7/Vtk5WcZbQITAvH4nMfR0akjTCaTsd5KWGpYmf7yC/ORkJWAjvM6QjTBALcBmHZsGkQTvLr81Wr6NqgEB6jUxLqoiXVRE+uiJtbFfgxAiIiIiIiIaocaDUD27Sswgo+SrVGjys8JSw2DaIIeq3pc0TWXnV6GMfvHwD/O/4rO/ye4+LtANMFzS56z2p+Zn4kj4UfgFeWFwiJ9qszBsINWAUhkeqRN14jNjMXxyOMITg622u8V5QXRBE3HN9Vn5hSakJGXgW0XtmFX8C6jXbYpG/fPuB9msxmrA1ajx6oe+Pv43zgeeRxfbPkC045Nu8pvgS7HASo1sS5qYl3UxLqoiXWxHwMQIiIiIiKi2qFGA5CAABOefz4S771XBGdnwMkJ2Lev8nO6r+huDPbbarbXbPxx4A9cSr10dTf8D9l0bhNEEzy76NkK20SlR6HB+AYQTTD/5HxEpUchJiOm0n7TctOw0m8l1geuN2ZqfLThI2y7sA2tprfCRxs+QlpuGnZc2IHxK8cbAyGXUi9BNEH9cfWNvgITAnGTw034ec/P1fPQVCUOUKmJdVET66Im1kVNrIv9GIAQERERERHVDsqsAWKrL7d+CdEEYz3G2nzOI7MfgWiCA5cOXMFd/vOy8rMQkhxS6WyO6IxoiCa40eFGm/v1i/ODaIJGjo2wxGcJ7pt2H77b8R3WnlkL0QQvLH0BQNm6RGdE48kFT0I0we0Tb8fO4J04m3AWjRwboeX0lkb/EWkRcPBwwGyv2Vf24FQpDlCpiXVRE+uiJtZFTayL/RiAEBERERER1Q41HoB07RqBN98sgo+Pbeek56UjMTsROaYcm69TMmNkic8SrPJfhV6re5VZYFwl6wPXw8HDAd7R3lb7LyRdwF1T7kKn+Z2QY8pBm5lt8Nicx6qc+VHileWvGN9FjikHognqaHVwKfUSjkUeQ2BCIADrgZBR7qMwbNcwJGQlGIvJbzm/pdz+j4QfgWiCB/9+8Oq+ACoXB6jUxLqoiXVRE+uiJtbFfgxAiIiIiIiIaocaD0BatEiHCLB7N3D0KLB3L1BUdGX95ecDPj7AgQPW+7ss7gLRBK5nXY0AoPTrnFTz7tp3IZpgjtccq/2r/FcZ959tykYdrQ5EE8RmxtrU70C3gRBN4HjYEdmmbKOvzPxMo01SdhLczroZr8C6zfE2iCa4kHQBYalhuJB0wao9AMz1novWM1rj/XXv4/aJt0M0wesrX7/6L4KscIBKTayLmlgXNbEuamJd7McAhIiIiIiIqHao0QAkONhkLH4eGmpZCD0rq+JzvKO98dyS5zB48+Ayx6Kj9fPr1rUOUXYE7cDS00sRlhqGhhMaGmtfqGrYrmEQTfD9zu+t9pfMsBBNkFeQh/WB67Ho1CLkF+bb1G+OKQcZeRnIL8yH2WxGXGYcYjNjUWS2fFkHLh2AaIJ7HO+ByWTCmP1j8MueX5CQlVBhvxMOTYBogoFuA40F3F9yfunKHp4qxAEqNbEuamJd1MS6qIl1sR8DECIiIiIiotqhRgOQixf1AOTmm80oKgLuvx94/HEgJaXic37Z80uFi6Dn5QF33aX3kZlZzskATIUm5BfmWw36q2Z1wOprHiJsD9qOt1e/jb+O/IWItAi4+LtgT8geeEd7o9P8Tug8vbMxEBKVHoXOizvjleWvGOeHpoTiM7fP8NPunxCVHgXPCE8EJwcjKz8L4WnhiMuMu2b3fr3iAJWaWBc1sS5qYl3UxLrYjwEIERERERFR7VCjAUh2tgkzZrjjzBnb/+AetHkQRBO0mdkGAFBYaDm2Zg3g6Ah8+y3wxReW/U8vfBo3OdyE3SG7q+vWr6kj4UfQe31vOHg4VGu/5xPPo+2stui6tCtmnZgF0QTvr3vfeDVYl8VdAJQdCAlODjZCp9les3Ex5SIGuA2oMIiia4MDVGpiXdTEuqiJdVET62I/BiBERERERES1Q42vAWLvH9xu59zw+ZbP4eLvAgB47jng1luBbduAzp0tr9GqX98SjjSd1BSiCdYHrkdabhqi0qOQlpt2LR5JaWM9xhqhxamYU2g1vRVedn4ZHpc88JLzS/hux3cArOuSX5iPpOwkq/VTZnvNNr7T0mt9HAo7hHrj6qH93PY19Yj/0zhApSbWRU2si5pYFzWxLvZjAEJERERERFQ71LoA5HI336wHHs2aAWPGAP/9L9C+PTB5MpCTo7fRDmi4b9p9iMuMQ7PJzSCaoPPiztX0FNWv38Z+qDeuHmadmGW1v/Qi6Ffiow0fGaFFSk6K0ZepUP/+AxMC0X1Fd3y26TOjLndOvhOiCfzj/DHSfaRxzqOzH8UPO3+Af5w/ziWew5qANfjryF/G8bVn1l7190DWOEClJtZFTayLmlgXNbEu9mMAQkREREREVDsoFYA4OgLPPw88+qi+9e4NRERYnxOdEY1DYYdwPvE8AOD0acusj9Kvw7qc2WwGAGOA/jbH267JM1WH3ut7QzTBjOMzrPYvPLXwqgKQ1QGr8d2O77AreBey8rMw0G0gBroNRGGR/sUdDj8M0QQP/v1gmQDEL84PANBrdS/UHVsXi30WG/1OOjIJogl6r++NKUenQDTBC0tfuLKHpwpxgEpNrIuaWBc1sS5qYl3sxwCEiIiIiIiodlAqABk4UA8yHnjAEmqIWC9oPttrNkQTvLf2PQB66DFxIrBxI2DL3+1LfJbgp90/4Xjk8WvxSNVi5omZEE3Qa3Uvq/0pOSnYdG4TdgbvvOprpOSkICA+AGGpYca++Kx4LPddjnUB64y6pOWmISYjBvsu7sPh8MNG27yCPERnRCMxOxFrAtag27JucDzsiOORx/GJ6ycYd3DcVd8jWeMAlZpYFzWxLmpiXdTEutiPAQgREREREVHtoFQA4uEBrFwJREfr/xUBbroJOH8eSErSz/llzy8QTfDQzIcq7PfiRaBvX+Drr/+Jp6h+i30WQzRBj1U9qrXf1NxUbDy7EbuCd2H+yflGyHLg0gE8NucxfOz6MYCydTmXeA6iCRpPbGz0deDSAavF6Ona4wCVmlgXNbEuamJd1MS62I8BCBERERERUe2gVAByubg44NAh4M47gQ4d9H05phws8VmC2MxYxMcDDg7A4sV66NGgAdC2reW1WHfd9Q8+TCVOnwbW2rEkRnJOMvzj/BGaElqt9+Ed7Q3RBPdOvRfLfZej6aSm6L+pP7ac3wLRBE8tfApA2bpcTLmItrPaQjTB3U53Y9uFbbjR4cYyr+MKTwuHk6cTnH2dq/W+SccBKjWxLmpiXdTEuqiJdbEfAxAiIiIiIqLaQdkAZPp04MUXgfHj9TDjlluA7GzrNseO6cfuuAPQNP3zvfcCiYnAhx/q248/Ah07AsnJ+jlrAtZg8ObB2HRu0z/whLqSV3kdPGhb+53BO+Hk6YST0Set9p+JP4N2c9vhjZVvXNF9vOT8khFaxGfFo8H4Bmjk2AgJWQnYd3Ef3EPdcTL6JPxi/Iy6OHk6YfT+0YjOiMZzS56DaIJmk5vhNsfbIJpghd8Ko/99F/dBNMFjcx67ovujynGASk2si5pYFzWxLmpiXezHAISIiIiIiKh2UDYAKQkNPvwQOHECyMsre35goL5uyAcfWNqfLM4MXn7Zeh2RefOK+y0OAJr81cTm+9yxA3j11bILstuq5B527LCtfd+NfSGaYMrRKVb7Z52YdVWLoA/ZNgSiCf448AdiMmIgmuCGsTcYx/eE7IFogsfnPG7UpcW0FhBN4B3tjQtJF9B0UlOIJvj7+N9IzE5EXkEenH2d8ficx/H26rdx+8TbIZpccUhDFeMAlZpYFzWxLmpiXdTEutiPAQgREREREVHtoHwAMnt21f0UFADt2wODBwMxMfq+t96y9PHNN0Bqqr6//rj6Vouo2+Kee/R+/vzT5lPKOHECiI+3re3QHUMhmuCn3T9Z7d8etP2qApD0vHTEZcYhMz8TBUUFuJhyESHJIcbxg2EHce/Ue/Gq86tGXUa5j8I3278xFktf7rscY/aPgW+sr3Gek6cTRBN84voJXM+6QjRBl8VdrugeqWIcoFIT66Im1kVNrIuaWBf7MQAhIiIiIiKqHZQNQPbtA3butLy6qipms/XniAjgkUfKvnoqMz8TKTkpyCsoZ0pJBXr3Bm69FVi2zOZTrHh46PfRrp1t7Utmery/7v0ru6ANDlw6gD4b+uCvI38hPisem89vhsclDwBl63Ip9RJeWf4KPlj3gXF+QHwAvtn+DSYdmYSw1DDsvbgXAfEBSM9Lx9mEs7iUeuma3fv1igNUamJd1MS6qIl1URPrYj8GIERERERERLWDsgFIaUuXAmPHAkFBtvVbUGCZ/XHmDODlpa8XUhKS5OcDRUXln3vuHHD//cCSJdb7s7KAmTMBJyfb7qGEyQT07Wu5H1tsu7ANb7m8BcfDjvZdrAr+cf7oNL8Teq3uhcU+iyGaoMeqHtgRtAOiCZ6Y/0TxPVvXJSA+wJh5suz0MlxKvYRPN31a5hVadG1xgEpNrIuaWBc1sS5qYl3sxwCEiIiIiIiodqgVAcjTT+vhwZYt1vsXLtRnZvTvX/acW24BGjXS1wkpCR8KCoBsUzZ+GZMGqZtn7N+61XLe0KH6vu7drftbvNjSz6hRZa/n5QWsW6cHLqUlJlrOKyys9DGvubEeY40g41jkMbSa3gqvrXgNxyKP4emFT+PTTZ8CKFuX1NxUrPRbaZy74OQCPDTzIYgmaD+3vdH//tD9aPJXE7y47MWaeLz/eRygUhProibWRU2si5pYF/sxACEiIiIiIqodakUAMmEC8OWXwOnT1vunT9eDhT59Kj43MxNo0QJo1UpfSL3JX030gfyP3rJaJL1dO33mx8iRwKBBeuBRmpcX0KCB3rZu3bLXKd1XaXFxwJNPAh06VPqIVr7b8R2a/NUE049Nt9o//+T8q1oDpGRx9S6LuyAsNQyiCeqPq28c94rywjtr3sHPu3826vLwrIdxw9gbcDTiKH7Z84tx/ReXvYgvtnyBA5cOIDQlFFvOb8GEQxOM4xvPbryie6SKcYBKTayLmlgXNbEuamJd7McAhIiIiIiIrnddRWSriMSI/sfRfy87XkdEHEQkVkRyRWSfiDx4WZsmIrJKRDJEJE1EFovIrZe1aScih0UkT0QiReQXO++zVgQgFUlPB0JCgKioqtsOHw588QWMAfpGDnfi2WeBd97RZ3uUhBe//Wa9nggAjBsHDBgA7N8PfPut3u7oUes2995r32uuKjPAbQBEkzKvwJp0ZNJVBSAu/i4YtHkQNp7diISsBPTZ0Af9N1mmz7idc4NogqcXPm3U5cG/H4RogsPhhwEALyx9AaIJ1p5Za5w3/dh0iCZ4y+UtTDw8EaIJnln0zBXdI1WMA1RqYl3UxLqoiXVRE+tiPwYgRERERER0vXtDRMaJyDtSfgDyq+ihRi/RQ4zNIhIqIvVKtdkpIr4i8rSIPCciwSLiUup4IxGJE5GVIvKoiPQRkRwR+cKO+6zVAYg9mjcvDiieWID7vhuEPSF7jWPHjwMPPGAJML77DggO1hdSf+EFy/5NmywBiAjg6grExOh9ZGYCsbFARkb51//sM+Dll8u+Iqs8Ja+qKnklVYnYzFjMPzkfLv4uV/YllJKZn4nQlFDEZsYa+0JTQjHXey7W+q816hKfFY+Q5BAcCT+C07GnYSo0Ia8gD7kFuUjLTUO2KRtrAtbgqYVPYaT7SGMWya97f73qeyRrHKBSE+uiJtZFTayLmlgX+zEAISIiIiIisrg8AKkj+syPn0rtu030WRx9in9uW3zek6XavC4iZhG5u/jnISKSIiI3l2ozUUTO23Fv100AMnMm8P33wM036+FFZGTZNv/+t/WrrLp0sXweMUJfhD0jQ19zpGT/vHnlX8/ZWX/1VUSE/nPPnnp7RxvWNS+Z6VF6dkZ1SMlJwe6Q3TgacRTLfZdDNEH3Fd1xIuoEnlr4FD52/RhA2bqcjj0N0QR3TbnL6GvtmbXGq7Don8EBKjWxLmpiXdTEuqiJdbEfAxAiIiIiIiKLywOQ1sX7OlzW7qCIzCj+PFBEUi87fqOIFIo+q0REZLmIuF3Wpltx341tvLdaEYB89RVQrx4wZYr1/v37gb//Bk6cqPhcsxno1UtfFL10uDF8OHDuHBAWpi+UDgA5OcANN1javPmmHmSMHWvpKyREb//HH0CbNsCiReVft0kTvY/PPwc6dwbatwc2bgTCw6v+XqIzonEs8hiCk4OrbmwHj0seEE3QZmYbrA5YjVvG34K3V7+NPSF7IJqg3dx2AMrWJTAhEPdNuw+iCR78+0Fsu7ANjRwblXkdV3haOOZ5z4PrWddqvW/ScYBKTayLmlgXNbEuamJd7McAhIiIiIiIyOLyAKRz8b67Lmu3TkTWFn/+XUQulNNXgugzP0RE9ojI/MuOP1Lcd9sK7uVfov+hVrL9R0SQlJQEk8n0j2/Z2dlwc3NDdnZ2pe0GDy6ECDB6dKHV/s8+K4IIMGpUYaXn16ljNkKN+3utQpPeP0Hu88BXXxUa+0+dMiE/34R69fS258+b8OSTRWjWzIyOHc347LMi5OSYjPbR0dbXePJJ/V769SuCyWRCly5FqFvXjK+/1q/RuXORzd/L/pD9mH18Nk5EnKjW7/vlZS8bocW5+HNoOqkpHvj7AUSnRmNj4EZsDNwIvxg/nI89b9RlgfcCjPMYh+DEYHRb2g2iCe6dei+emPcERBOMcR9j9O92Vl9DpNP8TjXy7+l/fbP194Ub68KNdVF1Y13U3FgsCGq7AAAgAElEQVQX+7ekpCQGIERERERERMVUCkC04uNWm4uLC9zc3JTdFi7chWeeicbTT8fA1dWy/6efvNChQzxGjjxW6flffeWL3r3PYcqUA5ZF0Id1xMCB/lazQurXN6Fbt3DMnr0XK1dutzp2yy0mrF+/2fj599+tr1m6bcm+jRvdsGjRLowYcQJjxx6x+Xm7z+wO0QQfzfuoWr/HnrN7QjTBe3Pew+w1syGaoMGfDSzf59KfIJrg8SmPG/taTGwB0QRjV4zFjNUzjO/v68VfY8G6BXBxdcEvy35Bm0lt0NGpI25xuAWiCZ6c+mSN/7vhxo0bN27cuHG7FpuLiwsDECIiIiIiomIqvQKrVs4AMZlM6NRJn2Fx/Lj914mKsszc2HVhD7ov745z8eeK78GELVsK8MsvltkgGRkmZGaasH17ASZNsux3dy/A22/r9zFnTgFyc00YP74Qd9xhRrduRfjPf8wYOrQQ7u4FOH/eBF9fE/z99XvIzzfh6NECODsXICND3/f883pf779vPTvk661fQzTBsF3DqvX7jkmLwfn484hLj0NmTiZORZ3C6ejTxvG1/mvR5K8meGvlW0Zdftv7G/pv7A/faF+YTCZM95yOH3f+CJ8oH+O8GZ56MPLemvc4C+Qabvw/dNXcWBc1N9ZFzY11UXNjXezfOAOEiIiIiIjIoqJF0IeX2tdIyl8EvVOpNt2l/EXQbyrVZoL8jy6C/uyzwI03Atu22X+d8HDgppv0dUQefFD/fPKkdZvISMsMjtOngQEDgGHD9GMPP6zvP3IEWLJEX0zd0xO47z59/7vvAq+/rrd1d9f3lSyo3ry5vnaI2Qzcfru+LyBAb1t61sj585Z7cfBwgGiCL7Z8Yf/D2uhE1AkM2jwIk49ORkpOCvZd3IdjkccAlK1LcHIweq3uhUGbBxnne0V54ec9P2Pp6aUITQnF5vOb4R3tjdTcVHhHe+Nswtlrdu/XK3t+X+ifw7qoiXVRE+uiJtbFflwDhIiIiIiIrne3ij7Do4Pofxz9WPy5RfHxX0Wf4fG2iDwu+kyOUBGpV6qPnSLiIyJPiUgXEQkSEZdSx28TkTjRZ4I8KiK9RSRbRL6w4z5rNAApOHwYQe+8g4J58/QVzSv5wzs+3vpwaCiQlKQHC1U5fx7w9weysoCWLVE8k8S6TXY2MGQI8OmnerghArRoYd3m8mu1aWMJMI4c0feNHGkdbIgArVrpC6736AG88ALg46O3HT689Cu2LP0u912Ol5xfgpOnU9UPZ4eT0SfRdWlXDHAbgNUBqyGaoNuybjhwSX81WNtZbQGUHQjxjvY2Xn217sw6hKWGod/GfhBN0Hhi42q9R6oYB6jUxLqoiXVRE+uiJtbFfgxAiIiIiIjoeveilLPWhogsKz5eR0QcRA8w8kRkn4g8dFkfTUQPPDJFJF1ElogerJTWTkQOF/cRJXqwYo+aDUDmzLFOCl580bZEA8ATT+in2DIjpEkTve3Zs0BwsP65QQPg0CHLpUuLiwMGDQLeew8IDAROnQK8vfVjP/0EfPwxEBICpKbqocqyZZYZJUuWlF5TBGjaVP/888/68TZtgAce0AMRAJgyRT/+3//a9NhXRTugGUHGkfAjaD2jNXqs6gGvKC88Nucx9FrdC0DZgZCErATMPznfOHfp6aV4auFTEE3QfEpzo/89IXtw79R7jX6oenGASk2si5pYFzWxLmpiXezHAISIiIiIiKh2qNkAZNWqstMlpkyp9Bw3Nz2cKGnu71/1ddq0Ae68Uw8dYmP18+rUAS5csPQTGAjMnAls2aKfM368JZMpCUwAfVZIyYyPoiK93bx5+mu2Svpq0gSYOBGYNAnYsUMPPzIz9fYlbfr1s9yf2azPQCkxev9o3Dv13mqfAVIya6P93Pbwi/ODaIJmk5sZxw+GHUTfjX3x1+G/jIGQrku7QjTB7pDdGLZrmBGC9F7fG5+4foJ1Z9YhKj0K7qHuGHdwnHF824Xyk6kz8Wew6NSian2u6wUHqNTEuqiJdVET66Im1sV+DECIiIiIiIhqh5oNQLZvLxuA3HxzpecMG6Y3+/ZbICcHKCys+jrr1gGDBwMbNujto6Mta254eOjByMKFer9vvaXvnz0baNdOv07JrcXG6q+zEgH8/PRXcJUcS0uzfoyuXfXZIKWVDkA++wyIiADS08tOevlm+zcQTTB6/2gbv0nbrPRbiT4b+mCl30qEpoSip0tP9NtoSWKW+CyBaII3V75pDIQ8s+gZPLPoGWNNj07zO0E0wfag7cZ5c73nGq/TKglBOs7rWO49tJvbDi2nt0RKTkq1Ptv1gANUamJd1MS6qIl1URPrYj8GIERERERERLVDzQYgJYttiFhWFP/3vys9Z/9+YNQo4MAB26/z449617/+CqxYoc/MCA21buPoaP06rKQk/TVXJhPQuLG+/9w5/ZVXFy/qbWbPtqzxAehhypQplvYjRpS9l5gYYNYsfUF2EX1h94ICYMECfbZJfj6MmRbf7/ze9oe0U15BHuIy45Cck2zsC4gPgJOnE9b6rzUGQrac34Ix+8cYbTLyMpCSk4LcglwUFBWgyFyEtWfW4tHZj+L7nd/DO9ob3Vd0x5BtQ8q9busZrSGawCfGp8yxrPws9F7fG2+vfhvRGdHV/9C1HAeo1MS6qIl1URProibWxX4MQIiIiIiIiGqHGg1ATGfOWFKHkgU56tSpclpHdrb+yqqICNuus3cv8OefgLs70LGjfpmdO63buLvr+x99VP+5YUP956AgPRwZNQpITLQ+5+OP9TaTJlnvP3wYmDoVOHq0/Pv57DPLYzdurD9uyc9JScCIvSMgmuCHnT/Y9oA2SslJweHww/CN9cWGwA0QTfDckufgH+ePbsu6GbNBbBkImXliJkQTfLDugyu6F99YX5yKOYX8wnxj346gHcYrtJb4LKnk7OsTB6jUxLqoiXVRE+uiJtbFfgxAiIiIiIiIaoeaDUCioy0j/1lZls8JCZWed9dderPWrW27zvDhQJ8++muv3n9fP3fsWOs2eXl6oBIerv/cogVw663A6dMV97tiBfD992Vno2zbpl/jySfLnlM67Ni/H8jN1ff/+iswZgyQkQEEJwdj38V9uJB0wbYHtFFJwPDE/CfgetbVCEAOhx+GaIIH/34QQMUDId9s/wYd5nXAlvNb0GxyMyOsKBGeFo7lvsuxK3hXmWtfSr0ErygvxGTEAADqjasH0QRhqWFGm4KiAiRkJSAyPbJan/t/BQeo1MS6qIl1URProibWxX4MQIiIiIiIiGqHmg1ATCZ4DxuGAldXfUeTJpYFNiqxYoXezNHRtus89JBlksnq1frnbt0qP6dkEorJBLz7LtCzp57R2GLTJv3VVs8/X/ZYejpQt65+DxWNM3hHe2O57/JyXxN1NV5d/qoRWvjF+aHl9JZ4bslzSMhKwOqA1VgTsAbhaeGITYstdyDk9ZWvQzRBq+mt8O7adyGaYIDbAON4SajSZXGXMtf+Zc8vEE3w464fAQD3z7gf90y9B+Fp4dX6jP/LOEClJtZFTayLmlgXNbEu9mMAQkREREREVDvUeABi9Qd3ly56MjBrVpXnRkeXXTy8IlOmAKNHA5cu6a+l6tcPGD/etnNLz9i4/BVYtpxbnlGjACenis/7YecPEE0wYm85i4hchV/3/mqEECeiTkA0wX3T7jOOz/aaDdEE76x+p9yBkJPRJ40AZZX/KpxNOIu4zDhsD9qOl5xfQrdl3dBwQkOIJui1upfVuQ4eDrh36r0QTfDV1q8Qmxlbrc92PeAAlZpYFzWxLmpiXdTEutiPAQgREREREVHtoFYAUrJauYi+CMfs2fZ1aDYDzs76IhylvPKK3uXKlVd2n6Xf0nWt5OXp63/Mmwd0GvETRBOMdB9ZrdeIzYxFQHwAYjJikJmfieORx61mmcz1not//fkvfLjuwwoHQv48+Ce+2voVziWeM/YtOLkAogneXv029l7cC9EEj8953Oq80JRQIzwRTcp9vVdAfACaT2kO0QTbg7ZX45P/b+AAlZpYFzWxLmpiXdTEutiPAQgREREREVHtoFYA4uVlSRtE9PdIFRTY3uGECfp5zZtb7X7xRX23q6v+OqvbbwfWrbO928xMICXF9vZXonXrUo/e9Ay6L+hjFTJUN/84fwzdMRRTPaciIy8DnhGeOBVzCoBtAyFHwo9AO6Bh8/nNCEkOgYu/Cw6GHURKTgoOhh3EyeiTAIAicxFOxZzCtgvbjPBDO6AhKTupTJ/rzqwz2jgetvH9ZtcRDlCpiXVRE+uiJtZFTayL/RiAEBERERER1Q5qBSCAvur4sGGWNCAjw/YOb7/dct6RI1aHCgv1rXt3/fDy5dX0ENXk/vsttz5iBJCcbH3c0xOYOBEoKrryaxyLPIY3Vr6BH3f9CLdzbhBN8PTCp3Es8pixtgdQ8UCId7Q3tgdtR0RaBPps6GN1TkVKXrvVcV5HJGQlGMHHQLeBeHftu4hIizDa+sT44IG/H8DdTnfjWOSxK3/Q/1EcoFIT66Im1kVNrIuaWBf7MQAhIiIiIiKqHdQLQAD9VVYlacCxY8DevRV3kpYGbNsGxMRYzx6pIDz5+mv90JdfVvPDXKULF/T7uuGG8tc2KXkke98KlpgIREXpr+8avX+0McPiYNhBtJreCm+5vIXTsafRekZrdF3aFUDFdXlz1ZsQTbDEZwnWB66HaIIJhyYYx3cG78TDsx5Gv439jH1rz6xFT5eeeGjmQ1Z93Tn5TogmCIgPsO+BrmMcoFIT66Im1kVNrIuaWBf7MQAhIiIiIiKqHdQMQADg5putw4wTJ8rvpH9//fjHH5cNQIYOLdP8998rPFSjoqOBzp31rbQjR4BJk/R7rl8f8Pe3r98BA/RzHR2Bfhv7QTRB6xmtcSjsEEQTPPj3g0bbPSF78OXWL7Ho5KJy61KyOLtogkNhh5CZnwkASMhKwPHI43DwcDCO7wnZU+79JGUnISUnBYtOLcJc77nlvgqLyscBKjWxLmpiXdTEuqiJdbEfAxAiIiIiIqLaQd0A5PIw45dfyu/k8naNGwPPPqt/bt++TPOkJODcOT1wUFVgIHD0qL7uyMiR+qM88QTg4QHs2QPk5tre12efAXXrAlOnAiv8VqCnS08sOLkA/nH+eMn5JfTf1N9oO/noZIgm6Ovat8K6PDTzISMAKbHEZwlEEzy18CmM9RgL0QSPzH7E6rys/CyMOzjOCEgi0yPLvd/0vHREZ0QjLTfN9oe8TnCASk2si5pYFzWxLmpiXezHAISIiIiIiKh2qD0BSPPm5a8Hcnm7++/X0wMR4IEHyjTfu1d/jZSf3zV4oKuwbh3w88/A4cNAhw767e/ape//978tj/f443qYYSuzGcjJKfvVFRQVIDM/E9mmbGOfZ4QnHDwcsD5gfYV1icuMQ2R6JPIK8ox96wPXo9X0VhjoNhA+MT7osrgL+m7sC0APNFJyUhCZHmmEH6IJojPKJlDLfZcbx3/f97vVsRxTDkbsHYETURXMBLoOcIBKTayLmlgXNbEuamJd7McAhIiIiIiIqHZQPwB56CGgVSv988yZ1m3y8soGII89pi+kLgLcdVeZbvv00Q9Nn36NHuoKffKJfl9TpgA9e+o5jpsbEBSkrwtS8ng33wx8843t/c6dq5/3zjtAam4qfGJ8EJQUhO1B2yGaoNP8TghODsZbLm/hM7fPAFTfQIhXlJcRaMw6MQuDNw/GoM2DkF+Yj4spF3Eu8RxyTDlG+2Wnl1UYgKzyXwXRBG1ntb2qe6rNOEClJtZFTayLmlgXNbEu9mMAQkREREREVDuoH4C89BIwYYL++b33rNtERZUNQJ56yrKiuAiwejVQqv9+/crPUmraF1/o99Wmjf5zUhLQrJn1oz38MNC3L7Bihe39rlihn/vKKzAWLn9+yfNWAcjJ6JMQTXDP1HsAVFyXX/b8gs6LO2PL+S3lXisiLQKuZ10hmqDppKYY5T7KCDSW+y63attqeiuIJjgeedzYl2PKQVxmHJJzksv0vSZgDUQTvLjsRdsf3gaJ2YnYe3FvtfZ5rXCASk2si5pYFzWxLmpiXezHAISIiIiIiKh2UD8A6dnT8kqrm24CkksNjpfM9Ci9vfACEBFRdv/hwwD0RcS/+w6IjweQmQksWFD8QyViY/UkoaDgyh40MxMID6+0ydq1ltsHgJMnrW+/bduqb7M8Dg566OPjA7yy/BUjkDgSfgStprfCm6veRGJ2IhadWoQlPkuQlJ2E1KzUcuvS06UnRBM8NPOhcl9hVTJLo2Rz8XfBXO+5WB+4HoVFhVZtO8zrgMYTG8MryqvS+y8yF8Erygsr/VZi7Zm18IzwtP9LqISDhwO+3PolwtMqr48KOEClJtZFTayLmlgXNbEu9mMAQkREREREVDuoG4Dceac+8u/srC9kce+9+s8HD1ra7NpVNuh49VV9+sTl+0Ws+w8NtUwHefppIDtbX3W8PF276u1atbqyB+3YUT8/JKTCJjExwLZtwCHL2uLYvl0PRC5durLLAvqEGBFgyxZgzP4xEE3w9bavsSdkD0QTPD7ncaOtg4cDRBMMdhtcbl08IzyNcKP0zA33UHf0dOmJLou7oMH4BhBN0GZmG2TlZ1mdX1hUiB93/Yjhu4dbrT1SmRnHZxjXPJ94/sq/iAr8uOtHNJ/SHL/u/bXa+65uHKBSE+uiJtZFTayLmlgX+zEAISIiIiIiqh3UDUBiYoDNm/XwAwBee00fyW/Z0vJKq0WL9H2dO1tCjlat9FW/ywtASvo6fLjssQ4dgMaNy5+pUbrdunXlP0xYGPDVV/rrtyo6f9w4m76XyZOBHj30x79aixYBY8botxWZHonjkccRmhKK5JxkuIe6WwUZYz3GQjTB55s/r7Auw3cPR/9N/RGSbAlznH2dIZrgtRWv4VDYIWOWSGmZ+ZmoO7auEWak5qaW6btkAfXmU5pjTcAaAPprtdaeWYv/OP0HoSmhV/+FXGZX8C6M2T8Ge0L2VHvf1Y0DVGpiXdTEuqiJdVET62I/BiBERERERES1g7oByOXWr7cECfPn6/v++EP/+fPPARcXoH594O+/9aCjvAAkuvi1TcOHl39cBPj1V31myJEjetAyf7718XfeKf/+SmZ5tGyp/2w2A4mJQG6u5dwvv7Tpe3nySb151676z66uwOzZ+uusSrqKiLCpKyQnA6NHA7/9VnGbHFMO/OL8EJgQiCJzEXLzcu0aCAlKCsLCUwuxM3gnknOSsSNoBzwueSArPwtDtg3B26vfxrHIY0b48c32b5BbkFumn3ne86zalJaQlYC9F/daBTZVMZcEXpVIz0vH7pDdOHDpgM391hQOUKmJdVET66Im1kVNrIv9GIAQERERERHVDrUnAAH0kfySBODAAeD//k//7OhY0qGlbUm7y9cJ2bJFXwSkogCk9DZ0aPn7P/ig7L1d/qqtb7/VP69ZY72Qhw0+/9xyyu7dls//+Y/l85o1VfeTkwM89phl+ZQj4Ufw3tr3oB3QrNr5xvpCNEHzKc2Lv8by63Im/gw8LnmUu/5HaSv8VmDByQXGouuiCTYEbkBoSijCUsNQZC7CSPeR6LexH87EnzHOO3DpAFrPaI1///VvbLuwzarPLee3QDTBUwufqvrBAXyw7gOciDpRZTufGB+IJrjb6W6b+q1JHKBSE+uiJtZFTayLmlgX+zEAISIiIiIiqh1qVwCSnw/UqWMdNtSvX/50iAMH9JXFCwttCzvs2erVK3u9ywOQks+NGlk+33KL5TVclSj9hq59+/RXYj34IBAQAPTurb/xy9296q42brT08/33wO/7RkI0QcMJDa3aBSYEotnkZmg3tx2Aiuvy3zX/hWiC+Sfnl3u9bRe24Yn5TxihxxyvOcbngPgAq7bt5raDaIK9F/dW+gzHIo9hhd8KzPGag8fnPI6PXT+u/KGL3eRwE4buGIqYjJhK252OPY2W01vihaUv2NRvTeIAlZpYFzWxLmpiXdTEutiPAQgREREREVHtULsCEEBPA0qHDaNHV31OdQUfP/xg/fO77+prlVx+jcqu6epq02OGhAAeHkBqqaUyzGZ9mzRJXyP+zTeBkSMr7qOwEHjiCf2ymZlAv439IJqg2eRm5bbfdmEbftz1Izac2VBuXb7d/q0RaPjG+hr7U3NT4R/nD+2AZhxvPLFxmTU7zGYzcgtykVeQh6Wnl2Ly0cm4lHqp0u9h8ObBEE0w7qBt66eUqDeuHkSTKgOQQZsHQTTB+EPj7eq/JnCASk2si5pYFzWxLmpiXezHAISIiIiIiKh2qH0BiKendaBw7lzV51QURsycaflckhRUtpW3eHqDBvrC6aX3mUwV99G//xV/X+fOATfeWLbL7dvLtjWZAF9f4NAhy0yRFX4r8LLzy5jqObXc/kfsHQHRBEO3D62wLndNuQuiCXxifIx9K/1WQjRB21ltMXr/aIgmuH/G/VbnFZmL8MeBP4yAxFRYfs3zC/ORlpuGrPwsAMBUz6novqI7XPxdbPmKrEw7Ng19NvSpdJbJALcBEE0w8fBEu/v/p3GASk2si5pYFzWxLmpiXezHAISIiIiIiKh2qH0BSGys9eh/YWHV55Ru37ix5fOWLZbPmmb53LOn5XPr1pbPl68nUtH2/PMVHytZJB0A0tKA5cuBjAybHn3/fks3N9xg+TxsWNm2ixdbjpvNQF5e1V/VzuCd+HXvr9gYuLHCulxMuYgLSResFjF3PeuKOyffiffXvQ+/OD90nNcRPV16AtADjfzCfBQUFRjhh2iCwqKyNzPzxEzjeP9NVx4UlXh37bvGq7gqUlhUaNyf6jhApSbWRU2si5pYFzWxLvZjAEJERERERFQ71L4ABCj7uilb2z/0kPUaIkVFwDffAHPnAr//btmfn2/5/Prrls9nz1o+DxliHY5UtY0ZY/lcv77+bqsPPrBrVkh2tp6tTJwInDkDrFwJ9OkD/PQTUHDZ+H1cHHD77cBzzwFt2uiX2XMwHReSLiAqPcqqbURaBD5c/yEGbR4EoPoGQkJTQo1AY2fwTvTZ0Advr34b4WnhiM+KR0RaBLJN2UZ7J08no33fjX2t+vKJ8cGLy17Ep5s+tfn6Wy9sxfRj0+EX51dhm8j0SHRd2hWvrXjN7uf7p3GASk2si5pYFzWxLmpiXezHAISIiIiIiKh2qJ0ByNmzehJw6JBt7UuCh5LAobzwZPjw8tfwKL3mSGCg5fOyZdavzZo1q/zg4+hR/T6Lisp/f1XJ5u9v33dQrOTtW82aATk5lv2+voCzM+DnB7RrV3yZ9ssgmpQZ7D8TfwaiCe6YdAeAiuvi4OGAV5e/ii3nt5R7L1HpUdgVvAuiCe6bdh/WB643Ao09IXus2j676FmIJnA752bsS8tNQ1BSECLSIsrMEDlw6QBEEzwy+5EqvxNToQlDtg3BN9u/QY4pp9K2IckhEE1w64Rbq+y3pnGASk2si5pYFzWxLmpiXezHAISIiIiIiKhymuh/NJXezpc6Xk9EZotIsohkiYiriDS7rI8WIrJdRHJEJEFEJovIjXbeR+0MQOxVEjL07VtxAPLtt9b7XV31faVng4SHA3v36guvFxZazwApKtIXRb882Cit9CyQ8rbSK57baP9+4LbbgE6drPcPHqx3OW5cqcv2f8kIJEpLzklGg/ENIJrglz2/VFiX99a+B9EEj85+FMk5yWXuZYnPEqvXXB2NOIo/D/4JJ0+nMmt+dF3aFTf/ebNVAFKeH3f9iIdnPQwnTyesCViDncE7q/xOsk3Zxj1k5mdW2nau91y0nN4Sv+79tcp+axoHqNTEuqiJdVET66Im1sV+DECIiIiIiIgqp4nIGRFpXmq7o9TxuSISISIviUgnETkmIkdLHa8rIgEisldEOojIGyKSKCIT7LyP6ysAGTSo4nCiJDEo77Vazs7AjBll95deKwQAYmIABwegVavy+4qLqzwA+fTTK3o8sxlITgZyc/UcJiEB6NcPeOABfaLKb7/p3d/6+gSIJsarrkobvnt4lQHIwbCDRrAQmBBo7PeM8ESfDX3wfwv+D/XG1YNogpbTW1qtEwLoMzxGuY/CWI+xNj/bB+s+gGiCmSdm2nxOfmE+/jjwB4ZsG4LzieeRmltxsFQS6sz2mm1z/zWFA1RqYl3UxLqoiXVRE+tiPwYgREREREREldNExLeCY7eJiElE3i+172HR/8h6pvjnN0SkSKxnhXwlIukicrMd93F9BSATJlivIl7atGn2rSsC6Auy9+gBbNxovf+778rvy2y2Dk1KZqUcPKh/rlMHyKx8xkJ5zGZL5vLqq8Czz+qfly7Vj2dk6G8NOxxwCe6h7jiXeK5MHxl5GYjOiEZqbmqldRngNgDvrX0PkemRxr41AWsgmqDbsm44EXXCeAXW5UrPDimPV5QXPtrwEZ6Y/wSWntZv/mzCWXhc8iizboktPt30KUQTTDoyqcI2zr7OGL57OI5GHLW7/38aB6jUxLqoiXVRE+uiJtbFfgxAiIiIiIiIKqeJSLaIxIhIqIisEv2VViL6rA+IyO2XnRMuIj8Wf3aQsgFKq+LzOtpxH9dHALJliz77IzfXEjzUq2fdJj9fn73h5XX110tPB774AvDwKP/42bNASIjlZ7PZsj5IZGT551ThhResc5VGjYAlSyo/Z906PffJL8xHSHIIQlNCAdhflwtJFzDj+Ay4nnVFck4y1geux46gHTAVmvDDzh/Qf1N/hKWGGeHHO2veKbef8YfGG23eXv221bHM/Ex4RnjiZPRJm+4JAL7c+iUajG8AJ0+nCtvkF+bjcPhhHAw7aHO/NYUDVGpiXdTEuqiJdVET62I/BiBERERERESVe0NEPhCRdiLymoh4ih5wNBSRj0Ukv5xzvETkr+LPC0Rk92XHbxH9D7E3Krnuv0T/Q61k+0i9q+gAACAASURBVI+IICkpCSaT6R/fsrOz4ebmhuzs7H/smiUJgblhwxp55oo2c+PGxr0VPfkkTPn5dp0fG2vCzJmFqFvXDBHgt98KkZtr3Wbaxv14zqkvft8yBZs2FRhhyeYj+iLotzneVmldzsWfg2eYJyJTIiu9l2U+y+B82hlekV5GoOFx0QO+0b7wjfZFVm4Wph2dhs83f44jl44Y560PWI/W01uj4YSGWOi90KrPo2FH9VdrTWtZ5XeRl5+H+PR4JGYkVtk2MiUSognqaHVq/N9AVVtN/L5wY11q68a6qLmxLmpurIv9W1JSEgMQIiIiIiIiO9wu+uurBsm1DUA0Kbv4OlxcXODm5nZdbCWj/nkNG9b4vZTesps2tZrCEfTOO5bjmzbZ3M+kSR5GNw8/nIQ//zxiHLvz42/1QOLHe6xmi4yYtNIIKiatmlRh312md4Fogs8Xfl7u8d+df8cjkx8x+pqwcoLxed7aeVZtOzh1gGiCH5b8UOnzOK50xIhlIzDKeRSaT2iORyc/WuV3sGz9MiPUsKVtswnNcLfj3dhkx/fMjRs3bty4cbt+NxcXFwYgREREREREdvIWEUe5tq/Auu5ngJjvu0+fZdG/f43/34NW91V64XQRmG+5Baa4OJi8vGBu0gSFTk429RMSYsL48YVGV+vXFxjH2o78WA8kRjSCCPDMM0VITzchP9+Evq59IZrA8ZBjhXX5astXRqBxIeGCsT81KxXn489jtPto43jDCQ0Rlx5X4X0u9VmKMe5jcDLqZJljWblZ2HpuK7ae24rXlr8G0QSLTi6y+bsMTwmHaIK6Y+tW2fYV51cgmmCpz9Ia/zdQ1cb/Q1fNjXVRc2Nd1NxYFzU31sX+jTNAiIiIiIiI7HOriKSIyFCxLIL+XqnjbaT8RdDvLNXmC9FnkfzLjuteH2uAlBYeDjg56et0qKRRI0sAUhzSwMMDeO45y/7Ro/X1QqqwbRvw4IPAW28B0dGW/Sv8VuDRqc9AujpABDhyxHJswckF+HTTp9gZvBPt2pnRsGEezpwpW5eGExpCNEFwcrCxb33geogmuGfqPfht32/G58uVHLvJ4aZK7z8hK8EIUobtGobOiztjZ/DOKp+7hNlshqnQhCU+SzBo8yBsOrepwrYvO78M0QSr/FfZ3H9NqZHfF6oS66Im1kVNrIuaWBf7cQ0QIiIiIiKiyk0RkRdEpKWIdBaRvSKSKCJNi4/PFX3GRzcR6ST6GiGepc6vKyIBor8Gq73o64gkiMgEO+/j+gtAVFX6nVTPPqv/19UVaN/e+lhVK5sDmDhRb/rZZ2WPFRQACQnAmTPAiy8Cr71WNlO55x59HZFjxwrKnO8X5wefGB/kFeQZ+zad24QG4xug+4ruOBN/Bg/NfAhdl3Yt+4jFoYZoUu59Ox52RNNJTfHV1q/wxPwn8MT8J6p81sp8t+M7iCYY5T6qwjaZ+ZlIzkm2eh5V8fdFTayLmlgXNbEuamJd7McAhIiIiIiIqHJrRCRG9LU+oop/vr/U8XoiMlv0WSHZIrJRRJpf1sd9IrJDRHJED0+miMiNdt4HAxBVDByopxbt2ulTN0SAPn2sw4+SLSKi0q62bAFGjgSCgqz3Z+ZnIjI9Esk5yZgwwdLdsvUJGOA2AEO2DQEAeHub8Pff7khPv7q6pOamGoHH6djT6L2+N55Z9Ay8oryQlZ+FpOwk5BbkGu1Huo+EaILvdnxXpq+w1DD0WNUDfTb0sfn6u0N2Y8KhCfC45FFhmxxTDl5f+Tq6r+hudS8q4u+LmlgXNbEuamJd1MS62I8BCBERERERUe3AAEQVeXnApEl6atGiRfnBR8k2bNgVXeL10XMgmqDTpHcxYoSlu5ffvwjRBA3GN0B+PjB0aCHeeScImZnWdXHydMJ/1/wXWy9sLbf/mIwYuIe6QzTBI7MfQVBSkBGA+MX5WbV9Z807+uLo3vOMfXGZcQiID0B0hv7ervOJ57EmYA08IzwRmBAI0QT//uvfVT5nYnYihu8ejjH7x1TZNtuUbdxjZn5mle1rEn9f1MS6qIl1URProibWxX4MQIiIiIiIiGoHBiAqGjq0/ODjxhstn8PD7e622a9djcH+Dz4ABg8u7q6eZabGYq/VxiUyMqzr8tGGjyCaoMO8DuWGBXO85li95io2MxZDdwzFt9u/hanQuq9PXD9Bh3kdcDbhbIX3O+XoFKOvTec2YYnPErj4u1T5nOcTz0M0we0Tb6+y7VzvuWg1vRVGuY8qc4+q4e+LmlgXNbEuamJd1MS62I8BCBERERERUe3AAERF2dmWoKNbN8DbW58dcvSodSCyYQNQWGhztz+5OumBwjt90bq1vq/kLVu3ffuKHoB4r8Szzxahfn0TvL2t67Lv4j4jkAhPswQwp2JOYaDbQDw+53HcMPYGiCa42+luFBRZryESkxEDx8OOmOM1B/5x/hh3cBwAYPP5zZh/cr5VnwCw7sw6qwDEVvFZ8fh5z88YtmsY4jLjkJ5X8b/vJxc8CdEE2y5ss7n/msLfFzWxLmpiXdTEuqiJdbEfAxAiIiIiIqLagQGIqpKSgOPHgaIiyz6zWQ9ESocgY8fa3OXRsxchD22FNPeBpyfg6QmsWAFMnw4c9o3GhaQLSMtNw0cfFUEEmDjREq7k5wOPPAI0HtIL3Z3fQEJWgnFs49mNuGvKXXh95evwjfWFaILmU5qXuX5Fi6D/34L/MxYrX3hqIU5EnTCOHYs8hu1B2xGbGWvzc5b4fd/vEE3w/c7vK2wz8fBEfLX1KwTEB9jd/z+Nvy9qYl3UxLqoiXVRE+tiPwYgREREREREtQMDkNqmsBC47TZLAPLKKzafGhRUPNvjNn2h9JIuCosKEZMRg5iMGACAk1Mh/u//YrBmjWUGR2Kipf3Fi9b9elzywLOLnkVsZiySc5Lh7OuMtWfWwmw247d9v2HYrmFIzkk2wo+XnV+2Ov+n3T+h1+peeH7J8xBN8POen8vce35hPnxjfeEb62vz845yH1Xhouql+cT44GT0Sb4Ci64I66Im1kVNrIuaWBf7MQAhIiIiIiKqHRiA1EYFBcC771oSCTe3ituGhwMODkBiIha770e3KUMwfOVi7N2rn9qgAeAVFI4btBvQ4M9GKCoC0tNNcHW1rktUFCANoyBNA7HncJLVJYrMRXAPdQegBxUbz27EpnObkJ6XbrUI+unY0/CO9kZWfla5t7rYZzF6uvTE0tNLyxwLSw2DaIL64+pX+fUUmYuQV5BX5hVcFamj1YFogrjMOJva1xT+vqiJdVET66Im1kVNrIv9GIAQERERERHVDgxAaqtjx6xfhdW6NRAdXbZdu3b68R490On34RBNcMeYRwEABw8CcXHAvBXxkH6v4K4vB8LjZBxEgEaN8qzq8swzgLz7CUQTjN7hVOFtJWUnGaFHZn6m8fliysUKz6nI5vObIZqg5fSW8I/zR/MpzdFqeivEZsYiJDkEhUXlr3/iHe0N0QQtprWw6TotprXAvVPvZQBCV4R1URProibWRU2si/0YgBAREREREdUODEBqq/PnrQMQEeDNN8u2K3V88BQ3iCbo5jjcqsn+/cB/PpiEx3/6ESdO5kMEaNIkB6dPmxAWVqqbHl8ZgUbAxQQ4OgJr11pfLiYjBvXH1UeD8Q1gNpthNpuv+BFX+K0wrrfv4j5j/4frP4RogjdWvlHueccjjxvBSVXazmqLOlodHA4/fMX3+U/h74uaWBc1sS5qYl3UxLrYjwEIERERERFR7cAApLZKSrKEG//5j/7fW2/VF0ovrVQAEhQE/O6QCmfnirstKgKSk01o0SIdN91kxh9/XNZdcSCxfmcsRIC2ba2PB8QHQDRB00lNy/Tda3UviCbovqK71f4vt36JFtNaYKXfSqv9MRkxaDyxMepodeAV5WXs77GqB9rOaovZXv/P3n2HR1G1bQC/qdKEV0REsSCoFMWKoqg0EUU/EAVRFEGqgsCLlaLC0nvvPbRIJ6F3Qi+RUKSX0EJPSG/b7u+Pk0x2E6JEX82i9++6zpWdM2dmZ+bZcmWePeeMvek5OFwORiVGceHhhey4siPnHJyT6fmO3TOWsIHbzm3LtI2v0PvFNykuvklx8U2Ki29SXLJOCRAREREREZHbgxIgt7PFi8lVq8ikJDJnTpPouHzZu41HAiQw0DysXDnzXZ4+TV6/bmerVgdYoICb/fqlrYuNJZcf3Mb1J7dyz95kNmtGfv+99/bHw4+z5NCSfHr80xn2nZo8KTm0pFd9g3kNCBt498C7WWpEKQ7fOTyLF+LmBmwdQNjA5gHNM22T7EzmcxOfy3ReEl+i94tvUlx8k+LimxQX36S4ZJ0SICIiIiIiIrcHJUD+KcqWNdmN2rVNL5CEBHL6dK8ESEgI2aYN2bfvzXcRGmqa1qnj4ty5y3jlip3Hj5PdupHjx5OvvGLWL15s2rvd5NGj5IULmR9WatLjRPgJfjD/Az466lGuPrnaq82x68e4O2w3G85vSNjAHpt6ZNhPdFI07xl0D2EDj14/ekuXZPPZzfxhww9cdGSRV33IpRDWmV2H3dZ3I0l+uvhTvjf3PV6KuXRL+80uer/4JsXFNykuvklx8U2KS9YpASIiIiIiInJ7UALkn6J1a+/5QB5/PMMcIbOm2fnSS2TPnt6bnjtneoUULpzWfPbsFbTb7Zw4MeNUI7Nmme3atjXLP/2Utq/LsZf5/MTn+crUV0imJUBuJNz43VM4E3mGuy7s4vmo8yTJq3FXufTYUgadCfKaXH3w9sG8FneNYdFhN93P6Run2X1jd47bM+6m6zeEbuDDwx/mq9NeJUkW6V+EsIHHw4//7jFmJ71ffJPi4psUF9+kuPgmxSXrlAARERERERG5PSgB8k9x5UrGTEW6Mjh3FwLkp5+mbHP2LPnrrzx71kwfki8fuX8/uXmzw4rLr7+SNWuaXeTOTfbrZ9pt2uTdweT110mHwyQxYAPz98lPkjwXde4PJxZWnlhpJT1CLoWw5NCShA2cvm+6Ve9yu6z28fZ4xtvjue70OsIGVhxXMdN9N5zfkN03didJTtk7hd+t/Y6tl7bmoG2D/tCx/q/F2+MZeCyQ4fHhVp3eL75JcfFNiotvUlx8k+KSdUqAiIiIiIiI3B6UAPkncTjIqVO9Ex8tW6ZNgo5HGVBrNENCaMavSql3X7rMjz8mW7Ui7faMcYmIIAcPJgcN8t51vnxkp05pyx07kifCTzB/n/wsPrj4LR/2Lxd/4ewDs7nv8j6v+l0XdlmJjv2X91v10UnRhA3M0ysPZ+yfwQFbB7Dq9KqEDXxx8os8ev0o2y1vxx6bejA2OZYJ9oQMzxmVGOW1/OniTwkbWG5MuSxc8KwJiw5jyKWQW2o7aNsglhlZhu/Pe9+q0/vFNykuvklx8U2Ki29SXLJOCRAREREREZHbgxIg/0S1aqVlJdatIwcO9M5cfPAB+cwzacurvefk+K24XLhAHjhghswCyFGjyBo1zOMaNchnah0lbGDRgUVv+XA7ruxoJTqG7RjGw9cOW+tWn1zNOQfnMDop7TXqdrvpdrvNqc6sZW1bYWwFr8TLmN1jCBvYcH5Dq27L2S0MvRFKp8vpdQwut4v+B/3ZZV2XWz7urHC73Xxg2ANssrgJHS7H77ZffXI16/rXZaVJlaw6vV98k+LimxQX36S4+CbFJeuUABEREREREbk9KAHyT9S5c1pyw5Fysz0+nqxe/ebDY02Z4rV5ZnGZM4f86isz/NXVq+Thw6Z3yPXr5KlT5MaNJPLdYJHXx3FqyFRru9hY8rdeYuP2jGPOnjmtRMbsA7MztHG5XTwZcZInwk94DXs1ePtgjto1im63m0mOJCY6Ernv8j663C6O2zOOsIHvz3uf7Za3s4bQSh1SKyt6BvXkY6Mes+YnyapER6L13J7JnMxci7vGZceXccf5HVad3i++SXHxTYqLb1JcfJPiknVKgIiIiIiIiNwelAD5JwoPJz//nNznPaQUGzXKfI6QLVtMkoSZx6VZM9O0Q4ebP+2NG+Tw4eZp1q41dcnJ5COPkA8/TMbF/fZhh0WHcf3p9VbvDk9xyXFWAuFc1LlM93H0+lE2W9KMy48vt+YESXIksa5/XebtndfqKZLkSLrp9iGXQrj65GpGJESQJBcfWUySLDOyDGEDZ+yf4XVMqb05LsZcZGxybKbH5XQ5ueP8Dq4/vZ7Lji9jvy39uDts929fEA83Em5ww6kNHD13NK/FXOOF6Au0O/W++atdj7/OEkNKcPLeyZm20eeYb1JcfJPi4psUl6xTAkREREREROT2oATIv0m1amkJjzFjvHuKAOQDD5AxMbSfOcN1Y8dmiMv69WTdumRMTOZP4e+fNhwWSa5Zk7b7gABy6dJbP9zgi8GEDSw5tCTdbjdfmPQCnxz3JJ0up5UMmbl/Jt1uN8Oiw0iSBfsWtNZ5JlJmH5jNHzb8wERHolcPkvSeHPckc/XMxfWn1zPeHs/C/Qtz76W99D/oz6khU3km8gxJcuyescxhy8FdF3aRJCtNqmQ97+fLPs+w3zORZ7j30l7GJcexyeImhA0cvH1wpsfx+bLP+c6cd7j30l6StCZ2f3jAw7xrwF2EDTx6/eitX0z5Q5YeW0rYwNemvZZpG32O+SbFxTcpLr5Jcck6JUBERERERERuD0qA/Js88URaNoI0E6G/9tpNe4Q48+ShY8sW7+0TE+lOSLzprtevJ5s3Jxs0MCNtffWVSXik7rJ9+7THCQlmUvWgoN8+3K3ntlpJBdL0okhNXqTW9wrqxT6b+1jLT41/irCBz0187g9doqrTq7LP5j48Hn6cXyz7gh1XdmTwxWBrvdPlZFxyHOvMrkPYwL5b+pIkp++bbh0DbGBYdBi3nN3Ch4c/zEYLGvGh4Q8RNnB32G5O3juZd/S+g7CB1aZXs3qC9N7cm5UnV+bms5v58PCHCRvYeV1nkuSG0A18bNRjfHHYi3xg6APM0ytPlofx+rs5XU72CurFIduHZNrjxhedijjFHzf8yEm/TOKx68fYeV1nLjm6JNP2+hzzTYqLb1JcfJPiknVKgIiIiIiIiNwelAD5N1mxwmQgvvnGu37nzsyHxkotkyaZv//5z00n9OjQwaxu0oR87LGbj7BVtiz54ouml0i+fGSxYr89NwhJjg8ez6AzQXS7yVWryCtXTH1d/7qsOK4iQy6FcGrIVBYbVIxNFjfhpZhLPB91nvH2+D90iVafXM1lx5eRJAOPBfLewffyrdlv0eV2MeBoAAv3L8w5B+cw9EYoV55Yac0JcvDKQfYM6mklQMbuGcs3Zr5B2MAXJr3Ax0Y9RtjAnkE9SZJnI89yxM4RzN0rN1efNJPQPzfxOcIGNlnchOODx1v7CjwWSDLt/ZKQlPCb53A17iqPXDvCs5Fn/9A1+F+JToq2ziHB/tvH7EtWnlhJ2MBnJzx7S+31OeabFBffpLj4JsUl65QAERERERERuT0oAfJvc+mS6fmRXmAgOXUquWEDnd26MeHuuzNPhixYYMbB6t2bDDG9EOLjSZuNnDkzrVmnTuTLL5Pbtpm52H/5hcyd26wrWdJMok6a5EhsrJm6JF8+04MkIcHss1Ursl07cuBAs92775qn3Lfv5qfxe/7INqlG7RpF2MBv1nxDp8t50zadVnXiU+OfYuCxQOvm//xD8xl0JoiwgWVHl7Xa7r20l/MOzePl2Mskyc1nN3Pd6XWMSoxiZGKkNe/IO3Peodvt/t33S/+t/fnp4k/ZMrAlc9hysMSQEr/Zc+GvFpMUwzZL27BI/yLstr4bN4Zu9Fp/+sZpXoi+YC1HJ0Wz3s/1ePDKwb/7UL0cvHKQ7Ve0Z78t/TJt4zm8mj7HfJPi4psUF9+kuGSdEiAiIiIiIiK3ByVAJAO73c6AJUvoWL6cLF/+t3uG5MxpMhUpN4TtdtOhZNmyjPudMcNsUrNmWt3Vq2SuXGTRomZIrHLlTJs33vB+mhIlzN+vviLfeiutfuXKm5/D8OFmHvjp08mqVU3yhTRDbz32GDlvnlkODCQLFMh8YndPSY4kdlzZ0eqx8XuaLmnKZkua8XzUeQZfDGa16dXYZHGT39zmQvQFjtszjk6Xk8fDj7NQv0LWEGA3e790WdeFz0x4hoHHAq1htu4dfC8rjqvI0zdO39JxptpxfgfnHJzjlZT4X/h82eeEDbRtsnnVpyaIUnvFLDi8gLCBQ7YP+Z8+/5+R7Ezm6RuneTz8uFXXIqCF15wg+hzzTYqLb1JcfJPiknVKgIiIiIiIiNwelACRDDLEJT6enDzZdOn4rWTIu++Su3ebobYcjgz7dbvJsLC0nh8kuX276RXSqJFZv2IF2aKFaZe62y+/JLduJefPJ48eJe+4I21d9+5p+zp+nDx/3hxurlxkjx5koUKm3emUXEDHjma5p7nnzvfe8x4VzO02vVj+CLfbzXNR53js+jE6XBnP/1a2f37i89YcJmHRYXS73YxIiOCbs94kbGAXvy7stakXYQOnhUxjowWNCBs4dMdQNlrQiN3Wd/Oa5H3buW1ePRkm753M5yY+x4HbBjLRkcircVf5zpx3uPPCTr44+UXCBi48vJBRiVFMdKTN9xKTFMPZB2YzPD48w3HHJMUw+GIw45LjrOUbCTesazDv0Dx2WNmBK094Z6tgAzuu7MgDVw6QJN+b+x5z9szJBvMa0OFyMDw+nFvObrEmms/MldgrnLx3Mqfvm86oxCivetsmG22bbNxxfsethsHLoauHCBt498C7rbo7+91J2GANf6bPMd+kuPgmxcU3KS5ZpwSIiIiIiIjI7UEJEMngN+Oyb5+Z3bxfP7JixcyTIV27mva7d5vlhx8m+/f3zn6kiI8n4+IyPtXp02RSJnNnjxtHli5NLlxIJiaSTZuap1mxggwNJZ97jnzwQXL5ctMDxJWSEzhzxhz+rpR76snJ5IYNJuHidpueIQB55AgZEUHWqWNOM7Ohs44fJ6tVM71ezp51M6ctJ2EDL8VcIkmuXm2NEnZTycnk3LnmMpHkrgu7+P689zll7xSvdqm9JTpM7cCmi5tac1RsP7+dy44vY1h0WIZ9u91u5uuTjzlsOUiSLreL1f2q897B91r7a7qkqfW43fJ2rOFXg2tOrWHZ0WUJG7jk6BK63W52XteZsIF7wvYwNjmWQWeCrOd4ctyThA3stKoTT4SfYO1ZtQkbWHJoSa+ERERCBL9d86015Jcnu9POewffy5emvESSLNC3gHVcrQJbZX4BSbZb3s5q22lVJ6v+4JWDzGHLwRYBLThq16jf3Ien/Zf382LMRZJk6I1QFuxbkA8Nf8haP2jbIHZc2ZHRSeZz8898jiXYE3gp5tIfnrNGMqfvF9+kuPgmxSXrlAARERERERG5PSgBIhlkKS4HD5ruE2XKZEyCPPvszZMjTzxBfvYZOWKEmfwjKsp7ny5XWsbh6lXTzWPhQnLkSLNPf38yMpK8ccPKbNhsZteeyQaXiyazMX8+eeqU2e7bb8lFi8j9+9OyIsnJJpNBsl498r77TAJk/37y6afNfrdtM00nTSILFrSa85dfzPp33klJnqTciD8ZcZIffmjWbdpk2g4caCaB/+QT0ulM2x9A9umTdsqhoSapk+rqVXLssq3sub4fFy9ZzGOXTvOtn8ax5ZdR1qTwpEme3DfkPtb1r2vVPT76cZYYUoIk6XQ5GXIphLCB/131XyvpcWe/Oznn4ByvEKSeB2zgMxOesR73CurFej/XI2xgn8196HK7eD3+Ov/P//9YcVxFnoo4xdqzavP5ic9z7J6xhA3WcFG/Xv2VsIH3DbmP8w/N93q+0BuhVtLE5XbxviH3Wc/51uy3SJJnIs9YvS5IMuBoAP32+THJkcTAY4FceWIllx9fzuPhx+lyuxgWHcYvln1B/4P+1jYrTqxgl3VduCF0A/tv7c83Zr7BNafW3PTcO67syN/y6eJPWXFcRW49s9Xr/ZLkSPrdSd/3hO3hIyMesZ5rWsi0m7bbe2kv7x18L/ts7nPT9aciTnHTmU08FXGKJHku6hz3Xd73P0+oePYqul3o+8U3KS6+SXHJOiVAREREREREbg9KgEgGfzguR46QAwb89jBZmZW77iJr1TJdNwDynnvIRx/9/e3uvJP2Rx5nnwfH89fxW8lVq8xE73v3mkzDb21btqyZVMSj7nzVT9iq1hluHn2A/PlnnlkQzL69XYy6EMO1q13Mm9c0PXXCRcbGcnvANb76QhIHDybPniVRfiFLfzyMbjfZrBlZsKCbAUtMZiMy0sxf8p//pF2y3r3N/n7+Oa0udaSxBQvM8vz5Zvmzz1wMCAjg9et2a66UffvStnu+9RTrhjpJBgeTwQej6XKldV+5EnuFG0/s4MkzSYxJisn0xrbdaefbc95mnl552GxJM8IGVp1elfH2eDYPaE7YwBYBLbwmA2+9tDVfnfYqQy6F0OFyMPhiMOvPrc/KkyuTNEmOKlOrsO+Wvl7Da5HmBvuV2CvW/iITIxmdFM0lR5dYbe/sdydLjyzNyMRIkuTrM163EjEkGZccZ53/tbhr1r49hyNrv6K9dewfLvjQGj7M0yeLPuHT45/m1nNb02KyqhNz9czFkxEnrbqXp7xM2MB5B+d5vV8WHF7AfH3yMfhiMEmy7fK2PBt51us5Np3ZxLsG3OWVWCo7uiyLDizK5gHNrXZbz21loX6F2HB+QwYeC+Rbs99iy8CWfGHSCyw/przVU+ebNWYMt5aBLa19Vp1elWVHl2WlSZWYYE9geHx4huuemWRnstULZuiOoaw5o+bvbJHRr1d/Zdvlbbnzws4sbxuREGHF+ffsCdvDL5Z9QafLZBUPXDnARUcWMTYhlgPmDGDxQcWZ5MikK1kWJdgTvObWcbld1vPKrdH3vm9SXLJOCRAREREREZHbgxIgksGfiovbTXbuTH7xCIgEMAAAIABJREFUBTl7NtmrV1r3iXr1zF378uXJdu3MBOp/JFly771/bDvPxMcf2C4ZebjzoUbc89ZPTLr/Ee/1BQvS/VN3Jrf+kmzcmOzVi8eqtuZJlCGLFydffZXOz9vRr8VmDnx3G/nUU+Srr9JVvSZjKtcyk5GMG0f3goVsXOsqAXLMh1vIfv14LOAo8+Z2Mk9OB5f/37d0TJnCX7+ZzvuKxDEy+CQZHEzXtXDizjCi9YtsOmw6SRMGgBw2LC08CxeSOXKQb76ZVpeQYPJOVat6h3LVKjIuMZlX467y6PWjjEiIIElODZnKmftn0u0mK1Uy20VE0Oopck+Vlbx2zbwU3ujdh+WaTOC5c2af58+bXjWNG6cNe+ZymaHLFi8mPV9yCQnkZY/RskqNKMW7BhTlN4uGMCmJrDmjJkuPLM1RQXN44gR59FQ8f9rYnfcPvZ8//UR++KEZXq335t58a/ZbPB91nv229CNs4IoTK7j+9Hr67fPjsevHGHA0gHX962YYKis1v9N1fVfCBo7dM5ZLji7htbhr3HJ2C9eeWsuLkRe5YPEC7g3by8uxl/nxoo8JG9h9Y3dGJUYRNrDN0ja8kXCDfvv8OHzncEYlRvGzgM/43drvrCTUyYiTLDemHBvMa+B1DPcPvZ9BZ4I4IXgCYQMrTarEWjNrETYwZ8+cLD+mPAduG0iS7LiyI8uOLssxu8ew8cLGfGzUYwy+GMxERyJhAwv2LchDVw+RJMPjwxlyyXSZGrpjKEfuGmklCur9XI8PDnvQOu+K4yryRPgJzjowi7Vn1SZJxtvjrfa9N/dm7Vm1+eniT63jTk02pdZdj7/O3pt7ZxiuLSw6jAFHA3gu6px1Dp49hxYcXsAG8xrwSqzp7jRuzziO2DmCscmx1vp7Bt3DC9EXmOhI5PMTn2fuXrnZcUVHVh1ZlbCBm85sIml6DT00/CGWHlmay44vI0nO2D/DSlaldy3umleC47Vpr7HRgkYkyR3nd7BQv0LM3Ss3JwRPIEnOPzSfQ3cM9Uq6Hb52mBtCN1jLJyNOsvvG7twYupEkuTtsN89EnrHWO11OJjuT6XQ5mehI5Khdo/jTxp+45ewWkuSG0A1sFdjKK/mY6kzkGS4/vpybz2626nps6sEXJr3AwGOBPBd1jjP2z2DojdCbnq8nt9vNy7GXeTHmotf5TAiewL2X9v7u9ulN3juZ1f2q850573DCvAkctn0YR+wcwatxV7O8L5J8YuwTLDu6LA9eOXjT9U6Xk1NDpvKbNd94Xf/zUedZ7+d61jlM3zed7897nxeiL5AkbyTcsF5bG0M3st+Wfrd0vW5VbHIsQ2+E8kzkGbrcLt5IuMHD1w5bcyj9WXvC9vDwtbShJhccXsCj14/+7na/972fYE9gTFJMlo7FcwjEWzE+eDw7rerEa3HXOHnvZE7eO/l/dl3+CkqAiIiIiIiI/H2+BHAWQBKA3QBezMK2SoBIBn9ZXBISyAsX0pZ37CDXrTN3uQcOJJs3J7/7zsyI/v335ODB5m79hx+aO9HJyWnbNm1KlixJrl1Lfv01mS+fGZuqQIGMyYtOncyYU9fSegXQz8/0EGnenOzSxexn2zbTRePPJFf+ByURd/AIyjEGhbzqLqBkpts4kZNzH/iGFws+RhYpwuSXq7HlIxsIkPNbrDTDf125wgndzhEge7+1zZzzzp1c2WMXAfLRMi4rA5GQYHY9JWUqkuXLTd6ofn2PeMbGmtxPARfdbrLetM+Idk/wjvuO0R0eQZfTzX79zH66vneU3LOHrvhEtm0SQ8CMTsbYWDoT7dapXD9nJoRJiojjyy+Yek/PPGPa7d8WS7fbzdkHZrN+ixMEyMKFyQlrNnLtiU3s29Nse/w4rR4RlTp3Ze68DvotTbsZOG6cmePls7mdCBv48JDHWbJk2hwxX39NPvQQOXjNTDZa0IglBpcgbGCODuU4dappY7fbmbfnHYQN/D+/jxh0JojTQqZxy+GT/GHGcsIGTgieYE2oDhvYun20NQIbSS5ZQnazxXFh0BFr/phVq8zxXb9hkgzHw4+z1rfT2KDTNl4Kj7OGA9u4kXz5ZfOWIEmHwySUtu+LYODR5bwad5VJjiTCBr46uTqDLwZz9oHZzNMrD9sub8u45Dg+OupRaw6VpCSy7uz3CRtYZ3Ydbj23lc9PfJ6XYi5xQvAElh9TnuejzrPd8nYs0r8IB22cwDl7F7P8mPJ8ePjDdLvN6HQR8ZEs0r8Ig84E0e12s83SNoQN3HJ2C8cHj2ezJc24/fx2VhhbwUoukeTy48v50LCH+MSYinS7ye/WfkfYwCfGPkm32807eptrnZow+Wa1WV9mZBlGJ0UzKjGab06vx/p+TThizmgWHViUCw8vJEn6H/Rnrp65OH3fdLrcLiY5kqyePLHJsfTb58f7h97PyXsnM9mZzDZL27Dd8nYkTcKnytQqzN8nP2OTYxkWHcZ6P9fjo6Me5aqTq5hgT+DAbQMJG3jwykG63W42mNeAsIGNFza2Yr3ixArCBrZf0Z4J9gQW6leIgccCrURYvy39WLBvQe68sJM7zu/gQ8MfMq8t//+j2+1m7829CRt47Poxnoo4xRy2HNYQaF+t/oqwgS9Pedl6vtemvUbYwLfnvM03Z73plZQKvRHK+YfmM94ez9Aboey8rrPVA+mbNd9Yr9fUax2TFMPas2rztWmv0eV2MfhisJVIcrld7LO5j5VUI02y5McNP/Jc1Dk+Nf4plhhSgtNDpnPGwhks3L8wYQM/X/Y5SZPQgA28EH2BdqedLQJacPXJ1WkfN8mxfGr8U3xj5huMTIwkbODdA+/mtJBpPBF+ghXGVmDD+Q2t9vH2eOva++3zY4N5DfjcxOescwo4GsDIxEjm7pWbsIG/Xv3Veo0W6FuAm89u5uOjH7feByS58PBC/rjhR6/PJP+D/mwe0Jz9tvSj2+3mx4s+ZrFBxXjk2hGSpjdVsjPZukavTnuVsIG5euaibZONk/dOto4ztZ3dmfl377W4axy5ayQXH1ls1X244EMuPbaULreLXdd3ZfHBxel0ORkeH85cPXMx8FggkxxJ/CzgM74y9RVrDifSDOVXemRpLjy00Pren7l/JlsvbW21SXYms+TQkqw4riJJ8mrcVT4w7AEr1uHx4fzl4i9ex1l7Vm0W7Fsw0/MgyWrTq7Ha9Gq8kXCDkYmRzNkzp3W98/fJT9jA79d+b8UztfeV3WnnhtANvzvU4F9NCRAREREREZG/x4cAkgE0B1ABwCQAkQCK3+L2SoBIBrd1XBwOcs4cM26U02nuxDqzMESNy2WG8nI4TLLm66/NnCEXLpCtWpm5S4YMMZmBkyfJY8fSEhGvv572uE4dk3jp1o1cs8ZM9vHee2TNmuaO+qOPkoMGkbNmkaNGme4aNWuSVaqY+VQKpSU/WKwY+fzzdL3zDi+89hpdb75p5kIpWpTMk+d3e60kI63NOTzIoyhLt0ebcBTlYtTndrxs9WYZkecbAmSfO3qRd9/N83iAAFmyYCT5xhvknXfSDfB9LGQLTCHvvpuR5UpxfIkX+DWGWPs+mOc5tsRkrkRaYmkzXuMTOQ/z2JMNTF2BAqycbz9fyb2L11CMBBiIugTI/DkTGVepmpnxvlw5Fs95jUURzk2oZq5LpUo89WQ9Fst9g7sKv2F61lSvzn65fiBABud/jUtq3MfPPy3OInlNz5qA/B+R99zDjU92YP5cSQTIo593Yu02+dm50YcEyFxwcNQjw3hvQZOsWfPpLHLgQPr3bcoHWtYkih/kgmqjyI4d6Rw5kjVafUDYwLo//kAeOkSuW8f5X+0gcjr4wMefc2739+n6oRs/6Po0C3/wCQE3nUNHmNfSwIH86tU9BMhJH64jO3emu83nLFM8mgAZ8vkE8ssv6ez6I796aYepm76fDAggJ0xg/3dNnd/rM8kffuDuDrP4n4LJBMgjCw6RAwbQHRDAL5uEEXDz1CnyXPhpPjj0Aea25WO+N22888dSvH/IfYy9cp4nDiQQhc+z5IMOr7dGtQ6zmPO7+3hf/zJcdGQR8/XOx9y2vES5xcyVy82Aveu5+MhiuuMTWKeWnXnzuhl0ZKcZjsztZvHOVcyN//GzWGXyS4QNLD+kMks2HErYwOE7h5M0898gh4uAm5cPhXPlwcXsuuZ71mi0j3nykFWHN2HjhY15Ne4qt28nc+Vy89MPLtMRfo10Oum+eo0l7zUJsHljf2bIiW10JiWyaFE3kT+c6w4H83Ks6Vo00z/BuiG+/fx2a7i3nN3vYNkuTa0bsicuh7F+ffLJ9ja+Ob2edU0ClyezcdN4Dh9uekykJhhadjvAb78l9x+LYnW/6qw9qzanTyfr1iW/HrmFpUeWZt8tfbn7wh7CBt71QwWrR0dqL6VctrzcezGEUYlR7LO5D7dsMZ3oiveoyO4bu/NE+Ak+PPxh01vmu+G8cYNMPPora/vV4sv9W/CFF0zec9eFXdwTtocnT7rZebY/iw0oYfXcST33Wn1sbLu8LWEDq/tV57Zt5Nz5TtrWDbQSIFu3km9/fJY5e+ThoyPKcf/l/db2Xw7cysHrpxI2cHzweO7ebToBvjayEWED35v7Hl0uN6t0HM+mX1zhtGmrWP/n+lx4eCFD9rk4dChZc2xjwgaeijjFRUcWEzYwd888VnInwW5iladHIfptW8WQSyGMSYrhuXPk+ClxbLmoPf8zwIwvuGcP+UHjRN7zQyWO3j2aJNl4odl/qf7PsfSIMlx9cjUdLgcD9gXxqSGvc8TEG+y6xsY8vfLwl4u/MCSEHDf/KN+a+X9ccHgB3W43v1syiLCBw1alJR86rjTJ01rT3ubFmIt8ctyTrO5Xnd3mzqbf/Ot8ZuwLhA1ce2otV60i+w2ws9KQdxl4LJAkOevALNNLbORcRkaSw3cON8P0zfqJXw7ZwLw987Pz2i7W19uwjdO95iiKTY4lbGCx/vfzfJideXrlYeOFjbn11zOcMP8k3/Vryhcnv8izkWdZaVIlwgZ+1GsRI0yHPr485WWWHPAo3+u6hH37buW2M9tYoG8BwgbOmuWmnx8ZHZ/AypMrEzYwONjNygOamkSwLQejk6JZtP89LNCrCDendTxi4X6FWah7SX7233N0ulz8YP4HzNs7L39aMJO7dpnfNKS+ftZuv8r+/cnv58xky8CW3Hd5H5cdX8Z6I7twwowILgrZaD4vxpRnRISb7Rb8ZCWxspMSICIiIiIiIn+P3QDGeCznBHARQJdb3F4JEMlAccmiWbPMzWjSjOuUemfpz0pO9kreZBqXmBhy927To2PSJHLZMtPD5fvvyRYtTOIlNeFRuLCZa6VOHTMUWfHiZr6VdImTSBRhK0ziZrxm1S3DO9yKV/62njAxKMTL8B7uzIUcf2hfboCn8QjP4wEm4g5r/xPQhrPwiZUQisad3I6XuRa1mIg7eA3FGIB6/AXPefW22YAajENab6OZOT4i7j3AHjl+sOp24CVWxk5+hmlex7IY9fkdBnqdyyx8wlexhavwpnVsn2AW38Mi7sPTVkxaYjJL4xSPoJy17QbUYHuM4l48a51rb5gE0HK8bbWrifUEyMWob9X1xE8EyG7oRVcOUxeLggTIOxFNFilClihB3nUXm+aeRRQ9wWF5OpL589ORE7yU824C5BtYY/ZZvDjn52hkne4N/IfMm5csUIAf3t2DeGwF16MmD90DfvsG+NV9bYicdj7+4Czac+c1PbkKFOD9CCNAHkIF65yaYyoBckGRliaJWLQo59/RxHr+1BgeRnnmhJMFEMd45CcBJiEvP8EsAuSJfBVNgvHuuzm8WB+i1Ea+/FxHMnduuvLk5r5SJYl8N5gr/2WO/rAM1zV8jqxRg88WOkHkiefJKk3MGHJvv82+j/sRIL8sPJOsUIGsWJHxT1Ui4CZAXn/+DZ6u9Twd1V5j55IzCZDfFptOVq5M1qjBQ/VfJ756gEU/qUHWqEFWqcLEiuX5VNG9RO5Ezr23g+npVqwY5+b+hABZ8emh7NvgHrJCBQbVqcA8HcoQpdfx1APVzEXPl48NC64gQC4p1op84AGybFl2enQZUfxXflhlAPn22+S77/KHJpWJjmVYoOivvF79RQ5u8yRndX6L1e4/bpKFrwwyWZtq1bildDMCZPnHpnFerfsZX7Y0m35WhHk/f4rIG8OX2z1C2MCJH5fl5DL9CZCVq3Zi16Ylea3K0+Szz7JwLtNrLOTB6nQ//TT5zDPsVmYuAbJhrR84rn1lOlq1YGTLTixYtS8LN/yQztpvkFWq0P1efT76ai8ibwy3vPA1Wbs2+dZbXPhsHyJXMsu/X5/vtbuHCY0b8lrl/2OBHPEEyLhXapO1avHo+1VZscIcIlcS1zSfRHbvTn7xBefVnECAfLHYabo6dqLzvx3o/PxzPlnkPAHy+EfdTTK7bVu+3rQO0ekhPtfgU9MzsUYNLm3fkHhuEh8sfJ32Hn24qMu7vKN7TlZ5bA5xz2He8VNe5umRk2u6NKStwjwCZI17DpING5LvvkvWr89C9+0h7jnME+93pq3Ts4QNfKjj40Sl8YQNzNsjFzfZmvHUt+OJ8ouYs8PjHNv/fbJLFyZ+Z3r94Nvi/Ln2QLb4viyb/vgEh1QNJB7ZwNw/5OOc+mXIl16i84kKzPP8WOLOiwyt8A754os8UOc5lm5VlqgyiJ8Vm8egT6ux19fPs0fbZ63XcUyDz9i33ZOc26IyOz++mLjnEB9u/TS3132Gm959mjm6m0Rhg5I7zeu1TBkO+OAp4plpzJEzkXzjDT793Z2EDcxfrR8B8nSD7zj/yxqc374mxz0zlAD57gO/kA0akO+8Q777Lh8qcI0AGdjgBytZMqaaH9HS9Nqq3/1xxk0c87/5vv0DlAARERERERH56+UF4ARQP139DACBt7gPJUAkA8XFN/2puMTGkr/+mnlvmJgYMiqK3LTJjP+0axfZvr1JqOzaRbZuTbZtS3btaoYm27jR9K65fp3cvt3MuB4YaNrfuEGeOkX26UOuX2+GOHM6zU9+o6PJq1fNZCTz55v1W7ea5922zfS0iYoyM8Zv2WJ62syZYxI6GzaY5zp71uwnJIScNo0cMcIkoHr2NMOZzZpFBgWZ8a+OHyc3byZXrjTjTKWWPXvMz+N79DDn+cUXZhypVq3IAQPIH38059q2rbkh99FHZoypTz81j/v2Jfv3J5s1o6tePUaWLs0k5DU9cooVI++7z9zkfuwxM27XO++QHTqYG6mtW5th3ho3Jps0IZs1Iz/+mCxXztyY/uADc4P+pZfIJ58kq1c3PYTatTNDtJUvb3oQpbZv0MBs06aNOZfSpTMmgcqVYzLy0B8fMRSlrPpLKMEjKMdwFPVqH4b7eQKPZqjbg0pWUoIAWagQXYUKe/UyIkzPo7N4iE6kzfOzH09xHj5gAvJZdaEoxRWow8WobyWmCDAKhRmLgl5JoiMoxy141SRVUuoicBd34wWv4eLcAJ1589OdN69X4swfH3EyWjIWBa36UyjNQNT1SnDFoBCH4Gv2QTev8+qHLrShO6NQ2Krbhiq0oTt34CWrLhYF2Rn92Rs/eF2TXXiRk9DK67liUZCVS4znN3d4tx2O//IbDPZKYIWiFCegDRfhPa+2TeHHLzHa6j1FmGTlaHzJMNxv1Y3H53wK+zkI31p113E3W2Mi22OU1z47YCRfxRbORSOvmIzGl17HT4Dd0IcfYzb35S/JXSXTzrUdxnAEOnq1HYN27IEeXtewH7qwMeYwAPWsugH4ngURy48x22v77rCxGjbxMMpbdZvxGmtjNeshwKt+ARpwIL5jNO606vqiK8viKNejplW3EO+zEvZYyUfCJEufxV6+iF08hwe9EpUVcIh90dUrhgUQx7xIsl7bCbnBjhjBl7CD8/LXYHyetNfhVxjKAfje2t6BXGyEuayLQF5DMbpygAeLg2ty1GDDnLPp/3hBBt8PunKAR1GWeZDMu3Hd67q8VWwo775/JYNQlc4coD0nuAjvsRJ2sUUe79j+F8PZCpMYiSJW3VrUYluM5US0tuqcyMnXsY5vYaVXstcfH7EeAvgNBtOJnEzKBXapnpcvFx/PHuhhtYtEEX6NIewOGwnwakFwwyNgo5yzWAqhXIj3rbY7UZlN4Ucbunsda2tM5OtYxzN4mGvKgFseMq8N5Ezmt3l6mM+HmjX/8Hfqn6UEiIiIiIiIyF/vfph/vF5OVz8IpmfIzdwB849aaikJgOHh4bTb7X97iY+PZ0BAAOPj47Pl+VUUl9upKC6+Way4REVl+7HY7Xbak5Npj4igPT7ePPaod2zdSvuxY7Rfvkx7WBjt+/aZv1ev0h4VRXtcnNn24kXaT52i/ddfaQ8Opj0khPYjR2g/d87UHz9O+5UrafuOjzfrf/mF9tOnaY+JMetDQ+nYts2sCw01+7pyxTzf6dNm/7t3m3L6NO0nT5rju3SJ9oQE83wXL9J+/Trte/bQERRE+y+/mH3u2mWO4+BB2iMjTbl0yZTUuCxezPiICNqvXqVjxQo6du402xw9Svvu3XRs2kRHUJDZX2ioObd9++jYsoWO5cvp+PlnOqZNo2PWLFNmzqTDz4+OqVPpmDyZjokT6Vi82Oxj7Vo6Vq0y2y1dSseSJXQsXEjHvHl0+PubbefPN8excKFZnjSJztGj6Zgzxyz7+5vtUx9v2GCOMyiIjmXL6Ni6lY4FC8yxrFpl9jN9Oh1TptAxb565JgcOmHbbt5vz3bWLjsmT6ezalc5+/egcNYqOSZPoGDfO/J01i47AQDqmTaPzm29M+fFH03b4cHOO48aZY1+7lo41a8zfoCDzOCDAHOuUKXT27m2OZ+5cc2z+/uZ4AwLM8QcEMGnuXO7s1o2JAQF0zJhB56BBdA4fbv727UunzUZn165M/rKj2d+UKabdqFF0TJhA54ABpm7qVPN30iQ6R46kc+RIOqZONfsZMoSO2bPpWLTIxHDGDHN8Y8bQ2aEDna1b0/nFF3T+97/mXLt1o/OHH8y5d+5M59df0/nTT3R2727+pl4Tm43OoUPp7NOHzu7d6WrZ0rRv3oJHn/6A9o8/Nfvv3t28bsaPN/to3ZrOTp3o/O47c11Hj6Zz1ChzPKNGmWMeMMCs69OHzl69zLXo1Yuuzz6js00bOtu0oatZM7o++ojOBg3p+uADOtu3p/Orr+j89lsT39696fz+e7qaNzfn0KOHiceiRSYO06aZWE6ZYq7P/Pnmtbd0KRMXLWJIhw5MHjTInOugQda1dA4bRueIEWnHPHZs2j4mTjTX4ccfzbUZNSrtuk+dap5z+nQ6u3al67336GrWjM4vv6SzSxdzvD17mu3GjKGzf386hw2zXnPOYcPMNene3Vy7Xr3o/PFHxr3/Ma9Wa2DOf/TobPusDQ8PVwJERERERETkL/ZHEiC2lG28ir+/PwMCAlRUVFRUVFRUVFRUfqf4+/srASIiIiIiIvIX+yNDYKkHiIricpsWxcU3i+Lim0Vx8c2iuPhmUVyyXtQDRERERERE5O+xG8Boj+WcAMKgSdDlT1BcfJPi4psUF9+kuPgmxcU3KS5ZpzlARERERERE/h4fAkgC0AxAeQATAUQCuPcWt1cCRDJQXHyT4uKbFBffpLj4JsXFNykuWacEiIiIiIiIyN+nPYBzAJJheoRUzsK2SoBIBoqLb1JcfJPi4psUF9+kuPgmxSXrlAARERERERG5PSgBIhkoLr5JcfFNiotvUlx8k+LimxSXrFMCRERERERE5PagBIhkoLj4JsXFNykuvklx8U2Ki29SXLJOCRAREREREZHbQ2EAvHDhAqOjo//2Eh4eTn9/f4aHh2fL86soLrdTUVx8syguvlkUF98siotvFsUl6+XChQtKgIiIiIiIiNwGSsL886aioqKioqKioqKikrVSEiIiIiIiIuKzcsD841Y4m0pqAiY7j0FFcbldiuLim0Vx8c2iuPhmUVx8syguf/y65YCIiIiIiIhIJgrD/MNdOLsPRLwoLr5JcfFNiotvUlx8k+LimxQXERERERERkb+A/uH2TYqLb1JcfJPi4psUF9+kuPgmxUVERERERETkL6B/uH2T4uKbFBffpLj4JsXFNykuvklxEREREREREfkL3AHAlvJXfIfi4psUF9+kuPgmxcU3KS6+SXERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERGf8yWAswCSAOwG8GK2Hs3trSqAZQAuASCA+unW5wDQC8BlAIkA1gN4LF2bogDmAIgBEAVgKoBC6do8BWArTMwuAPj+JsfyAYBjKW1+BfD2Hzmhf4CuAIIBxAK4BiAAQNl0bfIBGAsgAkAcgEUA7k3X5iEAKwAkpOxnMIDc6dpUBxACIBnAKQCf3eR49H4z2gI4CPM6jwGwE0Adj/WKiW/oAvNZNsKjTrH5+9lg4uBZjnmsV0yyT0kAs2GufSLM920lj/X63hcRERERERHJRh/C3OhoDqACgEkAIgEUz86Duo3VAdAHwHu4eQKkM8zNjXdhbmYEAgiFuXmVahWA/QAqA3gVwEkA/h7rCwO4AnPD5QkAH8Hc0Grj0aYKACeA7wCUB9AbgB3Ak3/y/G5Hq2Fu4j0B4GmYG4DnABT0aDMewHkANQE8D3MzfrvH+lwwN5PWAXgGJs7XAfTzaPMIgHgAQ2GueXuYGLzp0UbvtzR1YW7OPQbgcQB9YV6jT6SsV0yy3wsAzgA4AO8EiGLz97MBOASghEcp5rFeMcked8Ekg6bDJIIeAVAbQBmPNvreFxEREREREclGuwGM8VjOCeAizK9+5c9JnwDJAfML0G896orA/FLzo5Tl8inbef569C0AbgD3pyy3BXADQF6PNgPg/WvgeQCWpzueXQAmZPUk/oHugbnGVVOWi8DvPgVSAAAQ4ElEQVTcJGro0aZcSpuXUpbrAHDB+xfVXwCIRlocBsLcoPQ0FyYBk0rvt992A0BLKCa+oBCAEwBqAQhCWgJEsckeNpgb5DejmGSfATC9MjKj730RERERERGRbJQX5teC6XspzID5haL8OekTIKVT6p5J124zgJEpj1vA/JrWU26YOL2XsjwTZhgnTzVS9n1XyvJ5AJ3StekJ80vuf7tHYa5V6q9ia6Ys/yddu3MAvkp53AsZbz4+krLdsynLW+D9K3nA/Eo6OuWx3m+ZywVzMzAZ5lflikn2mwFgeMrjIKRdR8Ume9hgemdcguk9MAdmSCtAMclOR2DeJwtghhXbB6C1x3p974uIiIiIiIhko/th/nl+OV39IJhfecqfkz4BUiWl7r507ebD/HITALoBOH6TfV2D+QUoAKwFMDHd+gop+y6fsmwH0Dhdm3YArt7isf9T5YT5hew2j7qPYW68p7cH5hfRgBnmZU269QVgrnnqvBUnYOYb8fR2Spv80PvtZirCzFfghBkiJnW8esUke30EM1xS6hA9QUi7Ma7YZI86MPM7PAUzJNUOmATHnVBMslNSSukHk0hqAzPPR7OU9freFxEREREREclGupnx11ICxPeMhxmv/QGPOt08zD55YXrkPA+gP8ycBBWgmGSnB2E+J57yqAuCEiC+5j8wPTNaQjHJTnaYZJSnUTBzsAD63hcRERERERHJVhrO4q+lIbB8yxgAF2CGffGk4WN8x3qYm3yKSfapD3MNnR6FMPMROAG8DsXGVwTDJA71fsk+5wBMSVfXFmZeFEDf+yIiIiIiIiLZbjeA0R7LOQGE4d87oen/UmaToH/jUVcYN58M9XmPNrVx88lQ83i06YeMk6EuS3c8O/DvnAw1B0zy4yKAx26yPnUC4QYedWVx8wmEi3u0aQNzY/COlOWBMMMGefJHxgmE9X7L3EYAflBMstOdMPPjeJZgALNSHis2vqEQzPdARygm2ckfGSdBH460XiH63hcRERERERHJZh/C/CPeDOaf8Ikwv0S8NzsP6jZWCOaXns/A3ND4KuVx6mS1nWGubz2Y+Q8CYCa0zeexj1UAQgC8COAVmGFJ/D3WFwFwBeYXoU/AxDAe5mZWqioAHDA3XcrBTKBrR9rE3/8m42Dml6gGoIRHye/RZjzML3lrwNyE2gHvYU1ywdwYXAPgaZgx+K/B3IBK9QhMHAbBXPN2ML/gfdOjjd5vafoDqAqgFMx7oT/MDb83UtYrJr4jCN49AxSbv98QmM+wUjCf7+tghoy7J2W9YpI9XoD5ru0GM5zfxzDX8BOPNvreFxEREREREclm7WFunCTD/LqzcvYezm2tOkziI33xS1mfA2YokiswN5HWA3g83T6Kwtz4iIX5de40mMSKp6dgfnWaBPPr2843OZYPYMYVTwZwCGkTTP/b3CweBPCZR5t8AMbC/MI2HsBimCSJp4cBrASQAHPjcQjMMCWeqgPYB3PNT6d7jlR6vxlTYeZjSYa5EbseackPQDHxJUHwToAoNn+/uQAuwVyHsJTlMh7rFZPs838wyaUkAEcBtE63Xt/7IiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIre7UgAI4Jm/8Dn8AAT8hfsXEREREREREREREZF/GD+YBEb6svoWt88FoASA3H/FwaXwgxIgIiIiIiIiIiIiIiKSBX4AVsEkMTzLXdl4TOn5QQkQERERERERERERERHJAj/8dnKBANrCJEkSAYQCaOixvhS8h8C6C8AcANdT2p8E0NyjfUUAG1PWRQCYBKCQx/pcAIYBiEpZPwjAjHTHmBNAVwBnUvZzIN0xiYiIiIiIiIiIiIjIv5wffj8BEg6gFYDHAfQG4ARQPmV9KXgnQMYA2AegUsq6WgDqpqwrCOASgEUAngRQEyah4ufxfN8DuAHg/ZTnmAIgJt0x/gDgKIA3AZQG8BmAJADVbuF8RURERERERERERETkX8APJqERl650S1lPAOPTbbMLwLiUx6XgnQBZCmBaJs/VGia5UdCj7m0ALgD3pixfAvCdx/rcAC4gLQFyB4B4AC+n2/cUAP6ZPK+IiIiIiIiIiIiIiPzL+AFYB+DRdKVoynoCaJpum+EANqU8LgXvBEgdAAkA9sMMX1XFY7thHtulKpKyfdV0jz0tQVoC5ImUNukTNnYAu3/vZEVERERERERERERE5N/BD78/BFZWEiAAcA+AZgBmw8zRMSSl/n+RAKmc0qYaMiZtHvyN8xARERERERERERERkX8RP/x+AmRcurqdyHwIrPQ+h5nDA/jjQ2Cd9zjGO2Hm+/j0N45ZRERERERERERERET+5fwArAJQIl0plrKeAK4DaAEzCXpPmIRFhZT1peCdAOkF4F2YHhlPAFiGtKGpCsAkOBbCTIJeA8BpeE+C3hlABID6AMoBmISMk6D3gZmYvRmAMgCeA9AhZVlERERERERERERERAR+MAmM9OVYynoCaAdgLUzPizMAGnlsXwreCZAfARyBmQckAiZx8YhH+4oANsIMjRUBk+Ao5LE+N4ARAKIBRAIYCmAGvBMgOQD8N+UY7QCuAViNjENniYiIiIiIiIiIiIiI3BRhemOIiIiIiIiIiIiIiIj8YygBIiIiIiIiIiIiIiIi/zhKgIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiPx/e3BAAgAAACDo/+t2BCoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB8BRF6q6D6EjqPAAAAAElFTkSuQmCC\" width=\"800\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"800\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lander Env\n",
      "Landing_icgen:\n",
      "    nominal_g                   :  -3.7114\n",
      "    downrange                   :  (0, 2000, -70, -10)\n",
      "    crossrange                  :  (-1000, 1000, -30, 30)\n",
      "    altitude                    :  (2300, 2400, -90, -70)\n",
      "    adjust_apf_v0               :  True\n",
      "Policy with vectorized sample\n",
      "\txn_init: layer  Linear(in_features=3, out_features=30, bias=True)\n",
      "\txn_init: layer  GRUCell(30, 30)\n",
      "\txn_init: layer  Linear(in_features=30, out_features=30, bias=True)\n",
      "\txn_init: layer  Linear(in_features=30, out_features=3, bias=True)\n",
      "Policy: recurrent steps > 1, disabling shuffle\n",
      "[[-1.]\n",
      " [ 0.]\n",
      " [ 1.]]\n",
      "\tTest Mode:          False\n",
      "\tClip Param:         0.1\n",
      "\tShuffle :           False\n",
      "\tMax Grad Norm:      30\n",
      "\tRecurrent Steps:    60\n",
      "\tRollout Limit:      1\n",
      "Value Funtion\n",
      "\txn_init: layer  Linear(in_features=5, out_features=50, bias=True)\n",
      "\txn_init: layer  GRUCell(50, 15)\n",
      "\txn_init: layer  Linear(in_features=15, out_features=5, bias=True)\n",
      "\txn_init: layer  Linear(in_features=5, out_features=1, bias=True)\n",
      "Value Function: recurrent steps > 1, disabling shuffle and batching\n",
      "\tClip Range:         0.5\n",
      "\tShuffle :           False\n",
      "\tBatch Size :        9999999\n",
      "\tMax Grad Norm:      30\n",
      "\tRecurrent Steps:    60\n",
      "\tRollout Limit:      1\n",
      "Agent\n",
      "*** SCALER WARMUP COMPLETE *** \n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0861   0.0288   0.1261   0.1261   0.0861   0.0288\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7971   0.5555   1.6645   1.6645   0.7971   0.5555\n",
      "Update Cnt = 0    ET =     12.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   370.0   207.2    -3.8 |   779.9   575.8     2.4 | -1409.8 -1254.8    -8.4 |  1804.9  1352.3    -0.2\n",
      "v_f      |  -33.54    3.93 -155.48 |   24.81   17.06   11.49 |  -87.61  -26.73 -176.29 |    7.44   30.89 -132.34\n",
      "vr_f     |     6.6 |     8.0 |     1.5 |    45.0\n",
      "r_i      |  1029.8   165.8  2352.7 |   622.0   488.8    28.5 |   145.8  -890.5  2306.6 |  1985.7   959.6  2398.3\n",
      "v_i      |  -35.45    3.06  -77.04 |   18.19   15.40    5.62 |  -69.32  -22.47  -90.00 |  -10.02   29.81  -70.08\n",
      "norm_rf  |   936.9 |   491.7 |   221.0 |  1987.6\n",
      "norm_vf  |  161.85 |   12.54 |  135.50 |  186.46\n",
      "thrust   |     186     108    -210 |    7400    7373    7395 |  -14993  -14977  -14997 |   14992   14930   14944\n",
      "norm_thrust |   12357 |    3348 |    2000 |   15000\n",
      "fuel     |     123 |       8 |     111 |     144\n",
      "rewards  | -100.52 |    9.71 | -135.10 |  -86.91\n",
      "fuel_rewards |   -4.24 |    0.29 |   -4.95 |   -3.83\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    2.52 |    1.35 |    1.03 |    7.30\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  931.90 |  491.71 |  215.96 | 1982.61\n",
      "tracking_rewards |  -96.28 |    9.71 | -130.46 |  -82.82\n",
      "steps    |     102 |       6 |      93 |     119\n",
      "***** Episode 0, Mean R = -100.5  Std R = 9.7  Min R = -135.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.0023\n",
      "ExplainedVarOld: 0.0327\n",
      "KL: 0.000861\n",
      "PolicyEntropy: 2.74\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 3.17e+03\n",
      "TotalSteps: 3.17e+03\n",
      "ValFuncLoss: 0.235\n",
      "Variance: 0.609\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0736   0.0178   0.0906   0.1261   0.0861   0.0288\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0618   0.0138   0.1013   1.6645   0.7971   0.5555\n",
      "***** Episode 31, Mean R = -99.3  Std R = 9.2  Min R = -139.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.203\n",
      "ExplainedVarOld: -0.0427\n",
      "KL: 0.000987\n",
      "PolicyEntropy: 2.73\n",
      "PolicyLoss: -0.00128\n",
      "Steps: 3.18e+03\n",
      "TotalSteps: 6.35e+03\n",
      "ValFuncLoss: 0.0758\n",
      "Variance: 0.604\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1203   0.0348   0.1628   0.1628   0.1203   0.0348\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0467   0.0139   0.0809   1.6645   0.7971   0.5555\n",
      "***** Episode 62, Mean R = -99.8  Std R = 8.5  Min R = -125.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.545\n",
      "ExplainedVarOld: 0.4\n",
      "KL: 0.0023\n",
      "PolicyEntropy: 2.72\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 3.14e+03\n",
      "TotalSteps: 9.49e+03\n",
      "ValFuncLoss: 0.06\n",
      "Variance: 0.61\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1348   0.0366   0.1832   0.1832   0.1348   0.0366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0264   0.0025   0.0301   1.6645   0.7971   0.5555\n",
      "***** Episode 93, Mean R = -102.8  Std R = 11.6  Min R = -134.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.769\n",
      "ExplainedVarOld: 0.713\n",
      "KL: 0.000716\n",
      "PolicyEntropy: 2.71\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 3.18e+03\n",
      "TotalSteps: 1.27e+04\n",
      "ValFuncLoss: 0.033\n",
      "Variance: 0.609\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1163   0.0211   0.1549   0.1832   0.1348   0.0366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0422   0.0248   0.1167   1.6645   0.7971   0.5555\n",
      "***** Episode 124, Mean R = -96.9  Std R = 9.4  Min R = -125.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.795\n",
      "ExplainedVarOld: 0.725\n",
      "KL: 0.000597\n",
      "PolicyEntropy: 2.71\n",
      "PolicyLoss: -0.00176\n",
      "Steps: 3.36e+03\n",
      "TotalSteps: 1.6e+04\n",
      "ValFuncLoss: 0.0182\n",
      "Variance: 0.604\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1975   0.0699   0.3232   0.3232   0.1975   0.0699\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0413   0.0203   0.0984   1.6645   0.7971   0.5555\n",
      "***** Episode 155, Mean R = -100.5  Std R = 9.3  Min R = -120.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.874\n",
      "ExplainedVarOld: 0.852\n",
      "KL: 0.00086\n",
      "PolicyEntropy: 2.71\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 3.22e+03\n",
      "TotalSteps: 1.92e+04\n",
      "ValFuncLoss: 0.0103\n",
      "Variance: 0.604\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2106   0.0600   0.2909   0.3232   0.2106   0.0699\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0194   0.0078   0.0358   1.6645   0.7971   0.5555\n",
      "***** Episode 186, Mean R = -102.0  Std R = 10.9  Min R = -141.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.908\n",
      "ExplainedVarOld: 0.888\n",
      "KL: 0.00118\n",
      "PolicyEntropy: 2.7\n",
      "PolicyLoss: -0.00341\n",
      "Steps: 3.30e+03\n",
      "TotalSteps: 2.26e+04\n",
      "ValFuncLoss: 0.00599\n",
      "Variance: 0.599\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1824   0.0529   0.2354   0.3232   0.2106   0.0699\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0203   0.0087   0.0410   1.6645   0.7971   0.5555\n",
      "***** Episode 217, Mean R = -101.4  Std R = 10.7  Min R = -136.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000912\n",
      "PolicyEntropy: 2.69\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 3.34e+03\n",
      "TotalSteps: 2.59e+04\n",
      "ValFuncLoss: 0.00386\n",
      "Variance: 0.596\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1706   0.0540   0.2281   0.3232   0.2106   0.0699\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0133   0.0076   0.0322   1.6645   0.7971   0.5555\n",
      "***** Episode 248, Mean R = -101.1  Std R = 11.9  Min R = -140.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.907\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.00106\n",
      "PolicyEntropy: 2.68\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 3.39e+03\n",
      "TotalSteps: 2.93e+04\n",
      "ValFuncLoss: 0.00531\n",
      "Variance: 0.598\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1742   0.0523   0.2623   0.3232   0.2106   0.0699\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0041   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 279, Mean R = -99.8  Std R = 10.8  Min R = -125.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.912\n",
      "ExplainedVarOld: 0.888\n",
      "KL: 0.00123\n",
      "PolicyEntropy: 2.67\n",
      "PolicyLoss: -0.00393\n",
      "Steps: 3.40e+03\n",
      "TotalSteps: 3.27e+04\n",
      "ValFuncLoss: 0.00409\n",
      "Variance: 0.593\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1570   0.0705   0.2733   0.3232   0.2106   0.0705\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0181   0.0099   0.0505   1.6645   0.7971   0.5555\n",
      "Update Cnt = 10    ET =     83.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   205.1    28.0    -3.7 |   749.5   637.2     2.1 | -1642.8 -1529.9    -8.0 |  1852.4  1409.0    -0.0\n",
      "v_f      |  -38.89    2.86 -146.11 |   21.04   19.51   14.81 |  -91.09  -48.31 -177.69 |   10.82   61.17 -104.52\n",
      "vr_f     |     4.4 |     4.2 |     1.5 |    45.3\n",
      "r_i      |   964.5     7.0  2351.9 |   584.9   574.2    30.1 |     0.2  -988.6  2300.1 |  1991.6   998.1  2399.9\n",
      "v_i      |  -38.89    1.44  -80.55 |   17.20   17.26    5.78 |  -69.90  -29.59  -89.99 |  -10.06   29.97  -70.02\n",
      "norm_rf  |   907.9 |   431.8 |    43.3 |  2010.9\n",
      "norm_vf  |  153.86 |   15.41 |  110.99 |  192.31\n",
      "thrust   |      36     139    1178 |    7253    7263    7385 |  -14998  -14993  -14999 |   14998   14995   14998\n",
      "norm_thrust |   12226 |    3439 |    2000 |   15000\n",
      "fuel     |     126 |      11 |     102 |     170\n",
      "rewards  | -100.12 |   10.34 | -141.88 |  -80.41\n",
      "fuel_rewards |   -4.35 |    0.38 |   -5.87 |   -3.54\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    2.18 |    1.02 |    1.00 |    7.20\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  904.30 |  429.20 |  141.49 | 2005.91\n",
      "tracking_rewards |  -95.77 |   10.33 | -137.15 |  -75.46\n",
      "steps    |     106 |       8 |      90 |     137\n",
      "***** Episode 310, Mean R = -97.6  Std R = 8.9  Min R = -118.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.00104\n",
      "PolicyEntropy: 2.66\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 3.37e+03\n",
      "TotalSteps: 3.61e+04\n",
      "ValFuncLoss: 0.00297\n",
      "Variance: 0.588\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2268   0.0962   0.3654   0.3654   0.2268   0.0962\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0071   0.0030   0.0159   1.6645   0.7971   0.5555\n",
      "***** Episode 341, Mean R = -97.5  Std R = 10.2  Min R = -126.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.00115\n",
      "PolicyEntropy: 2.64\n",
      "PolicyLoss: -0.00345\n",
      "Steps: 3.47e+03\n",
      "TotalSteps: 3.95e+04\n",
      "ValFuncLoss: 0.00345\n",
      "Variance: 0.588\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2720   0.1001   0.4681   0.4681   0.2720   0.1001\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0145   0.0079   0.0390   1.6645   0.7971   0.5555\n",
      "***** Episode 372, Mean R = -96.1  Std R = 6.8  Min R = -113.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 2.61\n",
      "PolicyLoss: -0.00471\n",
      "Steps: 3.45e+03\n",
      "TotalSteps: 4.3e+04\n",
      "ValFuncLoss: 0.00147\n",
      "Variance: 0.585\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2289   0.1005   0.3955   0.4681   0.2720   0.1005\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0140   0.0064   0.0288   1.6645   0.7971   0.5555\n",
      "***** Episode 403, Mean R = -97.4  Std R = 10.2  Min R = -121.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 2.61\n",
      "PolicyLoss: -0.00371\n",
      "Steps: 3.58e+03\n",
      "TotalSteps: 4.65e+04\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.583\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2471   0.0812   0.3706   0.4681   0.2720   0.1005\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0263   0.0136   0.0637   1.6645   0.7971   0.5555\n",
      "***** Episode 434, Mean R = -97.7  Std R = 10.1  Min R = -126.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.00093\n",
      "PolicyEntropy: 2.6\n",
      "PolicyLoss: -0.00376\n",
      "Steps: 3.52e+03\n",
      "TotalSteps: 5.01e+04\n",
      "ValFuncLoss: 0.00375\n",
      "Variance: 0.577\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3087   0.1086   0.4738   0.4738   0.3087   0.1086\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0140   0.0075   0.0311   1.6645   0.7971   0.5555\n",
      "***** Episode 465, Mean R = -96.8  Std R = 9.2  Min R = -116.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 2.59\n",
      "PolicyLoss: -0.00411\n",
      "Steps: 3.68e+03\n",
      "TotalSteps: 5.38e+04\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.574\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2657   0.0756   0.4143   0.4738   0.3087   0.1086\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0172   0.0089   0.0406   1.6645   0.7971   0.5555\n",
      "***** Episode 496, Mean R = -93.6  Std R = 6.7  Min R = -110.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000778\n",
      "PolicyEntropy: 2.59\n",
      "PolicyLoss: -0.0038\n",
      "Steps: 3.62e+03\n",
      "TotalSteps: 5.74e+04\n",
      "ValFuncLoss: 0.00165\n",
      "Variance: 0.576\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1496   0.0624   0.2288   0.4738   0.3087   0.1086\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0189   0.0099   0.0454   1.6645   0.7971   0.5555\n",
      "***** Episode 527, Mean R = -98.8  Std R = 13.4  Min R = -149.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.888\n",
      "ExplainedVarOld: 0.865\n",
      "KL: 0.000905\n",
      "PolicyEntropy: 2.58\n",
      "PolicyLoss: -0.00204\n",
      "Steps: 3.77e+03\n",
      "TotalSteps: 6.11e+04\n",
      "ValFuncLoss: 0.00404\n",
      "Variance: 0.575\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2594   0.1007   0.3817   0.4738   0.3087   0.1086\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0038   0.0167   1.6645   0.7971   0.5555\n",
      "***** Episode 558, Mean R = -98.3  Std R = 12.0  Min R = -131.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000635\n",
      "PolicyEntropy: 2.58\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 3.88e+03\n",
      "TotalSteps: 6.5e+04\n",
      "ValFuncLoss: 0.00259\n",
      "Variance: 0.577\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2218   0.0843   0.3398   0.4738   0.3087   0.1086\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0082   0.0035   0.0144   1.6645   0.7971   0.5555\n",
      "***** Episode 589, Mean R = -94.8  Std R = 10.2  Min R = -128.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.000795\n",
      "PolicyEntropy: 2.57\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 3.83e+03\n",
      "TotalSteps: 6.89e+04\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.578\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2247   0.0900   0.3337   0.4738   0.3087   0.1086\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0170   0.0095   0.0451   1.6645   0.7971   0.5555\n",
      "Update Cnt = 20    ET =     89.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   225.0    37.0    -3.2 |   615.4   618.2     1.9 | -1233.3 -1652.5    -7.5 |  1668.5  1420.7    -0.0\n",
      "v_f      |  -35.59    4.87 -124.15 |   19.81   19.69   16.84 |  -78.95  -42.61 -166.06 |    9.98   47.01  -79.21\n",
      "vr_f     |     4.4 |     5.6 |     1.1 |    61.9\n",
      "r_i      |  1065.1    -5.7  2350.4 |   562.2   574.0    28.7 |    17.4  -992.3  2300.2 |  1987.3   999.4  2400.0\n",
      "v_i      |  -41.23    1.03  -79.99 |   17.50   17.36    6.06 |  -69.99  -29.73  -89.92 |  -10.31   29.45  -70.04\n",
      "norm_rf  |   817.1 |   381.2 |    48.8 |  1763.5\n",
      "norm_vf  |  132.36 |   15.73 |   83.77 |  168.87\n",
      "thrust   |     495     306    3527 |    7031    7125    6989 |  -14997  -14998  -14999 |   14998   14999   14999\n",
      "norm_thrust |   12251 |    3427 |    2000 |   15000\n",
      "fuel     |     141 |      17 |     107 |     199\n",
      "rewards  |  -96.47 |   10.14 | -149.77 |  -78.18\n",
      "fuel_rewards |   -4.87 |    0.58 |   -6.84 |   -3.67\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    2.04 |    0.97 |    0.96 |    6.61\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  813.13 |  379.17 |  113.27 | 1758.45\n",
      "tracking_rewards |  -91.61 |   10.13 | -143.37 |  -72.61\n",
      "steps    |     118 |      12 |      95 |     159\n",
      "***** Episode 620, Mean R = -93.8  Std R = 9.1  Min R = -113.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.00091\n",
      "PolicyEntropy: 2.55\n",
      "PolicyLoss: -0.00325\n",
      "Steps: 3.91e+03\n",
      "TotalSteps: 7.28e+04\n",
      "ValFuncLoss: 0.00139\n",
      "Variance: 0.574\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3173   0.1208   0.4858   0.4858   0.3173   0.1208\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0192   0.0104   0.0422   1.6645   0.7971   0.5555\n",
      "***** Episode 651, Mean R = -90.8  Std R = 7.0  Min R = -115.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000966\n",
      "PolicyEntropy: 2.53\n",
      "PolicyLoss: -0.00423\n",
      "Steps: 3.84e+03\n",
      "TotalSteps: 7.66e+04\n",
      "ValFuncLoss: 0.00143\n",
      "Variance: 0.572\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2985   0.1148   0.4783   0.4858   0.3173   0.1208\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0275   0.0156   0.0646   1.6645   0.7971   0.5555\n",
      "***** Episode 682, Mean R = -96.7  Std R = 11.4  Min R = -119.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000806\n",
      "PolicyEntropy: 2.51\n",
      "PolicyLoss: -0.00362\n",
      "Steps: 3.89e+03\n",
      "TotalSteps: 8.05e+04\n",
      "ValFuncLoss: 0.00172\n",
      "Variance: 0.568\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3053   0.1088   0.4935   0.4935   0.3173   0.1208\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0201   0.0115   0.0475   1.6645   0.7971   0.5555\n",
      "***** Episode 713, Mean R = -95.3  Std R = 15.0  Min R = -147.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000896\n",
      "PolicyEntropy: 2.5\n",
      "PolicyLoss: -0.00392\n",
      "Steps: 4.03e+03\n",
      "TotalSteps: 8.45e+04\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.565\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3661   0.1571   0.5926   0.5926   0.3661   0.1571\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0042   0.0185   1.6645   0.7971   0.5555\n",
      "***** Episode 744, Mean R = -95.6  Std R = 11.6  Min R = -125.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000934\n",
      "PolicyEntropy: 2.48\n",
      "PolicyLoss: -0.00493\n",
      "Steps: 4.02e+03\n",
      "TotalSteps: 8.85e+04\n",
      "ValFuncLoss: 0.00123\n",
      "Variance: 0.561\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1870   0.0600   0.2823   0.5926   0.3661   0.1571\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0188   0.0096   0.0440   1.6645   0.7971   0.5555\n",
      "***** Episode 775, Mean R = -94.1  Std R = 10.6  Min R = -123.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.912\n",
      "KL: 0.000958\n",
      "PolicyEntropy: 2.46\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 4.16e+03\n",
      "TotalSteps: 9.27e+04\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.555\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3439   0.1239   0.5199   0.5926   0.3661   0.1571\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0031   0.0147   1.6645   0.7971   0.5555\n",
      "***** Episode 806, Mean R = -93.3  Std R = 11.9  Min R = -140.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00122\n",
      "PolicyEntropy: 2.44\n",
      "PolicyLoss: -0.00461\n",
      "Steps: 4.14e+03\n",
      "TotalSteps: 9.68e+04\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.553\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3213   0.1311   0.5164   0.5926   0.3661   0.1571\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0143   0.0076   0.0349   1.6645   0.7971   0.5555\n",
      "***** Episode 837, Mean R = -98.3  Std R = 14.5  Min R = -140.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00121\n",
      "PolicyEntropy: 2.41\n",
      "PolicyLoss: -0.00461\n",
      "Steps: 4.16e+03\n",
      "TotalSteps: 1.01e+05\n",
      "ValFuncLoss: 0.00113\n",
      "Variance: 0.551\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3806   0.1487   0.6530   0.6530   0.3806   0.1571\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0123   0.0066   0.0303   1.6645   0.7971   0.5555\n",
      "***** Episode 868, Mean R = -89.8  Std R = 12.9  Min R = -140.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.00156\n",
      "PolicyEntropy: 2.38\n",
      "PolicyLoss: -0.00616\n",
      "Steps: 4.16e+03\n",
      "TotalSteps: 1.05e+05\n",
      "ValFuncLoss: 0.000835\n",
      "Variance: 0.544\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3689   0.1203   0.5801   0.6530   0.3806   0.1571\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0074   0.0035   0.0144   1.6645   0.7971   0.5555\n",
      "***** Episode 899, Mean R = -95.1  Std R = 12.7  Min R = -130.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000897\n",
      "PolicyEntropy: 2.35\n",
      "PolicyLoss: -0.00418\n",
      "Steps: 4.31e+03\n",
      "TotalSteps: 1.09e+05\n",
      "ValFuncLoss: 0.00137\n",
      "Variance: 0.542\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3278   0.1285   0.5238   0.6530   0.3806   0.1571\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0049   0.0254   1.6645   0.7971   0.5555\n",
      "Update Cnt = 30    ET =     99.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   150.9    18.5    -2.6 |   649.8   514.9     1.5 | -1426.7 -1311.7    -6.4 |  1751.4  1179.6    -0.0\n",
      "v_f      |  -25.68    3.39 -102.52 |   19.28   23.41   15.43 |  -84.08  -47.31 -137.39 |   26.00   63.93  -47.94\n",
      "vr_f     |     3.9 |     3.3 |     1.1 |    27.5\n",
      "r_i      |   985.7    -5.6  2348.5 |   568.4   575.9    28.9 |     1.6  -983.9  2301.2 |  1992.4   999.3  2399.4\n",
      "v_i      |  -41.94   -0.37  -79.33 |   17.38   17.16    5.78 |  -69.30  -29.94  -89.94 |  -10.00   29.88  -70.14\n",
      "norm_rf  |   739.7 |   404.2 |    39.6 |  2103.3\n",
      "norm_vf  |  110.09 |   14.84 |   63.63 |  143.32\n",
      "thrust   |    1189     292    5437 |    6725    6933    6381 |  -14998  -15000  -14969 |   14999   15000   15000\n",
      "norm_thrust |   12394 |    3384 |    2000 |   15000\n",
      "fuel     |     160 |      20 |     123 |     259\n",
      "rewards  |  -94.25 |   12.33 | -147.38 |  -71.62\n",
      "fuel_rewards |   -5.52 |    0.68 |   -8.91 |   -4.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.84 |    0.73 |    0.98 |    5.62\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  735.56 |  402.76 |   84.04 | 2098.34\n",
      "tracking_rewards |  -88.73 |   12.29 | -141.75 |  -65.28\n",
      "steps    |     133 |      14 |     104 |     206\n",
      "***** Episode 930, Mean R = -93.5  Std R = 11.4  Min R = -118.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000657\n",
      "PolicyEntropy: 2.34\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 4.5e+03\n",
      "TotalSteps: 1.14e+05\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.54\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3855   0.1696   0.6108   0.6530   0.3855   0.1696\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0023   0.0115   1.6645   0.7971   0.5555\n",
      "***** Episode 961, Mean R = -91.0  Std R = 11.1  Min R = -121.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000828\n",
      "PolicyEntropy: 2.32\n",
      "PolicyLoss: -0.00403\n",
      "Steps: 4.45e+03\n",
      "TotalSteps: 1.18e+05\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.537\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3721   0.1600   0.6104   0.6530   0.3855   0.1696\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0047   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 992, Mean R = -87.2  Std R = 10.4  Min R = -113.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.00127\n",
      "PolicyEntropy: 2.3\n",
      "PolicyLoss: -0.00469\n",
      "Steps: 4.75e+03\n",
      "TotalSteps: 1.23e+05\n",
      "ValFuncLoss: 0.00156\n",
      "Variance: 0.531\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2411   0.0869   0.4070   0.6530   0.3855   0.1696\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0049   0.0021   0.0097   1.6645   0.7971   0.5555\n",
      "***** Episode 1023, Mean R = -92.1  Std R = 10.4  Min R = -111.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.00119\n",
      "PolicyEntropy: 2.27\n",
      "PolicyLoss: -0.00341\n",
      "Steps: 4.85e+03\n",
      "TotalSteps: 1.28e+05\n",
      "ValFuncLoss: 0.00178\n",
      "Variance: 0.528\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2954   0.1123   0.5220   0.6530   0.3855   0.1696\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0153   0.0084   0.0339   1.6645   0.7971   0.5555\n",
      "***** Episode 1054, Mean R = -90.8  Std R = 12.8  Min R = -124.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.00107\n",
      "PolicyEntropy: 2.25\n",
      "PolicyLoss: -0.0043\n",
      "Steps: 4.77e+03\n",
      "TotalSteps: 1.33e+05\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.526\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3279   0.1198   0.5200   0.6530   0.3855   0.1696\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0029   0.0134   1.6645   0.7971   0.5555\n",
      "***** Episode 1085, Mean R = -93.5  Std R = 16.4  Min R = -143.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 2.23\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 4.98e+03\n",
      "TotalSteps: 1.38e+05\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.523\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2751   0.1153   0.4889   0.6530   0.3855   0.1696\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0133   0.0060   0.0303   1.6645   0.7971   0.5555\n",
      "***** Episode 1116, Mean R = -94.7  Std R = 22.8  Min R = -198.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000757\n",
      "PolicyEntropy: 2.21\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 5.28e+03\n",
      "TotalSteps: 1.43e+05\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.518\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3619   0.1798   0.6686   0.6686   0.3855   0.1798\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0127   0.0058   0.0293   1.6645   0.7971   0.5555\n",
      "***** Episode 1147, Mean R = -92.7  Std R = 15.6  Min R = -139.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000993\n",
      "PolicyEntropy: 2.19\n",
      "PolicyLoss: -0.00355\n",
      "Steps: 5.32e+03\n",
      "TotalSteps: 1.48e+05\n",
      "ValFuncLoss: 0.00295\n",
      "Variance: 0.516\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4041   0.1940   0.7268   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0128   0.0071   0.0326   1.6645   0.7971   0.5555\n",
      "***** Episode 1178, Mean R = -90.2  Std R = 14.8  Min R = -122.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.00118\n",
      "PolicyEntropy: 2.18\n",
      "PolicyLoss: -0.0035\n",
      "Steps: 5.21e+03\n",
      "TotalSteps: 1.54e+05\n",
      "ValFuncLoss: 0.00227\n",
      "Variance: 0.511\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2392   0.0756   0.3524   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0022   0.0132   1.6645   0.7971   0.5555\n",
      "***** Episode 1209, Mean R = -95.7  Std R = 20.4  Min R = -164.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.867\n",
      "KL: 0.000739\n",
      "PolicyEntropy: 2.16\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 5.68e+03\n",
      "TotalSteps: 1.59e+05\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.507\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2024   0.0583   0.2915   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0186   0.0100   0.0436   1.6645   0.7971   0.5555\n",
      "Update Cnt = 40    ET =    113.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   182.4    24.1    -1.9 |   518.5   435.5     1.1 | -1004.5  -991.7    -5.5 |  1379.0  1077.2    -0.0\n",
      "v_f      |  -16.91    1.06  -72.89 |   22.57   27.16   17.18 |  -69.96  -57.38 -114.78 |   36.55   61.64   -3.46\n",
      "vr_f     |     3.0 |     3.5 |     0.1 |    38.2\n",
      "r_i      |  1043.2    -8.9  2353.7 |   560.3   572.3    29.9 |     7.1  -999.3  2300.2 |  1987.8   998.5  2399.8\n",
      "v_i      |  -39.58   -0.70  -79.43 |   17.65   17.09    6.02 |  -69.86  -29.88  -89.98 |  -10.01   29.61  -70.04\n",
      "norm_rf  |   641.1 |   285.2 |    18.8 |  1454.5\n",
      "norm_vf  |   82.94 |   16.22 |   28.84 |  127.87\n",
      "thrust   |    1331      96    7365 |    6385    6582    5553 |  -14988  -15000  -14912 |   14993   14999   15000\n",
      "norm_thrust |   12668 |    3235 |    2000 |   15000\n",
      "fuel     |     201 |      36 |     138 |     409\n",
      "rewards  |  -91.51 |   15.55 | -198.03 |  -57.51\n",
      "fuel_rewards |   -6.92 |    1.24 |  -14.05 |   -4.75\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.58 |    0.65 |    0.11 |    4.58\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  636.62 |  284.10 |   63.35 | 1449.45\n",
      "tracking_rewards |  -84.59 |   15.13 | -184.69 |  -49.39\n",
      "steps    |     163 |      28 |     117 |     328\n",
      "***** Episode 1240, Mean R = -87.2  Std R = 13.1  Min R = -133.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.901\n",
      "KL: 0.000574\n",
      "PolicyEntropy: 2.14\n",
      "PolicyLoss: -0.00225\n",
      "Steps: 5.31e+03\n",
      "TotalSteps: 1.65e+05\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.504\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1094   0.0216   0.1449   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0208   0.0092   0.0386   1.6645   0.7971   0.5555\n",
      "***** Episode 1271, Mean R = -95.0  Std R = 36.8  Min R = -278.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.799\n",
      "ExplainedVarOld: 0.578\n",
      "KL: 0.000544\n",
      "PolicyEntropy: 2.13\n",
      "PolicyLoss: -0.00131\n",
      "Steps: 5.76e+03\n",
      "TotalSteps: 1.7e+05\n",
      "ValFuncLoss: 0.00887\n",
      "Variance: 0.505\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1940   0.0730   0.3307   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0141   0.0065   0.0275   1.6645   0.7971   0.5555\n",
      "***** Episode 1302, Mean R = -92.2  Std R = 21.7  Min R = -158.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.896\n",
      "ExplainedVarOld: 0.85\n",
      "KL: 0.000431\n",
      "PolicyEntropy: 2.12\n",
      "PolicyLoss: -0.00157\n",
      "Steps: 5.49e+03\n",
      "TotalSteps: 1.76e+05\n",
      "ValFuncLoss: 0.00488\n",
      "Variance: 0.501\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1895   0.0280   0.2459   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0181   0.0067   0.0316   1.6645   0.7971   0.5555\n",
      "***** Episode 1333, Mean R = -98.2  Std R = 38.6  Min R = -279.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.82\n",
      "ExplainedVarOld: 0.653\n",
      "KL: 0.0016\n",
      "PolicyEntropy: 2.12\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 6.02e+03\n",
      "TotalSteps: 1.82e+05\n",
      "ValFuncLoss: 0.00818\n",
      "Variance: 0.499\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3129   0.1272   0.4947   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0019   0.0113   1.6645   0.7971   0.5555\n",
      "***** Episode 1364, Mean R = -91.3  Std R = 16.5  Min R = -129.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.891\n",
      "ExplainedVarOld: 0.847\n",
      "KL: 0.00111\n",
      "PolicyEntropy: 2.11\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 5.84e+03\n",
      "TotalSteps: 1.88e+05\n",
      "ValFuncLoss: 0.00461\n",
      "Variance: 0.499\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1433   0.0471   0.2070   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0618   0.0306   0.1258   1.6645   0.7971   0.5555\n",
      "***** Episode 1395, Mean R = -111.4  Std R = 43.5  Min R = -235.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.653\n",
      "ExplainedVarOld: 0.231\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 2.1\n",
      "PolicyLoss: -0.00133\n",
      "Steps: 6.55e+03\n",
      "TotalSteps: 1.94e+05\n",
      "ValFuncLoss: 0.012\n",
      "Variance: 0.497\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1173   0.0297   0.1788   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0215   0.0084   0.0383   1.6645   0.7971   0.5555\n",
      "***** Episode 1426, Mean R = -115.3  Std R = 54.0  Min R = -282.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.754\n",
      "ExplainedVarOld: 0.709\n",
      "KL: 0.000949\n",
      "PolicyEntropy: 2.11\n",
      "PolicyLoss: -0.00135\n",
      "Steps: 6.72e+03\n",
      "TotalSteps: 2.01e+05\n",
      "ValFuncLoss: 0.0102\n",
      "Variance: 0.5\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0923   0.0127   0.1169   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0132   0.0053   0.0315   1.6645   0.7971   0.5555\n",
      "***** Episode 1457, Mean R = -121.4  Std R = 62.9  Min R = -285.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.727\n",
      "ExplainedVarOld: 0.686\n",
      "KL: 0.00156\n",
      "PolicyEntropy: 2.11\n",
      "PolicyLoss: -0.00124\n",
      "Steps: 7.34e+03\n",
      "TotalSteps: 2.08e+05\n",
      "ValFuncLoss: 0.0135\n",
      "Variance: 0.499\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1639   0.0510   0.2457   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0266   0.0118   0.0511   1.6645   0.7971   0.5555\n",
      "***** Episode 1488, Mean R = -128.3  Std R = 57.7  Min R = -267.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.79\n",
      "ExplainedVarOld: 0.731\n",
      "KL: 0.00077\n",
      "PolicyEntropy: 2.09\n",
      "PolicyLoss: -0.00139\n",
      "Steps: 7.38e+03\n",
      "TotalSteps: 2.16e+05\n",
      "ValFuncLoss: 0.0109\n",
      "Variance: 0.498\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1938   0.0726   0.3540   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0202   0.0087   0.0486   1.6645   0.7971   0.5555\n",
      "***** Episode 1519, Mean R = -116.1  Std R = 48.7  Min R = -288.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.81\n",
      "ExplainedVarOld: 0.707\n",
      "KL: 0.00127\n",
      "PolicyEntropy: 2.08\n",
      "PolicyLoss: -0.00213\n",
      "Steps: 6.99e+03\n",
      "TotalSteps: 2.23e+05\n",
      "ValFuncLoss: 0.0107\n",
      "Variance: 0.498\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0974   0.0412   0.1766   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0236   0.0103   0.0492   1.6645   0.7971   0.5555\n",
      "Update Cnt = 50    ET =    144.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   197.3    84.4    94.4 |   449.8   437.7   315.6 |  -849.3 -1299.7    -4.1 |  1262.1  1076.0  1862.1\n",
      "v_f      |   -2.17    1.59  -44.61 |   25.59   29.29   31.38 |  -64.74  -64.66  -99.01 |   55.55   61.54   69.95\n",
      "vr_f     |     2.0 |     2.1 |     0.1 |    20.6\n",
      "r_i      |   956.6   -31.4  2347.4 |   573.8   571.9    29.2 |     0.8  -983.0  2300.1 |  1993.2   999.7  2399.6\n",
      "v_i      |  -40.59    0.91  -80.42 |   17.50   17.53    5.73 |  -69.75  -29.62  -89.96 |  -10.37   29.93  -70.16\n",
      "norm_rf  |   655.0 |   345.7 |    23.1 |  2084.0\n",
      "norm_vf  |   65.04 |   16.29 |   17.83 |  108.72\n",
      "thrust   |    1679      53    8344 |    6154    6380    5158 |  -14985  -14995  -14890 |   15000   15000   15000\n",
      "norm_thrust |   12971 |    3062 |    2000 |   15000\n",
      "fuel     |     269 |      90 |     157 |     625\n",
      "rewards  | -111.03 |   50.27 | -357.88 |  -44.85\n",
      "fuel_rewards |   -9.25 |    3.10 |  -21.45 |   -5.41\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.12 |    0.66 |    0.01 |    4.26\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  650.37 |  345.04 |   36.55 | 2078.99\n",
      "tracking_rewards | -101.78 |   47.60 | -336.44 |  -34.60\n",
      "steps    |     213 |      71 |     127 |     500\n",
      "***** Episode 1550, Mean R = -141.1  Std R = 68.6  Min R = -357.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.854\n",
      "ExplainedVarOld: 0.785\n",
      "KL: 0.000892\n",
      "PolicyEntropy: 2.07\n",
      "PolicyLoss: -0.00113\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 2.31e+05\n",
      "ValFuncLoss: 0.011\n",
      "Variance: 0.499\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2056   0.0662   0.3361   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0383   0.0186   0.0827   1.6645   0.7971   0.5555\n",
      "***** Episode 1581, Mean R = -143.8  Std R = 82.9  Min R = -344.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.743\n",
      "ExplainedVarOld: 0.672\n",
      "KL: 0.00105\n",
      "PolicyEntropy: 2.07\n",
      "PolicyLoss: -0.00224\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 2.39e+05\n",
      "ValFuncLoss: 0.0139\n",
      "Variance: 0.503\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1690   0.0739   0.3221   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0195   0.0084   0.0369   1.6645   0.7971   0.5555\n",
      "***** Episode 1612, Mean R = -133.9  Std R = 60.3  Min R = -299.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.785\n",
      "ExplainedVarOld: 0.765\n",
      "KL: 0.000864\n",
      "PolicyEntropy: 2.06\n",
      "PolicyLoss: -0.00174\n",
      "Steps: 7.82e+03\n",
      "TotalSteps: 2.47e+05\n",
      "ValFuncLoss: 0.0132\n",
      "Variance: 0.499\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1471   0.0716   0.2826   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0200   0.0095   0.0440   1.6645   0.7971   0.5555\n",
      "***** Episode 1643, Mean R = -152.4  Std R = 75.9  Min R = -319.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.818\n",
      "ExplainedVarOld: 0.794\n",
      "KL: 0.001\n",
      "PolicyEntropy: 2.05\n",
      "PolicyLoss: -0.00152\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 2.55e+05\n",
      "ValFuncLoss: 0.0122\n",
      "Variance: 0.497\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1688   0.0682   0.3013   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0235   0.0081   0.0449   1.6645   0.7971   0.5555\n",
      "***** Episode 1674, Mean R = -120.1  Std R = 48.0  Min R = -233.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.846\n",
      "ExplainedVarOld: 0.735\n",
      "KL: 0.00134\n",
      "PolicyEntropy: 2.05\n",
      "PolicyLoss: -0.00182\n",
      "Steps: 6.96e+03\n",
      "TotalSteps: 2.62e+05\n",
      "ValFuncLoss: 0.00831\n",
      "Variance: 0.495\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1143   0.0432   0.1736   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0110   0.0042   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 1705, Mean R = -106.9  Std R = 46.4  Min R = -270.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.859\n",
      "ExplainedVarOld: 0.8\n",
      "KL: 0.000984\n",
      "PolicyEntropy: 2.05\n",
      "PolicyLoss: -0.00136\n",
      "Steps: 6.29e+03\n",
      "TotalSteps: 2.68e+05\n",
      "ValFuncLoss: 0.00684\n",
      "Variance: 0.493\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1432   0.0394   0.2030   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0105   0.0039   0.0215   1.6645   0.7971   0.5555\n",
      "***** Episode 1736, Mean R = -129.4  Std R = 54.0  Min R = -283.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.863\n",
      "ExplainedVarOld: 0.837\n",
      "KL: 0.00118\n",
      "PolicyEntropy: 2.04\n",
      "PolicyLoss: -0.00194\n",
      "Steps: 7.54e+03\n",
      "TotalSteps: 2.76e+05\n",
      "ValFuncLoss: 0.00873\n",
      "Variance: 0.488\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1811   0.0749   0.2965   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0123   0.0043   0.0207   1.6645   0.7971   0.5555\n",
      "***** Episode 1767, Mean R = -142.8  Std R = 75.9  Min R = -335.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.851\n",
      "ExplainedVarOld: 0.838\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 2.04\n",
      "PolicyLoss: -0.00216\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 2.84e+05\n",
      "ValFuncLoss: 0.00905\n",
      "Variance: 0.484\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1387   0.0559   0.2254   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0145   0.0052   0.0302   1.6645   0.7971   0.5555\n",
      "***** Episode 1798, Mean R = -111.4  Std R = 49.9  Min R = -235.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.839\n",
      "ExplainedVarOld: 0.816\n",
      "KL: 0.000967\n",
      "PolicyEntropy: 2.04\n",
      "PolicyLoss: -0.00179\n",
      "Steps: 7.11e+03\n",
      "TotalSteps: 2.91e+05\n",
      "ValFuncLoss: 0.00899\n",
      "Variance: 0.485\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1377   0.0568   0.2590   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0156   0.0075   0.0316   1.6645   0.7971   0.5555\n",
      "***** Episode 1829, Mean R = -115.4  Std R = 46.3  Min R = -227.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.899\n",
      "ExplainedVarOld: 0.887\n",
      "KL: 0.000798\n",
      "PolicyEntropy: 2.04\n",
      "PolicyLoss: -0.00118\n",
      "Steps: 7.05e+03\n",
      "TotalSteps: 2.98e+05\n",
      "ValFuncLoss: 0.00734\n",
      "Variance: 0.483\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2233   0.0932   0.4161   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0092   0.0031   0.0147   1.6645   0.7971   0.5555\n",
      "Update Cnt = 60    ET =    163.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   228.4    56.1   185.8 |   439.1   387.9   460.0 |  -737.5  -980.7    -4.4 |  1513.8   967.1  1928.1\n",
      "v_f      |   -0.37    2.69  -37.21 |   27.79   32.67   37.21 |  -73.22  -63.92  -91.08 |   74.21   93.19   67.96\n",
      "vr_f     |     2.0 |     4.3 |     0.1 |    55.9\n",
      "r_i      |  1005.4   -24.8  2348.1 |   571.1   579.8    28.7 |     2.2  -999.0  2300.0 |  1999.3   994.2  2399.9\n",
      "v_i      |  -42.24   -1.37  -80.18 |   16.85   16.82    6.08 |  -69.65  -29.94  -89.88 |  -10.06   29.87  -70.04\n",
      "norm_rf  |   673.2 |   437.6 |    25.1 |  2007.2\n",
      "norm_vf  |   65.37 |   18.52 |   19.62 |  115.74\n",
      "thrust   |    1621     161    8329 |    6147    6419    5172 |  -14983  -15000  -14945 |   15000   14998   15000\n",
      "norm_thrust |   12976 |    3061 |    2000 |   15000\n",
      "fuel     |     305 |     109 |     169 |     635\n",
      "rewards  | -127.50 |   63.24 | -344.88 |  -42.94\n",
      "fuel_rewards |  -10.50 |    3.72 |  -21.81 |   -5.80\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.86 |    0.57 |    0.01 |    2.88\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  668.67 |  436.92 |   39.84 | 2002.23\n",
      "tracking_rewards | -117.00 |   59.91 | -323.83 |  -32.53\n",
      "steps    |     242 |      87 |     138 |     500\n",
      "***** Episode 1860, Mean R = -119.0  Std R = 61.9  Min R = -297.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.864\n",
      "ExplainedVarOld: 0.846\n",
      "KL: 0.00115\n",
      "PolicyEntropy: 2.04\n",
      "PolicyLoss: -0.00207\n",
      "Steps: 7.17e+03\n",
      "TotalSteps: 3.06e+05\n",
      "ValFuncLoss: 0.00774\n",
      "Variance: 0.483\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1238   0.0319   0.1692   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0278   0.0135   0.0615   1.6645   0.7971   0.5555\n",
      "***** Episode 1891, Mean R = -116.5  Std R = 42.6  Min R = -246.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.874\n",
      "ExplainedVarOld: 0.85\n",
      "KL: 0.00134\n",
      "PolicyEntropy: 2.03\n",
      "PolicyLoss: -0.00178\n",
      "Steps: 6.73e+03\n",
      "TotalSteps: 3.12e+05\n",
      "ValFuncLoss: 0.00776\n",
      "Variance: 0.483\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1019   0.0345   0.1629   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0089   0.0036   0.0164   1.6645   0.7971   0.5555\n",
      "***** Episode 1922, Mean R = -145.9  Std R = 68.9  Min R = -307.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.832\n",
      "ExplainedVarOld: 0.817\n",
      "KL: 0.00101\n",
      "PolicyEntropy: 2.02\n",
      "PolicyLoss: -0.00141\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 3.2e+05\n",
      "ValFuncLoss: 0.00772\n",
      "Variance: 0.48\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1200   0.0360   0.1848   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0135   0.0066   0.0301   1.6645   0.7971   0.5555\n",
      "***** Episode 1953, Mean R = -137.6  Std R = 60.5  Min R = -264.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.87\n",
      "ExplainedVarOld: 0.857\n",
      "KL: 0.00137\n",
      "PolicyEntropy: 2\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 7.8e+03\n",
      "TotalSteps: 3.28e+05\n",
      "ValFuncLoss: 0.00694\n",
      "Variance: 0.475\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1427   0.0382   0.2024   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0071   0.0028   0.0134   1.6645   0.7971   0.5555\n",
      "***** Episode 1984, Mean R = -141.5  Std R = 69.1  Min R = -315.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.888\n",
      "ExplainedVarOld: 0.874\n",
      "KL: 0.00112\n",
      "PolicyEntropy: 1.99\n",
      "PolicyLoss: -0.00155\n",
      "Steps: 7.74e+03\n",
      "TotalSteps: 3.36e+05\n",
      "ValFuncLoss: 0.00672\n",
      "Variance: 0.475\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1319   0.0482   0.2105   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0087   0.0035   0.0176   1.6645   0.7971   0.5555\n",
      "***** Episode 2015, Mean R = -122.7  Std R = 42.0  Min R = -241.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.000936\n",
      "PolicyEntropy: 1.98\n",
      "PolicyLoss: -0.00165\n",
      "Steps: 7.37e+03\n",
      "TotalSteps: 3.43e+05\n",
      "ValFuncLoss: 0.00439\n",
      "Variance: 0.475\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0964   0.0177   0.1323   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0332   0.0167   0.0651   1.6645   0.7971   0.5555\n",
      "***** Episode 2046, Mean R = -139.8  Std R = 52.2  Min R = -252.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.908\n",
      "ExplainedVarOld: 0.876\n",
      "KL: 0.00124\n",
      "PolicyEntropy: 1.97\n",
      "PolicyLoss: -0.00151\n",
      "Steps: 7.8e+03\n",
      "TotalSteps: 3.51e+05\n",
      "ValFuncLoss: 0.00685\n",
      "Variance: 0.469\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1541   0.0718   0.3003   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0114   0.0054   0.0235   1.6645   0.7971   0.5555\n",
      "***** Episode 2077, Mean R = -127.3  Std R = 59.5  Min R = -285.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.908\n",
      "ExplainedVarOld: 0.892\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 1.97\n",
      "PolicyLoss: -0.00155\n",
      "Steps: 7.59e+03\n",
      "TotalSteps: 3.59e+05\n",
      "ValFuncLoss: 0.0062\n",
      "Variance: 0.469\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1433   0.0379   0.2405   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0044   0.0210   1.6645   0.7971   0.5555\n",
      "***** Episode 2108, Mean R = -133.6  Std R = 66.2  Min R = -303.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.893\n",
      "ExplainedVarOld: 0.882\n",
      "KL: 0.00133\n",
      "PolicyEntropy: 1.97\n",
      "PolicyLoss: -0.00144\n",
      "Steps: 7.47e+03\n",
      "TotalSteps: 3.66e+05\n",
      "ValFuncLoss: 0.0066\n",
      "Variance: 0.471\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0880   0.0246   0.1274   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0028   0.0156   1.6645   0.7971   0.5555\n",
      "***** Episode 2139, Mean R = -123.0  Std R = 52.1  Min R = -265.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.893\n",
      "ExplainedVarOld: 0.873\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 1.97\n",
      "PolicyLoss: -0.00139\n",
      "Steps: 6.77e+03\n",
      "TotalSteps: 3.73e+05\n",
      "ValFuncLoss: 0.00613\n",
      "Variance: 0.469\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1603   0.0712   0.3059   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0021   0.0097   1.6645   0.7971   0.5555\n",
      "Update Cnt = 70    ET =    162.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   304.4   102.3   187.1 |   446.9   445.2   487.7 |  -718.7  -973.7    -4.0 |  1459.5  1231.8  2057.6\n",
      "v_f      |   -4.64    3.98  -43.92 |   29.77   32.72   36.37 |  -84.08  -65.86  -87.45 |   75.37   78.27   69.74\n",
      "vr_f     |     2.0 |     2.2 |     0.0 |    21.3\n",
      "r_i      |  1017.8    12.9  2348.0 |   584.5   604.5    28.5 |     5.3  -997.5  2300.2 |  1998.1   993.0  2399.2\n",
      "v_i      |  -38.75   -1.06  -79.62 |   17.24   17.04    5.99 |  -69.88  -29.93  -89.96 |  -10.07   29.97  -70.13\n",
      "norm_rf  |   763.8 |   436.4 |    34.9 |  2215.5\n",
      "norm_vf  |   70.00 |   18.58 |   18.78 |  122.35\n",
      "thrust   |    1334     210    8125 |    6262    6436    5347 |  -14995  -14997  -14945 |   14992   14998   15000\n",
      "norm_thrust |   12947 |    3076 |    2000 |   15000\n",
      "fuel     |     301 |      97 |     174 |     624\n",
      "rewards  | -130.17 |   57.19 | -315.37 |  -51.74\n",
      "fuel_rewards |  -10.35 |    3.33 |  -21.44 |   -6.00\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.84 |    0.58 |    0.01 |    3.76\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  759.18 |  435.85 |   62.37 | 2210.50\n",
      "tracking_rewards | -119.82 |   54.18 | -294.00 |  -42.37\n",
      "steps    |     239 |      78 |     144 |     500\n",
      "***** Episode 2170, Mean R = -113.9  Std R = 38.4  Min R = -236.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00162\n",
      "PolicyEntropy: 1.95\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 6.88e+03\n",
      "TotalSteps: 3.8e+05\n",
      "ValFuncLoss: 0.00413\n",
      "Variance: 0.466\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1059   0.0437   0.2006   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0075   0.0033   0.0183   1.6645   0.7971   0.5555\n",
      "***** Episode 2201, Mean R = -114.5  Std R = 34.8  Min R = -227.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.00114\n",
      "PolicyEntropy: 1.93\n",
      "PolicyLoss: -0.00141\n",
      "Steps: 6.57e+03\n",
      "TotalSteps: 3.86e+05\n",
      "ValFuncLoss: 0.00453\n",
      "Variance: 0.464\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1467   0.0531   0.2460   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0081   0.0036   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 2232, Mean R = -135.7  Std R = 62.3  Min R = -272.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.894\n",
      "KL: 0.00109\n",
      "PolicyEntropy: 1.93\n",
      "PolicyLoss: -0.00143\n",
      "Steps: 7.71e+03\n",
      "TotalSteps: 3.94e+05\n",
      "ValFuncLoss: 0.00631\n",
      "Variance: 0.463\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1564   0.0445   0.2125   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0134   0.0057   0.0310   1.6645   0.7971   0.5555\n",
      "***** Episode 2263, Mean R = -137.2  Std R = 60.3  Min R = -295.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.901\n",
      "ExplainedVarOld: 0.874\n",
      "KL: 0.00132\n",
      "PolicyEntropy: 1.92\n",
      "PolicyLoss: -0.0021\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 4.02e+05\n",
      "ValFuncLoss: 0.0058\n",
      "Variance: 0.463\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0932   0.0139   0.1271   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0149   0.0059   0.0313   1.6645   0.7971   0.5555\n",
      "***** Episode 2294, Mean R = -129.0  Std R = 52.4  Min R = -272.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.898\n",
      "ExplainedVarOld: 0.869\n",
      "KL: 0.00134\n",
      "PolicyEntropy: 1.92\n",
      "PolicyLoss: -0.0016\n",
      "Steps: 7.48e+03\n",
      "TotalSteps: 4.1e+05\n",
      "ValFuncLoss: 0.00724\n",
      "Variance: 0.464\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1607   0.0644   0.2836   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0023   0.0130   1.6645   0.7971   0.5555\n",
      "***** Episode 2325, Mean R = -112.8  Std R = 37.2  Min R = -230.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.00135\n",
      "PolicyEntropy: 1.91\n",
      "PolicyLoss: -0.00216\n",
      "Steps: 6.48e+03\n",
      "TotalSteps: 4.16e+05\n",
      "ValFuncLoss: 0.0057\n",
      "Variance: 0.461\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2513   0.0956   0.4320   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0160   0.0078   0.0298   1.6645   0.7971   0.5555\n",
      "***** Episode 2356, Mean R = -147.0  Std R = 72.4  Min R = -320.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.00116\n",
      "PolicyEntropy: 1.9\n",
      "PolicyLoss: -0.00229\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 4.24e+05\n",
      "ValFuncLoss: 0.00577\n",
      "Variance: 0.46\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1777   0.0756   0.3419   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0075   0.0034   0.0154   1.6645   0.7971   0.5555\n",
      "***** Episode 2387, Mean R = -129.9  Std R = 58.4  Min R = -298.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.000977\n",
      "PolicyEntropy: 1.9\n",
      "PolicyLoss: -0.00147\n",
      "Steps: 7.31e+03\n",
      "TotalSteps: 4.32e+05\n",
      "ValFuncLoss: 0.00569\n",
      "Variance: 0.461\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2361   0.0836   0.3941   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0095   0.0041   0.0209   1.6645   0.7971   0.5555\n",
      "***** Episode 2418, Mean R = -121.4  Std R = 52.1  Min R = -289.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.914\n",
      "ExplainedVarOld: 0.892\n",
      "KL: 0.00125\n",
      "PolicyEntropy: 1.89\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 7.3e+03\n",
      "TotalSteps: 4.39e+05\n",
      "ValFuncLoss: 0.00649\n",
      "Variance: 0.46\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1460   0.0654   0.2960   0.7268   0.4041   0.1940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0131   0.0046   0.0263   1.6645   0.7971   0.5555\n",
      "***** Episode 2449, Mean R = -129.2  Std R = 57.0  Min R = -330.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.899\n",
      "ExplainedVarOld: 0.872\n",
      "KL: 0.000828\n",
      "PolicyEntropy: 1.88\n",
      "PolicyLoss: -0.00129\n",
      "Steps: 7.23e+03\n",
      "TotalSteps: 4.46e+05\n",
      "ValFuncLoss: 0.00742\n",
      "Variance: 0.459\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1047   0.0305   0.1582   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0140   0.0064   0.0282   1.6645   0.7971   0.5555\n",
      "Update Cnt = 80    ET =    161.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   252.2    73.4   152.4 |   450.9   419.6   450.0 | -1068.9 -1080.7    -3.9 |  1412.6  1079.0  1882.9\n",
      "v_f      |   -7.10    2.23  -51.83 |   32.49   31.93   34.41 |  -92.83  -87.04  -88.86 |   68.00   74.82   68.55\n",
      "vr_f     |     2.4 |     5.3 |     0.0 |    80.7\n",
      "r_i      |  1036.6    13.8  2352.3 |   612.9   568.5    28.1 |    10.9  -975.9  2300.4 |  1995.6   998.4  2399.8\n",
      "v_i      |  -39.75   -1.23  -79.88 |   17.70   17.10    5.80 |  -69.88  -29.90  -89.72 |  -10.06   29.84  -70.05\n",
      "norm_rf  |   693.2 |   440.0 |    55.0 |  1987.7\n",
      "norm_vf  |   75.49 |   17.38 |   14.12 |  127.72\n",
      "thrust   |    1315     151    7880 |    6409    6373    5477 |  -14997  -14994  -14976 |   15000   15000   15000\n",
      "norm_thrust |   12875 |    3128 |    2000 |   15000\n",
      "fuel     |     297 |      95 |     182 |     606\n",
      "rewards  | -128.66 |   56.24 | -330.48 |  -54.34\n",
      "fuel_rewards |  -10.22 |    3.26 |  -20.79 |   -6.24\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.80 |    0.48 |    0.00 |    2.66\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  688.87 |  439.09 |   72.38 | 1982.71\n",
      "tracking_rewards | -118.44 |   53.34 | -309.82 |  -45.56\n",
      "steps    |     237 |      77 |     147 |     500\n",
      "***** Episode 2480, Mean R = -130.0  Std R = 56.4  Min R = -294.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.911\n",
      "ExplainedVarOld: 0.886\n",
      "KL: 0.0011\n",
      "PolicyEntropy: 1.88\n",
      "PolicyLoss: -0.00114\n",
      "Steps: 7.34e+03\n",
      "TotalSteps: 4.53e+05\n",
      "ValFuncLoss: 0.00657\n",
      "Variance: 0.46\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1872   0.0607   0.2962   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0172   0.0092   0.0409   1.6645   0.7971   0.5555\n",
      "***** Episode 2511, Mean R = -110.6  Std R = 47.4  Min R = -317.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.894\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000887\n",
      "PolicyEntropy: 1.87\n",
      "PolicyLoss: -0.0019\n",
      "Steps: 6.84e+03\n",
      "TotalSteps: 4.6e+05\n",
      "ValFuncLoss: 0.00578\n",
      "Variance: 0.46\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1204   0.0462   0.2260   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0135   0.0059   0.0266   1.6645   0.7971   0.5555\n",
      "***** Episode 2542, Mean R = -119.8  Std R = 43.8  Min R = -277.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.904\n",
      "ExplainedVarOld: 0.882\n",
      "KL: 0.00107\n",
      "PolicyEntropy: 1.87\n",
      "PolicyLoss: -0.00126\n",
      "Steps: 6.86e+03\n",
      "TotalSteps: 4.67e+05\n",
      "ValFuncLoss: 0.00651\n",
      "Variance: 0.459\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1772   0.0493   0.2652   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0011   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 2573, Mean R = -111.7  Std R = 34.3  Min R = -192.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.00109\n",
      "PolicyEntropy: 1.86\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 6.74e+03\n",
      "TotalSteps: 4.74e+05\n",
      "ValFuncLoss: 0.00521\n",
      "Variance: 0.458\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2024   0.0826   0.3635   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0133   0.0069   0.0335   1.6645   0.7971   0.5555\n",
      "***** Episode 2604, Mean R = -125.6  Std R = 44.8  Min R = -228.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.912\n",
      "KL: 0.00156\n",
      "PolicyEntropy: 1.85\n",
      "PolicyLoss: -0.00205\n",
      "Steps: 6.86e+03\n",
      "TotalSteps: 4.81e+05\n",
      "ValFuncLoss: 0.00625\n",
      "Variance: 0.456\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1249   0.0453   0.2213   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0201   0.0124   0.0480   1.6645   0.7971   0.5555\n",
      "***** Episode 2635, Mean R = -108.1  Std R = 32.5  Min R = -219.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000847\n",
      "PolicyEntropy: 1.86\n",
      "PolicyLoss: -0.00158\n",
      "Steps: 6.56e+03\n",
      "TotalSteps: 4.87e+05\n",
      "ValFuncLoss: 0.00377\n",
      "Variance: 0.459\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2280   0.0733   0.3817   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0092   0.0032   0.0141   1.6645   0.7971   0.5555\n",
      "***** Episode 2666, Mean R = -101.4  Std R = 31.4  Min R = -204.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.00167\n",
      "PolicyEntropy: 1.84\n",
      "PolicyLoss: -0.0024\n",
      "Steps: 6.18e+03\n",
      "TotalSteps: 4.93e+05\n",
      "ValFuncLoss: 0.00453\n",
      "Variance: 0.455\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1905   0.0588   0.2826   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0188   0.0091   0.0378   1.6645   0.7971   0.5555\n",
      "***** Episode 2697, Mean R = -113.5  Std R = 42.3  Min R = -289.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.00113\n",
      "PolicyEntropy: 1.83\n",
      "PolicyLoss: -0.00216\n",
      "Steps: 6.11e+03\n",
      "TotalSteps: 5e+05\n",
      "ValFuncLoss: 0.00541\n",
      "Variance: 0.45\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1182   0.0349   0.1652   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0145   0.0076   0.0348   1.6645   0.7971   0.5555\n",
      "***** Episode 2728, Mean R = -127.3  Std R = 70.0  Min R = -362.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.00106\n",
      "PolicyEntropy: 1.81\n",
      "PolicyLoss: -0.00164\n",
      "Steps: 7.64e+03\n",
      "TotalSteps: 5.07e+05\n",
      "ValFuncLoss: 0.00397\n",
      "Variance: 0.447\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1212   0.0270   0.1526   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0073   0.0023   0.0131   1.6645   0.7971   0.5555\n",
      "***** Episode 2759, Mean R = -120.4  Std R = 37.8  Min R = -230.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.00149\n",
      "PolicyEntropy: 1.78\n",
      "PolicyLoss: -0.00189\n",
      "Steps: 7.14e+03\n",
      "TotalSteps: 5.14e+05\n",
      "ValFuncLoss: 0.00569\n",
      "Variance: 0.443\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1974   0.0811   0.3589   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0113   0.0056   0.0251   1.6645   0.7971   0.5555\n",
      "Update Cnt = 90    ET =    149.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   247.4    33.4    92.8 |   403.0   431.9   372.7 |  -773.1  -980.0    -4.5 |  1170.5  1125.5  2024.2\n",
      "v_f      |  -11.22   -0.28  -65.20 |   30.54   30.49   29.61 |  -89.65  -74.22 -101.30 |   53.25   64.76   65.64\n",
      "vr_f     |     2.8 |     4.4 |     0.1 |    59.3\n",
      "r_i      |  1012.9   -35.7  2348.3 |   554.3   552.0    28.9 |    18.1  -986.1  2300.1 |  1992.4   991.6  2400.0\n",
      "v_i      |  -39.51    0.29  -80.47 |   17.40   17.63    5.94 |  -69.48  -29.82  -89.95 |  -10.29   29.90  -70.13\n",
      "norm_rf  |   630.9 |   400.9 |    31.9 |  2164.0\n",
      "norm_vf  |   82.55 |   17.37 |   32.77 |  137.79\n",
      "thrust   |    1243      -7    7498 |    6416    6362    5701 |  -15000  -15000  -14956 |   14998   14997   15000\n",
      "norm_thrust |   12708 |    3227 |    2000 |   15000\n",
      "fuel     |     272 |      82 |     178 |     625\n",
      "rewards  | -115.89 |   46.78 | -362.54 |  -54.46\n",
      "fuel_rewards |   -9.34 |    2.80 |  -21.45 |   -6.11\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.92 |    0.48 |    0.01 |    2.52\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  627.04 |  399.36 |   54.54 | 2158.97\n",
      "tracking_rewards | -106.56 |   44.41 | -341.35 |  -46.90\n",
      "steps    |     220 |      67 |     142 |     500\n",
      "***** Episode 2790, Mean R = -120.5  Std R = 61.3  Min R = -361.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.0014\n",
      "PolicyEntropy: 1.76\n",
      "PolicyLoss: -0.00195\n",
      "Steps: 7.19e+03\n",
      "TotalSteps: 5.21e+05\n",
      "ValFuncLoss: 0.00535\n",
      "Variance: 0.44\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1501   0.0441   0.2111   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0020   0.0097   1.6645   0.7971   0.5555\n",
      "***** Episode 2821, Mean R = -97.9  Std R = 25.7  Min R = -157.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.00123\n",
      "PolicyEntropy: 1.75\n",
      "PolicyLoss: -0.00224\n",
      "Steps: 6.16e+03\n",
      "TotalSteps: 5.28e+05\n",
      "ValFuncLoss: 0.00365\n",
      "Variance: 0.438\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1620   0.0863   0.3577   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0073   0.0026   0.0140   1.6645   0.7971   0.5555\n",
      "***** Episode 2852, Mean R = -106.2  Std R = 33.3  Min R = -218.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00108\n",
      "PolicyEntropy: 1.75\n",
      "PolicyLoss: -0.00162\n",
      "Steps: 6.14e+03\n",
      "TotalSteps: 5.34e+05\n",
      "ValFuncLoss: 0.00454\n",
      "Variance: 0.438\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1888   0.0789   0.3140   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0142   0.0086   0.0315   1.6645   0.7971   0.5555\n",
      "***** Episode 2883, Mean R = -118.2  Std R = 41.0  Min R = -281.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00145\n",
      "PolicyEntropy: 1.76\n",
      "PolicyLoss: -0.00242\n",
      "Steps: 6.77e+03\n",
      "TotalSteps: 5.41e+05\n",
      "ValFuncLoss: 0.0035\n",
      "Variance: 0.441\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1248   0.0420   0.2165   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0240   0.0109   0.0466   1.6645   0.7971   0.5555\n",
      "***** Episode 2914, Mean R = -134.0  Std R = 67.4  Min R = -363.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.921\n",
      "ExplainedVarOld: 0.891\n",
      "KL: 0.000982\n",
      "PolicyEntropy: 1.75\n",
      "PolicyLoss: -0.0012\n",
      "Steps: 6.91e+03\n",
      "TotalSteps: 5.47e+05\n",
      "ValFuncLoss: 0.00592\n",
      "Variance: 0.441\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1637   0.0534   0.2339   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0137   0.0056   0.0273   1.6645   0.7971   0.5555\n",
      "***** Episode 2945, Mean R = -133.8  Std R = 48.1  Min R = -260.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.912\n",
      "KL: 0.00104\n",
      "PolicyEntropy: 1.74\n",
      "PolicyLoss: -0.00179\n",
      "Steps: 6.94e+03\n",
      "TotalSteps: 5.54e+05\n",
      "ValFuncLoss: 0.00603\n",
      "Variance: 0.437\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1372   0.0455   0.2233   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0169   0.0082   0.0367   1.6645   0.7971   0.5555\n",
      "***** Episode 2976, Mean R = -110.1  Std R = 33.0  Min R = -226.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.000873\n",
      "PolicyEntropy: 1.75\n",
      "PolicyLoss: -0.00156\n",
      "Steps: 6.28e+03\n",
      "TotalSteps: 5.61e+05\n",
      "ValFuncLoss: 0.00516\n",
      "Variance: 0.439\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1326   0.0376   0.2208   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0070   0.0032   0.0139   1.6645   0.7971   0.5555\n",
      "***** Episode 3007, Mean R = -124.9  Std R = 50.9  Min R = -291.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.00121\n",
      "PolicyEntropy: 1.74\n",
      "PolicyLoss: -0.00186\n",
      "Steps: 7e+03\n",
      "TotalSteps: 5.68e+05\n",
      "ValFuncLoss: 0.00477\n",
      "Variance: 0.438\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1699   0.0697   0.3254   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0116   0.0058   0.0254   1.6645   0.7971   0.5555\n",
      "***** Episode 3038, Mean R = -103.7  Std R = 35.5  Min R = -220.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.00153\n",
      "PolicyEntropy: 1.73\n",
      "PolicyLoss: -0.00164\n",
      "Steps: 6.47e+03\n",
      "TotalSteps: 5.74e+05\n",
      "ValFuncLoss: 0.00453\n",
      "Variance: 0.438\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1347   0.0537   0.2511   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0090   0.0039   0.0189   1.6645   0.7971   0.5555\n",
      "***** Episode 3069, Mean R = -109.2  Std R = 42.9  Min R = -258.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00126\n",
      "PolicyEntropy: 1.73\n",
      "PolicyLoss: -0.00153\n",
      "Steps: 6.43e+03\n",
      "TotalSteps: 5.81e+05\n",
      "ValFuncLoss: 0.00419\n",
      "Variance: 0.439\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0837   0.0117   0.0945   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0144   0.0078   0.0309   1.6645   0.7971   0.5555\n",
      "Update Cnt = 100    ET =    142.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   244.4   -58.1   102.6 |   375.7   439.1   401.1 |  -705.5 -1004.5    -4.8 |  1064.3  1025.6  1937.2\n",
      "v_f      |  -12.88   -0.44  -67.40 |   32.77   33.35   31.99 | -104.13  -70.59 -100.45 |   62.14   85.40   66.63\n",
      "vr_f     |     2.4 |     2.7 |     0.5 |    34.1\n",
      "r_i      |   934.2    40.8  2349.1 |   541.0   590.9    29.8 |    10.2  -999.8  2300.7 |  1985.7   997.1  2399.7\n",
      "v_i      |  -41.23    1.28  -80.61 |   17.79   17.67    5.83 |  -69.96  -29.94  -89.92 |  -10.25   29.97  -70.01\n",
      "norm_rf  |   635.9 |   405.1 |    41.6 |  2145.1\n",
      "norm_vf  |   87.43 |   16.56 |   43.56 |  154.05\n",
      "thrust   |    1288     -66    7461 |    6382    6420    5665 |  -14993  -14989  -14928 |   14996   14995   15000\n",
      "norm_thrust |   12686 |    3232 |    2000 |   15000\n",
      "fuel     |     262 |      70 |     172 |     602\n",
      "rewards  | -115.26 |   44.21 | -363.82 |  -54.87\n",
      "fuel_rewards |   -9.00 |    2.41 |  -20.68 |   -5.94\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.94 |    0.48 |    0.01 |    2.42\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  632.23 |  403.28 |   79.92 | 2140.05\n",
      "tracking_rewards | -106.26 |   42.13 | -343.15 |  -46.39\n",
      "steps    |     212 |      56 |     140 |     500\n",
      "***** Episode 3100, Mean R = -114.7  Std R = 33.1  Min R = -202.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000923\n",
      "PolicyEntropy: 1.73\n",
      "PolicyLoss: -0.00136\n",
      "Steps: 6.67e+03\n",
      "TotalSteps: 5.87e+05\n",
      "ValFuncLoss: 0.00417\n",
      "Variance: 0.441\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1463   0.0503   0.2558   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0139   0.0074   0.0308   1.6645   0.7971   0.5555\n",
      "***** Episode 3131, Mean R = -123.8  Std R = 41.6  Min R = -257.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000953\n",
      "PolicyEntropy: 1.73\n",
      "PolicyLoss: -0.00151\n",
      "Steps: 7.32e+03\n",
      "TotalSteps: 5.95e+05\n",
      "ValFuncLoss: 0.00395\n",
      "Variance: 0.44\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1083   0.0340   0.1734   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0130   0.0063   0.0248   1.6645   0.7971   0.5555\n",
      "***** Episode 3162, Mean R = -114.4  Std R = 53.9  Min R = -314.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.892\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.00131\n",
      "PolicyEntropy: 1.72\n",
      "PolicyLoss: -0.00154\n",
      "Steps: 7.13e+03\n",
      "TotalSteps: 6.02e+05\n",
      "ValFuncLoss: 0.00536\n",
      "Variance: 0.439\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1529   0.0637   0.2658   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0411   0.0203   0.0876   1.6645   0.7971   0.5555\n",
      "***** Episode 3193, Mean R = -129.8  Std R = 65.4  Min R = -333.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.813\n",
      "ExplainedVarOld: 0.765\n",
      "KL: 0.000938\n",
      "PolicyEntropy: 1.72\n",
      "PolicyLoss: -0.00132\n",
      "Steps: 6.91e+03\n",
      "TotalSteps: 6.09e+05\n",
      "ValFuncLoss: 0.0106\n",
      "Variance: 0.439\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1504   0.0360   0.2046   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0108   0.0044   0.0194   1.6645   0.7971   0.5555\n",
      "***** Episode 3224, Mean R = -111.2  Std R = 30.0  Min R = -201.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.00107\n",
      "PolicyEntropy: 1.71\n",
      "PolicyLoss: -0.00214\n",
      "Steps: 6.56e+03\n",
      "TotalSteps: 6.15e+05\n",
      "ValFuncLoss: 0.00492\n",
      "Variance: 0.441\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1614   0.0548   0.2681   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0115   0.0056   0.0239   1.6645   0.7971   0.5555\n",
      "***** Episode 3255, Mean R = -129.9  Std R = 49.0  Min R = -260.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000943\n",
      "PolicyEntropy: 1.69\n",
      "PolicyLoss: -0.00172\n",
      "Steps: 7.2e+03\n",
      "TotalSteps: 6.22e+05\n",
      "ValFuncLoss: 0.0051\n",
      "Variance: 0.439\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1185   0.0577   0.2383   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0158   0.0083   0.0348   1.6645   0.7971   0.5555\n",
      "***** Episode 3286, Mean R = -112.3  Std R = 56.8  Min R = -279.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.00105\n",
      "PolicyEntropy: 1.69\n",
      "PolicyLoss: -0.0013\n",
      "Steps: 6.59e+03\n",
      "TotalSteps: 6.29e+05\n",
      "ValFuncLoss: 0.00475\n",
      "Variance: 0.437\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1017   0.0261   0.1506   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0036   0.0177   1.6645   0.7971   0.5555\n",
      "***** Episode 3317, Mean R = -115.2  Std R = 39.0  Min R = -202.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00104\n",
      "PolicyEntropy: 1.68\n",
      "PolicyLoss: -0.00159\n",
      "Steps: 6.65e+03\n",
      "TotalSteps: 6.36e+05\n",
      "ValFuncLoss: 0.00369\n",
      "Variance: 0.436\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2046   0.0594   0.3041   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0028   0.0129   1.6645   0.7971   0.5555\n",
      "***** Episode 3348, Mean R = -120.8  Std R = 40.7  Min R = -221.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.0012\n",
      "PolicyEntropy: 1.67\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 6.64e+03\n",
      "TotalSteps: 6.42e+05\n",
      "ValFuncLoss: 0.00356\n",
      "Variance: 0.436\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1074   0.0142   0.1258   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0017   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 3379, Mean R = -145.2  Std R = 59.9  Min R = -266.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.896\n",
      "ExplainedVarOld: 0.87\n",
      "KL: 0.00148\n",
      "PolicyEntropy: 1.66\n",
      "PolicyLoss: -0.00153\n",
      "Steps: 7.74e+03\n",
      "TotalSteps: 6.5e+05\n",
      "ValFuncLoss: 0.00712\n",
      "Variance: 0.434\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2060   0.0656   0.3703   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0021   0.0109   1.6645   0.7971   0.5555\n",
      "Update Cnt = 110    ET =    153.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   178.1    13.9   134.6 |   438.0   426.5   439.7 |  -825.4 -1057.9    -4.8 |  1094.6  1124.4  2037.4\n",
      "v_f      |  -12.23    6.91  -63.12 |   31.88   32.71   34.40 |  -87.07  -73.97 -108.75 |   71.59   74.79   59.61\n",
      "vr_f     |     2.6 |     5.6 |     0.1 |    90.4\n",
      "r_i      |  1027.4   -26.1  2347.8 |   579.1   577.1    28.6 |     6.8  -993.7  2300.4 |  1995.4   999.1  2399.8\n",
      "v_i      |  -39.79    0.39  -79.94 |   17.72   18.07    5.82 |  -69.30  -29.90  -89.97 |  -10.23   29.92  -70.07\n",
      "norm_rf  |   667.8 |   413.6 |    71.2 |  2099.0\n",
      "norm_vf  |   84.68 |   16.70 |   36.18 |  132.26\n",
      "thrust   |    1165     276    7515 |    6326    6326    5533 |  -14998  -14995  -14919 |   14997   14986   15000\n",
      "norm_thrust |   12563 |    3276 |    2000 |   15000\n",
      "fuel     |     276 |      88 |     161 |     605\n",
      "rewards  | -122.57 |   51.73 | -333.25 |  -47.46\n",
      "fuel_rewards |   -9.48 |    3.03 |  -20.78 |   -5.55\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.87 |    0.49 |    0.00 |    2.23\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  662.95 |  413.35 |   88.28 | 2094.00\n",
      "tracking_rewards | -113.09 |   48.98 | -313.13 |  -39.98\n",
      "steps    |     226 |      71 |     129 |     500\n",
      "***** Episode 3410, Mean R = -123.1  Std R = 59.9  Min R = -313.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.00106\n",
      "PolicyEntropy: 1.66\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 7.17e+03\n",
      "TotalSteps: 6.57e+05\n",
      "ValFuncLoss: 0.0051\n",
      "Variance: 0.433\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1654   0.0601   0.2800   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0017   0.0091   1.6645   0.7971   0.5555\n",
      "***** Episode 3441, Mean R = -109.4  Std R = 35.4  Min R = -248.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000914\n",
      "PolicyEntropy: 1.65\n",
      "PolicyLoss: -0.00145\n",
      "Steps: 6.60e+03\n",
      "TotalSteps: 6.64e+05\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.432\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3867   0.1599   0.6813   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0090   0.0042   0.0179   1.6645   0.7971   0.5555\n",
      "***** Episode 3472, Mean R = -114.7  Std R = 39.2  Min R = -250.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.00242\n",
      "PolicyEntropy: 1.64\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 6.76e+03\n",
      "TotalSteps: 6.71e+05\n",
      "ValFuncLoss: 0.00324\n",
      "Variance: 0.43\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1920   0.0684   0.3364   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0203   0.0094   0.0366   1.6645   0.7971   0.5555\n",
      "***** Episode 3503, Mean R = -125.2  Std R = 53.4  Min R = -317.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.927\n",
      "ExplainedVarOld: 0.884\n",
      "KL: 0.000789\n",
      "PolicyEntropy: 1.64\n",
      "PolicyLoss: -0.00179\n",
      "Steps: 7.12e+03\n",
      "TotalSteps: 6.78e+05\n",
      "ValFuncLoss: 0.00553\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1144   0.0360   0.1810   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0124   0.0063   0.0278   1.6645   0.7971   0.5555\n",
      "***** Episode 3534, Mean R = -117.9  Std R = 52.8  Min R = -282.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.000328\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.000896\n",
      "Steps: 7.04e+03\n",
      "TotalSteps: 6.85e+05\n",
      "ValFuncLoss: 0.00479\n",
      "Variance: 0.426\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1627   0.0506   0.2656   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0123   0.0063   0.0262   1.6645   0.7971   0.5555\n",
      "***** Episode 3565, Mean R = -118.9  Std R = 48.1  Min R = -271.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.00107\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.00223\n",
      "Steps: 7.24e+03\n",
      "TotalSteps: 6.92e+05\n",
      "ValFuncLoss: 0.00396\n",
      "Variance: 0.424\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1953   0.0727   0.3471   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0142   0.0056   0.0261   1.6645   0.7971   0.5555\n",
      "***** Episode 3596, Mean R = -130.0  Std R = 56.4  Min R = -299.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.922\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.00148\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.00187\n",
      "Steps: 7.2e+03\n",
      "TotalSteps: 6.99e+05\n",
      "ValFuncLoss: 0.00607\n",
      "Variance: 0.423\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1897   0.1004   0.4099   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0107   0.0045   0.0227   1.6645   0.7971   0.5555\n",
      "***** Episode 3627, Mean R = -133.5  Std R = 43.6  Min R = -231.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.912\n",
      "KL: 0.00137\n",
      "PolicyEntropy: 1.64\n",
      "PolicyLoss: -0.0018\n",
      "Steps: 7.43e+03\n",
      "TotalSteps: 7.07e+05\n",
      "ValFuncLoss: 0.00561\n",
      "Variance: 0.424\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1521   0.0555   0.2695   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0180   0.0086   0.0388   1.6645   0.7971   0.5555\n",
      "***** Episode 3658, Mean R = -115.3  Std R = 55.9  Min R = -274.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.907\n",
      "KL: 0.0013\n",
      "PolicyEntropy: 1.64\n",
      "PolicyLoss: -0.00189\n",
      "Steps: 6.86e+03\n",
      "TotalSteps: 7.13e+05\n",
      "ValFuncLoss: 0.00457\n",
      "Variance: 0.426\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1506   0.0459   0.2136   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0025   0.0117   1.6645   0.7971   0.5555\n",
      "***** Episode 3689, Mean R = -111.1  Std R = 34.7  Min R = -202.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000924\n",
      "PolicyEntropy: 1.65\n",
      "PolicyLoss: -0.0021\n",
      "Steps: 6.38e+03\n",
      "TotalSteps: 7.2e+05\n",
      "ValFuncLoss: 0.00424\n",
      "Variance: 0.426\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0984   0.0350   0.1792   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0104   0.0050   0.0223   1.6645   0.7971   0.5555\n",
      "Update Cnt = 120    ET =    153.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   232.9   -43.5   108.5 |   424.3   405.6   415.4 |  -876.8 -1094.1    -4.4 |  1255.2   915.9  2038.8\n",
      "v_f      |   -9.35    2.29  -66.09 |   29.22   31.36   31.69 |  -91.14  -74.56 -111.69 |   69.21   75.95   65.19\n",
      "vr_f     |     2.5 |     2.4 |     0.1 |    26.7\n",
      "r_i      |   974.8     1.6  2348.5 |   560.6   568.8    29.7 |    21.3  -990.8  2300.5 |  1996.0   996.6  2399.9\n",
      "v_i      |  -40.06   -0.71  -79.92 |   17.32   16.33    5.83 |  -69.97  -29.97  -89.83 |  -10.04   29.80  -70.32\n",
      "norm_rf  |   635.6 |   425.4 |    21.4 |  2120.8\n",
      "norm_vf  |   83.85 |   16.43 |   35.09 |  130.41\n",
      "thrust   |    1299     131    7452 |    6305    6219    5597 |  -14999  -15000  -14962 |   14998   14991   15000\n",
      "norm_thrust |   12490 |    3318 |    2000 |   15000\n",
      "fuel     |     272 |      79 |     155 |     557\n",
      "rewards  | -118.88 |   47.29 | -317.17 |  -55.90\n",
      "fuel_rewards |   -9.35 |    2.72 |  -19.14 |   -5.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.89 |    0.49 |    0.01 |    2.38\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  631.16 |  424.67 |   75.49 | 2115.77\n",
      "tracking_rewards | -109.53 |   44.90 | -300.26 |  -49.13\n",
      "steps    |     224 |      65 |     130 |     472\n",
      "***** Episode 3720, Mean R = -112.8  Std R = 40.1  Min R = -253.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000724\n",
      "PolicyEntropy: 1.65\n",
      "PolicyLoss: -0.000878\n",
      "Steps: 6.78e+03\n",
      "TotalSteps: 7.27e+05\n",
      "ValFuncLoss: 0.00461\n",
      "Variance: 0.425\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1648   0.0534   0.2555   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0104   0.0052   0.0256   1.6645   0.7971   0.5555\n",
      "***** Episode 3751, Mean R = -128.6  Std R = 59.5  Min R = -382.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.0012\n",
      "PolicyEntropy: 1.65\n",
      "PolicyLoss: -0.00211\n",
      "Steps: 7.12e+03\n",
      "TotalSteps: 7.34e+05\n",
      "ValFuncLoss: 0.00507\n",
      "Variance: 0.427\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1603   0.0547   0.2514   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0122   0.0060   0.0272   1.6645   0.7971   0.5555\n",
      "***** Episode 3782, Mean R = -107.6  Std R = 40.4  Min R = -264.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.00112\n",
      "PolicyEntropy: 1.66\n",
      "PolicyLoss: -0.00187\n",
      "Steps: 6.46e+03\n",
      "TotalSteps: 7.4e+05\n",
      "ValFuncLoss: 0.00419\n",
      "Variance: 0.426\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2103   0.0850   0.3653   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0101   0.0047   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 3813, Mean R = -118.1  Std R = 38.2  Min R = -210.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00144\n",
      "PolicyEntropy: 1.66\n",
      "PolicyLoss: -0.00209\n",
      "Steps: 6.78e+03\n",
      "TotalSteps: 7.47e+05\n",
      "ValFuncLoss: 0.00438\n",
      "Variance: 0.425\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1755   0.0785   0.3463   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0121   0.0059   0.0296   1.6645   0.7971   0.5555\n",
      "***** Episode 3844, Mean R = -102.1  Std R = 25.0  Min R = -199.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.00137\n",
      "PolicyEntropy: 1.66\n",
      "PolicyLoss: -0.00207\n",
      "Steps: 5.91e+03\n",
      "TotalSteps: 7.53e+05\n",
      "ValFuncLoss: 0.00454\n",
      "Variance: 0.428\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1637   0.0482   0.2675   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0086   0.0038   0.0187   1.6645   0.7971   0.5555\n",
      "***** Episode 3875, Mean R = -117.6  Std R = 38.5  Min R = -239.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.00082\n",
      "PolicyEntropy: 1.65\n",
      "PolicyLoss: -0.00183\n",
      "Steps: 6.71e+03\n",
      "TotalSteps: 7.6e+05\n",
      "ValFuncLoss: 0.00465\n",
      "Variance: 0.43\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1293   0.0370   0.2042   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0114   0.0046   0.0201   1.6645   0.7971   0.5555\n",
      "***** Episode 3906, Mean R = -130.4  Std R = 57.7  Min R = -292.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.899\n",
      "ExplainedVarOld: 0.872\n",
      "KL: 0.000918\n",
      "PolicyEntropy: 1.66\n",
      "PolicyLoss: -0.00152\n",
      "Steps: 7.34e+03\n",
      "TotalSteps: 7.67e+05\n",
      "ValFuncLoss: 0.00708\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1747   0.0730   0.3423   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0034   0.0148   1.6645   0.7971   0.5555\n",
      "***** Episode 3937, Mean R = -111.3  Std R = 24.6  Min R = -158.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00137\n",
      "PolicyEntropy: 1.66\n",
      "PolicyLoss: -0.00133\n",
      "Steps: 6.67e+03\n",
      "TotalSteps: 7.74e+05\n",
      "ValFuncLoss: 0.00413\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2190   0.0620   0.3414   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0223   0.0105   0.0449   1.6645   0.7971   0.5555\n",
      "***** Episode 3968, Mean R = -139.9  Std R = 70.6  Min R = -299.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.891\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 1.65\n",
      "PolicyLoss: -0.00221\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 7.82e+05\n",
      "ValFuncLoss: 0.00485\n",
      "Variance: 0.427\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1120   0.0443   0.2003   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0150   0.0062   0.0268   1.6645   0.7971   0.5555\n",
      "***** Episode 3999, Mean R = -121.5  Std R = 52.4  Min R = -289.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000817\n",
      "PolicyEntropy: 1.65\n",
      "PolicyLoss: -0.00116\n",
      "Steps: 6.83e+03\n",
      "TotalSteps: 7.88e+05\n",
      "ValFuncLoss: 0.00534\n",
      "Variance: 0.427\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1215   0.0268   0.1753   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0036   0.0165   1.6645   0.7971   0.5555\n",
      "Update Cnt = 130    ET =    147.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   221.7     7.6   103.2 |   419.6   422.9   398.9 |  -950.4  -959.9    -4.4 |  1320.0   886.7  2072.7\n",
      "v_f      |   -9.57    0.09  -67.79 |   32.75   31.30   31.01 |  -80.29  -85.99 -113.13 |   79.07   66.88   64.60\n",
      "vr_f     |     2.4 |     2.3 |     0.3 |    19.2\n",
      "r_i      |  1024.7   -42.7  2350.6 |   583.5   561.7    28.8 |    10.5  -986.2  2300.1 |  1989.5   993.8  2399.8\n",
      "v_i      |  -39.48    1.37  -80.54 |   17.77   18.03    5.80 |  -69.76  -29.29  -89.96 |  -10.03   29.98  -70.02\n",
      "norm_rf  |   648.8 |   391.1 |    20.9 |  2107.3\n",
      "norm_vf  |   86.32 |   15.84 |   39.49 |  127.79\n",
      "thrust   |    1273     -37    7406 |    6316    6155    5739 |  -14997  -14994  -14987 |   14995   14999   14999\n",
      "norm_thrust |   12495 |    3323 |    2000 |   15000\n",
      "fuel     |     267 |      81 |     161 |     596\n",
      "rewards  | -118.77 |   48.72 | -382.31 |  -58.29\n",
      "fuel_rewards |   -9.19 |    2.77 |  -20.48 |   -5.55\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.91 |    0.51 |    0.01 |    2.94\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  644.32 |  390.28 |   61.53 | 2102.31\n",
      "tracking_rewards | -109.58 |   46.29 | -361.83 |  -51.16\n",
      "steps    |     220 |      66 |     130 |     500\n",
      "***** Episode 4030, Mean R = -110.5  Std R = 46.0  Min R = -282.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000853\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.00187\n",
      "Steps: 6.4e+03\n",
      "TotalSteps: 7.95e+05\n",
      "ValFuncLoss: 0.00489\n",
      "Variance: 0.424\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1613   0.0443   0.2587   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0026   0.0142   1.6645   0.7971   0.5555\n",
      "***** Episode 4061, Mean R = -115.4  Std R = 42.5  Min R = -283.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.00126\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.00179\n",
      "Steps: 6.88e+03\n",
      "TotalSteps: 8.02e+05\n",
      "ValFuncLoss: 0.00452\n",
      "Variance: 0.426\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1782   0.0760   0.3334   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0343   0.0151   0.0678   1.6645   0.7971   0.5555\n",
      "***** Episode 4092, Mean R = -144.4  Std R = 72.3  Min R = -298.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.914\n",
      "ExplainedVarOld: 0.86\n",
      "KL: 0.00134\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00166\n",
      "Steps: 7.65e+03\n",
      "TotalSteps: 8.09e+05\n",
      "ValFuncLoss: 0.007\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0836   0.0194   0.1220   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0142   0.0069   0.0276   1.6645   0.7971   0.5555\n",
      "***** Episode 4123, Mean R = -108.0  Std R = 30.5  Min R = -217.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000906\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00108\n",
      "Steps: 6.70e+03\n",
      "TotalSteps: 8.16e+05\n",
      "ValFuncLoss: 0.00432\n",
      "Variance: 0.43\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0810   0.0101   0.0928   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0095   0.0040   0.0208   1.6645   0.7971   0.5555\n",
      "***** Episode 4154, Mean R = -124.2  Std R = 58.2  Min R = -334.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.00156\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00144\n",
      "Steps: 6.89e+03\n",
      "TotalSteps: 8.23e+05\n",
      "ValFuncLoss: 0.00681\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1177   0.0217   0.1795   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0046   0.0223   1.6645   0.7971   0.5555\n",
      "***** Episode 4185, Mean R = -115.4  Std R = 46.6  Min R = -273.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00116\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00149\n",
      "Steps: 6.71e+03\n",
      "TotalSteps: 8.3e+05\n",
      "ValFuncLoss: 0.0047\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0769   0.0178   0.1173   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0105   0.0045   0.0236   1.6645   0.7971   0.5555\n",
      "***** Episode 4216, Mean R = -114.8  Std R = 36.5  Min R = -245.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.902\n",
      "ExplainedVarOld: 0.846\n",
      "KL: 0.00101\n",
      "PolicyEntropy: 1.61\n",
      "PolicyLoss: -0.000771\n",
      "Steps: 6.74e+03\n",
      "TotalSteps: 8.36e+05\n",
      "ValFuncLoss: 0.00587\n",
      "Variance: 0.428\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2063   0.0705   0.3661   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0026   0.0116   1.6645   0.7971   0.5555\n",
      "***** Episode 4247, Mean R = -108.3  Std R = 35.7  Min R = -238.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.00104\n",
      "PolicyEntropy: 1.61\n",
      "PolicyLoss: -0.00178\n",
      "Steps: 6.44e+03\n",
      "TotalSteps: 8.43e+05\n",
      "ValFuncLoss: 0.00408\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1915   0.1023   0.4176   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0018   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 4278, Mean R = -113.9  Std R = 34.8  Min R = -231.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.00144\n",
      "PolicyEntropy: 1.61\n",
      "PolicyLoss: -0.00206\n",
      "Steps: 6.64e+03\n",
      "TotalSteps: 8.49e+05\n",
      "ValFuncLoss: 0.00532\n",
      "Variance: 0.426\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1104   0.0320   0.1697   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0027   0.0146   1.6645   0.7971   0.5555\n",
      "***** Episode 4309, Mean R = -119.6  Std R = 45.1  Min R = -272.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.00113\n",
      "PolicyEntropy: 1.61\n",
      "PolicyLoss: -0.00172\n",
      "Steps: 6.95e+03\n",
      "TotalSteps: 8.56e+05\n",
      "ValFuncLoss: 0.00437\n",
      "Variance: 0.428\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2054   0.0863   0.3501   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0113   0.0050   0.0253   1.6645   0.7971   0.5555\n",
      "Update Cnt = 140    ET =    150.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   195.3   -82.5   128.0 |   400.7   425.0   447.9 |  -758.6 -1133.3    -4.8 |  1194.4   867.2  2037.8\n",
      "v_f      |  -10.68   -1.40  -66.27 |   31.75   32.17   34.20 |  -83.39  -72.68 -107.24 |  106.21   85.14   67.90\n",
      "vr_f     |     2.3 |     2.2 |     0.0 |    28.9\n",
      "r_i      |  1046.9    15.3  2350.0 |   579.7   591.5    30.9 |     8.2  -993.5  2300.2 |  1999.5   997.6  2399.7\n",
      "v_i      |  -40.47    0.20  -80.04 |   16.87   17.89    5.84 |  -69.82  -29.99  -89.87 |  -10.12   29.95  -70.10\n",
      "norm_rf  |   647.0 |   429.6 |    35.4 |  2230.7\n",
      "norm_vf  |   86.14 |   17.30 |   18.84 |  131.77\n",
      "thrust   |    1274     -64    7432 |    6242    6087    5744 |  -14976  -15000  -14971 |   14999   14997   15000\n",
      "norm_thrust |   12437 |    3344 |    2000 |   15000\n",
      "fuel     |     268 |      77 |     165 |     578\n",
      "rewards  | -118.93 |   49.36 | -334.51 |  -53.85\n",
      "fuel_rewards |   -9.22 |    2.63 |  -19.84 |   -5.71\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.87 |    0.47 |    0.01 |    2.47\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  642.72 |  428.62 |   77.42 | 2225.72\n",
      "tracking_rewards | -109.72 |   47.07 | -316.35 |  -46.67\n",
      "steps    |     222 |      62 |     137 |     476\n",
      "***** Episode 4340, Mean R = -125.2  Std R = 63.0  Min R = -326.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.861\n",
      "KL: 0.00158\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00202\n",
      "Steps: 7.1e+03\n",
      "TotalSteps: 8.63e+05\n",
      "ValFuncLoss: 0.00523\n",
      "Variance: 0.428\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1517   0.0598   0.2711   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0029   0.0143   1.6645   0.7971   0.5555\n",
      "***** Episode 4371, Mean R = -118.5  Std R = 45.3  Min R = -294.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.901\n",
      "KL: 0.000679\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00123\n",
      "Steps: 7.17e+03\n",
      "TotalSteps: 8.71e+05\n",
      "ValFuncLoss: 0.00539\n",
      "Variance: 0.427\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1998   0.0719   0.3326   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0088   0.0033   0.0168   1.6645   0.7971   0.5555\n",
      "***** Episode 4402, Mean R = -113.7  Std R = 42.7  Min R = -232.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.00164\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00217\n",
      "Steps: 6.69e+03\n",
      "TotalSteps: 8.77e+05\n",
      "ValFuncLoss: 0.00473\n",
      "Variance: 0.429\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1546   0.0453   0.2669   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0086   0.0041   0.0231   1.6645   0.7971   0.5555\n",
      "***** Episode 4433, Mean R = -111.4  Std R = 43.2  Min R = -256.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000721\n",
      "PolicyEntropy: 1.61\n",
      "PolicyLoss: -0.00145\n",
      "Steps: 6.62e+03\n",
      "TotalSteps: 8.84e+05\n",
      "ValFuncLoss: 0.00423\n",
      "Variance: 0.428\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2051   0.0885   0.4038   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0149   0.0068   0.0282   1.6645   0.7971   0.5555\n",
      "***** Episode 4464, Mean R = -113.6  Std R = 38.8  Min R = -232.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.00168\n",
      "PolicyEntropy: 1.62\n",
      "PolicyLoss: -0.00182\n",
      "Steps: 6.47e+03\n",
      "TotalSteps: 8.9e+05\n",
      "ValFuncLoss: 0.00447\n",
      "Variance: 0.432\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1358   0.0364   0.2192   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0090   0.0041   0.0175   1.6645   0.7971   0.5555\n",
      "***** Episode 4495, Mean R = -119.5  Std R = 47.9  Min R = -276.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000763\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.00149\n",
      "Steps: 6.94e+03\n",
      "TotalSteps: 8.97e+05\n",
      "ValFuncLoss: 0.00329\n",
      "Variance: 0.432\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2305   0.0883   0.4081   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0016   0.0077   1.6645   0.7971   0.5555\n",
      "***** Episode 4526, Mean R = -117.3  Std R = 48.3  Min R = -254.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.00179\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 6.8e+03\n",
      "TotalSteps: 9.04e+05\n",
      "ValFuncLoss: 0.004\n",
      "Variance: 0.43\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1336   0.0435   0.2171   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0033   0.0173   1.6645   0.7971   0.5555\n",
      "***** Episode 4557, Mean R = -102.7  Std R = 25.9  Min R = -178.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.00122\n",
      "PolicyEntropy: 1.63\n",
      "PolicyLoss: -0.00182\n",
      "Steps: 6.44e+03\n",
      "TotalSteps: 9.11e+05\n",
      "ValFuncLoss: 0.00372\n",
      "Variance: 0.43\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1183   0.0268   0.1687   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0032   0.0161   1.6645   0.7971   0.5555\n",
      "***** Episode 4588, Mean R = -105.9  Std R = 39.1  Min R = -276.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.00137\n",
      "PolicyEntropy: 1.6\n",
      "PolicyLoss: -0.00163\n",
      "Steps: 6.22e+03\n",
      "TotalSteps: 9.17e+05\n",
      "ValFuncLoss: 0.00408\n",
      "Variance: 0.427\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1538   0.0638   0.3165   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0029   0.0142   1.6645   0.7971   0.5555\n",
      "***** Episode 4619, Mean R = -107.3  Std R = 27.4  Min R = -192.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.00106\n",
      "PolicyEntropy: 1.59\n",
      "PolicyLoss: -0.0019\n",
      "Steps: 6.4e+03\n",
      "TotalSteps: 9.23e+05\n",
      "ValFuncLoss: 0.00358\n",
      "Variance: 0.426\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1162   0.0297   0.1611   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0087   0.0037   0.0190   1.6645   0.7971   0.5555\n",
      "Update Cnt = 150    ET =    144.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   158.7   -74.8    93.8 |   388.6   427.9   397.4 |  -823.6 -1052.1    -4.8 |  1137.0   834.1  2050.3\n",
      "v_f      |   -9.54    2.13  -72.61 |   29.48   30.89   30.58 |  -91.48  -76.12 -117.78 |   70.18   68.43   64.01\n",
      "vr_f     |     2.9 |     2.6 |     0.4 |    23.1\n",
      "r_i      |   940.3   -45.2  2350.8 |   563.1   591.7    28.4 |     7.3  -999.7  2300.8 |  1989.7   999.8  2400.0\n",
      "v_i      |  -40.62   -0.59  -79.72 |   17.02   17.78    5.70 |  -69.91  -29.92  -89.96 |  -10.32   30.00  -70.04\n",
      "norm_rf  |   609.7 |   399.8 |     4.5 |  2208.0\n",
      "norm_vf  |   88.69 |   16.11 |   41.70 |  139.46\n",
      "thrust   |    1391     131    7228 |    6274    6016    5855 |  -14999  -14997  -14959 |   15000   14991   15000\n",
      "norm_thrust |   12347 |    3404 |    2000 |   15000\n",
      "fuel     |     256 |      70 |     157 |     575\n",
      "rewards  | -112.13 |   41.60 | -294.69 |  -47.57\n",
      "fuel_rewards |   -8.82 |    2.41 |  -19.75 |   -5.42\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.95 |    0.50 |    0.00 |    3.11\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  605.41 |  398.82 |   79.17 | 2202.95\n",
      "tracking_rewards | -103.32 |   39.55 | -275.86 |  -39.68\n",
      "steps    |     213 |      58 |     131 |     500\n",
      "***** Episode 4650, Mean R = -111.5  Std R = 47.0  Min R = -293.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.00111\n",
      "PolicyEntropy: 1.6\n",
      "PolicyLoss: -0.00167\n",
      "Steps: 6.44e+03\n",
      "TotalSteps: 9.3e+05\n",
      "ValFuncLoss: 0.00569\n",
      "Variance: 0.427\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1560   0.0603   0.2569   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0027   0.0153   1.6645   0.7971   0.5555\n",
      "***** Episode 4681, Mean R = -109.9  Std R = 43.1  Min R = -270.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.000964\n",
      "PolicyEntropy: 1.57\n",
      "PolicyLoss: -0.0021\n",
      "Steps: 6.78e+03\n",
      "TotalSteps: 9.36e+05\n",
      "ValFuncLoss: 0.00378\n",
      "Variance: 0.422\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1071   0.0178   0.1461   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0024   0.0112   1.6645   0.7971   0.5555\n",
      "***** Episode 4712, Mean R = -101.1  Std R = 33.3  Min R = -227.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.000838\n",
      "PolicyEntropy: 1.55\n",
      "PolicyLoss: -0.00171\n",
      "Steps: 6.37e+03\n",
      "TotalSteps: 9.43e+05\n",
      "ValFuncLoss: 0.00358\n",
      "Variance: 0.42\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1630   0.0702   0.3100   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0241   0.0114   0.0526   1.6645   0.7971   0.5555\n",
      "***** Episode 4743, Mean R = -124.4  Std R = 65.0  Min R = -405.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.922\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.0015\n",
      "PolicyEntropy: 1.55\n",
      "PolicyLoss: -0.00189\n",
      "Steps: 6.78e+03\n",
      "TotalSteps: 9.5e+05\n",
      "ValFuncLoss: 0.00475\n",
      "Variance: 0.421\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1893   0.0609   0.2959   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0044   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 4774, Mean R = -107.9  Std R = 28.9  Min R = -205.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.00126\n",
      "PolicyEntropy: 1.54\n",
      "PolicyLoss: -0.00174\n",
      "Steps: 6.39e+03\n",
      "TotalSteps: 9.56e+05\n",
      "ValFuncLoss: 0.00401\n",
      "Variance: 0.421\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0979   0.0192   0.1335   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0034   0.0146   1.6645   0.7971   0.5555\n",
      "***** Episode 4805, Mean R = -115.0  Std R = 43.5  Min R = -256.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000845\n",
      "PolicyEntropy: 1.53\n",
      "PolicyLoss: -0.00135\n",
      "Steps: 6.58e+03\n",
      "TotalSteps: 9.63e+05\n",
      "ValFuncLoss: 0.00535\n",
      "Variance: 0.418\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2344   0.0677   0.3432   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0018   0.0084   1.6645   0.7971   0.5555\n",
      "***** Episode 4836, Mean R = -112.2  Std R = 37.7  Min R = -253.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00129\n",
      "PolicyEntropy: 1.53\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 6.75e+03\n",
      "TotalSteps: 9.69e+05\n",
      "ValFuncLoss: 0.00426\n",
      "Variance: 0.416\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1828   0.0895   0.4127   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0028   0.0125   1.6645   0.7971   0.5555\n",
      "***** Episode 4867, Mean R = -113.4  Std R = 38.7  Min R = -240.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00131\n",
      "PolicyEntropy: 1.52\n",
      "PolicyLoss: -0.00166\n",
      "Steps: 6.61e+03\n",
      "TotalSteps: 9.76e+05\n",
      "ValFuncLoss: 0.00441\n",
      "Variance: 0.418\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1891   0.0587   0.3329   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0017   0.0089   1.6645   0.7971   0.5555\n",
      "***** Episode 4898, Mean R = -117.0  Std R = 45.8  Min R = -271.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.00113\n",
      "PolicyEntropy: 1.53\n",
      "PolicyLoss: -0.00214\n",
      "Steps: 6.82e+03\n",
      "TotalSteps: 9.83e+05\n",
      "ValFuncLoss: 0.00476\n",
      "Variance: 0.42\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2104   0.0761   0.3518   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0112   0.0045   0.0223   1.6645   0.7971   0.5555\n",
      "***** Episode 4929, Mean R = -124.8  Std R = 53.4  Min R = -297.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.00144\n",
      "PolicyEntropy: 1.53\n",
      "PolicyLoss: -0.00189\n",
      "Steps: 7.03e+03\n",
      "TotalSteps: 9.9e+05\n",
      "ValFuncLoss: 0.00475\n",
      "Variance: 0.42\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1018   0.0367   0.1786   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0029   0.0149   1.6645   0.7971   0.5555\n",
      "Update Cnt = 160    ET =    146.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   192.6   -10.6    79.4 |   412.5   406.4   361.4 |  -931.0  -897.2    -5.4 |  1108.6   953.8  2154.9\n",
      "v_f      |  -11.30    3.65  -74.15 |   29.18   33.49   28.65 |  -84.04  -76.15 -113.63 |   76.83   85.45   67.14\n",
      "vr_f     |     2.4 |     1.9 |     0.0 |    19.3\n",
      "r_i      |   998.5   -36.8  2351.3 |   581.5   607.9    28.8 |     1.7  -990.0  2300.6 |  1994.6   999.7  2399.9\n",
      "v_i      |  -38.02   -2.17  -79.72 |   16.95   17.30    5.72 |  -69.69  -29.85  -89.97 |  -10.11   29.49  -70.00\n",
      "norm_rf  |   610.9 |   369.1 |    32.2 |  2194.0\n",
      "norm_vf  |   90.46 |   15.80 |   34.92 |  131.05\n",
      "thrust   |    1169     244    7174 |    6265    5940    5820 |  -14996  -14984  -14996 |   15000   14995   15000\n",
      "norm_thrust |   12227 |    3434 |    2000 |   15000\n",
      "fuel     |     257 |      76 |     155 |     570\n",
      "rewards  | -114.44 |   45.11 | -405.51 |  -47.68\n",
      "fuel_rewards |   -8.84 |    2.62 |  -19.56 |   -5.33\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.95 |    0.53 |    0.00 |    3.58\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  606.72 |  367.94 |   86.15 | 2188.96\n",
      "tracking_rewards | -105.61 |   42.81 | -385.95 |  -39.30\n",
      "steps    |     216 |      63 |     131 |     500\n",
      "***** Episode 4960, Mean R = -118.9  Std R = 45.5  Min R = -270.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000803\n",
      "PolicyEntropy: 1.52\n",
      "PolicyLoss: -0.00124\n",
      "Steps: 6.89e+03\n",
      "TotalSteps: 9.97e+05\n",
      "ValFuncLoss: 0.0051\n",
      "Variance: 0.419\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0912   0.0243   0.1249   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0098   0.0039   0.0226   1.6645   0.7971   0.5555\n",
      "***** Episode 4991, Mean R = -121.3  Std R = 47.8  Min R = -237.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000791\n",
      "PolicyEntropy: 1.52\n",
      "PolicyLoss: -0.00104\n",
      "Steps: 6.98e+03\n",
      "TotalSteps: 1e+06\n",
      "ValFuncLoss: 0.00463\n",
      "Variance: 0.415\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1262   0.0478   0.2465   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0040   0.0156   1.6645   0.7971   0.5555\n",
      "***** Episode 5022, Mean R = -111.8  Std R = 36.3  Min R = -253.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00123\n",
      "PolicyEntropy: 1.52\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 6.96e+03\n",
      "TotalSteps: 1.01e+06\n",
      "ValFuncLoss: 0.0041\n",
      "Variance: 0.412\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2219   0.0666   0.3241   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0023   0.0108   1.6645   0.7971   0.5555\n",
      "***** Episode 5053, Mean R = -99.2  Std R = 22.4  Min R = -150.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00156\n",
      "PolicyEntropy: 1.51\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 6.34e+03\n",
      "TotalSteps: 1.02e+06\n",
      "ValFuncLoss: 0.00522\n",
      "Variance: 0.41\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1489   0.0574   0.2668   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0017   0.0094   1.6645   0.7971   0.5555\n",
      "***** Episode 5084, Mean R = -105.8  Std R = 36.6  Min R = -231.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000959\n",
      "PolicyEntropy: 1.5\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 6.5e+03\n",
      "TotalSteps: 1.02e+06\n",
      "ValFuncLoss: 0.00472\n",
      "Variance: 0.409\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1931   0.0548   0.2865   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0091   0.0038   0.0208   1.6645   0.7971   0.5555\n",
      "***** Episode 5115, Mean R = -121.2  Std R = 63.8  Min R = -323.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.00138\n",
      "PolicyEntropy: 1.5\n",
      "PolicyLoss: -0.0017\n",
      "Steps: 6.80e+03\n",
      "TotalSteps: 1.03e+06\n",
      "ValFuncLoss: 0.00503\n",
      "Variance: 0.41\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1797   0.0676   0.3410   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0014   0.0079   1.6645   0.7971   0.5555\n",
      "***** Episode 5146, Mean R = -115.5  Std R = 53.0  Min R = -269.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.00144\n",
      "PolicyEntropy: 1.5\n",
      "PolicyLoss: -0.00223\n",
      "Steps: 6.56e+03\n",
      "TotalSteps: 1.04e+06\n",
      "ValFuncLoss: 0.00633\n",
      "Variance: 0.414\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1535   0.0506   0.2534   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0094   0.0050   0.0193   1.6645   0.7971   0.5555\n",
      "***** Episode 5177, Mean R = -99.7  Std R = 22.5  Min R = -165.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000956\n",
      "PolicyEntropy: 1.48\n",
      "PolicyLoss: -0.00196\n",
      "Steps: 5.91e+03\n",
      "TotalSteps: 1.04e+06\n",
      "ValFuncLoss: 0.00611\n",
      "Variance: 0.41\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1456   0.0615   0.2735   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0081   0.0034   0.0179   1.6645   0.7971   0.5555\n",
      "***** Episode 5208, Mean R = -117.6  Std R = 47.2  Min R = -270.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.89\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 1.47\n",
      "PolicyLoss: -0.00133\n",
      "Steps: 6.84e+03\n",
      "TotalSteps: 1.05e+06\n",
      "ValFuncLoss: 0.00828\n",
      "Variance: 0.408\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2980   0.1398   0.6158   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0088   0.0054   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 5239, Mean R = -104.0  Std R = 21.5  Min R = -162.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.00192\n",
      "PolicyEntropy: 1.46\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 6.15e+03\n",
      "TotalSteps: 1.06e+06\n",
      "ValFuncLoss: 0.00526\n",
      "Variance: 0.405\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1442   0.0380   0.2302   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0132   0.0080   0.0327   1.6645   0.7971   0.5555\n",
      "Update Cnt = 170    ET =    142.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   141.2   -45.1    63.5 |   394.1   405.4   325.7 |  -806.3 -1040.3    -5.0 |  1370.7  1019.7  2019.0\n",
      "v_f      |  -11.05   -3.81  -75.48 |   29.59   33.15   26.14 |  -86.43  -85.61 -107.55 |   62.88   61.33   54.00\n",
      "vr_f     |     2.6 |     2.2 |     0.4 |    20.2\n",
      "r_i      |   983.3    12.6  2351.4 |   571.7   586.5    27.7 |     2.5  -987.0  2300.1 |  1995.9   994.3  2399.8\n",
      "v_i      |  -39.67    1.10  -79.69 |   17.47   17.88    5.79 |  -69.95  -29.92  -89.93 |  -10.12   29.95  -70.02\n",
      "norm_rf  |   571.5 |   353.6 |    50.5 |  2040.8\n",
      "norm_vf  |   90.96 |   14.80 |   36.69 |  138.21\n",
      "thrust   |    1311    -206    7124 |    6132    5860    5808 |  -14989  -14999  -14882 |   14999   14998   15000\n",
      "norm_thrust |   12084 |    3488 |    2000 |   15000\n",
      "fuel     |     248 |      69 |     163 |     567\n",
      "rewards  | -109.50 |   41.10 | -323.90 |  -57.88\n",
      "fuel_rewards |   -8.52 |    2.38 |  -19.47 |   -5.60\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.98 |    0.47 |    0.01 |    3.14\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  567.36 |  352.51 |   85.54 | 2035.84\n",
      "tracking_rewards | -100.98 |   39.05 | -306.03 |  -50.42\n",
      "steps    |     211 |      58 |     138 |     500\n",
      "***** Episode 5270, Mean R = -98.8  Std R = 25.3  Min R = -175.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000873\n",
      "PolicyEntropy: 1.46\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 6.31e+03\n",
      "TotalSteps: 1.06e+06\n",
      "ValFuncLoss: 0.00522\n",
      "Variance: 0.401\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1935   0.0803   0.3568   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0036   0.0186   1.6645   0.7971   0.5555\n",
      "***** Episode 5301, Mean R = -101.8  Std R = 43.0  Min R = -307.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.00175\n",
      "PolicyEntropy: 1.45\n",
      "PolicyLoss: -0.00189\n",
      "Steps: 6.35e+03\n",
      "TotalSteps: 1.07e+06\n",
      "ValFuncLoss: 0.00465\n",
      "Variance: 0.399\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2826   0.1283   0.5826   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0115   0.0058   0.0222   1.6645   0.7971   0.5555\n",
      "***** Episode 5332, Mean R = -120.8  Std R = 40.0  Min R = -288.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.00186\n",
      "PolicyEntropy: 1.46\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 7e+03\n",
      "TotalSteps: 1.08e+06\n",
      "ValFuncLoss: 0.00502\n",
      "Variance: 0.399\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1257   0.0499   0.2461   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0124   0.0058   0.0255   1.6645   0.7971   0.5555\n",
      "***** Episode 5363, Mean R = -133.3  Std R = 57.8  Min R = -311.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.0013\n",
      "PolicyEntropy: 1.45\n",
      "PolicyLoss: -0.00144\n",
      "Steps: 7.61e+03\n",
      "TotalSteps: 1.08e+06\n",
      "ValFuncLoss: 0.00606\n",
      "Variance: 0.397\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2371   0.0866   0.4286   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0086   0.0043   0.0159   1.6645   0.7971   0.5555\n",
      "***** Episode 5394, Mean R = -96.5  Std R = 22.7  Min R = -156.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.00115\n",
      "PolicyEntropy: 1.45\n",
      "PolicyLoss: -0.00232\n",
      "Steps: 6.05e+03\n",
      "TotalSteps: 1.09e+06\n",
      "ValFuncLoss: 0.00438\n",
      "Variance: 0.395\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2260   0.0841   0.4211   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0166   0.0096   0.0350   1.6645   0.7971   0.5555\n",
      "***** Episode 5425, Mean R = -121.3  Std R = 66.3  Min R = -365.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.00141\n",
      "PolicyEntropy: 1.44\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 6.76e+03\n",
      "TotalSteps: 1.1e+06\n",
      "ValFuncLoss: 0.00443\n",
      "Variance: 0.395\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1838   0.0605   0.3365   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0132   0.0083   0.0337   1.6645   0.7971   0.5555\n",
      "***** Episode 5456, Mean R = -118.3  Std R = 48.7  Min R = -265.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.00111\n",
      "PolicyEntropy: 1.41\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 7.44e+03\n",
      "TotalSteps: 1.1e+06\n",
      "ValFuncLoss: 0.00437\n",
      "Variance: 0.392\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1317   0.0426   0.2127   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0067   0.0030   0.0145   1.6645   0.7971   0.5555\n",
      "***** Episode 5487, Mean R = -110.1  Std R = 44.1  Min R = -288.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000941\n",
      "PolicyEntropy: 1.4\n",
      "PolicyLoss: -0.00128\n",
      "Steps: 6.84e+03\n",
      "TotalSteps: 1.11e+06\n",
      "ValFuncLoss: 0.00605\n",
      "Variance: 0.39\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1440   0.0389   0.2100   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0175   0.0102   0.0412   1.6645   0.7971   0.5555\n",
      "***** Episode 5518, Mean R = -124.8  Std R = 60.5  Min R = -321.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000896\n",
      "PolicyEntropy: 1.39\n",
      "PolicyLoss: -0.00187\n",
      "Steps: 6.97e+03\n",
      "TotalSteps: 1.12e+06\n",
      "ValFuncLoss: 0.00511\n",
      "Variance: 0.391\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2399   0.1170   0.4734   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0104   0.0040   0.0233   1.6645   0.7971   0.5555\n",
      "***** Episode 5549, Mean R = -112.1  Std R = 44.7  Min R = -315.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.00153\n",
      "PolicyEntropy: 1.39\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 6.89e+03\n",
      "TotalSteps: 1.12e+06\n",
      "ValFuncLoss: 0.0037\n",
      "Variance: 0.393\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1652   0.0602   0.2989   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0108   0.0053   0.0250   1.6645   0.7971   0.5555\n",
      "Update Cnt = 180    ET =    151.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   133.2    -7.8    68.1 |   404.0   425.1   323.1 |  -832.7 -1031.0    -5.0 |  1029.3  1042.0  2102.3\n",
      "v_f      |  -11.14    1.79  -69.31 |   28.34   30.84   26.71 |  -80.36  -72.51 -108.77 |   48.45   66.50   55.49\n",
      "vr_f     |     2.9 |     5.0 |     0.7 |    76.4\n",
      "r_i      |  1015.3   -15.6  2349.2 |   586.8   601.9    28.7 |     5.0  -998.8  2300.1 |  1991.8   995.6  2400.0\n",
      "v_i      |  -39.05   -0.66  -79.68 |   17.05   17.03    5.65 |  -69.99  -29.89  -89.73 |  -10.42   29.93  -70.17\n",
      "norm_rf  |   590.4 |   349.4 |    88.2 |  2107.9\n",
      "norm_vf  |   84.40 |   16.58 |   21.71 |  128.19\n",
      "thrust   |    1201      93    7315 |    5984    5891    5622 |  -14999  -15000  -14976 |   14996   14991   15000\n",
      "norm_thrust |   12044 |    3465 |    2000 |   15000\n",
      "fuel     |     262 |      82 |     161 |     592\n",
      "rewards  | -116.39 |   51.30 | -365.56 |  -56.15\n",
      "fuel_rewards |   -9.01 |    2.81 |  -20.32 |   -5.53\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.93 |    0.49 |    0.01 |    2.43\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  585.54 |  349.26 |   87.85 | 2102.90\n",
      "tracking_rewards | -107.38 |   48.77 | -346.07 |  -48.93\n",
      "steps    |     224 |      70 |     131 |     500\n",
      "***** Episode 5580, Mean R = -125.0  Std R = 59.1  Min R = -319.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00165\n",
      "PolicyEntropy: 1.41\n",
      "PolicyLoss: -0.00206\n",
      "Steps: 7.44e+03\n",
      "TotalSteps: 1.13e+06\n",
      "ValFuncLoss: 0.00363\n",
      "Variance: 0.395\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2313   0.0773   0.3883   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0067   0.0027   0.0141   1.6645   0.7971   0.5555\n",
      "***** Episode 5611, Mean R = -115.7  Std R = 43.7  Min R = -283.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.00128\n",
      "PolicyEntropy: 1.41\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 6.74e+03\n",
      "TotalSteps: 1.14e+06\n",
      "ValFuncLoss: 0.004\n",
      "Variance: 0.394\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2154   0.0812   0.3649   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0130   0.0054   0.0245   1.6645   0.7971   0.5555\n",
      "***** Episode 5642, Mean R = -125.0  Std R = 60.1  Min R = -307.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.00178\n",
      "PolicyEntropy: 1.41\n",
      "PolicyLoss: -0.00209\n",
      "Steps: 6.81e+03\n",
      "TotalSteps: 1.14e+06\n",
      "ValFuncLoss: 0.00539\n",
      "Variance: 0.396\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1425   0.0499   0.2492   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0120   0.0039   0.0229   1.6645   0.7971   0.5555\n",
      "***** Episode 5673, Mean R = -128.8  Std R = 52.4  Min R = -288.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000742\n",
      "PolicyEntropy: 1.4\n",
      "PolicyLoss: -0.00197\n",
      "Steps: 7.73e+03\n",
      "TotalSteps: 1.15e+06\n",
      "ValFuncLoss: 0.00484\n",
      "Variance: 0.397\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1037   0.0403   0.1995   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0106   0.0044   0.0238   1.6645   0.7971   0.5555\n",
      "***** Episode 5704, Mean R = -127.4  Std R = 58.9  Min R = -298.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.000962\n",
      "PolicyEntropy: 1.4\n",
      "PolicyLoss: -0.00155\n",
      "Steps: 7.62e+03\n",
      "TotalSteps: 1.16e+06\n",
      "ValFuncLoss: 0.00537\n",
      "Variance: 0.396\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2561   0.1197   0.5625   0.7268   0.4041   0.1940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0031   0.0159   1.6645   0.7971   0.5555\n",
      "***** Episode 5735, Mean R = -101.2  Std R = 25.5  Min R = -165.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00132\n",
      "PolicyEntropy: 1.4\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 6.37e+03\n",
      "TotalSteps: 1.17e+06\n",
      "ValFuncLoss: 0.00428\n",
      "Variance: 0.395\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2168   0.0853   0.3838   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0092   0.0048   0.0217   1.6645   0.7971   0.5555\n",
      "***** Episode 5766, Mean R = -122.5  Std R = 49.6  Min R = -294.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.00129\n",
      "PolicyEntropy: 1.38\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 7.07e+03\n",
      "TotalSteps: 1.17e+06\n",
      "ValFuncLoss: 0.00512\n",
      "Variance: 0.395\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2509   0.0823   0.4167   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0086   0.0034   0.0160   1.6645   0.7971   0.5555\n",
      "***** Episode 5797, Mean R = -102.7  Std R = 18.4  Min R = -164.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00113\n",
      "PolicyEntropy: 1.38\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 6.35e+03\n",
      "TotalSteps: 1.18e+06\n",
      "ValFuncLoss: 0.00476\n",
      "Variance: 0.395\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1593   0.0430   0.2233   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0046   0.0017   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 5828, Mean R = -105.2  Std R = 32.5  Min R = -229.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000929\n",
      "PolicyEntropy: 1.38\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 7.06e+03\n",
      "TotalSteps: 1.19e+06\n",
      "ValFuncLoss: 0.00403\n",
      "Variance: 0.393\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1603   0.0540   0.2471   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0106   0.0060   0.0239   1.6645   0.7971   0.5555\n",
      "***** Episode 5859, Mean R = -98.2  Std R = 18.7  Min R = -141.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000974\n",
      "PolicyEntropy: 1.36\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 6.37e+03\n",
      "TotalSteps: 1.19e+06\n",
      "ValFuncLoss: 0.00412\n",
      "Variance: 0.393\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1251   0.0424   0.1989   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0105   0.0043   0.0233   1.6645   0.7971   0.5555\n",
      "Update Cnt = 190    ET =    148.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   120.5    28.4    71.9 |   404.3   410.1   342.5 |  -808.3  -992.9    -4.7 |  1018.2   842.6  2129.4\n",
      "v_f      |  -12.37   -3.46  -67.84 |   27.89   29.92   26.59 |  -85.94  -71.78 -107.58 |   72.35   67.05   61.98\n",
      "vr_f     |     2.5 |     2.4 |     0.4 |    34.4\n",
      "r_i      |  1002.2    46.7  2349.6 |   573.1   580.8    30.4 |     2.1  -990.4  2300.1 |  1998.0   993.0  2399.6\n",
      "v_i      |  -39.80    1.33  -79.88 |   17.27   17.58    5.70 |  -69.33  -29.35  -89.96 |  -10.07   29.74  -70.01\n",
      "norm_rf  |   574.3 |   373.6 |    53.2 |  2280.7\n",
      "norm_vf  |   83.02 |   15.96 |   26.66 |  130.74\n",
      "thrust   |    1171    -178    7413 |    5877    5848    5610 |  -14994  -14999  -14961 |   14988   14999   15000\n",
      "norm_thrust |   12015 |    3496 |    2000 |   15000\n",
      "fuel     |     259 |      73 |     165 |     574\n",
      "rewards  | -113.83 |   44.48 | -306.99 |  -47.06\n",
      "fuel_rewards |   -8.90 |    2.52 |  -19.72 |   -5.67\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.95 |    0.49 |    0.01 |    3.22\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  569.77 |  373.01 |   65.22 | 2275.73\n",
      "tracking_rewards | -104.93 |   42.33 | -291.58 |  -38.76\n",
      "steps    |     222 |      62 |     139 |     500\n",
      "***** Episode 5890, Mean R = -111.6  Std R = 44.4  Min R = -284.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.00162\n",
      "PolicyEntropy: 1.37\n",
      "PolicyLoss: -0.00178\n",
      "Steps: 6.6e+03\n",
      "TotalSteps: 1.2e+06\n",
      "ValFuncLoss: 0.00608\n",
      "Variance: 0.395\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2013   0.0876   0.4001   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0019   0.0105   1.6645   0.7971   0.5555\n",
      "***** Episode 5921, Mean R = -109.5  Std R = 43.3  Min R = -262.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00146\n",
      "PolicyEntropy: 1.36\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 6.76e+03\n",
      "TotalSteps: 1.21e+06\n",
      "ValFuncLoss: 0.00508\n",
      "Variance: 0.396\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1860   0.0388   0.2401   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0019   0.0097   1.6645   0.7971   0.5555\n",
      "***** Episode 5952, Mean R = -112.5  Std R = 49.9  Min R = -300.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.00189\n",
      "PolicyEntropy: 1.34\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 6.9e+03\n",
      "TotalSteps: 1.21e+06\n",
      "ValFuncLoss: 0.00526\n",
      "Variance: 0.393\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2427   0.0704   0.4049   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0014   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 5983, Mean R = -117.6  Std R = 50.3  Min R = -263.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.00179\n",
      "PolicyEntropy: 1.34\n",
      "PolicyLoss: -0.00345\n",
      "Steps: 7.51e+03\n",
      "TotalSteps: 1.22e+06\n",
      "ValFuncLoss: 0.00453\n",
      "Variance: 0.392\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1894   0.0688   0.3256   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0074   0.0035   0.0153   1.6645   0.7971   0.5555\n",
      "***** Episode 6014, Mean R = -104.1  Std R = 25.3  Min R = -183.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.00127\n",
      "PolicyEntropy: 1.32\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 6.6e+03\n",
      "TotalSteps: 1.23e+06\n",
      "ValFuncLoss: 0.00474\n",
      "Variance: 0.392\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2317   0.0942   0.4844   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0170   0.0074   0.0370   1.6645   0.7971   0.5555\n",
      "***** Episode 6045, Mean R = -124.6  Std R = 64.3  Min R = -352.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.00158\n",
      "PolicyEntropy: 1.3\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 7.08e+03\n",
      "TotalSteps: 1.23e+06\n",
      "ValFuncLoss: 0.00596\n",
      "Variance: 0.391\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2563   0.0813   0.4031   0.7268   0.4041   0.1940\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0114   0.0055   0.0228   1.6645   0.7971   0.5555\n",
      "***** Episode 6076, Mean R = -107.0  Std R = 24.7  Min R = -173.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00103\n",
      "PolicyEntropy: 1.29\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 6.63e+03\n",
      "TotalSteps: 1.24e+06\n",
      "ValFuncLoss: 0.00495\n",
      "Variance: 0.392\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4219   0.2366   0.9253   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0120   0.0064   0.0285   1.6645   0.7971   0.5555\n",
      "***** Episode 6107, Mean R = -93.0  Std R = 22.6  Min R = -169.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00185\n",
      "PolicyEntropy: 1.28\n",
      "PolicyLoss: -0.00382\n",
      "Steps: 6.26e+03\n",
      "TotalSteps: 1.25e+06\n",
      "ValFuncLoss: 0.00357\n",
      "Variance: 0.393\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2554   0.0986   0.4871   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0132   0.0068   0.0276   1.6645   0.7971   0.5555\n",
      "***** Episode 6138, Mean R = -99.7  Std R = 30.6  Min R = -202.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00155\n",
      "PolicyEntropy: 1.24\n",
      "PolicyLoss: -0.00383\n",
      "Steps: 6.13e+03\n",
      "TotalSteps: 1.25e+06\n",
      "ValFuncLoss: 0.00443\n",
      "Variance: 0.389\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2437   0.1005   0.4665   0.9253   0.4219   0.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0113   0.0063   0.0244   1.6645   0.7971   0.5555\n",
      "***** Episode 6169, Mean R = -112.2  Std R = 49.0  Min R = -273.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00105\n",
      "PolicyEntropy: 1.22\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 7.13e+03\n",
      "TotalSteps: 1.26e+06\n",
      "ValFuncLoss: 0.00518\n",
      "Variance: 0.384\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1697   0.0418   0.2399   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0029   0.0143   1.6645   0.7971   0.5555\n",
      "Update Cnt = 200    ET =    149.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   158.2    28.4    53.9 |   358.8   397.0   296.7 |  -722.9  -893.9    -4.2 |  1207.9   983.3  2075.9\n",
      "v_f      |  -11.74    1.82  -67.22 |   27.00   30.88   23.52 |  -85.99  -72.18 -100.10 |   65.57   71.25   55.54\n",
      "vr_f     |     2.8 |     3.0 |     0.2 |    25.3\n",
      "r_i      |  1051.5   -18.9  2348.7 |   580.2   594.8    29.3 |     1.8  -980.0  2300.0 |  1997.3   997.8  2399.3\n",
      "v_i      |  -39.75   -3.07  -80.06 |   16.94   17.05    5.71 |  -69.56  -29.55  -89.94 |  -10.12   29.95  -70.04\n",
      "norm_rf  |   540.6 |   332.9 |    36.9 |  2205.8\n",
      "norm_vf  |   81.48 |   16.03 |   43.56 |  131.46\n",
      "thrust   |    1199     233    7448 |    5701    5651    5543 |  -14997  -14992  -14983 |   14993   14987   15000\n",
      "norm_thrust |   11813 |    3545 |    2000 |   15000\n",
      "fuel     |     252 |      70 |     161 |     572\n",
      "rewards  | -108.47 |   43.68 | -352.34 |  -51.92\n",
      "fuel_rewards |   -8.66 |    2.39 |  -19.64 |   -5.52\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    0.96 |    0.47 |    0.01 |    3.08\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  536.27 |  332.01 |   75.04 | 2200.78\n",
      "tracking_rewards |  -99.80 |   41.60 | -332.70 |  -44.85\n",
      "steps    |     219 |      61 |     140 |     500\n",
      "***** Episode 6200, Mean R = -104.6  Std R = 47.3  Min R = -323.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00135\n",
      "PolicyEntropy: 1.21\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 6.99e+03\n",
      "TotalSteps: 1.27e+06\n",
      "ValFuncLoss: 0.00551\n",
      "Variance: 0.386\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2472   0.0927   0.4571   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0023   0.0119   1.6645   0.7971   0.5555\n",
      "***** Episode 6231, Mean R = -111.8  Std R = 54.6  Min R = -332.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.00151\n",
      "PolicyEntropy: 1.21\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 7.09e+03\n",
      "TotalSteps: 1.28e+06\n",
      "ValFuncLoss: 0.00506\n",
      "Variance: 0.389\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1512   0.0484   0.2370   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0110   0.0058   0.0282   1.6645   0.7971   0.5555\n",
      "***** Episode 6262, Mean R = -126.0  Std R = 60.4  Min R = -274.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.00142\n",
      "PolicyEntropy: 1.19\n",
      "PolicyLoss: -0.00175\n",
      "Steps: 7.39e+03\n",
      "TotalSteps: 1.28e+06\n",
      "ValFuncLoss: 0.00614\n",
      "Variance: 0.386\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2470   0.1095   0.5290   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0143   0.0070   0.0289   1.6645   0.7971   0.5555\n",
      "***** Episode 6293, Mean R = -99.6  Std R = 30.3  Min R = -195.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000984\n",
      "PolicyEntropy: 1.18\n",
      "PolicyLoss: -0.00229\n",
      "Steps: 6.5e+03\n",
      "TotalSteps: 1.29e+06\n",
      "ValFuncLoss: 0.00502\n",
      "Variance: 0.386\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1388   0.0243   0.1881   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0168   0.0072   0.0321   1.6645   0.7971   0.5555\n",
      "***** Episode 6324, Mean R = -111.1  Std R = 55.9  Min R = -341.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.883\n",
      "KL: 0.00114\n",
      "PolicyEntropy: 1.17\n",
      "PolicyLoss: -0.00178\n",
      "Steps: 6.55e+03\n",
      "TotalSteps: 1.3e+06\n",
      "ValFuncLoss: 0.00483\n",
      "Variance: 0.387\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2546   0.0962   0.4631   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0035   0.0164   1.6645   0.7971   0.5555\n",
      "***** Episode 6355, Mean R = -95.8  Std R = 25.6  Min R = -201.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00128\n",
      "PolicyEntropy: 1.15\n",
      "PolicyLoss: -0.00207\n",
      "Steps: 6.22e+03\n",
      "TotalSteps: 1.3e+06\n",
      "ValFuncLoss: 0.00402\n",
      "Variance: 0.387\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2397   0.1000   0.4932   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0026   0.0127   1.6645   0.7971   0.5555\n",
      "***** Episode 6386, Mean R = -104.8  Std R = 44.9  Min R = -297.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.00151\n",
      "PolicyEntropy: 1.14\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 6.54e+03\n",
      "TotalSteps: 1.31e+06\n",
      "ValFuncLoss: 0.00411\n",
      "Variance: 0.385\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3159   0.1125   0.5124   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0035   0.0149   1.6645   0.7971   0.5555\n",
      "***** Episode 6417, Mean R = -113.9  Std R = 52.7  Min R = -308.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.00148\n",
      "PolicyEntropy: 1.13\n",
      "PolicyLoss: -0.00369\n",
      "Steps: 7.28e+03\n",
      "TotalSteps: 1.32e+06\n",
      "ValFuncLoss: 0.00492\n",
      "Variance: 0.385\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2374   0.0852   0.3858   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0026   0.0133   1.6645   0.7971   0.5555\n",
      "***** Episode 6448, Mean R = -113.9  Std R = 50.4  Min R = -332.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.00148\n",
      "PolicyEntropy: 1.13\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 7.12e+03\n",
      "TotalSteps: 1.32e+06\n",
      "ValFuncLoss: 0.00416\n",
      "Variance: 0.386\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1881   0.0742   0.3640   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0076   0.0029   0.0166   1.6645   0.7971   0.5555\n",
      "***** Episode 6479, Mean R = -102.5  Std R = 33.9  Min R = -225.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.00168\n",
      "PolicyEntropy: 1.1\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 6.86e+03\n",
      "TotalSteps: 1.33e+06\n",
      "ValFuncLoss: 0.00428\n",
      "Variance: 0.382\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2748   0.1326   0.5862   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0052   0.0027   0.0122   1.6645   0.7971   0.5555\n",
      "Update Cnt = 210    ET =    147.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   221.3    39.7    68.6 |   324.0   379.0   330.4 |  -605.7  -815.3    -4.9 |  1249.1   883.1  2165.0\n",
      "v_f      |   -9.70   -4.95  -66.37 |   26.65   29.39   26.34 |  -83.45  -70.66 -101.80 |   57.10   65.19   57.89\n",
      "vr_f     |     2.6 |     3.1 |     0.3 |    42.2\n",
      "r_i      |  1013.8   -40.4  2352.5 |   586.1   597.2    29.4 |     5.3  -996.2  2300.5 |  1997.7   994.9  2400.0\n",
      "v_i      |  -41.12    0.52  -80.31 |   17.02   17.87    5.86 |  -69.87  -29.89  -89.95 |  -10.10   29.55  -70.06\n",
      "norm_rf  |   532.5 |   359.8 |    30.9 |  2268.1\n",
      "norm_vf  |   80.93 |   15.52 |   21.83 |  123.92\n",
      "thrust   |    1362    -191    7487 |    5497    5473    5496 |  -14965  -14985  -14988 |   14965   14978   15000\n",
      "norm_thrust |   11637 |    3594 |    2000 |   15000\n",
      "fuel     |     248 |      73 |     151 |     557\n",
      "rewards  | -107.18 |   46.17 | -341.94 |  -49.68\n",
      "fuel_rewards |   -8.51 |    2.50 |  -19.11 |   -5.20\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.02 |    0.49 |    0.01 |    2.77\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  528.19 |  358.91 |   61.83 | 2263.05\n",
      "tracking_rewards |  -98.67 |   44.02 | -323.80 |  -42.88\n",
      "steps    |     219 |      65 |     134 |     500\n",
      "***** Episode 6510, Mean R = -92.5  Std R = 24.3  Min R = -164.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00138\n",
      "PolicyEntropy: 1.09\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 6.26e+03\n",
      "TotalSteps: 1.34e+06\n",
      "ValFuncLoss: 0.00405\n",
      "Variance: 0.38\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2470   0.0969   0.4914   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0117   0.0060   0.0260   1.6645   0.7971   0.5555\n",
      "***** Episode 6541, Mean R = -105.4  Std R = 42.3  Min R = -274.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.00144\n",
      "PolicyEntropy: 1.08\n",
      "PolicyLoss: -0.00252\n",
      "Steps: 7.12e+03\n",
      "TotalSteps: 1.34e+06\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.38\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2865   0.1473   0.7167   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0091   0.0049   0.0194   1.6645   0.7971   0.5555\n",
      "***** Episode 6572, Mean R = -98.9  Std R = 36.5  Min R = -225.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.00122\n",
      "PolicyEntropy: 1.07\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 7.08e+03\n",
      "TotalSteps: 1.35e+06\n",
      "ValFuncLoss: 0.00336\n",
      "Variance: 0.378\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1333   0.0240   0.1893   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0087   0.0047   0.0183   1.6645   0.7971   0.5555\n",
      "***** Episode 6603, Mean R = -96.7  Std R = 26.8  Min R = -183.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.00119\n",
      "PolicyEntropy: 1.07\n",
      "PolicyLoss: -0.00196\n",
      "Steps: 6.12e+03\n",
      "TotalSteps: 1.36e+06\n",
      "ValFuncLoss: 0.00415\n",
      "Variance: 0.38\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2432   0.0612   0.3892   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0080   0.0041   0.0175   1.6645   0.7971   0.5555\n",
      "***** Episode 6634, Mean R = -102.2  Std R = 38.7  Min R = -261.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00158\n",
      "PolicyEntropy: 1.08\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 6.42e+03\n",
      "TotalSteps: 1.36e+06\n",
      "ValFuncLoss: 0.00384\n",
      "Variance: 0.383\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2380   0.0772   0.4600   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0025   0.0095   1.6645   0.7971   0.5555\n",
      "***** Episode 6665, Mean R = -105.3  Std R = 49.4  Min R = -319.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.0012\n",
      "PolicyEntropy: 1.08\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 6.57e+03\n",
      "TotalSteps: 1.37e+06\n",
      "ValFuncLoss: 0.00368\n",
      "Variance: 0.384\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3438   0.1602   0.6847   0.9253   0.4219   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0066   0.0033   0.0165   1.6645   0.7971   0.5555\n",
      "***** Episode 6696, Mean R = -96.0  Std R = 29.5  Min R = -209.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.00178\n",
      "PolicyEntropy: 1.07\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 6.54e+03\n",
      "TotalSteps: 1.38e+06\n",
      "ValFuncLoss: 0.00403\n",
      "Variance: 0.383\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4888   0.1838   0.8869   0.9253   0.4888   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0017   0.0085   1.6645   0.7971   0.5555\n",
      "***** Episode 6727, Mean R = -89.9  Std R = 19.1  Min R = -142.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.0015\n",
      "PolicyEntropy: 1.06\n",
      "PolicyLoss: -0.00461\n",
      "Steps: 6.07e+03\n",
      "TotalSteps: 1.38e+06\n",
      "ValFuncLoss: 0.00366\n",
      "Variance: 0.381\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4958   0.2021   0.9255   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0012   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 6758, Mean R = -96.3  Std R = 23.2  Min R = -152.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00209\n",
      "PolicyEntropy: 1.05\n",
      "PolicyLoss: -0.00402\n",
      "Steps: 6.61e+03\n",
      "TotalSteps: 1.39e+06\n",
      "ValFuncLoss: 0.00352\n",
      "Variance: 0.381\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2594   0.0563   0.3661   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0048   0.0185   1.6645   0.7971   0.5555\n",
      "***** Episode 6789, Mean R = -98.1  Std R = 38.2  Min R = -239.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000536\n",
      "PolicyEntropy: 1.04\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 6.88e+03\n",
      "TotalSteps: 1.4e+06\n",
      "ValFuncLoss: 0.00302\n",
      "Variance: 0.376\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3829   0.1598   0.7615   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0013   0.0056   1.6645   0.7971   0.5555\n",
      "Update Cnt = 220    ET =    143.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   182.7   -16.0    36.6 |   303.7   362.4   240.2 |  -545.7  -856.3    -4.8 |  1218.4   854.8  1782.6\n",
      "v_f      |  -15.09   -6.02  -66.80 |   24.84   28.14   20.51 |  -70.60  -74.66 -106.22 |   42.17   64.81   54.99\n",
      "vr_f     |     3.1 |     5.7 |     0.1 |    89.2\n",
      "r_i      |  1030.0    50.7  2348.0 |   584.7   589.7    28.1 |     4.6  -999.1  2300.2 |  1999.5   998.4  2399.3\n",
      "v_i      |  -38.83    0.24  -80.12 |   17.39   17.41    5.35 |  -69.95  -29.94  -89.85 |  -10.01   29.81  -70.10\n",
      "norm_rf  |   470.5 |   307.8 |     4.0 |  2055.5\n",
      "norm_vf  |   79.58 |   14.95 |   32.06 |  117.31\n",
      "thrust   |    1103    -278    7518 |    5329    5334    5441 |  -14970  -14998  -14615 |   14993   14982   15000\n",
      "norm_thrust |   11442 |    3652 |    2000 |   15000\n",
      "fuel     |     236 |      57 |     152 |     536\n",
      "rewards  |  -97.73 |   35.02 | -319.29 |  -47.11\n",
      "fuel_rewards |   -8.12 |    1.97 |  -18.40 |   -5.25\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.09 |    0.48 |    0.01 |    2.54\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  466.54 |  306.51 |   65.36 | 2050.51\n",
      "tracking_rewards |  -89.60 |   33.41 | -300.89 |  -40.45\n",
      "steps    |     212 |      52 |     136 |     500\n",
      "***** Episode 6820, Mean R = -88.4  Std R = 31.2  Min R = -230.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000959\n",
      "PolicyEntropy: 1.02\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 6.4e+03\n",
      "TotalSteps: 1.4e+06\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.373\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3788   0.1554   0.7116   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0010   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 6851, Mean R = -89.4  Std R = 21.4  Min R = -139.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000705\n",
      "PolicyEntropy: 1.01\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 6.45e+03\n",
      "TotalSteps: 1.41e+06\n",
      "ValFuncLoss: 0.00332\n",
      "Variance: 0.372\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2644   0.1157   0.4967   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0015   0.0077   1.6645   0.7971   0.5555\n",
      "***** Episode 6882, Mean R = -97.8  Std R = 42.8  Min R = -301.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000679\n",
      "PolicyEntropy: 1.01\n",
      "PolicyLoss: -0.00203\n",
      "Steps: 6.91e+03\n",
      "TotalSteps: 1.42e+06\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.369\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2827   0.1043   0.5192   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0066   0.0035   0.0139   1.6645   0.7971   0.5555\n",
      "***** Episode 6913, Mean R = -89.8  Std R = 29.5  Min R = -190.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000603\n",
      "PolicyEntropy: 0.997\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 6.43e+03\n",
      "TotalSteps: 1.42e+06\n",
      "ValFuncLoss: 0.00349\n",
      "Variance: 0.367\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2354   0.0600   0.3456   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0026   0.0116   1.6645   0.7971   0.5555\n",
      "***** Episode 6944, Mean R = -96.9  Std R = 44.5  Min R = -273.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000817\n",
      "PolicyEntropy: 0.983\n",
      "PolicyLoss: -0.00193\n",
      "Steps: 6.8e+03\n",
      "TotalSteps: 1.43e+06\n",
      "ValFuncLoss: 0.00355\n",
      "Variance: 0.365\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2793   0.1070   0.4676   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0053   0.0016   0.0097   1.6645   0.7971   0.5555\n",
      "***** Episode 6975, Mean R = -117.9  Std R = 68.2  Min R = -321.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000684\n",
      "PolicyEntropy: 0.987\n",
      "PolicyLoss: -0.00189\n",
      "Steps: 7.76e+03\n",
      "TotalSteps: 1.44e+06\n",
      "ValFuncLoss: 0.00428\n",
      "Variance: 0.365\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3125   0.1428   0.5738   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0052   0.0022   0.0096   1.6645   0.7971   0.5555\n",
      "***** Episode 7006, Mean R = -92.5  Std R = 30.3  Min R = -214.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000711\n",
      "PolicyEntropy: 0.979\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 6.76e+03\n",
      "TotalSteps: 1.44e+06\n",
      "ValFuncLoss: 0.00286\n",
      "Variance: 0.365\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4898   0.1703   0.7893   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0011   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 7037, Mean R = -87.9  Std R = 25.6  Min R = -147.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.00101\n",
      "PolicyEntropy: 0.966\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 6.44e+03\n",
      "TotalSteps: 1.45e+06\n",
      "ValFuncLoss: 0.00305\n",
      "Variance: 0.363\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2969   0.0873   0.4959   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0025   0.0114   1.6645   0.7971   0.5555\n",
      "***** Episode 7068, Mean R = -94.0  Std R = 27.1  Min R = -199.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000917\n",
      "PolicyEntropy: 0.953\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 6.4e+03\n",
      "TotalSteps: 1.46e+06\n",
      "ValFuncLoss: 0.00295\n",
      "Variance: 0.361\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2828   0.1351   0.6434   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0073   0.0032   0.0168   1.6645   0.7971   0.5555\n",
      "***** Episode 7099, Mean R = -102.3  Std R = 50.9  Min R = -294.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000354\n",
      "PolicyEntropy: 0.951\n",
      "PolicyLoss: -0.00134\n",
      "Steps: 6.98e+03\n",
      "TotalSteps: 1.46e+06\n",
      "ValFuncLoss: 0.00335\n",
      "Variance: 0.36\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3218   0.0878   0.4981   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0130   0.0068   0.0276   1.6645   0.7971   0.5555\n",
      "Update Cnt = 230    ET =    149.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   150.8     1.3    44.8 |   275.3   336.7   253.8 |  -502.3  -898.0    -4.0 |  1061.3   904.3  1746.8\n",
      "v_f      |  -13.14   -2.04  -60.03 |   23.12   25.83   21.40 |  -70.71  -66.78  -99.73 |   57.19   64.55   53.67\n",
      "vr_f     |     2.5 |     2.0 |     0.2 |    15.5\n",
      "r_i      |   982.5    11.5  2350.5 |   578.7   583.5    29.5 |     1.1  -984.7  2300.2 |  1997.8   998.7  2399.8\n",
      "v_i      |  -39.95   -1.21  -79.86 |   17.03   17.44    5.45 |  -69.65  -29.95  -90.00 |  -10.12   29.62  -70.03\n",
      "norm_rf  |   430.3 |   305.2 |     9.0 |  1990.9\n",
      "norm_vf  |   72.19 |   15.14 |   16.26 |  108.21\n",
      "thrust   |    1185       9    7784 |    5199    5294    5124 |  -14855  -14983  -14888 |   14980   14989   15000\n",
      "norm_thrust |   11407 |    3632 |    2000 |   15000\n",
      "fuel     |     243 |      68 |     154 |     542\n",
      "rewards  |  -96.93 |   42.98 | -321.92 |  -47.58\n",
      "fuel_rewards |   -8.36 |    2.33 |  -18.60 |   -5.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.12 |    0.50 |    0.01 |    3.63\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  426.09 |  304.24 |   64.50 | 1985.88\n",
      "tracking_rewards |  -88.57 |   41.01 | -303.88 |  -39.63\n",
      "steps    |     219 |      62 |     126 |     500\n",
      "***** Episode 7130, Mean R = -100.9  Std R = 55.5  Min R = -314.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.00167\n",
      "PolicyEntropy: 0.946\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 7.04e+03\n",
      "TotalSteps: 1.47e+06\n",
      "ValFuncLoss: 0.00375\n",
      "Variance: 0.357\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2972   0.1403   0.6505   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0075   0.0035   0.0150   1.6645   0.7971   0.5555\n",
      "***** Episode 7161, Mean R = -96.9  Std R = 33.1  Min R = -229.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00156\n",
      "PolicyEntropy: 0.941\n",
      "PolicyLoss: -0.00216\n",
      "Steps: 6.57e+03\n",
      "TotalSteps: 1.48e+06\n",
      "ValFuncLoss: 0.00354\n",
      "Variance: 0.355\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3640   0.1337   0.7105   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0093   0.0045   0.0207   1.6645   0.7971   0.5555\n",
      "***** Episode 7192, Mean R = -84.8  Std R = 25.5  Min R = -180.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.00127\n",
      "PolicyEntropy: 0.923\n",
      "PolicyLoss: -0.00437\n",
      "Steps: 6.33e+03\n",
      "TotalSteps: 1.48e+06\n",
      "ValFuncLoss: 0.00343\n",
      "Variance: 0.353\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3970   0.1631   0.7278   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0014   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 7223, Mean R = -84.9  Std R = 16.1  Min R = -126.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00131\n",
      "PolicyEntropy: 0.919\n",
      "PolicyLoss: -0.00444\n",
      "Steps: 6.59e+03\n",
      "TotalSteps: 1.49e+06\n",
      "ValFuncLoss: 0.00336\n",
      "Variance: 0.353\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3742   0.1758   0.7987   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0021   0.0113   1.6645   0.7971   0.5555\n",
      "***** Episode 7254, Mean R = -123.0  Std R = 76.6  Min R = -401.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 0.91\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 7.76e+03\n",
      "TotalSteps: 1.5e+06\n",
      "ValFuncLoss: 0.00498\n",
      "Variance: 0.353\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3391   0.0937   0.5031   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0025   0.0117   1.6645   0.7971   0.5555\n",
      "***** Episode 7285, Mean R = -89.4  Std R = 25.0  Min R = -195.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00103\n",
      "PolicyEntropy: 0.894\n",
      "PolicyLoss: -0.00412\n",
      "Steps: 6.57e+03\n",
      "TotalSteps: 1.5e+06\n",
      "ValFuncLoss: 0.00365\n",
      "Variance: 0.351\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.1669   0.0378   0.2447   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0106   0.0039   0.0224   1.6645   0.7971   0.5555\n",
      "***** Episode 7316, Mean R = -104.2  Std R = 55.4  Min R = -301.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.00124\n",
      "PolicyEntropy: 0.885\n",
      "PolicyLoss: -0.00194\n",
      "Steps: 6.86e+03\n",
      "TotalSteps: 1.51e+06\n",
      "ValFuncLoss: 0.00489\n",
      "Variance: 0.35\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2835   0.0863   0.4906   0.9255   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0107   0.0054   0.0207   1.6645   0.7971   0.5555\n",
      "***** Episode 7347, Mean R = -88.5  Std R = 26.3  Min R = -147.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00117\n",
      "PolicyEntropy: 0.864\n",
      "PolicyLoss: -0.00369\n",
      "Steps: 6.69e+03\n",
      "TotalSteps: 1.52e+06\n",
      "ValFuncLoss: 0.00459\n",
      "Variance: 0.349\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4536   0.1806   0.9751   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0067   0.0033   0.0177   1.6645   0.7971   0.5555\n",
      "***** Episode 7378, Mean R = -87.8  Std R = 42.5  Min R = -294.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00203\n",
      "PolicyEntropy: 0.852\n",
      "PolicyLoss: -0.004\n",
      "Steps: 6.7e+03\n",
      "TotalSteps: 1.52e+06\n",
      "ValFuncLoss: 0.00384\n",
      "Variance: 0.35\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3127   0.1701   0.8356   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0061   0.0030   0.0122   1.6645   0.7971   0.5555\n",
      "***** Episode 7409, Mean R = -89.8  Std R = 44.2  Min R = -305.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000541\n",
      "PolicyEntropy: 0.837\n",
      "PolicyLoss: -0.00171\n",
      "Steps: 7.26e+03\n",
      "TotalSteps: 1.53e+06\n",
      "ValFuncLoss: 0.00397\n",
      "Variance: 0.35\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3624   0.0877   0.5785   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0052   0.0021   0.0101   1.6645   0.7971   0.5555\n",
      "Update Cnt = 240    ET =    151.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   137.6     9.3    53.6 |   269.7   337.2   274.6 |  -546.3  -891.8    -3.8 |  1019.6   991.4  1805.3\n",
      "v_f      |  -13.88   -6.24  -54.22 |   22.04   24.86   22.07 |  -80.64  -80.28  -89.94 |   44.35   64.17   44.05\n",
      "vr_f     |     2.5 |     2.8 |     0.1 |    30.2\n",
      "r_i      |   968.7    10.0  2349.8 |   582.1   574.1    27.8 |     2.2  -993.8  2300.0 |  1975.4   996.5  2399.1\n",
      "v_i      |  -40.35   -0.14  -80.10 |   16.60   17.04    6.19 |  -69.98  -29.65  -89.99 |  -10.51   29.45  -70.08\n",
      "norm_rf  |   425.9 |   320.0 |    12.6 |  2217.1\n",
      "norm_vf  |   67.17 |   15.83 |   13.34 |  109.23\n",
      "thrust   |    1110    -227    7985 |    5198    5274    4900 |  -14999  -14995  -14729 |   14975   14965   15000\n",
      "norm_thrust |   11443 |    3599 |    2000 |   15000\n",
      "fuel     |     247 |      65 |     157 |     553\n",
      "rewards  |  -95.54 |   45.02 | -401.59 |  -44.75\n",
      "fuel_rewards |   -8.49 |    2.22 |  -19.00 |   -5.42\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.11 |    0.51 |    0.01 |    3.35\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  421.60 |  319.17 |   46.88 | 2212.13\n",
      "tracking_rewards |  -87.05 |   43.26 | -383.47 |  -37.05\n",
      "steps    |     222 |      60 |     137 |     500\n",
      "***** Episode 7440, Mean R = -106.1  Std R = 53.9  Min R = -256.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.00072\n",
      "PolicyEntropy: 0.829\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 7.44e+03\n",
      "TotalSteps: 1.54e+06\n",
      "ValFuncLoss: 0.0044\n",
      "Variance: 0.349\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3425   0.1285   0.7021   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0029   0.0162   1.6645   0.7971   0.5555\n",
      "***** Episode 7471, Mean R = -89.5  Std R = 31.8  Min R = -198.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000588\n",
      "PolicyEntropy: 0.823\n",
      "PolicyLoss: -0.00216\n",
      "Steps: 6.73e+03\n",
      "TotalSteps: 1.55e+06\n",
      "ValFuncLoss: 0.00379\n",
      "Variance: 0.349\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3649   0.1452   0.6776   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0173   0.0087   0.0353   1.6645   0.7971   0.5555\n",
      "***** Episode 7502, Mean R = -111.8  Std R = 64.0  Min R = -278.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.885\n",
      "KL: 0.000782\n",
      "PolicyEntropy: 0.809\n",
      "PolicyLoss: -0.00203\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 1.55e+06\n",
      "ValFuncLoss: 0.00384\n",
      "Variance: 0.347\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3297   0.0886   0.5436   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0083   0.0041   0.0198   1.6645   0.7971   0.5555\n",
      "***** Episode 7533, Mean R = -91.3  Std R = 21.4  Min R = -141.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000699\n",
      "PolicyEntropy: 0.806\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 6.68e+03\n",
      "TotalSteps: 1.56e+06\n",
      "ValFuncLoss: 0.00243\n",
      "Variance: 0.346\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4015   0.1672   0.9032   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0017   0.0083   1.6645   0.7971   0.5555\n",
      "***** Episode 7564, Mean R = -84.9  Std R = 22.3  Min R = -149.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000744\n",
      "PolicyEntropy: 0.777\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 6.64e+03\n",
      "TotalSteps: 1.57e+06\n",
      "ValFuncLoss: 0.0024\n",
      "Variance: 0.343\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3848   0.2085   0.8983   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0014   0.0077   1.6645   0.7971   0.5555\n",
      "***** Episode 7595, Mean R = -102.1  Std R = 71.8  Min R = -378.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000777\n",
      "PolicyEntropy: 0.76\n",
      "PolicyLoss: -0.00183\n",
      "Steps: 7.12e+03\n",
      "TotalSteps: 1.57e+06\n",
      "ValFuncLoss: 0.00327\n",
      "Variance: 0.34\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3655   0.0980   0.5641   0.9751   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0049   0.0022   0.0111   1.6645   0.7971   0.5555\n",
      "***** Episode 7626, Mean R = -106.0  Std R = 50.0  Min R = -295.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000513\n",
      "PolicyEntropy: 0.762\n",
      "PolicyLoss: -0.00219\n",
      "Steps: 7.6e+03\n",
      "TotalSteps: 1.58e+06\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.34\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4549   0.1710   0.9917   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0014   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 7657, Mean R = -92.9  Std R = 37.1  Min R = -233.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.915\n",
      "KL: 0.000722\n",
      "PolicyEntropy: 0.753\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 6.85e+03\n",
      "TotalSteps: 1.59e+06\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.339\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3162   0.0999   0.6300   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0017   0.0080   1.6645   0.7971   0.5555\n",
      "***** Episode 7688, Mean R = -103.1  Std R = 56.5  Min R = -306.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.000784\n",
      "PolicyEntropy: 0.735\n",
      "PolicyLoss: -0.00219\n",
      "Steps: 7.27e+03\n",
      "TotalSteps: 1.6e+06\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.336\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2011   0.0631   0.3684   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0081   0.0047   0.0200   1.6645   0.7971   0.5555\n",
      "***** Episode 7719, Mean R = -100.2  Std R = 54.7  Min R = -317.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.795\n",
      "KL: 0.000524\n",
      "PolicyEntropy: 0.732\n",
      "PolicyLoss: -0.00133\n",
      "Steps: 7.12e+03\n",
      "TotalSteps: 1.6e+06\n",
      "ValFuncLoss: 0.00377\n",
      "Variance: 0.336\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2627   0.1077   0.5157   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0014   0.0076   1.6645   0.7971   0.5555\n",
      "Update Cnt = 250    ET =    155.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    87.7    -0.1    31.6 |   251.7   309.3   191.3 |  -484.7  -824.6    -3.7 |   947.5   691.3  1544.0\n",
      "v_f      |  -12.85   -9.70  -54.65 |   17.77   23.29   20.82 |  -69.00  -63.28  -92.27 |   39.96   44.26   44.42\n",
      "vr_f     |     2.7 |     3.0 |     0.2 |    21.4\n",
      "r_i      |   976.0   -61.4  2351.0 |   560.1   586.4    29.6 |     2.3  -997.8  2300.2 |  1993.4   997.5  2399.8\n",
      "v_i      |  -40.49    1.47  -79.41 |   16.63   17.30    5.59 |  -69.89  -29.95  -89.93 |  -10.59   29.96  -70.01\n",
      "norm_rf  |   377.3 |   249.0 |    13.2 |  1811.6\n",
      "norm_vf  |   65.18 |   16.97 |   10.34 |  112.00\n",
      "thrust   |    1188    -417    7880 |    4981    5231    4849 |  -14900  -14998  -14606 |   14998   14935   15000\n",
      "norm_thrust |   11237 |    3617 |    2000 |   15000\n",
      "fuel     |     250 |      75 |     159 |     538\n",
      "rewards  |  -98.04 |   49.26 | -378.07 |  -49.87\n",
      "fuel_rewards |   -8.59 |    2.56 |  -18.49 |   -5.48\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.11 |    0.54 |    0.02 |    3.53\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  373.26 |  247.70 |   42.05 | 1806.57\n",
      "tracking_rewards |  -89.45 |   47.07 | -360.86 |  -41.49\n",
      "steps    |     229 |      72 |     144 |     500\n",
      "***** Episode 7750, Mean R = -98.6  Std R = 48.7  Min R = -348.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000583\n",
      "PolicyEntropy: 0.721\n",
      "PolicyLoss: -0.00209\n",
      "Steps: 6.92e+03\n",
      "TotalSteps: 1.61e+06\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.334\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3401   0.1394   0.7254   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0057   0.0234   1.6645   0.7971   0.5555\n",
      "***** Episode 7781, Mean R = -92.3  Std R = 55.9  Min R = -323.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000832\n",
      "PolicyEntropy: 0.707\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 7e+03\n",
      "TotalSteps: 1.62e+06\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.331\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.2942   0.1050   0.5417   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0083   0.0041   0.0190   1.6645   0.7971   0.5555\n",
      "***** Episode 7812, Mean R = -94.2  Std R = 47.3  Min R = -285.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00059\n",
      "PolicyEntropy: 0.688\n",
      "PolicyLoss: -0.00191\n",
      "Steps: 6.91e+03\n",
      "TotalSteps: 1.62e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.329\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3720   0.1306   0.6891   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0030   0.0127   1.6645   0.7971   0.5555\n",
      "***** Episode 7843, Mean R = -104.0  Std R = 52.5  Min R = -283.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000796\n",
      "PolicyEntropy: 0.681\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 7.6e+03\n",
      "TotalSteps: 1.63e+06\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.329\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3557   0.1411   0.8306   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0020   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 7874, Mean R = -82.6  Std R = 25.3  Min R = -149.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000716\n",
      "PolicyEntropy: 0.678\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 6.58e+03\n",
      "TotalSteps: 1.64e+06\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.329\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3911   0.2161   0.8827   0.9917   0.4958   0.2366\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0030   0.0126   1.6645   0.7971   0.5555\n",
      "***** Episode 7905, Mean R = -77.0  Std R = 20.8  Min R = -132.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000577\n",
      "PolicyEntropy: 0.682\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 6.72e+03\n",
      "TotalSteps: 1.64e+06\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.329\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4836   0.2379   0.9921   0.9921   0.4958   0.2379\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0046   0.0018   0.0088   1.6645   0.7971   0.5555\n",
      "***** Episode 7936, Mean R = -88.4  Std R = 38.3  Min R = -273.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.000939\n",
      "PolicyEntropy: 0.664\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 6.64e+03\n",
      "TotalSteps: 1.65e+06\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.327\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4257   0.1316   0.6893   0.9921   0.4958   0.2379\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0013   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 7967, Mean R = -87.7  Std R = 26.7  Min R = -191.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.000837\n",
      "PolicyEntropy: 0.663\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 6.64e+03\n",
      "TotalSteps: 1.66e+06\n",
      "ValFuncLoss: 0.00259\n",
      "Variance: 0.328\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4141   0.1410   0.7901   0.9921   0.4958   0.2379\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0179   0.0082   0.0375   1.6645   0.7971   0.5555\n",
      "***** Episode 7998, Mean R = -104.1  Std R = 62.4  Min R = -297.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.882\n",
      "KL: 0.000976\n",
      "PolicyEntropy: 0.671\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 1.67e+06\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.33\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3668   0.1321   0.5949   0.9921   0.4958   0.2379\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0093   0.0043   0.0197   1.6645   0.7971   0.5555\n",
      "***** Episode 8029, Mean R = -86.0  Std R = 38.6  Min R = -274.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000722\n",
      "PolicyEntropy: 0.653\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 6.69e+03\n",
      "TotalSteps: 1.67e+06\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.328\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5633   0.3051   1.5764   1.5764   0.5633   0.3051\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0013   0.0067   1.6645   0.7971   0.5555\n",
      "Update Cnt = 260    ET =    151.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   119.1   -53.1    21.8 |   211.3   269.3   159.4 |  -395.9  -730.2    -3.9 |   928.4   956.2  1621.3\n",
      "v_f      |  -15.09   -7.28  -56.96 |   16.98   21.65   19.84 |  -54.12  -67.42 -101.46 |   29.69   47.04   36.74\n",
      "vr_f     |     2.6 |     2.4 |     0.1 |    22.7\n",
      "r_i      |   976.0     9.1  2349.4 |   583.9   596.8    30.0 |    13.3  -999.4  2300.2 |  1988.7   988.1  2399.7\n",
      "v_i      |  -37.84    0.10  -80.46 |   17.14   16.95    5.98 |  -69.99  -29.91  -89.97 |  -10.02   30.00  -70.04\n",
      "norm_rf  |   324.4 |   234.1 |     5.8 |  1902.7\n",
      "norm_vf  |   66.21 |   17.08 |    9.18 |  116.04\n",
      "thrust   |     989    -304    7837 |    4969    5018    4821 |  -14961  -14951  -14968 |   14983   14956   15000\n",
      "norm_thrust |   11050 |    3675 |    2000 |   15000\n",
      "fuel     |     241 |      74 |     153 |     540\n",
      "rewards  |  -89.44 |   42.27 | -323.43 |  -44.64\n",
      "fuel_rewards |   -8.27 |    2.52 |  -18.54 |   -5.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.17 |    0.54 |    0.01 |    3.25\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  320.87 |  232.45 |   42.20 | 1897.68\n",
      "tracking_rewards |  -81.17 |   40.16 | -305.44 |  -37.63\n",
      "steps    |     224 |      72 |     135 |     500\n",
      "***** Episode 8060, Mean R = -78.1  Std R = 17.5  Min R = -113.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.000847\n",
      "PolicyEntropy: 0.65\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 6.63e+03\n",
      "TotalSteps: 1.68e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.329\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8706   0.4931   2.3536   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0116   0.0058   0.0260   1.6645   0.7971   0.5555\n",
      "***** Episode 8091, Mean R = -94.9  Std R = 51.2  Min R = -299.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000718\n",
      "PolicyEntropy: 0.65\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 7.3e+03\n",
      "TotalSteps: 1.69e+06\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.329\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5221   0.1745   0.9297   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0091   0.0044   0.0202   1.6645   0.7971   0.5555\n",
      "***** Episode 8122, Mean R = -84.5  Std R = 43.2  Min R = -309.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00074\n",
      "PolicyEntropy: 0.655\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 6.67e+03\n",
      "TotalSteps: 1.69e+06\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.33\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8493   0.3148   1.5840   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0091   0.0049   0.0190   1.6645   0.7971   0.5555\n",
      "***** Episode 8153, Mean R = -74.2  Std R = 15.2  Min R = -131.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000881\n",
      "PolicyEntropy: 0.655\n",
      "PolicyLoss: -0.00446\n",
      "Steps: 6.39e+03\n",
      "TotalSteps: 1.7e+06\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.33\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6169   0.2867   1.3064   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0075   0.0028   0.0123   1.6645   0.7971   0.5555\n",
      "***** Episode 8184, Mean R = -80.6  Std R = 41.1  Min R = -293.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.000825\n",
      "PolicyEntropy: 0.647\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 6.9e+03\n",
      "TotalSteps: 1.71e+06\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.328\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4772   0.2291   1.1698   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0016   0.0082   1.6645   0.7971   0.5555\n",
      "***** Episode 8215, Mean R = -80.4  Std R = 38.7  Min R = -270.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000884\n",
      "PolicyEntropy: 0.63\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 6.8e+03\n",
      "TotalSteps: 1.71e+06\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.326\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6503   0.1826   1.0137   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0015   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 8246, Mean R = -73.2  Std R = 20.0  Min R = -163.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 0.629\n",
      "PolicyLoss: -0.004\n",
      "Steps: 6.68e+03\n",
      "TotalSteps: 1.72e+06\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.327\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5736   0.2292   1.0403   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0053   0.0028   0.0130   1.6645   0.7971   0.5555\n",
      "***** Episode 8277, Mean R = -75.0  Std R = 18.8  Min R = -147.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000914\n",
      "PolicyEntropy: 0.62\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 7.05e+03\n",
      "TotalSteps: 1.73e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.325\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4792   0.1995   0.8801   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0017   0.0091   1.6645   0.7971   0.5555\n",
      "***** Episode 8308, Mean R = -76.7  Std R = 29.6  Min R = -213.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000856\n",
      "PolicyEntropy: 0.606\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 6.91e+03\n",
      "TotalSteps: 1.73e+06\n",
      "ValFuncLoss: 0.00176\n",
      "Variance: 0.324\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6274   0.2307   1.3034   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 8339, Mean R = -78.5  Std R = 34.5  Min R = -239.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000864\n",
      "PolicyEntropy: 0.605\n",
      "PolicyLoss: -0.00361\n",
      "Steps: 6.83e+03\n",
      "TotalSteps: 1.74e+06\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.323\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5502   0.1968   0.9564   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0037   0.0147   1.6645   0.7971   0.5555\n",
      "Update Cnt = 270    ET =    153.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   117.8   -33.7    33.5 |   186.3   172.8   212.8 |  -349.0  -503.2    -4.0 |   895.9   428.0  1617.9\n",
      "v_f      |  -13.14   -8.35  -55.01 |   14.76   15.07   21.65 |  -45.25  -53.76  -92.48 |   33.21   37.95   42.67\n",
      "vr_f     |     3.1 |     2.5 |     0.4 |    24.4\n",
      "r_i      |   968.8     8.0  2350.8 |   562.3   572.4    28.3 |    15.6 -1000.0  2300.1 |  1998.0   993.5  2399.7\n",
      "v_i      |  -39.79   -0.32  -79.76 |   17.33   16.66    5.76 |  -69.94  -29.98  -89.93 |  -10.69   29.90  -70.29\n",
      "norm_rf  |   264.5 |   236.6 |     5.8 |  1817.1\n",
      "norm_vf  |   62.35 |   17.14 |    4.49 |  102.19\n",
      "thrust   |    1154    -318    7925 |    4873    4826    4746 |  -14809  -14955  -13015 |   14970   14985   15000\n",
      "norm_thrust |   10969 |    3672 |    2000 |   15000\n",
      "fuel     |     238 |      67 |     153 |     516\n",
      "rewards  |  -82.00 |   42.12 | -352.95 |  -40.31\n",
      "fuel_rewards |   -8.20 |    2.31 |  -17.71 |   -5.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.24 |    0.52 |    0.02 |    3.54\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  261.22 |  235.13 |   25.66 | 1812.07\n",
      "tracking_rewards |  -73.80 |   40.44 | -336.08 |  -32.88\n",
      "steps    |     224 |      66 |     148 |     500\n",
      "***** Episode 8370, Mean R = -101.9  Std R = 78.8  Min R = -352.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.00124\n",
      "PolicyEntropy: 0.607\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 7.78e+03\n",
      "TotalSteps: 1.75e+06\n",
      "ValFuncLoss: 0.00381\n",
      "Variance: 0.326\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3857   0.1808   1.0785   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0027   0.0115   1.6645   0.7971   0.5555\n",
      "***** Episode 8401, Mean R = -78.8  Std R = 38.7  Min R = -262.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000664\n",
      "PolicyEntropy: 0.594\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 6.85e+03\n",
      "TotalSteps: 1.75e+06\n",
      "ValFuncLoss: 0.00173\n",
      "Variance: 0.323\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5057   0.1811   0.9060   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0007   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 8432, Mean R = -75.9  Std R = 20.4  Min R = -152.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000735\n",
      "PolicyEntropy: 0.586\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 6.93e+03\n",
      "TotalSteps: 1.76e+06\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.322\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3805   0.1283   0.7252   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0022   0.0111   1.6645   0.7971   0.5555\n",
      "***** Episode 8463, Mean R = -76.0  Std R = 38.6  Min R = -273.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.912\n",
      "KL: 0.00093\n",
      "PolicyEntropy: 0.581\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 6.82e+03\n",
      "TotalSteps: 1.77e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.32\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4902   0.1231   0.7794   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0049   0.0022   0.0108   1.6645   0.7971   0.5555\n",
      "***** Episode 8494, Mean R = -76.5  Std R = 36.4  Min R = -267.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00112\n",
      "PolicyEntropy: 0.565\n",
      "PolicyLoss: -0.00353\n",
      "Steps: 6.52e+03\n",
      "TotalSteps: 1.78e+06\n",
      "ValFuncLoss: 0.00151\n",
      "Variance: 0.319\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8611   0.4868   2.2725   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0121   0.0064   0.0266   1.6645   0.7971   0.5555\n",
      "***** Episode 8525, Mean R = -114.3  Std R = 84.6  Min R = -345.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000861\n",
      "PolicyEntropy: 0.568\n",
      "PolicyLoss: -0.00222\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 1.78e+06\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.32\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3058   0.1112   0.5369   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0026   0.0119   1.6645   0.7971   0.5555\n",
      "***** Episode 8556, Mean R = -80.9  Std R = 46.4  Min R = -320.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000709\n",
      "PolicyEntropy: 0.554\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 6.94e+03\n",
      "TotalSteps: 1.79e+06\n",
      "ValFuncLoss: 0.00165\n",
      "Variance: 0.319\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5396   0.3178   1.6549   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0024   0.0123   1.6645   0.7971   0.5555\n",
      "***** Episode 8587, Mean R = -76.4  Std R = 35.7  Min R = -217.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.000883\n",
      "PolicyEntropy: 0.537\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 7e+03\n",
      "TotalSteps: 1.8e+06\n",
      "ValFuncLoss: 0.00189\n",
      "Variance: 0.318\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6436   0.3373   1.5121   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0012   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 8618, Mean R = -86.0  Std R = 52.0  Min R = -277.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00072\n",
      "PolicyEntropy: 0.524\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 7.51e+03\n",
      "TotalSteps: 1.8e+06\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.316\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5766   0.2165   1.1534   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0092   0.0047   0.0225   1.6645   0.7971   0.5555\n",
      "***** Episode 8649, Mean R = -105.4  Std R = 77.0  Min R = -332.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.000639\n",
      "PolicyEntropy: 0.528\n",
      "PolicyLoss: -0.00194\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.81e+06\n",
      "ValFuncLoss: 0.00352\n",
      "Variance: 0.318\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6932   0.3687   1.7398   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0026   0.0108   1.6645   0.7971   0.5555\n",
      "Update Cnt = 280    ET =    159.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   131.6   -13.2    78.9 |   231.2   132.1   330.6 |  -403.0  -341.3    -3.6 |  1227.9   398.1  1764.2\n",
      "v_f      |  -12.09   -5.23  -47.21 |   13.79   13.45   25.49 |  -41.80  -45.97  -89.76 |   30.80   36.91   40.59\n",
      "vr_f     |     3.1 |     3.0 |     0.4 |    37.0\n",
      "r_i      |  1016.0    -4.4  2348.4 |   599.6   586.4    28.7 |     0.2  -980.8  2300.1 |  1987.9   997.2  2399.7\n",
      "v_i      |  -39.16   -0.68  -79.77 |   17.17   17.65    5.79 |  -69.57  -29.62  -89.98 |  -10.08   29.79  -70.01\n",
      "norm_rf  |   272.8 |   359.9 |    11.2 |  2183.4\n",
      "norm_vf  |   55.77 |   17.67 |    7.38 |  102.11\n",
      "thrust   |    1099    -159    8111 |    4838    4773    4596 |  -14819  -14798  -13215 |   14993   14741   15000\n",
      "norm_thrust |   11005 |    3638 |    2000 |   15000\n",
      "fuel     |     253 |      75 |     155 |     527\n",
      "rewards  |  -86.02 |   53.51 | -345.86 |  -41.74\n",
      "fuel_rewards |   -8.69 |    2.58 |  -18.09 |   -5.33\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.17 |    0.52 |    0.02 |    2.90\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  269.24 |  358.97 |   18.43 | 2178.36\n",
      "tracking_rewards |  -77.33 |   51.47 | -327.77 |  -34.47\n",
      "steps    |     236 |      76 |     142 |     500\n",
      "***** Episode 8680, Mean R = -89.8  Std R = 55.1  Min R = -318.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000714\n",
      "PolicyEntropy: 0.522\n",
      "PolicyLoss: -0.00214\n",
      "Steps: 8e+03\n",
      "TotalSteps: 1.82e+06\n",
      "ValFuncLoss: 0.00176\n",
      "Variance: 0.316\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4271   0.1842   1.0526   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0036   0.0181   1.6645   0.7971   0.5555\n",
      "***** Episode 8711, Mean R = -94.1  Std R = 66.0  Min R = -347.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000599\n",
      "PolicyEntropy: 0.527\n",
      "PolicyLoss: -0.00206\n",
      "Steps: 7.34e+03\n",
      "TotalSteps: 1.83e+06\n",
      "ValFuncLoss: 0.00162\n",
      "Variance: 0.315\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3007   0.1134   0.5030   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0032   0.0151   1.6645   0.7971   0.5555\n",
      "***** Episode 8742, Mean R = -83.8  Std R = 50.7  Min R = -307.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.856\n",
      "KL: 0.000665\n",
      "PolicyEntropy: 0.52\n",
      "PolicyLoss: -0.00158\n",
      "Steps: 6.69e+03\n",
      "TotalSteps: 1.84e+06\n",
      "ValFuncLoss: 0.00192\n",
      "Variance: 0.314\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7456   0.2865   1.3588   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0017   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 8773, Mean R = -69.0  Std R = 11.7  Min R = -110.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.00136\n",
      "PolicyEntropy: 0.5\n",
      "PolicyLoss: -0.00399\n",
      "Steps: 6.46e+03\n",
      "TotalSteps: 1.84e+06\n",
      "ValFuncLoss: 0.000745\n",
      "Variance: 0.312\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3928   0.0905   0.5921   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 8804, Mean R = -67.7  Std R = 13.9  Min R = -112.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.00103\n",
      "PolicyEntropy: 0.49\n",
      "PolicyLoss: -0.00348\n",
      "Steps: 6.8e+03\n",
      "TotalSteps: 1.85e+06\n",
      "ValFuncLoss: 0.000844\n",
      "Variance: 0.312\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4849   0.2437   1.2528   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0011   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 8835, Mean R = -77.3  Std R = 41.3  Min R = -234.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000994\n",
      "PolicyEntropy: 0.484\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 7.19e+03\n",
      "TotalSteps: 1.86e+06\n",
      "ValFuncLoss: 0.00118\n",
      "Variance: 0.31\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4233   0.2078   0.8295   2.3536   0.8706   0.4931\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0025   0.0131   1.6645   0.7971   0.5555\n",
      "***** Episode 8866, Mean R = -87.6  Std R = 73.6  Min R = -334.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000642\n",
      "PolicyEntropy: 0.478\n",
      "PolicyLoss: -0.00157\n",
      "Steps: 7.36e+03\n",
      "TotalSteps: 1.86e+06\n",
      "ValFuncLoss: 0.00331\n",
      "Variance: 0.31\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9542   0.4953   2.9231   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0094   0.0045   0.0203   1.6645   0.7971   0.5555\n",
      "***** Episode 8897, Mean R = -77.5  Std R = 45.3  Min R = -295.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.000888\n",
      "PolicyEntropy: 0.47\n",
      "PolicyLoss: -0.0023\n",
      "Steps: 7.23e+03\n",
      "TotalSteps: 1.87e+06\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.31\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5093   0.1762   0.9018   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0022   0.0099   1.6645   0.7971   0.5555\n",
      "***** Episode 8928, Mean R = -82.8  Std R = 60.9  Min R = -359.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000803\n",
      "PolicyEntropy: 0.461\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 7.51e+03\n",
      "TotalSteps: 1.88e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.31\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5182   0.1656   1.0222   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0013   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 8959, Mean R = -70.6  Std R = 39.0  Min R = -278.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00106\n",
      "PolicyEntropy: 0.443\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 6.65e+03\n",
      "TotalSteps: 1.88e+06\n",
      "ValFuncLoss: 0.00147\n",
      "Variance: 0.309\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7024   0.4011   2.1824   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0016   0.0072   1.6645   0.7971   0.5555\n",
      "Update Cnt = 290    ET =    154.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   107.1    -4.7    54.3 |   177.6   120.9   271.0 |  -291.4  -411.5    -4.1 |  1052.2   291.6  1698.8\n",
      "v_f      |  -15.17   -2.13  -48.31 |   12.15   11.77   22.10 |  -48.09  -31.55  -91.49 |   21.33   31.22   38.80\n",
      "vr_f     |     3.4 |     4.3 |     0.2 |    53.8\n",
      "r_i      |   971.7   -31.1  2349.4 |   594.1   542.4    29.7 |     1.4  -985.7  2300.1 |  1991.8   978.3  2399.5\n",
      "v_i      |  -38.37   -1.39  -80.22 |   17.03   17.81    5.52 |  -69.66  -29.94  -90.00 |  -10.02   29.72  -70.02\n",
      "norm_rf  |   228.2 |   286.4 |     6.5 |  2019.4\n",
      "norm_vf  |   55.48 |   16.31 |    6.83 |   94.13\n",
      "thrust   |     984      11    8193 |    4851    4661    4478 |  -14925  -14996  -12315 |   14955   14853   15000\n",
      "norm_thrust |   10970 |    3613 |    2000 |   15000\n",
      "fuel     |     242 |      70 |     143 |     507\n",
      "rewards  |  -78.28 |   47.57 | -359.22 |  -43.12\n",
      "fuel_rewards |   -8.33 |    2.40 |  -17.39 |   -4.92\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.26 |    0.51 |    0.01 |    2.78\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  224.57 |  285.50 |   28.95 | 2014.42\n",
      "tracking_rewards |  -69.95 |   45.72 | -342.02 |  -34.15\n",
      "steps    |     227 |      71 |     139 |     500\n",
      "***** Episode 8990, Mean R = -72.4  Std R = 16.2  Min R = -122.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.893\n",
      "KL: 0.00083\n",
      "PolicyEntropy: 0.434\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 7.16e+03\n",
      "TotalSteps: 1.89e+06\n",
      "ValFuncLoss: 0.00153\n",
      "Variance: 0.309\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7761   0.3415   1.8873   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0026   0.0107   1.6645   0.7971   0.5555\n",
      "***** Episode 9021, Mean R = -64.2  Std R = 9.5  Min R = -83.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000947\n",
      "PolicyEntropy: 0.422\n",
      "PolicyLoss: -0.00366\n",
      "Steps: 6.31e+03\n",
      "TotalSteps: 1.9e+06\n",
      "ValFuncLoss: 0.00169\n",
      "Variance: 0.308\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5032   0.2186   0.9670   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0133   0.0066   0.0339   1.6645   0.7971   0.5555\n",
      "***** Episode 9052, Mean R = -80.0  Std R = 49.0  Min R = -304.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.865\n",
      "KL: 0.000701\n",
      "PolicyEntropy: 0.426\n",
      "PolicyLoss: -0.00159\n",
      "Steps: 7.59e+03\n",
      "TotalSteps: 1.91e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.309\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6119   0.2415   1.1478   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0032   0.0148   1.6645   0.7971   0.5555\n",
      "***** Episode 9083, Mean R = -82.2  Std R = 62.3  Min R = -319.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.919\n",
      "KL: 0.000811\n",
      "PolicyEntropy: 0.422\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 6.93e+03\n",
      "TotalSteps: 1.91e+06\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.308\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6350   0.2912   1.4144   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0071   0.0039   0.0190   1.6645   0.7971   0.5555\n",
      "***** Episode 9114, Mean R = -78.1  Std R = 45.5  Min R = -232.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.871\n",
      "ExplainedVarOld: 0.831\n",
      "KL: 0.000942\n",
      "PolicyEntropy: 0.408\n",
      "PolicyLoss: -0.00223\n",
      "Steps: 7.5e+03\n",
      "TotalSteps: 1.92e+06\n",
      "ValFuncLoss: 0.00239\n",
      "Variance: 0.307\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4797   0.1682   0.8053   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0165   0.0083   0.0356   1.6645   0.7971   0.5555\n",
      "***** Episode 9145, Mean R = -94.6  Std R = 79.2  Min R = -313.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.897\n",
      "KL: 0.000903\n",
      "PolicyEntropy: 0.397\n",
      "PolicyLoss: -0.00202\n",
      "Steps: 7.73e+03\n",
      "TotalSteps: 1.93e+06\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.306\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8520   0.2400   1.2691   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0106   0.0061   0.0220   1.6645   0.7971   0.5555\n",
      "***** Episode 9176, Mean R = -63.2  Std R = 6.8  Min R = -73.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.00104\n",
      "PolicyEntropy: 0.394\n",
      "PolicyLoss: -0.00468\n",
      "Steps: 6.07e+03\n",
      "TotalSteps: 1.93e+06\n",
      "ValFuncLoss: 0.000782\n",
      "Variance: 0.306\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6378   0.3597   1.6574   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0014   0.0066   1.6645   0.7971   0.5555\n",
      "***** Episode 9207, Mean R = -88.0  Std R = 77.6  Min R = -359.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.00085\n",
      "PolicyEntropy: 0.388\n",
      "PolicyLoss: -0.00173\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 1.94e+06\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.305\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5029   0.2099   0.9334   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0041   0.0210   1.6645   0.7971   0.5555\n",
      "***** Episode 9238, Mean R = -98.6  Std R = 86.6  Min R = -398.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.919\n",
      "KL: 0.000933\n",
      "PolicyEntropy: 0.371\n",
      "PolicyLoss: -0.00168\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 1.95e+06\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.302\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8594   0.2906   1.4116   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0010   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 9269, Mean R = -64.9  Std R = 11.6  Min R = -94.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 0.356\n",
      "PolicyLoss: -0.00391\n",
      "Steps: 6.5e+03\n",
      "TotalSteps: 1.96e+06\n",
      "ValFuncLoss: 0.000811\n",
      "Variance: 0.301\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3022   0.0759   0.4673   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0026   0.0140   1.6645   0.7971   0.5555\n",
      "Update Cnt = 300    ET =    156.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |   101.6     7.0    50.5 |   149.5   120.3   235.1 |  -183.5  -333.3    -3.6 |  1002.2   331.9  1654.4\n",
      "v_f      |  -16.04   -1.97  -45.31 |   11.34    9.61   21.99 |  -43.61  -27.97  -84.02 |   16.43   28.66   38.84\n",
      "vr_f     |     3.3 |     8.0 |     0.1 |   139.4\n",
      "r_i      |   964.5    15.8  2349.8 |   560.4   567.2    28.6 |     5.1  -999.3  2300.2 |  1996.4   997.1  2398.9\n",
      "v_i      |  -39.82   -2.43  -80.09 |   17.08   17.70    5.63 |  -69.91  -29.91  -89.92 |  -10.14   29.56  -70.05\n",
      "norm_rf  |   210.5 |   246.3 |     2.5 |  1935.7\n",
      "norm_vf  |   52.24 |   17.02 |    6.27 |   85.55\n",
      "thrust   |     970      50    8216 |    4777    4581    4397 |  -14738  -14814  -11345 |   14973   14912   15000\n",
      "norm_thrust |   10885 |    3618 |    2000 |   15000\n",
      "fuel     |     245 |      76 |     158 |     504\n",
      "rewards  |  -78.46 |   56.66 | -398.86 |  -41.10\n",
      "fuel_rewards |   -8.42 |    2.61 |  -17.31 |   -5.43\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.26 |    0.54 |    0.01 |    3.18\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  206.62 |  245.54 |   17.47 | 1930.73\n",
      "tracking_rewards |  -70.05 |   54.56 | -382.61 |  -32.65\n",
      "steps    |     231 |      81 |     145 |     500\n",
      "***** Episode 9300, Mean R = -70.8  Std R = 47.3  Min R = -325.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000825\n",
      "PolicyEntropy: 0.341\n",
      "PolicyLoss: -0.00208\n",
      "Steps: 6.93e+03\n",
      "TotalSteps: 1.96e+06\n",
      "ValFuncLoss: 0.00137\n",
      "Variance: 0.298\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6669   0.3097   1.3898   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0142   0.0065   0.0343   1.6645   0.7971   0.5555\n",
      "***** Episode 9331, Mean R = -81.5  Std R = 60.3  Min R = -287.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.909\n",
      "ExplainedVarOld: 0.864\n",
      "KL: 0.000742\n",
      "PolicyEntropy: 0.324\n",
      "PolicyLoss: -0.00248\n",
      "Steps: 7.33e+03\n",
      "TotalSteps: 1.97e+06\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.297\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5382   0.1356   0.9144   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0045   0.0198   1.6645   0.7971   0.5555\n",
      "***** Episode 9362, Mean R = -100.4  Std R = 77.0  Min R = -335.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.891\n",
      "KL: 0.00103\n",
      "PolicyEntropy: 0.314\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.98e+06\n",
      "ValFuncLoss: 0.00307\n",
      "Variance: 0.297\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7133   0.3551   1.5799   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0042   0.0167   1.6645   0.7971   0.5555\n",
      "***** Episode 9393, Mean R = -68.5  Std R = 37.5  Min R = -268.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000727\n",
      "PolicyEntropy: 0.292\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 6.86e+03\n",
      "TotalSteps: 1.99e+06\n",
      "ValFuncLoss: 0.000908\n",
      "Variance: 0.295\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.3257   0.0895   0.5422   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0027   0.0123   1.6645   0.7971   0.5555\n",
      "***** Episode 9424, Mean R = -79.5  Std R = 58.8  Min R = -321.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.905\n",
      "KL: 0.000714\n",
      "PolicyEntropy: 0.294\n",
      "PolicyLoss: -0.00194\n",
      "Steps: 7.41e+03\n",
      "TotalSteps: 1.99e+06\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.298\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4991   0.1940   0.9007   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0025   0.0113   1.6645   0.7971   0.5555\n",
      "***** Episode 9455, Mean R = -74.2  Std R = 48.1  Min R = -306.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000646\n",
      "PolicyEntropy: 0.296\n",
      "PolicyLoss: -0.00223\n",
      "Steps: 7.61e+03\n",
      "TotalSteps: 2e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.299\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4458   0.1433   0.8922   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0016   0.0090   1.6645   0.7971   0.5555\n",
      "***** Episode 9486, Mean R = -74.6  Std R = 45.3  Min R = -310.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00085\n",
      "PolicyEntropy: 0.307\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 6.65e+03\n",
      "TotalSteps: 2.01e+06\n",
      "ValFuncLoss: 0.00051\n",
      "Variance: 0.3\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7160   0.3050   1.1180   2.9231   0.9542   0.4953\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0023   0.0112   1.6645   0.7971   0.5555\n",
      "***** Episode 9517, Mean R = -71.4  Std R = 36.4  Min R = -261.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.899\n",
      "ExplainedVarOld: 0.855\n",
      "KL: 0.000847\n",
      "PolicyEntropy: 0.308\n",
      "PolicyLoss: -0.00196\n",
      "Steps: 7.08e+03\n",
      "TotalSteps: 2.01e+06\n",
      "ValFuncLoss: 0.00144\n",
      "Variance: 0.302\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0694   0.6143   2.2630   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0013   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 9548, Mean R = -69.3  Std R = 34.8  Min R = -251.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.905\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.00134\n",
      "PolicyEntropy: 0.294\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 7e+03\n",
      "TotalSteps: 2.02e+06\n",
      "ValFuncLoss: 0.00139\n",
      "Variance: 0.301\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5330   0.3659   1.8250   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0115   0.0055   0.0280   1.6645   0.7971   0.5555\n",
      "***** Episode 9579, Mean R = -86.6  Std R = 68.1  Min R = -359.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.927\n",
      "ExplainedVarOld: 0.901\n",
      "KL: 0.00058\n",
      "PolicyEntropy: 0.287\n",
      "PolicyLoss: -0.00144\n",
      "Steps: 7.55e+03\n",
      "TotalSteps: 2.03e+06\n",
      "ValFuncLoss: 0.00226\n",
      "Variance: 0.3\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0441   0.5679   2.6767   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0058   0.0022   0.0117   1.6645   0.7971   0.5555\n",
      "Update Cnt = 310    ET =    161.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    83.6    16.9    39.1 |   131.0   114.9   178.3 |  -225.9  -296.1    -3.4 |   841.2   320.8  1513.1\n",
      "v_f      |  -16.17   -1.00  -44.11 |   10.95    8.36   21.87 |  -42.10  -27.38  -81.29 |   21.36   25.51   41.49\n",
      "vr_f     |     3.1 |     3.1 |     0.4 |    35.2\n",
      "r_i      |  1012.1   -14.9  2351.6 |   581.7   566.5    29.0 |     7.6  -991.8  2300.4 |  1998.9   994.5  2399.9\n",
      "v_i      |  -39.37   -0.36  -79.75 |   17.66   17.00    5.77 |  -69.83  -29.96  -89.96 |  -10.81   29.51  -70.33\n",
      "norm_rf  |   192.1 |   184.5 |     3.3 |  1738.1\n",
      "norm_vf  |   50.56 |   17.88 |    5.35 |   83.81\n",
      "thrust   |     942     -18    8230 |    4623    4490    4338 |  -14644  -14978   -9596 |   14985   14971   15000\n",
      "norm_thrust |   10763 |    3624 |    2000 |   15000\n",
      "fuel     |     249 |      81 |     154 |     525\n",
      "rewards  |  -78.63 |   55.11 | -359.86 |  -39.25\n",
      "fuel_rewards |   -8.55 |    2.79 |  -18.03 |   -5.28\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.24 |    0.51 |    0.02 |    2.79\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  188.96 |  182.99 |   21.50 | 1733.06\n",
      "tracking_rewards |  -70.08 |   52.81 | -342.87 |  -31.84\n",
      "steps    |     238 |      87 |     151 |     500\n",
      "***** Episode 9610, Mean R = -80.3  Std R = 59.7  Min R = -296.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.893\n",
      "KL: 0.000995\n",
      "PolicyEntropy: 0.284\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 7.58e+03\n",
      "TotalSteps: 2.04e+06\n",
      "ValFuncLoss: 0.00168\n",
      "Variance: 0.299\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5173   0.1369   0.8009   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0083   0.0041   0.0171   1.6645   0.7971   0.5555\n",
      "***** Episode 9641, Mean R = -64.3  Std R = 15.3  Min R = -107.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.919\n",
      "ExplainedVarOld: 0.85\n",
      "KL: 0.000681\n",
      "PolicyEntropy: 0.282\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 6.87e+03\n",
      "TotalSteps: 2.04e+06\n",
      "ValFuncLoss: 0.000743\n",
      "Variance: 0.3\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7596   0.2488   1.5064   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0018   0.0079   1.6645   0.7971   0.5555\n",
      "***** Episode 9672, Mean R = -62.5  Std R = 10.5  Min R = -95.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.00107\n",
      "PolicyEntropy: 0.273\n",
      "PolicyLoss: -0.00431\n",
      "Steps: 6.51e+03\n",
      "TotalSteps: 2.05e+06\n",
      "ValFuncLoss: 0.000602\n",
      "Variance: 0.299\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6026   0.2258   1.1165   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0124   0.0061   0.0310   1.6645   0.7971   0.5555\n",
      "***** Episode 9703, Mean R = -79.7  Std R = 50.1  Min R = -282.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.894\n",
      "ExplainedVarOld: 0.855\n",
      "KL: 0.000828\n",
      "PolicyEntropy: 0.276\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 7.19e+03\n",
      "TotalSteps: 2.06e+06\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.301\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7376   0.3049   1.6357   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0074   0.0037   0.0167   1.6645   0.7971   0.5555\n",
      "***** Episode 9734, Mean R = -66.6  Std R = 30.5  Min R = -225.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.00075\n",
      "PolicyEntropy: 0.26\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 6.76e+03\n",
      "TotalSteps: 2.06e+06\n",
      "ValFuncLoss: 0.00113\n",
      "Variance: 0.297\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5665   0.2145   0.9453   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0035   0.0150   1.6645   0.7971   0.5555\n",
      "***** Episode 9765, Mean R = -66.4  Std R = 13.2  Min R = -118.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000698\n",
      "PolicyEntropy: 0.262\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 6.83e+03\n",
      "TotalSteps: 2.07e+06\n",
      "ValFuncLoss: 0.000791\n",
      "Variance: 0.297\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6240   0.1575   0.9164   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0029   0.0120   1.6645   0.7971   0.5555\n",
      "***** Episode 9796, Mean R = -64.0  Std R = 16.3  Min R = -144.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 0.243\n",
      "PolicyLoss: -0.00397\n",
      "Steps: 6.4e+03\n",
      "TotalSteps: 2.08e+06\n",
      "ValFuncLoss: 0.000795\n",
      "Variance: 0.296\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6258   0.2809   1.1874   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0011   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 9827, Mean R = -75.5  Std R = 48.4  Min R = -314.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000981\n",
      "PolicyEntropy: 0.224\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 7.26e+03\n",
      "TotalSteps: 2.08e+06\n",
      "ValFuncLoss: 0.00125\n",
      "Variance: 0.295\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5359   0.2540   1.1005   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0008   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 9858, Mean R = -66.8  Std R = 23.4  Min R = -158.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000762\n",
      "PolicyEntropy: 0.214\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 7.19e+03\n",
      "TotalSteps: 2.09e+06\n",
      "ValFuncLoss: 0.00118\n",
      "Variance: 0.293\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4860   0.2155   1.1012   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0008   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 9889, Mean R = -73.0  Std R = 49.8  Min R = -306.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.000875\n",
      "PolicyEntropy: 0.204\n",
      "PolicyLoss: -0.00231\n",
      "Steps: 7.02e+03\n",
      "TotalSteps: 2.1e+06\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.292\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4370   0.1560   0.8301   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0108   0.0055   0.0293   1.6645   0.7971   0.5555\n",
      "Update Cnt = 320    ET =    154.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    54.1    27.8    11.8 |   124.5   115.6    93.9 |  -242.6  -327.0    -3.7 |   455.6   339.1  1135.6\n",
      "v_f      |  -17.27    1.02  -47.52 |    8.91    8.47   16.77 |  -38.59  -20.98  -85.80 |    7.37   30.31   20.38\n",
      "vr_f     |     3.0 |     2.6 |     0.2 |    36.2\n",
      "r_i      |   996.7   -17.1  2350.7 |   568.9   576.3    29.5 |     7.5  -989.6  2300.4 |  1989.5   995.4  2399.8\n",
      "v_i      |  -40.62    1.15  -80.31 |   17.35   17.52    5.81 |  -69.90  -29.68  -89.89 |  -10.25   29.90  -70.05\n",
      "norm_rf  |   169.7 |   112.8 |     8.4 |  1240.8\n",
      "norm_vf  |   52.15 |   16.43 |    4.87 |   90.28\n",
      "thrust   |    1002     -11    8275 |    4571    4515    4317 |  -14824  -14883  -10932 |   14948   14971   15000\n",
      "norm_thrust |   10786 |    3615 |    2000 |   15000\n",
      "fuel     |     236 |      66 |     148 |     495\n",
      "rewards  |  -70.38 |   39.25 | -347.55 |  -39.58\n",
      "fuel_rewards |   -8.13 |    2.26 |  -16.98 |   -5.10\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.32 |    0.50 |    0.03 |    3.07\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  166.60 |  110.75 |   34.68 | 1235.77\n",
      "tracking_rewards |  -62.25 |   37.61 | -330.56 |  -29.54\n",
      "steps    |     225 |      72 |     145 |     500\n",
      "***** Episode 9920, Mean R = -85.0  Std R = 72.8  Min R = -347.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.00104\n",
      "PolicyEntropy: 0.188\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 7.88e+03\n",
      "TotalSteps: 2.11e+06\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.29\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5635   0.1915   0.9314   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0019   0.0084   1.6645   0.7971   0.5555\n",
      "***** Episode 9951, Mean R = -75.3  Std R = 44.2  Min R = -296.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000772\n",
      "PolicyEntropy: 0.184\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 7.49e+03\n",
      "TotalSteps: 2.11e+06\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.29\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7226   0.2775   1.2114   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0074   0.0036   0.0168   1.6645   0.7971   0.5555\n",
      "***** Episode 9982, Mean R = -62.2  Std R = 23.2  Min R = -182.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.893\n",
      "KL: 0.00092\n",
      "PolicyEntropy: 0.182\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 6.71e+03\n",
      "TotalSteps: 2.12e+06\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.289\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7473   0.2495   1.3585   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0034   0.0171   1.6645   0.7971   0.5555\n",
      "***** Episode 10013, Mean R = -69.1  Std R = 48.4  Min R = -329.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.907\n",
      "KL: 0.000959\n",
      "PolicyEntropy: 0.156\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 6.55e+03\n",
      "TotalSteps: 2.13e+06\n",
      "ValFuncLoss: 0.00214\n",
      "Variance: 0.286\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6973   0.4343   2.4349   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0030   0.0111   1.6645   0.7971   0.5555\n",
      "***** Episode 10044, Mean R = -68.8  Std R = 31.9  Min R = -234.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000831\n",
      "PolicyEntropy: 0.152\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 7.35e+03\n",
      "TotalSteps: 2.13e+06\n",
      "ValFuncLoss: 0.00111\n",
      "Variance: 0.286\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4869   0.2036   0.9254   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0067   0.0029   0.0156   1.6645   0.7971   0.5555\n",
      "***** Episode 10075, Mean R = -71.1  Std R = 49.3  Min R = -334.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.000779\n",
      "PolicyEntropy: 0.136\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 7.09e+03\n",
      "TotalSteps: 2.14e+06\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.284\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6179   0.2032   1.0440   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0032   0.0176   1.6645   0.7971   0.5555\n",
      "***** Episode 10106, Mean R = -69.8  Std R = 33.4  Min R = -243.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000688\n",
      "PolicyEntropy: 0.129\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 7.31e+03\n",
      "TotalSteps: 2.15e+06\n",
      "ValFuncLoss: 0.00108\n",
      "Variance: 0.283\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6957   0.3365   1.3512   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0019   0.0083   1.6645   0.7971   0.5555\n",
      "***** Episode 10137, Mean R = -70.4  Std R = 31.0  Min R = -174.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000624\n",
      "PolicyEntropy: 0.122\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 7.41e+03\n",
      "TotalSteps: 2.16e+06\n",
      "ValFuncLoss: 0.000963\n",
      "Variance: 0.282\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7109   0.3045   1.3318   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 10168, Mean R = -70.3  Std R = 43.8  Min R = -282.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000644\n",
      "PolicyEntropy: 0.128\n",
      "PolicyLoss: -0.00232\n",
      "Steps: 7.25e+03\n",
      "TotalSteps: 2.16e+06\n",
      "ValFuncLoss: 0.00126\n",
      "Variance: 0.284\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7920   0.4667   2.2785   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0013   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 10199, Mean R = -65.2  Std R = 17.4  Min R = -138.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000662\n",
      "PolicyEntropy: 0.113\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 6.86e+03\n",
      "TotalSteps: 2.17e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.283\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7609   0.2285   1.1874   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0043   1.6645   0.7971   0.5555\n",
      "Update Cnt = 330    ET =    155.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    65.4    28.8    11.5 |   114.1   102.5   112.0 |  -220.8  -246.4    -3.4 |   787.9   258.0  1554.4\n",
      "v_f      |  -17.18   -0.54  -45.95 |    8.50    7.68   15.43 |  -46.42  -16.20  -77.25 |   20.59   42.62   20.38\n",
      "vr_f     |     2.9 |     2.4 |     0.7 |    30.8\n",
      "r_i      |  1020.5    32.0  2352.6 |   597.6   562.6    28.2 |     4.5  -993.3  2300.0 |  1992.4   986.1  2399.6\n",
      "v_i      |  -41.51    2.66  -79.85 |   17.71   17.10    5.65 |  -69.88  -29.95  -89.93 |  -10.43   29.97  -70.06\n",
      "norm_rf  |   158.2 |   127.6 |     4.6 |  1743.9\n",
      "norm_vf  |   50.38 |   15.44 |    2.33 |   83.35\n",
      "thrust   |    1023    -126    8253 |    4511    4445    4266 |  -13919  -14981  -10181 |   14999   15000   15000\n",
      "norm_thrust |   10690 |    3635 |    2000 |   15000\n",
      "fuel     |     239 |      61 |     155 |     499\n",
      "rewards  |  -68.52 |   35.99 | -334.71 |  -37.99\n",
      "fuel_rewards |   -8.21 |    2.11 |  -17.12 |   -5.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.28 |    0.45 |    0.02 |    3.37\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  154.17 |  126.69 |   17.06 | 1738.92\n",
      "tracking_rewards |  -60.30 |   34.47 | -317.59 |  -29.99\n",
      "steps    |     230 |      67 |     141 |     500\n",
      "***** Episode 10230, Mean R = -63.1  Std R = 14.9  Min R = -114.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000783\n",
      "PolicyEntropy: 0.119\n",
      "PolicyLoss: -0.00357\n",
      "Steps: 7.22e+03\n",
      "TotalSteps: 2.18e+06\n",
      "ValFuncLoss: 0.000981\n",
      "Variance: 0.283\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7998   0.2632   1.4994   2.9231   1.0694   0.6143\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0024   0.0127   1.6645   0.7971   0.5555\n",
      "***** Episode 10261, Mean R = -72.0  Std R = 46.7  Min R = -311.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000748\n",
      "PolicyEntropy: 0.109\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 2.19e+06\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.281\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2707   0.8079   3.5719   3.5719   1.2707   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0016   0.0079   1.6645   0.7971   0.5555\n",
      "***** Episode 10292, Mean R = -75.3  Std R = 42.0  Min R = -281.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000876\n",
      "PolicyEntropy: 0.0991\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 7.44e+03\n",
      "TotalSteps: 2.19e+06\n",
      "ValFuncLoss: 0.00137\n",
      "Variance: 0.282\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5986   0.1982   1.0380   3.5719   1.2707   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0016   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 10323, Mean R = -60.0  Std R = 6.9  Min R = -74.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.00113\n",
      "PolicyEntropy: 0.0864\n",
      "PolicyLoss: -0.0037\n",
      "Steps: 6.67e+03\n",
      "TotalSteps: 2.2e+06\n",
      "ValFuncLoss: 0.000976\n",
      "Variance: 0.281\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9336   0.3627   1.8744   3.5719   1.2707   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0022   0.0094   1.6645   0.7971   0.5555\n",
      "***** Episode 10354, Mean R = -65.4  Std R = 20.0  Min R = -147.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000761\n",
      "PolicyEntropy: 0.0807\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 7.16e+03\n",
      "TotalSteps: 2.21e+06\n",
      "ValFuncLoss: 0.000889\n",
      "Variance: 0.28\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0166   0.4622   2.0791   3.5719   1.2707   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0011   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 10385, Mean R = -69.3  Std R = 31.7  Min R = -212.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.00113\n",
      "PolicyEntropy: 0.0651\n",
      "PolicyLoss: -0.00359\n",
      "Steps: 7.67e+03\n",
      "TotalSteps: 2.21e+06\n",
      "ValFuncLoss: 0.000884\n",
      "Variance: 0.279\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0109   0.3847   1.7424   3.5719   1.2707   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0021   0.0085   1.6645   0.7971   0.5555\n",
      "***** Episode 10416, Mean R = -61.4  Std R = 16.8  Min R = -120.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000688\n",
      "PolicyEntropy: 0.0623\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 7.2e+03\n",
      "TotalSteps: 2.22e+06\n",
      "ValFuncLoss: 0.000872\n",
      "Variance: 0.279\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5621   0.1268   0.8062   3.5719   1.2707   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0061   0.0031   0.0164   1.6645   0.7971   0.5555\n",
      "***** Episode 10447, Mean R = -69.6  Std R = 52.3  Min R = -319.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.0012\n",
      "PolicyEntropy: 0.0555\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 7.3e+03\n",
      "TotalSteps: 2.23e+06\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.276\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2809   0.7578   3.6594   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0114   0.0070   0.0335   1.6645   0.7971   0.5555\n",
      "***** Episode 10478, Mean R = -67.9  Std R = 42.6  Min R = -252.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.00102\n",
      "PolicyEntropy: 0.0515\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 7.82e+03\n",
      "TotalSteps: 2.24e+06\n",
      "ValFuncLoss: 0.0012\n",
      "Variance: 0.277\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5862   0.2914   1.3084   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0053   0.0235   1.6645   0.7971   0.5555\n",
      "***** Episode 10509, Mean R = -76.5  Std R = 52.2  Min R = -245.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.000701\n",
      "PolicyEntropy: 0.038\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 2.25e+06\n",
      "ValFuncLoss: 0.0014\n",
      "Variance: 0.275\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7120   0.1459   1.0548   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0058   0.0025   0.0129   1.6645   0.7971   0.5555\n",
      "Update Cnt = 340    ET =    163.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    61.0     1.2    30.2 |   150.2   116.5   208.4 |  -246.7  -275.5    -3.3 |  1253.5   684.4  1991.8\n",
      "v_f      |  -15.49    0.79  -40.59 |    8.76    6.94   17.10 |  -37.53  -20.00  -77.21 |   34.58   27.85   41.20\n",
      "vr_f     |     2.8 |     2.0 |     0.4 |    20.1\n",
      "r_i      |  1026.2   -23.8  2349.0 |   583.0   610.6    28.8 |    16.8  -995.4  2300.3 |  1986.0   995.9  2399.6\n",
      "v_i      |  -38.55    0.40  -78.92 |   17.63   17.53    5.73 |  -69.88  -29.95  -89.94 |  -10.47   29.97  -70.23\n",
      "norm_rf  |   163.1 |   239.9 |     3.0 |  2428.0\n",
      "norm_vf  |   45.50 |   15.34 |    5.10 |   85.82\n",
      "thrust   |     924      18    8318 |    4369    4441    4189 |  -13950  -14973   -9200 |   14945   14837   15000\n",
      "norm_thrust |   10640 |    3633 |    2000 |   15000\n",
      "fuel     |     249 |      64 |     155 |     507\n",
      "rewards  |  -69.24 |   38.86 | -319.35 |  -39.96\n",
      "fuel_rewards |   -8.58 |    2.21 |  -17.40 |   -5.35\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.25 |    0.52 |    0.01 |    3.07\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  160.17 |  238.87 |   15.91 | 2422.95\n",
      "tracking_rewards |  -60.67 |   37.22 | -303.07 |  -31.16\n",
      "steps    |     241 |      72 |     151 |     500\n",
      "***** Episode 10540, Mean R = -75.0  Std R = 43.1  Min R = -203.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.000821\n",
      "PolicyEntropy: 0.0386\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 7.6e+03\n",
      "TotalSteps: 2.25e+06\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.275\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6798   0.1936   1.0955   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0015   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 10571, Mean R = -62.8  Std R = 14.7  Min R = -112.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000706\n",
      "PolicyEntropy: 0.0473\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 7.42e+03\n",
      "TotalSteps: 2.26e+06\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.277\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6563   0.2591   1.0913   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0013   0.0070   1.6645   0.7971   0.5555\n",
      "***** Episode 10602, Mean R = -66.9  Std R = 31.8  Min R = -185.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000668\n",
      "PolicyEntropy: 0.0396\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 7.34e+03\n",
      "TotalSteps: 2.27e+06\n",
      "ValFuncLoss: 0.00176\n",
      "Variance: 0.275\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4941   0.1565   0.7785   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0006   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 10633, Mean R = -60.6  Std R = 12.0  Min R = -94.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.000726\n",
      "PolicyEntropy: 0.035\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 6.98e+03\n",
      "TotalSteps: 2.27e+06\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.275\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8127   0.3787   1.7267   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0170   0.0075   0.0379   1.6645   0.7971   0.5555\n",
      "***** Episode 10664, Mean R = -91.8  Std R = 70.6  Min R = -348.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.919\n",
      "KL: 0.000653\n",
      "PolicyEntropy: 0.0374\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 8.72e+03\n",
      "TotalSteps: 2.28e+06\n",
      "ValFuncLoss: 0.00282\n",
      "Variance: 0.274\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8410   0.2402   1.2223   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0101   0.0053   0.0227   1.6645   0.7971   0.5555\n",
      "***** Episode 10695, Mean R = -62.5  Std R = 14.3  Min R = -118.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.915\n",
      "KL: 0.000678\n",
      "PolicyEntropy: 0.0354\n",
      "PolicyLoss: -0.00329\n",
      "Steps: 7.33e+03\n",
      "TotalSteps: 2.29e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.273\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8576   0.2853   1.4745   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0016   0.0080   1.6645   0.7971   0.5555\n",
      "***** Episode 10726, Mean R = -59.9  Std R = 15.1  Min R = -112.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000869\n",
      "PolicyEntropy: 0.0266\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 7.24e+03\n",
      "TotalSteps: 2.3e+06\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.273\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1565   0.7409   3.1595   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0119   0.0056   0.0216   1.6645   0.7971   0.5555\n",
      "***** Episode 10757, Mean R = -61.5  Std R = 29.1  Min R = -205.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.862\n",
      "ExplainedVarOld: 0.774\n",
      "KL: 0.000872\n",
      "PolicyEntropy: 0.00867\n",
      "PolicyLoss: -0.00215\n",
      "Steps: 7.35e+03\n",
      "TotalSteps: 2.31e+06\n",
      "ValFuncLoss: 0.00456\n",
      "Variance: 0.271\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9468   0.4700   1.9793   3.6594   1.2809   0.8079\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0096   0.0053   0.0263   1.6645   0.7971   0.5555\n",
      "***** Episode 10788, Mean R = -70.5  Std R = 44.4  Min R = -248.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.893\n",
      "ExplainedVarOld: 0.866\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -0.00293\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 7.41e+03\n",
      "TotalSteps: 2.31e+06\n",
      "ValFuncLoss: 0.00367\n",
      "Variance: 0.27\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4470   0.9445   3.8552   3.8552   1.4470   0.9445\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0067   0.0035   0.0180   1.6645   0.7971   0.5555\n",
      "***** Episode 10819, Mean R = -61.0  Std R = 17.5  Min R = -109.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000963\n",
      "PolicyEntropy: -0.00902\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 6.99e+03\n",
      "TotalSteps: 2.32e+06\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.27\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0146   0.3723   1.6863   3.8552   1.4470   0.9445\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0043   1.6645   0.7971   0.5555\n",
      "Update Cnt = 350    ET =    161.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    33.7    -0.8     5.4 |    98.4    92.3    69.0 |  -253.2  -251.6    -3.3 |   448.2   296.0  1137.5\n",
      "v_f      |  -15.84    0.59  -39.27 |    7.67    6.61   14.73 |  -33.11  -19.80  -77.36 |   13.44   18.64    1.68\n",
      "vr_f     |     2.6 |     1.5 |     0.2 |    12.0\n",
      "r_i      |   997.2    36.6  2349.5 |   580.9   573.3    28.6 |     8.0  -991.3  2300.0 |  1998.5   993.8  2399.7\n",
      "v_i      |  -39.51   -0.88  -79.72 |   17.53   17.63    5.70 |  -69.83  -29.74  -89.99 |  -10.17   29.91  -70.05\n",
      "norm_rf  |   125.6 |    91.3 |     2.8 |  1248.2\n",
      "norm_vf  |   43.38 |   15.18 |    2.36 |   83.88\n",
      "thrust   |     958      63    8467 |    4339    4342    4087 |  -13799  -14872   -9532 |   14996   14920   14999\n",
      "norm_thrust |   10682 |    3591 |    2000 |   15000\n",
      "fuel     |     246 |      62 |     150 |     499\n",
      "rewards  |  -65.44 |   33.04 | -348.65 |  -37.12\n",
      "fuel_rewards |   -8.47 |    2.12 |  -17.13 |   -5.16\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.28 |    0.48 |    0.01 |    3.15\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  122.66 |   89.41 |   10.67 | 1243.22\n",
      "tracking_rewards |  -56.97 |   31.50 | -332.99 |  -29.63\n",
      "steps    |     237 |      69 |     146 |     500\n",
      "***** Episode 10850, Mean R = -56.8  Std R = 10.2  Min R = -77.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00091\n",
      "PolicyEntropy: -0.0128\n",
      "PolicyLoss: -0.00422\n",
      "Steps: 6.75e+03\n",
      "TotalSteps: 2.33e+06\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.269\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4840   0.2699   1.4137   3.8552   1.4470   0.9445\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0101   0.0053   0.0272   1.6645   0.7971   0.5555\n",
      "***** Episode 10881, Mean R = -86.6  Std R = 78.2  Min R = -335.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000577\n",
      "PolicyEntropy: -0.023\n",
      "PolicyLoss: -0.0019\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 2.33e+06\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.269\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9701   0.4018   1.6949   3.8552   1.4470   0.9445\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0037   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 10912, Mean R = -72.2  Std R = 53.9  Min R = -323.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000978\n",
      "PolicyEntropy: -0.0281\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 2.34e+06\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.27\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9099   0.3871   2.3959   3.8552   1.4470   0.9445\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0018   0.0082   1.6645   0.7971   0.5555\n",
      "***** Episode 10943, Mean R = -61.6  Std R = 18.5  Min R = -130.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.000725\n",
      "PolicyEntropy: -0.0349\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 7.67e+03\n",
      "TotalSteps: 2.35e+06\n",
      "ValFuncLoss: 0.00146\n",
      "Variance: 0.27\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5655   0.2762   1.2053   3.8552   1.4470   0.9445\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0066   0.0033   0.0132   1.6645   0.7971   0.5555\n",
      "***** Episode 10974, Mean R = -58.9  Std R = 31.9  Min R = -224.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.896\n",
      "ExplainedVarOld: 0.846\n",
      "KL: 0.000905\n",
      "PolicyEntropy: -0.0484\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 7.46e+03\n",
      "TotalSteps: 2.36e+06\n",
      "ValFuncLoss: 0.00416\n",
      "Variance: 0.269\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3325   1.5995   5.7518   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0089   0.0041   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 11005, Mean R = -69.7  Std R = 39.1  Min R = -237.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.885\n",
      "ExplainedVarOld: 0.854\n",
      "KL: 0.00138\n",
      "PolicyEntropy: -0.0688\n",
      "PolicyLoss: -0.00155\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 2.37e+06\n",
      "ValFuncLoss: 0.00388\n",
      "Variance: 0.266\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2586   0.7872   3.0434   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0030   0.0145   1.6645   0.7971   0.5555\n",
      "***** Episode 11036, Mean R = -72.4  Std R = 44.5  Min R = -243.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.891\n",
      "ExplainedVarOld: 0.871\n",
      "KL: 0.000833\n",
      "PolicyEntropy: -0.0553\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 7.46e+03\n",
      "TotalSteps: 2.37e+06\n",
      "ValFuncLoss: 0.00369\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8371   0.3124   1.4759   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0093   0.0053   0.0239   1.6645   0.7971   0.5555\n",
      "***** Episode 11067, Mean R = -66.0  Std R = 28.1  Min R = -191.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.905\n",
      "KL: 0.000676\n",
      "PolicyEntropy: -0.0569\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 7.85e+03\n",
      "TotalSteps: 2.38e+06\n",
      "ValFuncLoss: 0.00287\n",
      "Variance: 0.266\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9306   0.5199   2.2121   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0034   0.0129   1.6645   0.7971   0.5555\n",
      "***** Episode 11098, Mean R = -61.9  Std R = 20.4  Min R = -163.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000595\n",
      "PolicyEntropy: -0.0474\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 7.33e+03\n",
      "TotalSteps: 2.39e+06\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5627   0.1801   0.9723   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0018   0.0079   1.6645   0.7971   0.5555\n",
      "***** Episode 11129, Mean R = -62.0  Std R = 38.2  Min R = -262.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -0.0571\n",
      "PolicyLoss: -0.00231\n",
      "Steps: 7.67e+03\n",
      "TotalSteps: 2.4e+06\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6115   0.2185   1.0832   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0023   0.0112   1.6645   0.7971   0.5555\n",
      "Update Cnt = 360    ET =    169.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    29.6     7.0    20.2 |    99.3    80.7   146.0 |  -167.7  -221.3    -3.5 |  1012.7   288.1  1907.8\n",
      "v_f      |  -13.52    1.39  -35.85 |    7.23    6.18   16.25 |  -32.76  -13.68  -71.78 |   22.79   21.01   27.48\n",
      "vr_f     |     2.7 |     2.1 |     0.0 |    30.8\n",
      "r_i      |   982.7    23.8  2351.0 |   579.1   552.0    29.0 |     2.9  -978.8  2300.0 |  1989.3   999.4  2399.8\n",
      "v_i      |  -38.59    0.40  -79.32 |   17.60   17.86    5.54 |  -69.71  -29.80  -89.97 |  -10.22   29.94  -70.03\n",
      "norm_rf  |   118.2 |   158.3 |     9.2 |  2179.0\n",
      "norm_vf  |   39.88 |   15.30 |    2.82 |   80.32\n",
      "thrust   |     971      42    8442 |    4291    4192    4065 |  -14311  -14634   -8917 |   14993   14912   15000\n",
      "norm_thrust |   10576 |    3588 |    2000 |   15000\n",
      "fuel     |     257 |      68 |     158 |     511\n",
      "rewards  |  -67.59 |   43.49 | -335.26 |  -32.86\n",
      "fuel_rewards |   -8.82 |    2.34 |  -17.56 |   -5.44\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.27 |    0.52 |    0.02 |    2.95\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  116.27 |  156.74 |   11.30 | 2174.01\n",
      "tracking_rewards |  -58.77 |   41.78 | -319.13 |  -24.32\n",
      "steps    |     250 |      76 |     154 |     500\n",
      "***** Episode 11160, Mean R = -64.7  Std R = 41.9  Min R = -285.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000953\n",
      "PolicyEntropy: -0.0704\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 7.32e+03\n",
      "TotalSteps: 2.4e+06\n",
      "ValFuncLoss: 0.00226\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6707   0.2660   1.5225   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0155   0.0072   0.0295   1.6645   0.7971   0.5555\n",
      "***** Episode 11191, Mean R = -67.9  Std R = 53.1  Min R = -326.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.887\n",
      "ExplainedVarOld: 0.801\n",
      "KL: 0.000691\n",
      "PolicyEntropy: -0.0655\n",
      "PolicyLoss: -0.00192\n",
      "Steps: 7.70e+03\n",
      "TotalSteps: 2.41e+06\n",
      "ValFuncLoss: 0.00768\n",
      "Variance: 0.268\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0972   0.5748   2.6188   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0030   0.0119   1.6645   0.7971   0.5555\n",
      "***** Episode 11222, Mean R = -66.2  Std R = 35.1  Min R = -237.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.898\n",
      "ExplainedVarOld: 0.854\n",
      "KL: 0.00125\n",
      "PolicyEntropy: -0.0719\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 7.3e+03\n",
      "TotalSteps: 2.42e+06\n",
      "ValFuncLoss: 0.00507\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9656   0.4232   2.2278   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0012   0.0053   1.6645   0.7971   0.5555\n",
      "***** Episode 11253, Mean R = -60.5  Std R = 21.9  Min R = -145.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000697\n",
      "PolicyEntropy: -0.061\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 7.74e+03\n",
      "TotalSteps: 2.43e+06\n",
      "ValFuncLoss: 0.0036\n",
      "Variance: 0.269\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8479   0.4480   2.0800   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0020   0.0085   1.6645   0.7971   0.5555\n",
      "***** Episode 11284, Mean R = -64.0  Std R = 30.7  Min R = -212.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.9\n",
      "ExplainedVarOld: 0.872\n",
      "KL: 0.000783\n",
      "PolicyEntropy: -0.0572\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 7.61e+03\n",
      "TotalSteps: 2.43e+06\n",
      "ValFuncLoss: 0.00355\n",
      "Variance: 0.268\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1035   0.4939   2.1187   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0027   0.0125   1.6645   0.7971   0.5555\n",
      "***** Episode 11315, Mean R = -59.8  Std R = 21.1  Min R = -159.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.884\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -0.0636\n",
      "PolicyLoss: -0.00218\n",
      "Steps: 7.42e+03\n",
      "TotalSteps: 2.44e+06\n",
      "ValFuncLoss: 0.0036\n",
      "Variance: 0.268\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7714   0.2674   1.2920   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0094   0.0051   0.0264   1.6645   0.7971   0.5555\n",
      "***** Episode 11346, Mean R = -66.7  Std R = 34.8  Min R = -218.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.903\n",
      "ExplainedVarOld: 0.853\n",
      "KL: 0.000767\n",
      "PolicyEntropy: -0.0539\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 7.53e+03\n",
      "TotalSteps: 2.45e+06\n",
      "ValFuncLoss: 0.00335\n",
      "Variance: 0.268\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1165   0.5035   2.5961   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0071   0.0039   0.0181   1.6645   0.7971   0.5555\n",
      "***** Episode 11377, Mean R = -58.4  Std R = 13.6  Min R = -111.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.927\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000844\n",
      "PolicyEntropy: -0.0546\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 7.16e+03\n",
      "TotalSteps: 2.46e+06\n",
      "ValFuncLoss: 0.00332\n",
      "Variance: 0.268\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6623   0.7225   3.9199   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0088   0.0046   0.0230   1.6645   0.7971   0.5555\n",
      "***** Episode 11408, Mean R = -70.0  Std R = 41.1  Min R = -281.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000551\n",
      "PolicyEntropy: -0.0519\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 6.85e+03\n",
      "TotalSteps: 2.46e+06\n",
      "ValFuncLoss: 0.00363\n",
      "Variance: 0.269\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8233   0.4085   1.9078   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0021   0.0105   1.6645   0.7971   0.5555\n",
      "***** Episode 11439, Mean R = -76.1  Std R = 51.2  Min R = -239.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.895\n",
      "KL: 0.000707\n",
      "PolicyEntropy: -0.0671\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 2.47e+06\n",
      "ValFuncLoss: 0.00419\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4258   0.7174   3.8173   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0017   0.0076   1.6645   0.7971   0.5555\n",
      "Update Cnt = 370    ET =    162.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    15.1    12.6    10.7 |    92.3    82.1   105.9 |  -192.1  -238.8    -2.9 |   849.2   266.7  1745.6\n",
      "v_f      |  -13.88    1.14  -37.22 |    8.10    6.50   16.32 |  -33.45  -14.78  -79.13 |   17.28   17.64   26.22\n",
      "vr_f     |     3.1 |     4.6 |     0.2 |    71.3\n",
      "r_i      |   950.9    11.1  2349.8 |   564.4   604.3    29.6 |     2.5  -995.5  2300.6 |  1997.4   993.7  2399.8\n",
      "v_i      |  -40.90    0.73  -80.27 |   17.51   17.44    5.76 |  -69.84  -29.72  -89.99 |  -10.29   29.86  -70.17\n",
      "norm_rf  |   110.6 |   121.4 |     4.2 |  1955.9\n",
      "norm_vf  |   41.26 |   15.85 |    5.92 |   81.09\n",
      "thrust   |    1094       5    8488 |    4257    4359    4041 |  -13751  -14844   -8782 |   14966   14838   15000\n",
      "norm_thrust |   10669 |    3586 |    2000 |   15000\n",
      "fuel     |     249 |      66 |     157 |     510\n",
      "rewards  |  -64.46 |   34.70 | -326.67 |  -32.43\n",
      "fuel_rewards |   -8.55 |    2.27 |  -17.49 |   -5.40\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.30 |    0.49 |    0.01 |    2.80\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |  108.34 |  119.78 |   13.17 | 1950.87\n",
      "tracking_rewards |  -55.91 |   33.09 | -309.44 |  -23.09\n",
      "steps    |     240 |      72 |     158 |     500\n",
      "***** Episode 11470, Mean R = -55.1  Std R = 8.0  Min R = -71.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -0.071\n",
      "PolicyLoss: -0.00397\n",
      "Steps: 6.7e+03\n",
      "TotalSteps: 2.48e+06\n",
      "ValFuncLoss: 0.00293\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9435   0.4909   2.6655   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 11501, Mean R = -65.6  Std R = 31.8  Min R = -172.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.000769\n",
      "PolicyEntropy: -0.0801\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 7.68e+03\n",
      "TotalSteps: 2.49e+06\n",
      "ValFuncLoss: 0.0023\n",
      "Variance: 0.267\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7134   0.3276   1.7097   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0094   0.0044   0.0161   1.6645   0.7971   0.5555\n",
      "***** Episode 11532, Mean R = -66.6  Std R = 42.2  Min R = -238.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.906\n",
      "ExplainedVarOld: 0.869\n",
      "KL: 0.000766\n",
      "PolicyEntropy: -0.0914\n",
      "PolicyLoss: -0.0023\n",
      "Steps: 7.61e+03\n",
      "TotalSteps: 2.49e+06\n",
      "ValFuncLoss: 0.00468\n",
      "Variance: 0.266\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5336   0.4167   2.2181   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0075   0.0032   0.0138   1.6645   0.7971   0.5555\n",
      "***** Episode 11563, Mean R = -70.3  Std R = 47.7  Min R = -294.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.9\n",
      "ExplainedVarOld: 0.872\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -0.104\n",
      "PolicyLoss: -0.00205\n",
      "Steps: 7.62e+03\n",
      "TotalSteps: 2.5e+06\n",
      "ValFuncLoss: 0.00534\n",
      "Variance: 0.266\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9519   0.2724   1.3622   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0014   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 11594, Mean R = -70.6  Std R = 28.2  Min R = -146.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.897\n",
      "ExplainedVarOld: 0.874\n",
      "KL: 0.000952\n",
      "PolicyEntropy: -0.111\n",
      "PolicyLoss: -0.00373\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 2.51e+06\n",
      "ValFuncLoss: 0.00403\n",
      "Variance: 0.264\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9069   0.4125   1.8379   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0016   0.0076   1.6645   0.7971   0.5555\n",
      "***** Episode 11625, Mean R = -60.5  Std R = 36.2  Min R = -248.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.919\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.000682\n",
      "PolicyEntropy: -0.127\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 7.23e+03\n",
      "TotalSteps: 2.52e+06\n",
      "ValFuncLoss: 0.00552\n",
      "Variance: 0.265\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8121   0.2289   1.3720   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0019   0.0106   1.6645   0.7971   0.5555\n",
      "***** Episode 11656, Mean R = -74.4  Std R = 54.9  Min R = -259.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000616\n",
      "PolicyEntropy: -0.132\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 2.52e+06\n",
      "ValFuncLoss: 0.00357\n",
      "Variance: 0.263\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9500   0.3744   2.1486   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0020   0.0101   1.6645   0.7971   0.5555\n",
      "***** Episode 11687, Mean R = -56.8  Std R = 17.2  Min R = -104.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.897\n",
      "KL: 0.000926\n",
      "PolicyEntropy: -0.126\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 7.59e+03\n",
      "TotalSteps: 2.53e+06\n",
      "ValFuncLoss: 0.00235\n",
      "Variance: 0.264\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6696   0.2648   1.2872   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0099   0.0050   0.0269   1.6645   0.7971   0.5555\n",
      "***** Episode 11718, Mean R = -69.7  Std R = 42.8  Min R = -277.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.878\n",
      "KL: 0.000716\n",
      "PolicyEntropy: -0.125\n",
      "PolicyLoss: -0.00229\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 2.54e+06\n",
      "ValFuncLoss: 0.00306\n",
      "Variance: 0.265\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8627   0.3740   2.1757   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0022   0.0105   1.6645   0.7971   0.5555\n",
      "***** Episode 11749, Mean R = -62.5  Std R = 25.3  Min R = -176.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000709\n",
      "PolicyEntropy: -0.132\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 7.62e+03\n",
      "TotalSteps: 2.55e+06\n",
      "ValFuncLoss: 0.00196\n",
      "Variance: 0.262\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6995   0.2798   1.4201   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0026   0.0117   1.6645   0.7971   0.5555\n",
      "Update Cnt = 380    ET =    169.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.1    -3.4     8.1 |    72.6    69.3    67.1 |  -271.9  -255.3    -3.3 |   212.4   233.8   699.3\n",
      "v_f      |  -14.19    1.84  -35.39 |    7.36    6.27   14.46 |  -33.05  -18.23  -79.43 |   11.55   19.93   22.85\n",
      "vr_f     |     2.6 |     1.8 |     0.3 |    15.1\n",
      "r_i      |  1016.7   -73.4  2350.2 |   584.4   590.9    28.9 |    13.9  -992.3  2300.3 |  1995.0   997.8  2399.7\n",
      "v_i      |  -39.75   -1.21  -80.24 |   17.13   17.44    6.02 |  -69.96  -29.93  -89.92 |  -10.38   30.00  -70.14\n",
      "norm_rf  |    91.0 |    80.4 |     0.9 |   738.1\n",
      "norm_vf  |   39.50 |   14.12 |    0.34 |   83.89\n",
      "thrust   |     983     117    8491 |    4165    4250    4064 |  -13438  -14667  -10664 |   14940   14916   15000\n",
      "norm_thrust |   10582 |    3609 |    2000 |   15000\n",
      "fuel     |     258 |      68 |     160 |     522\n",
      "rewards  |  -66.79 |   39.32 | -294.21 |  -32.00\n",
      "fuel_rewards |   -8.88 |    2.33 |  -17.93 |   -5.50\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.24 |    0.54 |    0.02 |    3.35\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   90.02 |   77.42 |   17.40 |  733.08\n",
      "tracking_rewards |  -57.91 |   37.45 | -277.68 |  -22.65\n",
      "steps    |     251 |      75 |     149 |     500\n",
      "***** Episode 11780, Mean R = -70.8  Std R = 47.4  Min R = -276.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.859\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -0.141\n",
      "PolicyLoss: -0.00197\n",
      "Steps: 7.91e+03\n",
      "TotalSteps: 2.56e+06\n",
      "ValFuncLoss: 0.00309\n",
      "Variance: 0.262\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1794   0.4992   2.7792   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0011   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 11811, Mean R = -57.3  Std R = 19.6  Min R = -151.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.904\n",
      "ExplainedVarOld: 0.882\n",
      "KL: 0.00094\n",
      "PolicyEntropy: -0.155\n",
      "PolicyLoss: -0.00338\n",
      "Steps: 7.67e+03\n",
      "TotalSteps: 2.56e+06\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.26\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2183   0.5097   2.6724   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0024   0.0095   1.6645   0.7971   0.5555\n",
      "***** Episode 11842, Mean R = -68.7  Std R = 38.3  Min R = -208.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.914\n",
      "ExplainedVarOld: 0.868\n",
      "KL: 0.000882\n",
      "PolicyEntropy: -0.153\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 7.74e+03\n",
      "TotalSteps: 2.57e+06\n",
      "ValFuncLoss: 0.00188\n",
      "Variance: 0.261\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9681   0.3939   2.0407   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 11873, Mean R = -64.6  Std R = 30.2  Min R = -171.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.905\n",
      "ExplainedVarOld: 0.888\n",
      "KL: 0.000671\n",
      "PolicyEntropy: -0.152\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 2.58e+06\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.259\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.4414   0.1230   0.6523   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0082   0.0055   0.0214   1.6645   0.7971   0.5555\n",
      "***** Episode 11904, Mean R = -72.4  Std R = 66.5  Min R = -366.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.851\n",
      "KL: 0.000875\n",
      "PolicyEntropy: -0.15\n",
      "PolicyLoss: -0.00182\n",
      "Steps: 7.59e+03\n",
      "TotalSteps: 2.59e+06\n",
      "ValFuncLoss: 0.0048\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5776   0.1491   0.8458   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0025   0.0103   1.6645   0.7971   0.5555\n",
      "***** Episode 11935, Mean R = -57.3  Std R = 12.7  Min R = -102.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.901\n",
      "KL: 0.000853\n",
      "PolicyEntropy: -0.157\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 7.47e+03\n",
      "TotalSteps: 2.59e+06\n",
      "ValFuncLoss: 0.00247\n",
      "Variance: 0.257\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2511   0.7746   3.7059   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0014   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 11966, Mean R = -74.5  Std R = 46.9  Min R = -267.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.914\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000825\n",
      "PolicyEntropy: -0.162\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 7.74e+03\n",
      "TotalSteps: 2.6e+06\n",
      "ValFuncLoss: 0.00379\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2133   0.4666   2.2749   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0082   0.0041   0.0168   1.6645   0.7971   0.5555\n",
      "***** Episode 11997, Mean R = -51.7  Std R = 9.4  Min R = -71.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.921\n",
      "ExplainedVarOld: 0.885\n",
      "KL: 0.000761\n",
      "PolicyEntropy: -0.163\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 6.98e+03\n",
      "TotalSteps: 2.61e+06\n",
      "ValFuncLoss: 0.00228\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6280   0.2087   1.1283   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0121   0.0068   0.0304   1.6645   0.7971   0.5555\n",
      "***** Episode 12028, Mean R = -79.6  Std R = 72.1  Min R = -356.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.922\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000855\n",
      "PolicyEntropy: -0.176\n",
      "PolicyLoss: -0.00196\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 2.62e+06\n",
      "ValFuncLoss: 0.00452\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9641   0.4168   1.7929   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0114   0.0067   0.0279   1.6645   0.7971   0.5555\n",
      "***** Episode 12059, Mean R = -70.5  Std R = 49.7  Min R = -260.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.902\n",
      "ExplainedVarOld: 0.88\n",
      "KL: 0.00076\n",
      "PolicyEntropy: -0.17\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 7.69e+03\n",
      "TotalSteps: 2.63e+06\n",
      "ValFuncLoss: 0.0041\n",
      "Variance: 0.26\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1283   0.5165   2.8424   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0071   0.0042   0.0160   1.6645   0.7971   0.5555\n",
      "Update Cnt = 390    ET =    167.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.2     3.5    13.9 |    77.6    68.4    88.6 |  -227.7  -227.0    -3.6 |   216.6   251.2   818.3\n",
      "v_f      |  -15.65    1.41  -36.14 |    7.42    6.23   15.04 |  -34.93  -22.38  -72.62 |    8.56   18.51   36.84\n",
      "vr_f     |     2.4 |     1.4 |     0.2 |    15.0\n",
      "r_i      |  1050.0     0.3  2351.4 |   581.7   579.7    30.0 |     6.7  -992.8  2300.5 |  1993.3   989.3  2400.0\n",
      "v_i      |  -39.34   -1.83  -80.23 |   16.45   17.23    5.67 |  -69.79  -29.94  -89.82 |  -10.27   29.65  -70.06\n",
      "norm_rf  |    99.2 |    96.5 |     4.7 |   871.7\n",
      "norm_vf  |   40.96 |   13.97 |    5.97 |   77.13\n",
      "thrust   |     927     116    8513 |    4156    4260    3997 |  -14307  -14878   -8202 |   14990   14957   15000\n",
      "norm_thrust |   10578 |    3584 |    2000 |   15000\n",
      "fuel     |     253 |      68 |     153 |     523\n",
      "rewards  |  -65.63 |   43.12 | -366.28 |  -30.20\n",
      "fuel_rewards |   -8.69 |    2.32 |  -17.95 |   -5.25\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.22 |    0.50 |    0.03 |    2.90\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   98.32 |   93.74 |   20.80 |  866.68\n",
      "tracking_rewards |  -56.94 |   41.31 | -348.33 |  -21.84\n",
      "steps    |     246 |      73 |     149 |     500\n",
      "***** Episode 12090, Mean R = -59.6  Std R = 24.0  Min R = -150.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -0.186\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 6.98e+03\n",
      "TotalSteps: 2.63e+06\n",
      "ValFuncLoss: 0.0023\n",
      "Variance: 0.259\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0791   0.5746   2.9538   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0026   0.0108   1.6645   0.7971   0.5555\n",
      "***** Episode 12121, Mean R = -66.7  Std R = 43.2  Min R = -271.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000745\n",
      "PolicyEntropy: -0.193\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 2.64e+06\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.26\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0800   0.6123   2.8241   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0018   0.0088   1.6645   0.7971   0.5555\n",
      "***** Episode 12152, Mean R = -55.2  Std R = 14.3  Min R = -119.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000958\n",
      "PolicyEntropy: -0.205\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 7.38e+03\n",
      "TotalSteps: 2.65e+06\n",
      "ValFuncLoss: 0.00192\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7374   0.3404   1.6766   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0043   0.0206   1.6645   0.7971   0.5555\n",
      "***** Episode 12183, Mean R = -79.7  Std R = 55.0  Min R = -251.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.911\n",
      "ExplainedVarOld: 0.829\n",
      "KL: 0.000694\n",
      "PolicyEntropy: -0.214\n",
      "PolicyLoss: -0.00201\n",
      "Steps: 7.73e+03\n",
      "TotalSteps: 2.66e+06\n",
      "ValFuncLoss: 0.00347\n",
      "Variance: 0.257\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8114   0.4888   2.2918   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0073   0.0040   0.0185   1.6645   0.7971   0.5555\n",
      "***** Episode 12214, Mean R = -76.1  Std R = 57.7  Min R = -287.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.834\n",
      "KL: 0.000634\n",
      "PolicyEntropy: -0.209\n",
      "PolicyLoss: -0.00202\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 2.66e+06\n",
      "ValFuncLoss: 0.00543\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8756   0.3821   1.6855   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0023   0.0109   1.6645   0.7971   0.5555\n",
      "***** Episode 12245, Mean R = -63.2  Std R = 30.8  Min R = -196.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.921\n",
      "ExplainedVarOld: 0.897\n",
      "KL: 0.000745\n",
      "PolicyEntropy: -0.216\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 7.85e+03\n",
      "TotalSteps: 2.67e+06\n",
      "ValFuncLoss: 0.00333\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7288   0.2592   1.4731   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0123   0.0065   0.0262   1.6645   0.7971   0.5555\n",
      "***** Episode 12276, Mean R = -71.4  Std R = 38.1  Min R = -191.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.889\n",
      "ExplainedVarOld: 0.854\n",
      "KL: 0.000735\n",
      "PolicyEntropy: -0.226\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 2.68e+06\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0163   0.4578   2.0444   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0026   0.0108   1.6645   0.7971   0.5555\n",
      "***** Episode 12307, Mean R = -77.1  Std R = 53.9  Min R = -238.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.000681\n",
      "PolicyEntropy: -0.233\n",
      "PolicyLoss: -0.0025\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 2.69e+06\n",
      "ValFuncLoss: 0.00286\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5307   0.2218   1.0601   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0018   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 12338, Mean R = -77.4  Std R = 58.9  Min R = -291.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000911\n",
      "PolicyEntropy: -0.244\n",
      "PolicyLoss: -0.00212\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 2.7e+06\n",
      "ValFuncLoss: 0.00408\n",
      "Variance: 0.259\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5449   0.2390   1.0920   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0096   0.0047   0.0220   1.6645   0.7971   0.5555\n",
      "***** Episode 12369, Mean R = -60.9  Std R = 47.0  Min R = -308.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000761\n",
      "PolicyEntropy: -0.247\n",
      "PolicyLoss: -0.00219\n",
      "Steps: 7.54e+03\n",
      "TotalSteps: 2.7e+06\n",
      "ValFuncLoss: 0.00381\n",
      "Variance: 0.258\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6228   0.8017   3.4203   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0080   0.0039   0.0166   1.6645   0.7971   0.5555\n",
      "Update Cnt = 400    ET =    172.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.5    -2.8     9.8 |    68.6    61.9    70.8 |  -191.3  -153.8    -2.6 |   220.2   173.3   872.0\n",
      "v_f      |  -15.27    1.31  -34.95 |    7.41    5.42   13.89 |  -32.50  -14.67  -69.61 |    9.22   14.23   10.69\n",
      "vr_f     |     2.3 |     1.1 |     0.1 |     9.5\n",
      "r_i      |  1028.1     2.0  2351.4 |   575.7   604.0    27.8 |     5.1  -995.8  2300.2 |  1989.9   995.3  2399.8\n",
      "v_i      |  -38.99   -1.38  -80.30 |   17.69   16.80    5.86 |  -69.63  -29.96  -90.00 |  -10.09   29.48  -70.09\n",
      "norm_rf  |    88.2 |    77.5 |     1.6 |   908.9\n",
      "norm_vf  |   39.13 |   14.23 |    3.55 |   73.34\n",
      "thrust   |     915     130    8465 |    4105    4202    4038 |  -14263  -14872   -9525 |   14958   14987   15000\n",
      "norm_thrust |   10500 |    3617 |    2000 |   15000\n",
      "fuel     |     263 |      77 |     160 |     534\n",
      "rewards  |  -70.15 |   46.43 | -308.86 |  -35.39\n",
      "fuel_rewards |   -9.05 |    2.64 |  -18.35 |   -5.51\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.22 |    0.58 |    0.01 |    3.07\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   86.77 |   74.95 |   18.97 |  903.89\n",
      "tracking_rewards |  -61.10 |   44.22 | -290.60 |  -26.60\n",
      "steps    |     258 |      83 |     156 |     500\n",
      "***** Episode 12400, Mean R = -73.9  Std R = 39.2  Min R = -193.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.893\n",
      "ExplainedVarOld: 0.86\n",
      "KL: 0.000807\n",
      "PolicyEntropy: -0.256\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 2.71e+06\n",
      "ValFuncLoss: 0.00458\n",
      "Variance: 0.257\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7452   0.2807   1.3132   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0063   0.0034   0.0152   1.6645   0.7971   0.5555\n",
      "***** Episode 12431, Mean R = -64.0  Std R = 50.6  Min R = -323.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -0.271\n",
      "PolicyLoss: -0.00242\n",
      "Steps: 7.77e+03\n",
      "TotalSteps: 2.72e+06\n",
      "ValFuncLoss: 0.00446\n",
      "Variance: 0.255\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7330   0.2667   1.4260   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0021   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 12462, Mean R = -60.2  Std R = 35.1  Min R = -202.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.000791\n",
      "PolicyEntropy: -0.268\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 7.46e+03\n",
      "TotalSteps: 2.73e+06\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.254\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6036   0.7447   3.1314   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0026   0.0117   1.6645   0.7971   0.5555\n",
      "***** Episode 12493, Mean R = -79.9  Std R = 57.9  Min R = -278.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.000916\n",
      "PolicyEntropy: -0.258\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 2.74e+06\n",
      "ValFuncLoss: 0.00436\n",
      "Variance: 0.255\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7824   0.3210   1.5506   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0024   0.0127   1.6645   0.7971   0.5555\n",
      "***** Episode 12524, Mean R = -71.7  Std R = 40.8  Min R = -217.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.886\n",
      "KL: 0.00065\n",
      "PolicyEntropy: -0.262\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 2.74e+06\n",
      "ValFuncLoss: 0.00343\n",
      "Variance: 0.254\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6145   0.1931   0.9162   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0018   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 12555, Mean R = -65.9  Std R = 43.2  Min R = -281.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.921\n",
      "ExplainedVarOld: 0.894\n",
      "KL: 0.000683\n",
      "PolicyEntropy: -0.259\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 2.75e+06\n",
      "ValFuncLoss: 0.00311\n",
      "Variance: 0.253\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0144   0.5388   2.9541   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0016   0.0088   1.6645   0.7971   0.5555\n",
      "***** Episode 12586, Mean R = -56.2  Std R = 13.7  Min R = -115.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.871\n",
      "KL: 0.000839\n",
      "PolicyEntropy: -0.272\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 7.47e+03\n",
      "TotalSteps: 2.76e+06\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.252\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7664   0.4453   2.3102   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0012   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 12617, Mean R = -62.1  Std R = 32.5  Min R = -223.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -0.279\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 7.3e+03\n",
      "TotalSteps: 2.77e+06\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.251\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7336   0.2700   1.6695   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0035   0.0185   1.6645   0.7971   0.5555\n",
      "***** Episode 12648, Mean R = -75.3  Std R = 50.8  Min R = -289.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.915\n",
      "KL: 0.000779\n",
      "PolicyEntropy: -0.278\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 7.89e+03\n",
      "TotalSteps: 2.77e+06\n",
      "ValFuncLoss: 0.00333\n",
      "Variance: 0.251\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2969   0.5035   2.7189   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0018   0.0088   1.6645   0.7971   0.5555\n",
      "***** Episode 12679, Mean R = -57.0  Std R = 22.2  Min R = -141.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.908\n",
      "KL: 0.000883\n",
      "PolicyEntropy: -0.289\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 7.44e+03\n",
      "TotalSteps: 2.78e+06\n",
      "ValFuncLoss: 0.00268\n",
      "Variance: 0.25\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5553   0.3029   1.4989   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0015   0.0076   1.6645   0.7971   0.5555\n",
      "Update Cnt = 410    ET =    170.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    12.8   -15.9     4.7 |    66.7    55.9    37.7 |  -191.1  -206.4    -2.8 |   214.0   149.0   389.8\n",
      "v_f      |  -14.40    1.61  -35.96 |    6.92    6.09   11.84 |  -32.80  -13.42  -72.50 |    4.68   17.08    4.06\n",
      "vr_f     |     2.5 |     1.2 |     0.6 |     8.7\n",
      "r_i      |   930.3    -3.7  2349.1 |   594.1   567.3    29.0 |     5.0  -994.6  2300.2 |  1996.9   996.4  2400.0\n",
      "v_i      |  -39.06    0.88  -79.88 |   16.77   17.38    5.65 |  -70.00  -29.98  -89.91 |  -10.02   29.85  -70.08\n",
      "norm_rf  |    79.0 |    56.5 |     3.2 |   409.6\n",
      "norm_vf  |   39.78 |   12.06 |    6.50 |   73.75\n",
      "thrust   |     954      23    8461 |    4171    4158    4009 |  -14041  -14846   -9768 |   14995   14938   15000\n",
      "norm_thrust |   10495 |    3621 |    2000 |   15000\n",
      "fuel     |     257 |      66 |     160 |     521\n",
      "rewards  |  -66.51 |   42.92 | -323.80 |  -35.66\n",
      "fuel_rewards |   -8.83 |    2.25 |  -17.88 |   -5.51\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.28 |    0.61 |    0.02 |    4.11\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   79.06 |   52.21 |   21.51 |  404.62\n",
      "tracking_rewards |  -57.68 |   41.03 | -305.92 |  -26.97\n",
      "steps    |     252 |      70 |     162 |     500\n",
      "***** Episode 12710, Mean R = -73.0  Std R = 53.3  Min R = -280.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.882\n",
      "KL: 0.000619\n",
      "PolicyEntropy: -0.297\n",
      "PolicyLoss: -0.00184\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 2.79e+06\n",
      "ValFuncLoss: 0.00381\n",
      "Variance: 0.249\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0328   0.3562   2.0616   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0016   0.0072   1.6645   0.7971   0.5555\n",
      "***** Episode 12741, Mean R = -73.3  Std R = 48.1  Min R = -257.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000904\n",
      "PolicyEntropy: -0.306\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 2.8e+06\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9055   0.3173   1.5943   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0017   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 12772, Mean R = -67.3  Std R = 37.7  Min R = -238.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000778\n",
      "PolicyEntropy: -0.318\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 7.80e+03\n",
      "TotalSteps: 2.81e+06\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6746   0.3498   1.9148   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0029   0.0145   1.6645   0.7971   0.5555\n",
      "***** Episode 12803, Mean R = -67.2  Std R = 32.4  Min R = -207.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.89\n",
      "ExplainedVarOld: 0.855\n",
      "KL: 0.0009\n",
      "PolicyEntropy: -0.323\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 2.81e+06\n",
      "ValFuncLoss: 0.00403\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9635   0.5766   3.0636   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0069   0.0037   0.0177   1.6645   0.7971   0.5555\n",
      "***** Episode 12834, Mean R = -56.4  Std R = 17.7  Min R = -127.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.907\n",
      "ExplainedVarOld: 0.895\n",
      "KL: 0.000759\n",
      "PolicyEntropy: -0.327\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 7.61e+03\n",
      "TotalSteps: 2.82e+06\n",
      "ValFuncLoss: 0.00243\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7565   0.3302   1.6175   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0044   0.0237   1.6645   0.7971   0.5555\n",
      "***** Episode 12865, Mean R = -65.0  Std R = 37.9  Min R = -243.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000731\n",
      "PolicyEntropy: -0.328\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 7.67e+03\n",
      "TotalSteps: 2.83e+06\n",
      "ValFuncLoss: 0.0024\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1379   0.6414   2.8932   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0061   0.0033   0.0159   1.6645   0.7971   0.5555\n",
      "***** Episode 12896, Mean R = -55.8  Std R = 11.4  Min R = -87.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.905\n",
      "KL: 0.000683\n",
      "PolicyEntropy: -0.326\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 7.57e+03\n",
      "TotalSteps: 2.84e+06\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4713   0.8743   4.1665   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0078   0.0030   0.0178   1.6645   0.7971   0.5555\n",
      "***** Episode 12927, Mean R = -61.2  Std R = 24.3  Min R = -163.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.905\n",
      "ExplainedVarOld: 0.872\n",
      "KL: 0.00116\n",
      "PolicyEntropy: -0.337\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 7.11e+03\n",
      "TotalSteps: 2.84e+06\n",
      "ValFuncLoss: 0.0024\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7008   0.2363   1.2825   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0023   0.0103   1.6645   0.7971   0.5555\n",
      "***** Episode 12958, Mean R = -72.2  Std R = 47.1  Min R = -200.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.927\n",
      "ExplainedVarOld: 0.885\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -0.344\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 2.85e+06\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.246\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0381   0.5662   3.0251   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0080   0.0042   0.0185   1.6645   0.7971   0.5555\n",
      "***** Episode 12989, Mean R = -54.1  Std R = 19.7  Min R = -149.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.895\n",
      "KL: 0.000719\n",
      "PolicyEntropy: -0.333\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 7.47e+03\n",
      "TotalSteps: 2.86e+06\n",
      "ValFuncLoss: 0.00081\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7806   0.2077   1.2577   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0049   0.0022   0.0094   1.6645   0.7971   0.5555\n",
      "Update Cnt = 420    ET =    169.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.8   -15.3     1.9 |    59.8    55.7    47.1 |  -169.4  -246.3    -2.5 |   190.1   184.1   829.6\n",
      "v_f      |  -13.94    1.52  -35.62 |    6.86    5.78   11.57 |  -32.43  -12.93  -63.66 |   19.58   20.49   17.45\n",
      "vr_f     |     2.7 |     1.8 |     0.2 |    25.0\n",
      "r_i      |   981.9     1.3  2351.5 |   574.9   576.8    28.1 |     0.1  -991.1  2300.2 |  1999.2   999.8  2399.7\n",
      "v_i      |  -39.09   -0.30  -80.25 |   16.84   17.89    5.82 |  -69.98  -29.88  -89.90 |  -10.31   29.86  -70.03\n",
      "norm_rf  |    74.4 |    64.7 |     2.8 |   886.1\n",
      "norm_vf  |   39.35 |   11.47 |    4.37 |   67.15\n",
      "thrust   |     955      69    8491 |    4089    4189    3950 |  -14377  -14989   -9286 |   14991   14889   15000\n",
      "norm_thrust |   10481 |    3610 |    2000 |   15000\n",
      "fuel     |     255 |      59 |     164 |     483\n",
      "rewards  |  -64.18 |   34.24 | -257.76 |  -34.03\n",
      "fuel_rewards |   -8.78 |    2.03 |  -16.58 |   -5.65\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.28 |    0.56 |    0.02 |    3.44\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   74.28 |   61.28 |   18.91 |  881.07\n",
      "tracking_rewards |  -55.40 |   32.64 | -242.28 |  -25.40\n",
      "steps    |     251 |      64 |     162 |     500\n",
      "***** Episode 13020, Mean R = -69.3  Std R = 37.9  Min R = -255.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -0.341\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 2.87e+06\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.246\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6043   0.3502   1.5986   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0069   0.0030   0.0124   1.6645   0.7971   0.5555\n",
      "***** Episode 13051, Mean R = -71.6  Std R = 57.6  Min R = -313.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.886\n",
      "KL: 0.000967\n",
      "PolicyEntropy: -0.351\n",
      "PolicyLoss: -0.00221\n",
      "Steps: 8.09e+03\n",
      "TotalSteps: 2.88e+06\n",
      "ValFuncLoss: 0.00269\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3936   1.1345   4.0428   5.7518   2.3325   1.5995\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0143   0.0074   0.0373   1.6645   0.7971   0.5555\n",
      "***** Episode 13082, Mean R = -82.8  Std R = 57.5  Min R = -254.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.891\n",
      "KL: 0.000629\n",
      "PolicyEntropy: -0.346\n",
      "PolicyLoss: -0.00211\n",
      "Steps: 8.74e+03\n",
      "TotalSteps: 2.88e+06\n",
      "ValFuncLoss: 0.00359\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8093   2.3200   6.1234   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0080   0.0028   0.0138   1.6645   0.7971   0.5555\n",
      "***** Episode 13113, Mean R = -78.6  Std R = 57.9  Min R = -286.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000598\n",
      "PolicyEntropy: -0.35\n",
      "PolicyLoss: -0.00215\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 2.89e+06\n",
      "ValFuncLoss: 0.00319\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4181   0.7818   3.0209   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0014   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 13144, Mean R = -66.7  Std R = 37.6  Min R = -220.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000679\n",
      "PolicyEntropy: -0.346\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 7.74e+03\n",
      "TotalSteps: 2.9e+06\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7117   0.2800   1.5464   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0069   0.0037   0.0183   1.6645   0.7971   0.5555\n",
      "***** Episode 13175, Mean R = -66.3  Std R = 41.2  Min R = -249.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.000807\n",
      "PolicyEntropy: -0.352\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 2.91e+06\n",
      "ValFuncLoss: 0.00162\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9947   0.3689   1.7799   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0112   0.0057   0.0250   1.6645   0.7971   0.5555\n",
      "***** Episode 13206, Mean R = -65.6  Std R = 30.4  Min R = -167.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.908\n",
      "KL: 0.000843\n",
      "PolicyEntropy: -0.354\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 2.92e+06\n",
      "ValFuncLoss: 0.00156\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9848   0.7999   4.0556   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0038   0.0146   1.6645   0.7971   0.5555\n",
      "***** Episode 13237, Mean R = -69.9  Std R = 44.6  Min R = -275.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.893\n",
      "ExplainedVarOld: 0.856\n",
      "KL: 0.000666\n",
      "PolicyEntropy: -0.347\n",
      "PolicyLoss: -0.00186\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 2.93e+06\n",
      "ValFuncLoss: 0.00301\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8656   0.2971   1.4766   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0067   0.0030   0.0131   1.6645   0.7971   0.5555\n",
      "***** Episode 13268, Mean R = -53.8  Std R = 13.7  Min R = -91.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.000835\n",
      "PolicyEntropy: -0.348\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 7.18e+03\n",
      "TotalSteps: 2.93e+06\n",
      "ValFuncLoss: 0.0024\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7714   0.2373   1.5532   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0012   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 13299, Mean R = -55.8  Std R = 16.1  Min R = -118.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.909\n",
      "ExplainedVarOld: 0.873\n",
      "KL: 0.00088\n",
      "PolicyEntropy: -0.359\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 7.39e+03\n",
      "TotalSteps: 2.94e+06\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8434   0.4502   2.2600   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0036   0.0174   1.6645   0.7971   0.5555\n",
      "Update Cnt = 430    ET =    175.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.1   -15.0     4.4 |    65.8    56.6    38.3 |  -254.1  -195.2    -2.5 |   236.1   145.9   429.4\n",
      "v_f      |  -13.40    1.69  -34.53 |    6.63    5.53   11.69 |  -29.21  -11.73  -74.92 |    3.46   18.94   -2.71\n",
      "vr_f     |     2.6 |     1.3 |     0.3 |    11.2\n",
      "r_i      |  1024.8   -12.8  2349.4 |   573.1   574.6    30.7 |     9.5  -991.5  2300.1 |  1998.7   997.4  2399.7\n",
      "v_i      |  -40.61   -0.72  -80.38 |   18.00   17.27    5.66 |  -69.80  -29.80  -89.94 |  -10.02   29.66  -70.01\n",
      "norm_rf  |    78.8 |    57.7 |     3.8 |   461.4\n",
      "norm_vf  |   37.94 |   12.11 |    6.02 |   76.34\n",
      "thrust   |     986      78    8439 |    4005    4153    3991 |  -13833  -14889   -7787 |   15000   14931   15000\n",
      "norm_thrust |   10409 |    3615 |    2000 |   15000\n",
      "fuel     |     263 |      68 |     161 |     510\n",
      "rewards  |  -69.40 |   46.49 | -313.08 |  -30.78\n",
      "fuel_rewards |   -9.05 |    2.33 |  -17.52 |   -5.55\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.18 |    0.54 |    0.02 |    2.91\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   78.42 |   53.72 |   18.02 |  456.40\n",
      "tracking_rewards |  -60.35 |   44.51 | -295.56 |  -22.46\n",
      "steps    |     260 |      74 |     152 |     500\n",
      "***** Episode 13330, Mean R = -83.0  Std R = 65.2  Min R = -277.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000647\n",
      "PolicyEntropy: -0.36\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 2.95e+06\n",
      "ValFuncLoss: 0.00396\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8872   0.3830   1.7368   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0016   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 13361, Mean R = -58.8  Std R = 21.1  Min R = -143.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.000833\n",
      "PolicyEntropy: -0.361\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 7.79e+03\n",
      "TotalSteps: 2.96e+06\n",
      "ValFuncLoss: 0.00171\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7038   0.2008   1.2029   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 13392, Mean R = -55.2  Std R = 13.6  Min R = -105.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.904\n",
      "ExplainedVarOld: 0.883\n",
      "KL: 0.00077\n",
      "PolicyEntropy: -0.363\n",
      "PolicyLoss: -0.00355\n",
      "Steps: 7.63e+03\n",
      "TotalSteps: 2.96e+06\n",
      "ValFuncLoss: 0.00165\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0488   0.5384   2.6640   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0172   0.0075   0.0320   1.6645   0.7971   0.5555\n",
      "***** Episode 13423, Mean R = -63.7  Std R = 35.7  Min R = -197.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.884\n",
      "ExplainedVarOld: 0.763\n",
      "KL: 0.000624\n",
      "PolicyEntropy: -0.355\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 7.56e+03\n",
      "TotalSteps: 2.97e+06\n",
      "ValFuncLoss: 0.00442\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7638   0.3391   1.9166   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0084   0.0038   0.0149   1.6645   0.7971   0.5555\n",
      "***** Episode 13454, Mean R = -74.4  Std R = 59.0  Min R = -286.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -0.352\n",
      "PolicyLoss: -0.00242\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 2.98e+06\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.249\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8431   0.5260   2.7714   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0024   0.0104   1.6645   0.7971   0.5555\n",
      "***** Episode 13485, Mean R = -65.6  Std R = 29.0  Min R = -170.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.866\n",
      "ExplainedVarOld: 0.833\n",
      "KL: 0.000647\n",
      "PolicyEntropy: -0.348\n",
      "PolicyLoss: -0.00214\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 2.99e+06\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.249\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6332   0.3140   1.7766   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0027   0.0133   1.6645   0.7971   0.5555\n",
      "***** Episode 13516, Mean R = -66.7  Std R = 47.3  Min R = -257.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.906\n",
      "ExplainedVarOld: 0.879\n",
      "KL: 0.000837\n",
      "PolicyEntropy: -0.345\n",
      "PolicyLoss: -0.00205\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 3e+06\n",
      "ValFuncLoss: 0.00376\n",
      "Variance: 0.249\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5837   0.2321   1.1969   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0013   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 13547, Mean R = -67.6  Std R = 50.1  Min R = -254.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000743\n",
      "PolicyEntropy: -0.348\n",
      "PolicyLoss: -0.00211\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 3e+06\n",
      "ValFuncLoss: 0.00297\n",
      "Variance: 0.249\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5218   0.2417   1.3435   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0098   0.0042   0.0195   1.6645   0.7971   0.5555\n",
      "***** Episode 13578, Mean R = -79.4  Std R = 57.9  Min R = -258.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.89\n",
      "KL: 0.000732\n",
      "PolicyEntropy: -0.359\n",
      "PolicyLoss: -0.00173\n",
      "Steps: 9.16e+03\n",
      "TotalSteps: 3.01e+06\n",
      "ValFuncLoss: 0.00262\n",
      "Variance: 0.248\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7983   0.2512   1.2468   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0016   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 13609, Mean R = -63.5  Std R = 26.9  Min R = -145.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.000597\n",
      "PolicyEntropy: -0.36\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 7.73e+03\n",
      "TotalSteps: 3.02e+06\n",
      "ValFuncLoss: 0.00169\n",
      "Variance: 0.247\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6661   0.3262   1.5476   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0073   0.0025   0.0128   1.6645   0.7971   0.5555\n",
      "Update Cnt = 440    ET =    175.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    22.3   -13.7     4.2 |    63.5    62.2    56.3 |  -178.6  -215.9    -2.8 |   255.7   158.2   714.0\n",
      "v_f      |  -13.23    1.85  -33.31 |    7.52    5.41   11.54 |  -29.45  -20.81  -59.41 |   53.42   16.50   32.49\n",
      "vr_f     |     2.6 |     2.2 |     0.3 |    35.5\n",
      "r_i      |   996.6   -23.0  2349.4 |   574.9   607.7    30.0 |     3.8  -989.5  2300.2 |  1986.9   996.2  2399.6\n",
      "v_i      |  -38.34   -0.67  -79.69 |   17.72   17.33    5.88 |  -69.94  -29.59  -89.88 |  -10.30   29.67  -70.02\n",
      "norm_rf  |    82.2 |    70.8 |     6.9 |   735.9\n",
      "norm_vf  |   37.17 |   11.21 |    3.82 |   65.90\n",
      "thrust   |     924      94    8529 |    3969    4127    3981 |  -13764  -14910   -8378 |   14960   14767   14999\n",
      "norm_thrust |   10446 |    3621 |    2000 |   15000\n",
      "fuel     |     264 |      64 |     170 |     520\n",
      "rewards  |  -65.87 |   41.56 | -286.35 |  -32.83\n",
      "fuel_rewards |   -9.07 |    2.19 |  -17.86 |   -5.86\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.22 |    0.57 |    0.02 |    3.13\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   80.76 |   68.26 |   19.17 |  730.92\n",
      "tracking_rewards |  -56.80 |   39.71 | -269.58 |  -23.63\n",
      "steps    |     260 |      69 |     159 |     500\n",
      "***** Episode 13640, Mean R = -63.9  Std R = 42.3  Min R = -221.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.822\n",
      "KL: 0.000625\n",
      "PolicyEntropy: -0.36\n",
      "PolicyLoss: -0.00169\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 3.03e+06\n",
      "ValFuncLoss: 0.00323\n",
      "Variance: 0.245\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2400   0.8578   4.2126   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0078   0.0043   0.0196   1.6645   0.7971   0.5555\n",
      "***** Episode 13671, Mean R = -57.7  Std R = 16.7  Min R = -106.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.905\n",
      "ExplainedVarOld: 0.874\n",
      "KL: 0.000708\n",
      "PolicyEntropy: -0.363\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 7.8e+03\n",
      "TotalSteps: 3.04e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.246\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2532   0.8538   3.3105   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0027   0.0138   1.6645   0.7971   0.5555\n",
      "***** Episode 13702, Mean R = -78.6  Std R = 57.2  Min R = -291.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.00057\n",
      "PolicyEntropy: -0.37\n",
      "PolicyLoss: -0.00199\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 3.05e+06\n",
      "ValFuncLoss: 0.00301\n",
      "Variance: 0.245\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7080   0.3370   1.5014   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0070   0.0038   0.0162   1.6645   0.7971   0.5555\n",
      "***** Episode 13733, Mean R = -63.8  Std R = 44.5  Min R = -291.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.91\n",
      "ExplainedVarOld: 0.866\n",
      "KL: 0.000716\n",
      "PolicyEntropy: -0.388\n",
      "PolicyLoss: -0.00216\n",
      "Steps: 7.64e+03\n",
      "TotalSteps: 3.05e+06\n",
      "ValFuncLoss: 0.00447\n",
      "Variance: 0.244\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8180   0.2429   1.2968   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0072   0.0039   0.0203   1.6645   0.7971   0.5555\n",
      "***** Episode 13764, Mean R = -59.7  Std R = 26.3  Min R = -170.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.868\n",
      "ExplainedVarOld: 0.824\n",
      "KL: 0.000846\n",
      "PolicyEntropy: -0.399\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 3.06e+06\n",
      "ValFuncLoss: 0.00377\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7197   0.3416   1.4864   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0094   0.0044   0.0199   1.6645   0.7971   0.5555\n",
      "***** Episode 13795, Mean R = -60.1  Std R = 39.8  Min R = -273.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.864\n",
      "KL: 0.000705\n",
      "PolicyEntropy: -0.394\n",
      "PolicyLoss: -0.00151\n",
      "Steps: 7.75e+03\n",
      "TotalSteps: 3.07e+06\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9120   0.4852   2.0998   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0013   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 13826, Mean R = -66.4  Std R = 39.1  Min R = -211.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -0.397\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 3.08e+06\n",
      "ValFuncLoss: 0.00191\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1481   0.4436   1.9093   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0120   0.0047   0.0205   1.6645   0.7971   0.5555\n",
      "***** Episode 13857, Mean R = -76.1  Std R = 47.6  Min R = -247.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.000594\n",
      "PolicyEntropy: -0.393\n",
      "PolicyLoss: -0.00203\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 3.08e+06\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7105   0.2883   1.5176   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0031   0.0144   1.6645   0.7971   0.5555\n",
      "***** Episode 13888, Mean R = -62.3  Std R = 38.2  Min R = -242.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -0.404\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 7.83e+03\n",
      "TotalSteps: 3.09e+06\n",
      "ValFuncLoss: 0.00166\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7280   0.2945   1.4466   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 13919, Mean R = -56.1  Std R = 10.6  Min R = -91.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.911\n",
      "ExplainedVarOld: 0.882\n",
      "KL: 0.000627\n",
      "PolicyEntropy: -0.396\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 7.65e+03\n",
      "TotalSteps: 3.1e+06\n",
      "ValFuncLoss: 0.00122\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7492   0.2867   1.4145   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0078   0.0049   0.0219   1.6645   0.7971   0.5555\n",
      "Update Cnt = 450    ET =    172.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.3   -10.5     1.3 |    63.1    65.8    22.8 |  -176.9  -305.5    -3.2 |   228.5   166.4   304.6\n",
      "v_f      |  -12.77    1.70  -34.62 |    6.48    6.22   10.58 |  -29.08  -20.12  -70.05 |   12.70   21.66   -3.98\n",
      "vr_f     |     2.8 |     1.7 |     0.3 |    12.6\n",
      "r_i      |   964.9     1.0  2350.6 |   565.5   570.3    28.9 |     8.8  -999.6  2300.2 |  1995.5   987.7  2399.3\n",
      "v_i      |  -39.40    1.50  -79.94 |   17.38   17.03    6.06 |  -69.97  -29.95  -89.94 |  -10.67   29.87  -70.02\n",
      "norm_rf  |    79.7 |    54.7 |     3.1 |   324.6\n",
      "norm_vf  |   38.05 |   10.46 |   14.01 |   71.31\n",
      "thrust   |     985       0    8496 |    4025    4136    3979 |  -13966  -14925   -9086 |   14978   14833   14999\n",
      "norm_thrust |   10452 |    3613 |    2000 |   15000\n",
      "fuel     |     260 |      57 |     159 |     497\n",
      "rewards  |  -64.76 |   37.95 | -291.33 |  -28.80\n",
      "fuel_rewards |   -8.94 |    1.96 |  -17.05 |   -5.47\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.24 |    0.57 |    0.02 |    3.27\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   78.63 |   51.18 |   13.43 |  319.65\n",
      "tracking_rewards |  -55.82 |   36.38 | -274.68 |  -20.47\n",
      "steps    |     256 |      62 |     154 |     500\n",
      "***** Episode 13950, Mean R = -66.7  Std R = 26.8  Min R = -155.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.864\n",
      "KL: 0.000732\n",
      "PolicyEntropy: -0.393\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 3.11e+06\n",
      "ValFuncLoss: 0.00129\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6122   0.2160   1.1988   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0016   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 13981, Mean R = -60.2  Std R = 21.5  Min R = -153.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.89\n",
      "KL: 0.000742\n",
      "PolicyEntropy: -0.398\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 3.12e+06\n",
      "ValFuncLoss: 0.00145\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2617   0.9478   4.6644   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0007   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 14012, Mean R = -56.5  Std R = 8.6  Min R = -77.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.907\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.000758\n",
      "PolicyEntropy: -0.398\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 7.34e+03\n",
      "TotalSteps: 3.12e+06\n",
      "ValFuncLoss: 0.0011\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0964   0.5109   1.9447   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 14043, Mean R = -54.9  Std R = 9.9  Min R = -79.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.891\n",
      "ExplainedVarOld: 0.877\n",
      "KL: 0.00106\n",
      "PolicyEntropy: -0.396\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 7.55e+03\n",
      "TotalSteps: 3.13e+06\n",
      "ValFuncLoss: 0.000862\n",
      "Variance: 0.243\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2116   0.5677   2.8171   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0017   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 14074, Mean R = -61.9  Std R = 23.5  Min R = -136.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.909\n",
      "ExplainedVarOld: 0.895\n",
      "KL: 0.000869\n",
      "PolicyEntropy: -0.404\n",
      "PolicyLoss: -0.00345\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 3.14e+06\n",
      "ValFuncLoss: 0.000935\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9179   0.2960   1.6297   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 14105, Mean R = -55.9  Std R = 14.3  Min R = -100.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.893\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -0.406\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 7.7e+03\n",
      "TotalSteps: 3.15e+06\n",
      "ValFuncLoss: 0.000858\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7634   0.2910   1.4099   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0012   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 14136, Mean R = -66.2  Std R = 52.6  Min R = -303.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.00071\n",
      "PolicyEntropy: -0.409\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 7.94e+03\n",
      "TotalSteps: 3.16e+06\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9643   0.3424   1.6026   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0066   0.0034   0.0167   1.6645   0.7971   0.5555\n",
      "***** Episode 14167, Mean R = -70.3  Std R = 46.6  Min R = -225.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.000829\n",
      "PolicyEntropy: -0.413\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 3.16e+06\n",
      "ValFuncLoss: 0.00189\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9978   0.3247   1.6003   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0008   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 14198, Mean R = -64.8  Std R = 37.7  Min R = -217.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.00106\n",
      "PolicyEntropy: -0.429\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 3.17e+06\n",
      "ValFuncLoss: 0.00146\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1903   0.5228   3.1356   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0011   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 14229, Mean R = -58.8  Std R = 25.9  Min R = -170.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -0.436\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 7.49e+03\n",
      "TotalSteps: 3.18e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7516   0.2648   1.5320   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0016   0.0068   1.6645   0.7971   0.5555\n",
      "Update Cnt = 460    ET =    172.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.8    -5.6    -0.1 |    58.4    61.2    12.5 |  -127.9  -202.5    -2.4 |   181.7   144.7   219.4\n",
      "v_f      |  -12.38    0.75  -33.53 |    6.04    6.07   10.68 |  -28.39  -16.90  -62.69 |    6.87   19.80   -2.72\n",
      "vr_f     |     2.7 |     1.3 |     0.2 |    11.7\n",
      "r_i      |   977.1    -3.1  2351.2 |   552.5   581.8    28.5 |    24.9  -988.5  2301.0 |  1997.6   993.2  2399.5\n",
      "v_i      |  -38.90    0.27  -79.81 |   17.65   17.40    5.88 |  -69.97  -29.84  -89.96 |  -10.43   29.63  -70.02\n",
      "norm_rf  |    77.8 |    43.0 |     2.4 |   234.6\n",
      "norm_vf  |   36.66 |   11.02 |    8.69 |   65.61\n",
      "thrust   |     990      25    8560 |    3977    4167    3933 |  -13756  -14862   -8702 |   14998   14883   15000\n",
      "norm_thrust |   10487 |    3596 |    2000 |   15000\n",
      "fuel     |     260 |      53 |     162 |     532\n",
      "rewards  |  -61.50 |   30.84 | -303.65 |  -31.49\n",
      "fuel_rewards |   -8.94 |    1.83 |  -18.26 |   -5.58\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.22 |    0.51 |    0.02 |    3.23\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   75.54 |   40.00 |   19.60 |  229.59\n",
      "tracking_rewards |  -52.56 |   29.43 | -285.39 |  -22.95\n",
      "steps    |     255 |      57 |     158 |     500\n",
      "***** Episode 14260, Mean R = -65.7  Std R = 29.2  Min R = -150.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.927\n",
      "ExplainedVarOld: 0.888\n",
      "KL: 0.000886\n",
      "PolicyEntropy: -0.451\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 3.19e+06\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0111   0.3937   1.9484   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0020   0.0085   1.6645   0.7971   0.5555\n",
      "***** Episode 14291, Mean R = -55.0  Std R = 21.2  Min R = -138.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.912\n",
      "KL: 0.000679\n",
      "PolicyEntropy: -0.447\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 7.84e+03\n",
      "TotalSteps: 3.2e+06\n",
      "ValFuncLoss: 0.00134\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3055   0.4805   2.5925   6.1234   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0015   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 14322, Mean R = -53.9  Std R = 18.3  Min R = -135.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.000888\n",
      "PolicyEntropy: -0.442\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 7.49e+03\n",
      "TotalSteps: 3.2e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5103   1.7789   6.2114   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0047   0.0188   1.6645   0.7971   0.5555\n",
      "***** Episode 14353, Mean R = -76.6  Std R = 45.1  Min R = -223.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000796\n",
      "PolicyEntropy: -0.451\n",
      "PolicyLoss: -0.0022\n",
      "Steps: 8.89e+03\n",
      "TotalSteps: 3.21e+06\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.239\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2137   0.3120   1.8933   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0015   0.0069   1.6645   0.7971   0.5555\n",
      "***** Episode 14384, Mean R = -59.3  Std R = 18.7  Min R = -110.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.892\n",
      "ExplainedVarOld: 0.875\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -0.46\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 3.22e+06\n",
      "ValFuncLoss: 0.00147\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3514   0.5825   2.3363   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0034   0.0150   1.6645   0.7971   0.5555\n",
      "***** Episode 14415, Mean R = -48.7  Std R = 8.1  Min R = -68.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.9\n",
      "ExplainedVarOld: 0.887\n",
      "KL: 0.00079\n",
      "PolicyEntropy: -0.459\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 7.9e+03\n",
      "TotalSteps: 3.23e+06\n",
      "ValFuncLoss: 0.00103\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0315   0.6083   2.4954   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0082   0.0055   0.0246   1.6645   0.7971   0.5555\n",
      "***** Episode 14446, Mean R = -74.6  Std R = 52.0  Min R = -253.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000556\n",
      "PolicyEntropy: -0.459\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 8.87e+03\n",
      "TotalSteps: 3.24e+06\n",
      "ValFuncLoss: 0.00189\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6938   1.0391   3.9202   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0014   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 14477, Mean R = -68.1  Std R = 49.1  Min R = -277.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000962\n",
      "PolicyEntropy: -0.465\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.09e+03\n",
      "TotalSteps: 3.24e+06\n",
      "ValFuncLoss: 0.00165\n",
      "Variance: 0.239\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4490   0.6573   3.1867   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0022   0.0100   1.6645   0.7971   0.5555\n",
      "***** Episode 14508, Mean R = -57.3  Std R = 25.7  Min R = -152.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -0.476\n",
      "PolicyLoss: -0.00369\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 3.25e+06\n",
      "ValFuncLoss: 0.000878\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6771   0.3025   1.7103   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0005   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 14539, Mean R = -52.0  Std R = 16.9  Min R = -125.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.907\n",
      "KL: 0.000743\n",
      "PolicyEntropy: -0.488\n",
      "PolicyLoss: -0.0025\n",
      "Steps: 7.53e+03\n",
      "TotalSteps: 3.26e+06\n",
      "ValFuncLoss: 0.000697\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1739   0.4191   2.0211   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0015   0.0079   1.6645   0.7971   0.5555\n",
      "Update Cnt = 470    ET =    175.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.5    -5.5    -0.5 |    55.0    52.0     4.8 |  -206.5  -169.3    -2.2 |   191.9   133.2    84.2\n",
      "v_f      |  -11.78    1.91  -31.46 |    5.69    5.00    9.34 |  -28.38  -13.48  -52.35 |    2.48   12.72   -2.17\n",
      "vr_f     |     2.8 |     1.5 |     0.6 |    12.0\n",
      "r_i      |  1034.3   -47.8  2348.2 |   585.2   560.1    28.7 |     7.0  -994.4  2300.2 |  1993.3   995.6  2399.9\n",
      "v_i      |  -38.92   -0.37  -79.24 |   16.84   17.39    5.61 |  -69.84  -29.99  -89.95 |  -10.02   29.62  -70.10\n",
      "norm_rf  |    69.1 |    39.5 |     6.9 |   242.5\n",
      "norm_vf  |   34.42 |    9.57 |    2.83 |   54.83\n",
      "thrust   |     997      85    8554 |    3889    4023    3925 |  -13188  -14881  -11073 |   14995   14853   14999\n",
      "norm_thrust |   10393 |    3590 |    2000 |   15000\n",
      "fuel     |     265 |      54 |     183 |     517\n",
      "rewards  |  -60.86 |   34.34 | -276.96 |  -31.67\n",
      "fuel_rewards |   -9.10 |    1.87 |  -17.74 |   -6.29\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.22 |    0.58 |    0.02 |    3.27\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   66.97 |   36.72 |   13.90 |  237.46\n",
      "tracking_rewards |  -51.76 |   32.80 | -259.49 |  -22.73\n",
      "steps    |     262 |      58 |     170 |     500\n",
      "***** Episode 14570, Mean R = -63.0  Std R = 41.0  Min R = -240.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.000826\n",
      "PolicyEntropy: -0.481\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 3.27e+06\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9257   0.2648   1.3618   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0012   0.0053   1.6645   0.7971   0.5555\n",
      "***** Episode 14601, Mean R = -53.1  Std R = 18.7  Min R = -132.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.878\n",
      "KL: 0.00082\n",
      "PolicyEntropy: -0.487\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 7.87e+03\n",
      "TotalSteps: 3.28e+06\n",
      "ValFuncLoss: 0.000821\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3780   0.6195   2.8754   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0024   0.0109   1.6645   0.7971   0.5555\n",
      "***** Episode 14632, Mean R = -52.7  Std R = 20.2  Min R = -116.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.9\n",
      "ExplainedVarOld: 0.885\n",
      "KL: 0.00088\n",
      "PolicyEntropy: -0.488\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 7.7e+03\n",
      "TotalSteps: 3.28e+06\n",
      "ValFuncLoss: 0.00091\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4934   0.6908   2.8077   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0111   0.0053   0.0216   1.6645   0.7971   0.5555\n",
      "***** Episode 14663, Mean R = -73.3  Std R = 48.1  Min R = -291.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.897\n",
      "KL: 0.000719\n",
      "PolicyEntropy: -0.481\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 3.29e+06\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6113   0.9620   3.8853   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0025   0.0116   1.6645   0.7971   0.5555\n",
      "***** Episode 14694, Mean R = -81.0  Std R = 58.4  Min R = -224.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.000764\n",
      "PolicyEntropy: -0.479\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 8.73e+03\n",
      "TotalSteps: 3.3e+06\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9917   0.3973   2.2110   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0017   0.0090   1.6645   0.7971   0.5555\n",
      "***** Episode 14725, Mean R = -70.1  Std R = 47.7  Min R = -188.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000787\n",
      "PolicyEntropy: -0.478\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 3.31e+06\n",
      "ValFuncLoss: 0.00178\n",
      "Variance: 0.239\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7538   0.5626   2.9910   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0054   0.0033   0.0160   1.6645   0.7971   0.5555\n",
      "***** Episode 14756, Mean R = -66.3  Std R = 37.3  Min R = -174.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.9\n",
      "ExplainedVarOld: 0.833\n",
      "KL: 0.000784\n",
      "PolicyEntropy: -0.482\n",
      "PolicyLoss: -0.00241\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 3.32e+06\n",
      "ValFuncLoss: 0.00253\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9348   1.3917   4.9653   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0015   0.0081   1.6645   0.7971   0.5555\n",
      "***** Episode 14787, Mean R = -61.2  Std R = 31.9  Min R = -200.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.895\n",
      "KL: 0.000798\n",
      "PolicyEntropy: -0.493\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 7.54e+03\n",
      "TotalSteps: 3.33e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8839   0.4463   2.4424   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0018   0.0080   1.6645   0.7971   0.5555\n",
      "***** Episode 14818, Mean R = -65.7  Std R = 42.0  Min R = -241.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -0.505\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 3.33e+06\n",
      "ValFuncLoss: 0.00111\n",
      "Variance: 0.239\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0337   0.4894   2.5147   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0016   0.0082   1.6645   0.7971   0.5555\n",
      "***** Episode 14849, Mean R = -64.2  Std R = 45.2  Min R = -258.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.000753\n",
      "PolicyEntropy: -0.491\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 3.34e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.239\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9946   0.2931   1.7077   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "Update Cnt = 480    ET =    176.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.3   -16.1     1.1 |    60.1    55.2    32.5 |  -158.4  -299.9    -2.1 |   213.8   148.0   572.3\n",
      "v_f      |  -10.44    1.79  -30.45 |    6.29    6.38   10.18 |  -26.22  -23.16  -53.84 |   28.48   33.30   29.85\n",
      "vr_f     |     2.9 |     1.7 |     0.5 |    12.2\n",
      "r_i      |   951.8   -41.1  2348.2 |   567.0   575.1    29.4 |     2.6  -999.4  2300.1 |  1991.6   998.3  2400.0\n",
      "v_i      |  -41.80   -0.73  -80.25 |   17.93   17.14    5.70 |  -69.81  -29.98  -89.98 |  -10.23   29.77  -70.09\n",
      "norm_rf  |    75.4 |    53.2 |     3.9 |   646.4\n",
      "norm_vf  |   33.57 |    9.82 |    7.59 |   59.91\n",
      "thrust   |    1150      82    8620 |    4006    4114    3939 |  -13335  -14716  -10905 |   14995   14823   15000\n",
      "norm_thrust |   10542 |    3605 |    2000 |   15000\n",
      "fuel     |     268 |      58 |     181 |     503\n",
      "rewards  |  -65.06 |   40.49 | -291.57 |  -31.29\n",
      "fuel_rewards |   -9.21 |    2.00 |  -17.28 |   -6.22\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.17 |    0.59 |    0.02 |    3.48\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   73.81 |   50.16 |    9.55 |  641.44\n",
      "tracking_rewards |  -55.85 |   38.75 | -274.70 |  -22.93\n",
      "steps    |     262 |      59 |     172 |     487\n",
      "***** Episode 14880, Mean R = -63.0  Std R = 27.5  Min R = -151.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000741\n",
      "PolicyEntropy: -0.478\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 7.96e+03\n",
      "TotalSteps: 3.35e+06\n",
      "ValFuncLoss: 0.0018\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0230   0.4188   2.1636   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0010   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 14911, Mean R = -63.9  Std R = 33.7  Min R = -196.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.922\n",
      "ExplainedVarOld: 0.894\n",
      "KL: 0.000871\n",
      "PolicyEntropy: -0.486\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 3.36e+06\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7957   0.5364   2.8742   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0026   0.0119   1.6645   0.7971   0.5555\n",
      "***** Episode 14942, Mean R = -67.2  Std R = 50.7  Min R = -248.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.887\n",
      "KL: 0.00086\n",
      "PolicyEntropy: -0.497\n",
      "PolicyLoss: -0.00205\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 3.37e+06\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2244   1.5760   5.1341   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0020   0.0086   1.6645   0.7971   0.5555\n",
      "***** Episode 14973, Mean R = -55.8  Std R = 24.5  Min R = -153.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.876\n",
      "KL: 0.000876\n",
      "PolicyEntropy: -0.5\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 7.65e+03\n",
      "TotalSteps: 3.37e+06\n",
      "ValFuncLoss: 0.00214\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8915   1.2675   4.9733   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0070   0.0037   0.0173   1.6645   0.7971   0.5555\n",
      "***** Episode 15004, Mean R = -56.8  Std R = 23.7  Min R = -141.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.885\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -0.503\n",
      "PolicyLoss: -0.00213\n",
      "Steps: 7.96e+03\n",
      "TotalSteps: 3.38e+06\n",
      "ValFuncLoss: 0.00227\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7281   0.3814   1.6226   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0023   0.0089   1.6645   0.7971   0.5555\n",
      "***** Episode 15035, Mean R = -60.3  Std R = 25.6  Min R = -127.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.904\n",
      "ExplainedVarOld: 0.874\n",
      "KL: 0.000879\n",
      "PolicyEntropy: -0.503\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 3.39e+06\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9646   0.2970   1.9960   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0013   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 15066, Mean R = -52.6  Std R = 17.0  Min R = -118.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.89\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -0.502\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 7.69e+03\n",
      "TotalSteps: 3.4e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9064   1.0134   4.6086   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0054   0.0250   1.6645   0.7971   0.5555\n",
      "***** Episode 15097, Mean R = -66.8  Std R = 37.1  Min R = -185.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000772\n",
      "PolicyEntropy: -0.508\n",
      "PolicyLoss: -0.00325\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 3.41e+06\n",
      "ValFuncLoss: 0.00225\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2388   0.4722   2.0831   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0048   0.0226   1.6645   0.7971   0.5555\n",
      "***** Episode 15128, Mean R = -68.2  Std R = 40.1  Min R = -220.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.000655\n",
      "PolicyEntropy: -0.495\n",
      "PolicyLoss: -0.00228\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 3.41e+06\n",
      "ValFuncLoss: 0.00305\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2696   0.5152   2.8168   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0046   0.0022   0.0106   1.6645   0.7971   0.5555\n",
      "***** Episode 15159, Mean R = -65.9  Std R = 33.4  Min R = -183.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.91\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -0.494\n",
      "PolicyLoss: -0.00233\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 3.42e+06\n",
      "ValFuncLoss: 0.00288\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8546   0.3256   1.8328   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0017   0.0081   1.6645   0.7971   0.5555\n",
      "Update Cnt = 490    ET =    173.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    24.5   -16.8    -0.7 |    65.4    57.0     0.7 |  -158.7  -200.4    -2.1 |   193.6   178.9     5.7\n",
      "v_f      |  -10.73    1.60  -30.98 |    6.13    5.25    8.91 |  -25.26  -14.36  -54.70 |   11.17   20.79   -2.91\n",
      "vr_f     |     3.0 |     2.5 |     0.5 |    32.1\n",
      "r_i      |   985.0   -11.7  2350.4 |   585.0   591.5    28.5 |    26.6  -994.3  2300.8 |  1986.6   997.6  2398.9\n",
      "v_i      |  -39.31    0.68  -80.04 |   17.60   16.91    5.57 |  -69.78  -29.99  -90.00 |  -10.02   29.54  -70.07\n",
      "norm_rf  |    79.3 |    45.9 |     3.9 |   214.1\n",
      "norm_vf  |   33.70 |    9.28 |    6.07 |   56.08\n",
      "thrust   |    1048      18    8618 |    3963    4073    3933 |  -13306  -14910   -8913 |   14995   14934   15000\n",
      "norm_thrust |   10500 |    3591 |    2000 |   15000\n",
      "fuel     |     264 |      51 |     177 |     523\n",
      "rewards  |  -61.03 |   32.58 | -248.59 |  -28.65\n",
      "fuel_rewards |   -9.08 |    1.74 |  -17.94 |   -6.09\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.18 |    0.53 |    0.01 |    3.22\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   77.06 |   42.80 |   21.16 |  209.07\n",
      "tracking_rewards |  -51.95 |   31.13 | -230.80 |  -19.92\n",
      "steps    |     259 |      53 |     164 |     500\n",
      "***** Episode 15190, Mean R = -52.9  Std R = 19.0  Min R = -121.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.849\n",
      "KL: 0.000838\n",
      "PolicyEntropy: -0.483\n",
      "PolicyLoss: -0.0024\n",
      "Steps: 7.5e+03\n",
      "TotalSteps: 3.43e+06\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1455   0.7456   3.0217   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0008   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 15221, Mean R = -67.2  Std R = 41.1  Min R = -226.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000824\n",
      "PolicyEntropy: -0.494\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 3.44e+06\n",
      "ValFuncLoss: 0.00349\n",
      "Variance: 0.241\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7314   1.2169   4.8286   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0029   0.0139   1.6645   0.7971   0.5555\n",
      "***** Episode 15252, Mean R = -62.4  Std R = 26.4  Min R = -155.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.00106\n",
      "PolicyEntropy: -0.507\n",
      "PolicyLoss: -0.00348\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 3.45e+06\n",
      "ValFuncLoss: 0.00235\n",
      "Variance: 0.242\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2034   0.6098   3.6393   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0069   0.0030   0.0124   1.6645   0.7971   0.5555\n",
      "***** Episode 15283, Mean R = -62.8  Std R = 36.8  Min R = -193.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000811\n",
      "PolicyEntropy: -0.508\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 3.45e+06\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.24\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3246   0.5660   2.6323   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0008   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 15314, Mean R = -67.0  Std R = 47.9  Min R = -246.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.000797\n",
      "PolicyEntropy: -0.503\n",
      "PolicyLoss: -0.00235\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 3.46e+06\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.239\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8738   0.2692   1.5437   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0010   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 15345, Mean R = -65.3  Std R = 42.3  Min R = -209.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000681\n",
      "PolicyEntropy: -0.503\n",
      "PolicyLoss: -0.00347\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 3.47e+06\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9949   0.4597   2.3073   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0016   0.0082   1.6645   0.7971   0.5555\n",
      "***** Episode 15376, Mean R = -64.6  Std R = 35.9  Min R = -202.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000663\n",
      "PolicyEntropy: -0.512\n",
      "PolicyLoss: -0.00217\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 3.48e+06\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4054   0.6481   2.9197   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0025   0.0132   1.6645   0.7971   0.5555\n",
      "***** Episode 15407, Mean R = -66.7  Std R = 49.9  Min R = -263.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -0.514\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 3.49e+06\n",
      "ValFuncLoss: 0.00185\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3539   0.5735   3.1117   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 15438, Mean R = -49.5  Std R = 10.2  Min R = -80.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.894\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.000971\n",
      "PolicyEntropy: -0.512\n",
      "PolicyLoss: -0.00351\n",
      "Steps: 7.56e+03\n",
      "TotalSteps: 3.49e+06\n",
      "ValFuncLoss: 0.00159\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3984   0.6879   3.5775   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0012   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 15469, Mean R = -64.5  Std R = 29.0  Min R = -155.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000704\n",
      "PolicyEntropy: -0.519\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 3.5e+06\n",
      "ValFuncLoss: 0.00123\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9356   0.3120   1.8198   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0043   1.6645   0.7971   0.5555\n",
      "Update Cnt = 500    ET =    176.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.5   -19.7    -0.7 |    68.0    60.4     0.5 |  -156.5  -253.7    -2.2 |   208.4   112.6    -0.0\n",
      "v_f      |  -11.07    1.09  -29.31 |    5.99    5.83    8.61 |  -24.95  -27.64  -47.32 |    8.14   21.65   -5.99\n",
      "vr_f     |     2.6 |     1.3 |     0.3 |    13.3\n",
      "r_i      |  1010.2    16.9  2350.2 |   604.3   581.2    27.4 |     1.4  -989.0  2300.7 |  1999.9   988.6  2399.1\n",
      "v_i      |  -41.79   -1.91  -80.44 |   16.79   17.60    5.75 |  -69.73  -30.00  -90.00 |  -10.05   29.78  -70.06\n",
      "norm_rf  |    82.1 |    47.2 |     4.2 |   268.3\n",
      "norm_vf  |   32.42 |    8.72 |    7.54 |   52.10\n",
      "thrust   |    1120     109    8682 |    3963    4096    3909 |  -13443  -14980   -8154 |   14992   14804   15000\n",
      "norm_thrust |   10566 |    3574 |    2000 |   15000\n",
      "fuel     |     269 |      50 |     195 |     512\n",
      "rewards  |  -63.15 |   36.83 | -263.32 |  -30.46\n",
      "fuel_rewards |   -9.23 |    1.73 |  -17.60 |   -6.73\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.13 |    0.54 |    0.03 |    3.76\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   79.44 |   44.51 |   15.68 |  263.35\n",
      "tracking_rewards |  -53.91 |   35.33 | -247.33 |  -21.54\n",
      "steps    |     262 |      53 |     173 |     483\n",
      "***** Episode 15500, Mean R = -61.5  Std R = 27.7  Min R = -168.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000666\n",
      "PolicyEntropy: -0.525\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 3.51e+06\n",
      "ValFuncLoss: 0.00128\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7907   1.1677   5.1592   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0038   0.0160   1.6645   0.7971   0.5555\n",
      "***** Episode 15531, Mean R = -47.0  Std R = 10.0  Min R = -77.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.905\n",
      "KL: 0.000683\n",
      "PolicyEntropy: -0.527\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 7.71e+03\n",
      "TotalSteps: 3.52e+06\n",
      "ValFuncLoss: 0.000935\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7970   0.7925   4.6334   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0018   0.0069   1.6645   0.7971   0.5555\n",
      "***** Episode 15562, Mean R = -51.4  Std R = 15.4  Min R = -114.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.919\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.000691\n",
      "PolicyEntropy: -0.528\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8e+03\n",
      "TotalSteps: 3.53e+06\n",
      "ValFuncLoss: 0.00113\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7999   0.8371   4.1676   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 15593, Mean R = -59.1  Std R = 34.8  Min R = -185.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000922\n",
      "PolicyEntropy: -0.521\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 3.53e+06\n",
      "ValFuncLoss: 0.00176\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2967   0.5952   3.2242   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0016   0.0070   1.6645   0.7971   0.5555\n",
      "***** Episode 15624, Mean R = -64.6  Std R = 37.6  Min R = -199.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000729\n",
      "PolicyEntropy: -0.518\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 3.54e+06\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.235\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2090   0.5169   2.4950   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 15655, Mean R = -50.1  Std R = 13.3  Min R = -88.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.899\n",
      "ExplainedVarOld: 0.869\n",
      "KL: 0.000652\n",
      "PolicyEntropy: -0.521\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 3.55e+06\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9892   0.4182   2.3532   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0009   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 15686, Mean R = -53.9  Std R = 28.3  Min R = -177.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000965\n",
      "PolicyEntropy: -0.531\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 7.77e+03\n",
      "TotalSteps: 3.56e+06\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.235\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9928   0.3323   1.7903   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0021   0.0095   1.6645   0.7971   0.5555\n",
      "***** Episode 15717, Mean R = -62.9  Std R = 48.2  Min R = -293.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.000616\n",
      "PolicyEntropy: -0.527\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 3.57e+06\n",
      "ValFuncLoss: 0.0018\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.6673   0.2980   1.5373   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0151   0.0062   0.0242   1.6645   0.7971   0.5555\n",
      "***** Episode 15748, Mean R = -61.8  Std R = 39.8  Min R = -235.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.865\n",
      "KL: 0.000621\n",
      "PolicyEntropy: -0.532\n",
      "PolicyLoss: -0.00174\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 3.58e+06\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9104   0.4248   2.1658   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0063   0.0032   0.0149   1.6645   0.7971   0.5555\n",
      "***** Episode 15779, Mean R = -62.3  Std R = 35.2  Min R = -186.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.00064\n",
      "PolicyEntropy: -0.537\n",
      "PolicyLoss: -0.00215\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 3.58e+06\n",
      "ValFuncLoss: 0.00196\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9079   0.2708   1.4818   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0016   0.0087   1.6645   0.7971   0.5555\n",
      "Update Cnt = 510    ET =    175.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    12.7   -28.0     1.4 |    56.1    58.6    38.4 |  -158.4  -292.4    -2.2 |   149.5    97.6   676.5\n",
      "v_f      |  -10.06    0.93  -28.54 |    5.21    5.02    8.47 |  -23.13  -14.04  -46.20 |   17.93   23.94   19.18\n",
      "vr_f     |     2.9 |     1.8 |     0.5 |    22.0\n",
      "r_i      |   983.4   -24.1  2349.7 |   570.6   571.4    28.7 |     0.1  -994.9  2300.1 |  1998.9   996.7  2399.8\n",
      "v_i      |  -40.54   -0.10  -79.82 |   16.86   17.24    5.86 |  -69.88  -29.66  -89.81 |  -10.03   29.81  -70.13\n",
      "norm_rf  |    76.4 |    56.3 |     3.3 |   707.5\n",
      "norm_vf  |   31.26 |    8.00 |    8.46 |   48.81\n",
      "thrust   |    1141      36    8683 |    3949    3945    3870 |  -13528  -14952   -8886 |   14998   14795   15000\n",
      "norm_thrust |   10499 |    3548 |    2000 |   15000\n",
      "fuel     |     266 |      41 |     203 |     515\n",
      "rewards  |  -56.94 |   31.42 | -293.61 |  -27.89\n",
      "fuel_rewards |   -9.14 |    1.42 |  -17.69 |   -6.99\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.21 |    0.51 |    0.03 |    2.86\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   74.02 |   53.97 |   24.28 |  702.50\n",
      "tracking_rewards |  -47.80 |   30.23 | -275.92 |  -19.42\n",
      "steps    |     261 |      44 |     174 |     480\n",
      "***** Episode 15810, Mean R = -56.2  Std R = 21.1  Min R = -115.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.919\n",
      "ExplainedVarOld: 0.892\n",
      "KL: 0.000811\n",
      "PolicyEntropy: -0.528\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 3.59e+06\n",
      "ValFuncLoss: 0.00133\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7443   0.2414   1.4829   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0061   0.0040   0.0170   1.6645   0.7971   0.5555\n",
      "***** Episode 15841, Mean R = -53.0  Std R = 24.6  Min R = -152.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000701\n",
      "PolicyEntropy: -0.525\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 3.6e+06\n",
      "ValFuncLoss: 0.00137\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8018   0.3280   1.7887   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0021   0.0106   1.6645   0.7971   0.5555\n",
      "***** Episode 15872, Mean R = -56.4  Std R = 28.2  Min R = -171.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.927\n",
      "ExplainedVarOld: 0.893\n",
      "KL: 0.000655\n",
      "PolicyEntropy: -0.527\n",
      "PolicyLoss: -0.00219\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 3.61e+06\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2298   0.4932   2.8131   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 15903, Mean R = -58.7  Std R = 30.9  Min R = -165.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.907\n",
      "KL: 0.000743\n",
      "PolicyEntropy: -0.528\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 3.62e+06\n",
      "ValFuncLoss: 0.00117\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3032   1.0229   4.4705   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0015   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 15934, Mean R = -56.3  Std R = 17.7  Min R = -130.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.897\n",
      "KL: 0.000909\n",
      "PolicyEntropy: -0.539\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 3.62e+06\n",
      "ValFuncLoss: 0.00109\n",
      "Variance: 0.237\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2285   0.7098   3.1792   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0066   0.0341   1.6645   0.7971   0.5555\n",
      "***** Episode 15965, Mean R = -72.4  Std R = 51.5  Min R = -240.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.859\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -0.534\n",
      "PolicyLoss: -0.0016\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 3.63e+06\n",
      "ValFuncLoss: 0.00228\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2894   0.6195   2.9918   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0046   0.0021   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 15996, Mean R = -54.2  Std R = 21.1  Min R = -142.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.878\n",
      "KL: 0.0008\n",
      "PolicyEntropy: -0.523\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 7.75e+03\n",
      "TotalSteps: 3.64e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.238\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4065   0.8856   4.1941   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0103   0.0054   0.0225   1.6645   0.7971   0.5555\n",
      "***** Episode 16027, Mean R = -61.0  Std R = 26.6  Min R = -152.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.922\n",
      "ExplainedVarOld: 0.871\n",
      "KL: 0.000884\n",
      "PolicyEntropy: -0.54\n",
      "PolicyLoss: -0.0025\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 3.65e+06\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9304   0.4070   2.3042   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0021   0.0099   1.6645   0.7971   0.5555\n",
      "***** Episode 16058, Mean R = -54.6  Std R = 19.0  Min R = -119.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.904\n",
      "ExplainedVarOld: 0.86\n",
      "KL: 0.000879\n",
      "PolicyEntropy: -0.553\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 3.66e+06\n",
      "ValFuncLoss: 0.00265\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8121   0.8668   4.3205   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0011   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 16089, Mean R = -55.3  Std R = 39.4  Min R = -249.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000555\n",
      "PolicyEntropy: -0.548\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 3.67e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.236\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0174   0.3352   1.8756   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0015   0.0072   1.6645   0.7971   0.5555\n",
      "Update Cnt = 520    ET =    176.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    12.3   -35.1    -0.8 |    48.6    59.2     0.5 |   -99.2  -247.0    -2.3 |   184.0   130.4    -0.0\n",
      "v_f      |   -8.37    0.29  -28.73 |    4.27    5.45    8.71 |  -22.34  -17.39  -52.83 |    5.51   16.34   -4.17\n",
      "vr_f     |     3.4 |     2.4 |     0.3 |    27.9\n",
      "r_i      |   957.5   -86.7  2351.1 |   586.5   591.3    30.1 |     3.3  -995.3  2300.3 |  1999.5   996.1  2400.0\n",
      "v_i      |  -39.03    0.05  -80.15 |   16.74   18.16    5.72 |  -69.93  -29.84  -89.99 |  -10.11   29.77  -70.15\n",
      "norm_rf  |    73.3 |    43.4 |     8.6 |   249.4\n",
      "norm_vf  |   30.78 |    8.50 |    9.70 |   54.94\n",
      "thrust   |    1122      10    8671 |    3884    4078    3892 |  -13706  -14943   -9215 |   14995   14851   15000\n",
      "norm_thrust |   10514 |    3574 |    2000 |   15000\n",
      "fuel     |     269 |      41 |     191 |     500\n",
      "rewards  |  -57.80 |   29.85 | -249.29 |  -29.76\n",
      "fuel_rewards |   -9.26 |    1.40 |  -17.16 |   -6.59\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.20 |    0.51 |    0.02 |    2.89\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   70.45 |   41.11 |   20.80 |  244.39\n",
      "tracking_rewards |  -48.54 |   28.69 | -232.12 |  -21.01\n",
      "steps    |     263 |      43 |     176 |     465\n",
      "***** Episode 16120, Mean R = -56.0  Std R = 15.4  Min R = -105.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.851\n",
      "KL: 0.000921\n",
      "PolicyEntropy: -0.55\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 3.67e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.235\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9165   0.5153   2.7684   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0026   0.0111   1.6645   0.7971   0.5555\n",
      "***** Episode 16151, Mean R = -49.2  Std R = 11.6  Min R = -82.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.894\n",
      "ExplainedVarOld: 0.881\n",
      "KL: 0.000679\n",
      "PolicyEntropy: -0.561\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 7.76e+03\n",
      "TotalSteps: 3.68e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.234\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8528   0.2576   1.5143   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0020   0.0097   1.6645   0.7971   0.5555\n",
      "***** Episode 16182, Mean R = -60.1  Std R = 36.0  Min R = -211.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.921\n",
      "ExplainedVarOld: 0.869\n",
      "KL: 0.000763\n",
      "PolicyEntropy: -0.559\n",
      "PolicyLoss: -0.00206\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 3.69e+06\n",
      "ValFuncLoss: 0.00253\n",
      "Variance: 0.234\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1954   0.5127   2.8543   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0015   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 16213, Mean R = -48.9  Std R = 11.6  Min R = -93.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.89\n",
      "ExplainedVarOld: 0.824\n",
      "KL: 0.000706\n",
      "PolicyEntropy: -0.571\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 7.31e+03\n",
      "TotalSteps: 3.7e+06\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.233\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5856   0.9027   5.0686   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 16244, Mean R = -46.7  Std R = 9.7  Min R = -67.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.891\n",
      "ExplainedVarOld: 0.862\n",
      "KL: 0.000808\n",
      "PolicyEntropy: -0.573\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 7.64e+03\n",
      "TotalSteps: 3.7e+06\n",
      "ValFuncLoss: 0.00125\n",
      "Variance: 0.234\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0374   1.0663   5.2142   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 16275, Mean R = -49.8  Std R = 11.0  Min R = -82.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.00112\n",
      "PolicyEntropy: -0.571\n",
      "PolicyLoss: -0.00395\n",
      "Steps: 7.66e+03\n",
      "TotalSteps: 3.71e+06\n",
      "ValFuncLoss: 0.00111\n",
      "Variance: 0.233\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9287   0.4046   1.6645   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0013   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 16306, Mean R = -54.5  Std R = 24.3  Min R = -134.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.881\n",
      "KL: 0.000745\n",
      "PolicyEntropy: -0.582\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 7.84e+03\n",
      "TotalSteps: 3.72e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.232\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6070   1.0892   5.2234   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0014   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 16337, Mean R = -55.1  Std R = 29.1  Min R = -160.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000997\n",
      "PolicyEntropy: -0.583\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 3.73e+06\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.231\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7961   0.2726   1.4388   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0025   0.0113   1.6645   0.7971   0.5555\n",
      "***** Episode 16368, Mean R = -55.2  Std R = 27.4  Min R = -169.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.912\n",
      "KL: 0.000716\n",
      "PolicyEntropy: -0.578\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 3.74e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.232\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1043   0.4029   1.6534   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0015   0.0083   1.6645   0.7971   0.5555\n",
      "***** Episode 16399, Mean R = -59.4  Std R = 37.2  Min R = -244.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000805\n",
      "PolicyEntropy: -0.596\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 3.74e+06\n",
      "ValFuncLoss: 0.0014\n",
      "Variance: 0.231\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4713   1.8414   5.9083   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0080   0.0032   0.0138   1.6645   0.7971   0.5555\n",
      "Update Cnt = 530    ET =    174.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    29.6   -15.8    -0.8 |    48.9    54.8     0.5 |  -124.5  -181.0    -2.6 |   178.3    92.1    -0.0\n",
      "v_f      |   -9.73    1.07  -31.11 |    4.62    5.72    8.40 |  -24.04  -15.58  -52.26 |    4.32   25.09   -6.61\n",
      "vr_f     |     3.2 |     1.9 |     0.5 |    18.3\n",
      "r_i      |  1061.5    55.1  2350.1 |   566.1   542.4    30.3 |     3.6  -986.9  2300.4 |  1987.1   999.5  2399.8\n",
      "v_i      |  -39.96   -1.27  -80.11 |   17.28   17.04    5.72 |  -69.77  -29.79  -89.93 |  -10.38   29.94  -70.02\n",
      "norm_rf  |    71.5 |    37.4 |     3.5 |   195.1\n",
      "norm_vf  |   33.39 |    8.55 |   10.30 |   55.23\n",
      "thrust   |    1141      74    8654 |    3759    3986    3881 |  -13201  -14876   -9220 |   14986   14522   14999\n",
      "norm_thrust |   10422 |    3559 |    2000 |   15000\n",
      "fuel     |     261 |      41 |     182 |     504\n",
      "rewards  |  -54.77 |   28.32 | -244.32 |  -26.99\n",
      "fuel_rewards |   -8.96 |    1.40 |  -17.30 |   -6.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.19 |    0.47 |    0.03 |    3.23\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   68.74 |   34.96 |   19.46 |  190.14\n",
      "tracking_rewards |  -45.81 |   27.13 | -227.02 |  -18.72\n",
      "steps    |     257 |      42 |     166 |     464\n",
      "***** Episode 16430, Mean R = -68.7  Std R = 47.6  Min R = -241.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.000716\n",
      "PolicyEntropy: -0.606\n",
      "PolicyLoss: -0.00215\n",
      "Steps: 8.74e+03\n",
      "TotalSteps: 3.75e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.231\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4919   1.0184   4.3920   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0015   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 16461, Mean R = -57.0  Std R = 29.0  Min R = -141.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00084\n",
      "PolicyEntropy: -0.598\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 3.76e+06\n",
      "ValFuncLoss: 0.00162\n",
      "Variance: 0.231\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4483   0.5128   3.2425   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0013   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 16492, Mean R = -56.9  Std R = 22.4  Min R = -137.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000675\n",
      "PolicyEntropy: -0.601\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 3.77e+06\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.23\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1359   0.2994   2.0388   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0014   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 16523, Mean R = -55.1  Std R = 18.1  Min R = -97.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.888\n",
      "KL: 0.000868\n",
      "PolicyEntropy: -0.608\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 3.78e+06\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.231\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1075   0.4688   2.5807   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0008   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 16554, Mean R = -56.6  Std R = 29.8  Min R = -177.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.00099\n",
      "PolicyEntropy: -0.614\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 3.79e+06\n",
      "ValFuncLoss: 0.00123\n",
      "Variance: 0.231\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4881   0.6557   3.4296   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0014   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 16585, Mean R = -52.0  Std R = 26.6  Min R = -187.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000895\n",
      "PolicyEntropy: -0.622\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 3.79e+06\n",
      "ValFuncLoss: 0.00156\n",
      "Variance: 0.23\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3280   0.8324   3.5920   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0022   0.0093   1.6645   0.7971   0.5555\n",
      "***** Episode 16616, Mean R = -58.4  Std R = 30.3  Min R = -188.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -0.63\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 3.8e+06\n",
      "ValFuncLoss: 0.00127\n",
      "Variance: 0.23\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2290   0.5028   2.9265   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0022   0.0098   1.6645   0.7971   0.5555\n",
      "***** Episode 16647, Mean R = -48.5  Std R = 17.7  Min R = -111.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.000797\n",
      "PolicyEntropy: -0.639\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 7.85e+03\n",
      "TotalSteps: 3.81e+06\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.229\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9762   1.4478   5.0748   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0014   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 16678, Mean R = -54.9  Std R = 20.8  Min R = -132.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.914\n",
      "ExplainedVarOld: 0.871\n",
      "KL: 0.000627\n",
      "PolicyEntropy: -0.636\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 3.82e+06\n",
      "ValFuncLoss: 0.00126\n",
      "Variance: 0.229\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0035   0.3615   1.7669   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0011   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 16709, Mean R = -60.5  Std R = 42.6  Min R = -267.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000904\n",
      "PolicyEntropy: -0.651\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 3.83e+06\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.227\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3930   0.4884   3.1615   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "Update Cnt = 540    ET =    174.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.6   -14.8    -0.7 |    45.8    56.9     0.4 |   -91.9  -212.3    -1.9 |   144.5    90.8    -0.0\n",
      "v_f      |   -8.86    1.44  -29.27 |    4.08    4.78    7.41 |  -20.54  -13.30  -47.67 |    2.12   17.31   -3.27\n",
      "vr_f     |     3.3 |     1.6 |     0.6 |    12.8\n",
      "r_i      |   971.4    61.3  2351.7 |   575.0   562.7    28.7 |     1.7  -992.8  2301.0 |  1989.7   993.8  2399.9\n",
      "v_i      |  -37.97   -0.97  -79.80 |   16.55   17.27    5.72 |  -69.82  -29.97  -89.99 |  -10.03   29.45  -70.00\n",
      "norm_rf  |    66.7 |    39.6 |     3.2 |   214.1\n",
      "norm_vf  |   31.24 |    7.45 |    6.63 |   49.20\n",
      "thrust   |    1043      92    8641 |    3755    4019    3855 |  -14345  -14686   -6741 |   14979   14707   14999\n",
      "norm_thrust |   10400 |    3566 |    2000 |   15000\n",
      "fuel     |     265 |      37 |     200 |     524\n",
      "rewards  |  -54.46 |   26.51 | -267.67 |  -28.89\n",
      "fuel_rewards |   -9.11 |    1.28 |  -17.99 |   -6.85\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.23 |    0.48 |    0.02 |    2.93\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   64.39 |   36.79 |   15.70 |  209.12\n",
      "tracking_rewards |  -45.35 |   25.44 | -249.68 |  -20.23\n",
      "steps    |     262 |      38 |     180 |     479\n",
      "***** Episode 16740, Mean R = -44.7  Std R = 8.6  Min R = -75.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.001\n",
      "PolicyEntropy: -0.661\n",
      "PolicyLoss: -0.00414\n",
      "Steps: 7.77e+03\n",
      "TotalSteps: 3.83e+06\n",
      "ValFuncLoss: 0.000998\n",
      "Variance: 0.227\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2241   0.5989   2.8117   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0026   0.0108   1.6645   0.7971   0.5555\n",
      "***** Episode 16771, Mean R = -56.6  Std R = 23.2  Min R = -144.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000792\n",
      "PolicyEntropy: -0.658\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 3.84e+06\n",
      "ValFuncLoss: 0.00109\n",
      "Variance: 0.227\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9197   0.3179   1.6480   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0009   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 16802, Mean R = -53.9  Std R = 25.5  Min R = -162.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.907\n",
      "KL: 0.000841\n",
      "PolicyEntropy: -0.673\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 7.85e+03\n",
      "TotalSteps: 3.85e+06\n",
      "ValFuncLoss: 0.00106\n",
      "Variance: 0.227\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1189   0.4447   2.7143   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0025   0.0106   1.6645   0.7971   0.5555\n",
      "***** Episode 16833, Mean R = -47.3  Std R = 13.1  Min R = -90.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.000845\n",
      "PolicyEntropy: -0.684\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 3.86e+06\n",
      "ValFuncLoss: 0.000838\n",
      "Variance: 0.227\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5244   0.5621   2.6043   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 16864, Mean R = -49.0  Std R = 13.0  Min R = -91.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.919\n",
      "KL: 0.000666\n",
      "PolicyEntropy: -0.693\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 3.87e+06\n",
      "ValFuncLoss: 0.00068\n",
      "Variance: 0.226\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7866   0.3052   1.6424   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0052   0.0022   0.0104   1.6645   0.7971   0.5555\n",
      "***** Episode 16895, Mean R = -50.3  Std R = 19.4  Min R = -139.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.841\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -0.688\n",
      "PolicyLoss: -0.0019\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 3.87e+06\n",
      "ValFuncLoss: 0.000961\n",
      "Variance: 0.226\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0617   0.5565   3.0303   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0011   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 16926, Mean R = -53.0  Std R = 30.8  Min R = -214.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.862\n",
      "KL: 0.000728\n",
      "PolicyEntropy: -0.69\n",
      "PolicyLoss: -0.0025\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 3.88e+06\n",
      "ValFuncLoss: 0.000965\n",
      "Variance: 0.226\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6732   0.8776   4.9704   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0013   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 16957, Mean R = -47.3  Std R = 19.7  Min R = -147.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -0.704\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 3.89e+06\n",
      "ValFuncLoss: 0.00148\n",
      "Variance: 0.225\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6059   0.6062   2.9079   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0062   0.0029   0.0132   1.6645   0.7971   0.5555\n",
      "***** Episode 16988, Mean R = -69.3  Std R = 53.1  Min R = -255.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000811\n",
      "PolicyEntropy: -0.711\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 9.09e+03\n",
      "TotalSteps: 3.9e+06\n",
      "ValFuncLoss: 0.00157\n",
      "Variance: 0.225\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7633   0.8156   3.9442   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0008   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 17019, Mean R = -54.5  Std R = 25.3  Min R = -169.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000891\n",
      "PolicyEntropy: -0.726\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 3.91e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.223\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8058   0.3196   1.8962   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0028   0.0124   1.6645   0.7971   0.5555\n",
      "Update Cnt = 550    ET =    177.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    24.3    -7.4    -0.7 |    36.5    50.9     0.5 |   -87.1  -149.1    -2.0 |   145.4   108.0    -0.0\n",
      "v_f      |   -8.28    1.96  -28.30 |    4.23    4.63    7.90 |  -23.15  -14.46  -46.20 |    9.48   16.14   -5.43\n",
      "vr_f     |     3.4 |     3.4 |     0.7 |    55.5\n",
      "r_i      |   988.5   -22.0  2350.6 |   556.6   585.9    27.5 |    14.6  -990.4  2300.2 |  1988.4   998.8  2399.8\n",
      "v_i      |  -36.67   -0.18  -79.80 |   17.74   17.39    5.82 |  -69.83  -29.79  -89.91 |  -10.05   29.77  -70.00\n",
      "norm_rf  |    60.1 |    31.0 |     4.1 |   162.7\n",
      "norm_vf  |   30.17 |    8.03 |    5.70 |   47.25\n",
      "thrust   |    1005      83    8634 |    3705    3932    3792 |  -13008  -14665   -9345 |   14974   14862   15000\n",
      "norm_thrust |   10319 |    3558 |    2000 |   15000\n",
      "fuel     |     265 |      38 |     201 |     492\n",
      "rewards  |  -53.29 |   27.26 | -254.96 |  -28.87\n",
      "fuel_rewards |   -9.10 |    1.29 |  -16.91 |   -6.92\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.24 |    0.52 |    0.02 |    2.85\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   57.15 |   28.62 |   17.49 |  157.68\n",
      "tracking_rewards |  -44.19 |   26.17 | -239.23 |  -20.39\n",
      "steps    |     264 |      40 |     176 |     462\n",
      "***** Episode 17050, Mean R = -51.6  Std R = 18.7  Min R = -103.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.892\n",
      "ExplainedVarOld: 0.864\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -0.741\n",
      "PolicyLoss: -0.00205\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 3.92e+06\n",
      "ValFuncLoss: 0.00127\n",
      "Variance: 0.222\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9953   0.2772   1.6521   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0052   0.0024   0.0101   1.6645   0.7971   0.5555\n",
      "***** Episode 17081, Mean R = -64.6  Std R = 34.5  Min R = -178.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000865\n",
      "PolicyEntropy: -0.749\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 3.92e+06\n",
      "ValFuncLoss: 0.00144\n",
      "Variance: 0.222\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3905   0.4883   2.3141   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0088   0.0038   0.0195   1.6645   0.7971   0.5555\n",
      "***** Episode 17112, Mean R = -62.0  Std R = 35.5  Min R = -212.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.844\n",
      "KL: 0.000894\n",
      "PolicyEntropy: -0.73\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.68e+03\n",
      "TotalSteps: 3.93e+06\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.222\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2508   0.4592   2.5263   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0020   0.0103   1.6645   0.7971   0.5555\n",
      "***** Episode 17143, Mean R = -61.5  Std R = 32.0  Min R = -190.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.91\n",
      "ExplainedVarOld: 0.825\n",
      "KL: 0.000687\n",
      "PolicyEntropy: -0.734\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 3.94e+06\n",
      "ValFuncLoss: 0.00334\n",
      "Variance: 0.221\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3565   0.9954   5.5302   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0043   0.0174   1.6645   0.7971   0.5555\n",
      "***** Episode 17174, Mean R = -53.2  Std R = 20.5  Min R = -130.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.886\n",
      "KL: 0.000997\n",
      "PolicyEntropy: -0.738\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 3.95e+06\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.22\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9955   1.1676   5.2821   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0017   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 17205, Mean R = -49.7  Std R = 22.5  Min R = -151.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.000657\n",
      "PolicyEntropy: -0.738\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 3.96e+06\n",
      "ValFuncLoss: 0.00264\n",
      "Variance: 0.221\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2711   0.8465   4.0005   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0013   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 17236, Mean R = -53.5  Std R = 23.1  Min R = -141.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.905\n",
      "KL: 0.000645\n",
      "PolicyEntropy: -0.74\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 7.84e+03\n",
      "TotalSteps: 3.97e+06\n",
      "ValFuncLoss: 0.00313\n",
      "Variance: 0.22\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0448   0.3386   1.9514   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0027   0.0119   1.6645   0.7971   0.5555\n",
      "***** Episode 17267, Mean R = -48.4  Std R = 17.5  Min R = -130.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.912\n",
      "ExplainedVarOld: 0.856\n",
      "KL: 0.000965\n",
      "PolicyEntropy: -0.757\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 3.97e+06\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.22\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1248   0.5521   2.2543   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 17298, Mean R = -53.4  Std R = 36.6  Min R = -245.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -0.759\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 3.98e+06\n",
      "ValFuncLoss: 0.00253\n",
      "Variance: 0.22\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2985   0.4125   2.6694   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0009   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 17329, Mean R = -56.7  Std R = 32.2  Min R = -181.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -0.763\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 3.99e+06\n",
      "ValFuncLoss: 0.00224\n",
      "Variance: 0.22\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4500   0.6022   3.6519   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "Update Cnt = 560    ET =    177.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.9    -4.4    -0.6 |    41.4    59.4     0.5 |  -115.0  -154.0    -2.2 |   150.5   163.3    -0.0\n",
      "v_f      |   -8.30    1.51  -26.81 |    4.56    4.46    8.37 |  -22.18  -22.59  -49.26 |   12.07   18.89   -4.57\n",
      "vr_f     |     3.2 |     2.0 |     0.7 |    24.7\n",
      "r_i      |  1071.0    37.6  2349.5 |   604.4   578.2    28.8 |     8.5  -990.4  2300.6 |  1994.9   997.8  2399.9\n",
      "v_i      |  -40.51   -0.93  -80.46 |   17.58   17.23    5.58 |  -69.91  -29.83  -89.97 |  -10.27   28.64  -70.01\n",
      "norm_rf  |    67.8 |    35.1 |     1.2 |   188.7\n",
      "norm_vf  |   28.76 |    8.58 |    6.29 |   52.78\n",
      "thrust   |    1163      77    8758 |    3710    3912    3745 |  -13534  -14547   -9069 |   14928   14029   15000\n",
      "norm_thrust |   10428 |    3523 |    2000 |   15000\n",
      "fuel     |     270 |      37 |     208 |     464\n",
      "rewards  |  -55.34 |   28.85 | -245.13 |  -25.73\n",
      "fuel_rewards |   -9.28 |    1.28 |  -15.95 |   -7.15\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.12 |    0.47 |    0.02 |    3.10\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   64.50 |   32.94 |   11.40 |  183.74\n",
      "tracking_rewards |  -46.06 |   27.73 | -229.69 |  -17.28\n",
      "steps    |     266 |      39 |     152 |     449\n",
      "***** Episode 17360, Mean R = -50.3  Std R = 20.5  Min R = -131.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000924\n",
      "PolicyEntropy: -0.777\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 4e+06\n",
      "ValFuncLoss: 0.00272\n",
      "Variance: 0.22\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2984   0.3363   1.9948   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 17391, Mean R = -51.8  Std R = 21.0  Min R = -132.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.919\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -0.784\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 4.01e+06\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.218\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2190   0.4000   2.2282   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0053   0.0029   0.0122   1.6645   0.7971   0.5555\n",
      "***** Episode 17422, Mean R = -54.3  Std R = 30.9  Min R = -186.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000797\n",
      "PolicyEntropy: -0.787\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 4.02e+06\n",
      "ValFuncLoss: 0.00253\n",
      "Variance: 0.218\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5049   0.8265   3.3460   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 17453, Mean R = -51.6  Std R = 17.1  Min R = -95.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.000909\n",
      "PolicyEntropy: -0.79\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 4.02e+06\n",
      "ValFuncLoss: 0.00217\n",
      "Variance: 0.218\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8825   0.2927   1.6339   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0018   0.0088   1.6645   0.7971   0.5555\n",
      "***** Episode 17484, Mean R = -53.0  Std R = 28.8  Min R = -190.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000814\n",
      "PolicyEntropy: -0.794\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 4.03e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.219\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5961   1.3102   5.1337   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0007   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 17515, Mean R = -49.5  Std R = 15.5  Min R = -92.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.000643\n",
      "PolicyEntropy: -0.799\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 4.04e+06\n",
      "ValFuncLoss: 0.00197\n",
      "Variance: 0.218\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8022   1.0586   4.0246   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0014   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 17546, Mean R = -59.0  Std R = 27.9  Min R = -148.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000887\n",
      "PolicyEntropy: -0.798\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 4.05e+06\n",
      "ValFuncLoss: 0.00155\n",
      "Variance: 0.219\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0839   0.8362   4.1299   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 17577, Mean R = -53.1  Std R = 16.8  Min R = -109.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.908\n",
      "KL: 0.000876\n",
      "PolicyEntropy: -0.801\n",
      "PolicyLoss: -0.00364\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 4.06e+06\n",
      "ValFuncLoss: 0.00111\n",
      "Variance: 0.219\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3931   0.6501   3.6526   6.2114   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0017   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 17608, Mean R = -53.2  Std R = 20.1  Min R = -107.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.902\n",
      "KL: 0.000676\n",
      "PolicyEntropy: -0.801\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 4.06e+06\n",
      "ValFuncLoss: 0.000803\n",
      "Variance: 0.218\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6532   1.7717   7.1791   7.1791   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0027   0.0110   1.6645   0.7971   0.5555\n",
      "***** Episode 17639, Mean R = -65.5  Std R = 46.9  Min R = -233.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00121\n",
      "PolicyEntropy: -0.799\n",
      "PolicyLoss: -0.00195\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 4.07e+06\n",
      "ValFuncLoss: 0.00173\n",
      "Variance: 0.216\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4100   0.5957   2.7955   7.1791   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0052   0.0024   0.0120   1.6645   0.7971   0.5555\n",
      "Update Cnt = 570    ET =    177.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.7   -10.6    -0.7 |    35.4    55.5     0.4 |  -109.4  -209.3    -2.0 |   163.0   107.9    -0.0\n",
      "v_f      |   -7.27    1.56  -27.74 |    3.97    4.87    7.08 |  -20.33  -12.37  -48.64 |    4.17   17.15   -6.29\n",
      "vr_f     |     3.7 |     2.4 |     0.4 |    27.5\n",
      "r_i      |  1007.8    11.8  2350.1 |   570.9   590.2    28.9 |    24.2  -998.8  2300.2 |  1994.9   978.3  2399.3\n",
      "v_i      |  -39.40    0.18  -79.92 |   18.08   17.62    5.70 |  -69.74  -29.96  -89.96 |  -10.14   29.99  -70.08\n",
      "norm_rf  |    60.2 |    37.1 |     2.0 |   216.0\n",
      "norm_vf  |   29.40 |    7.07 |   10.38 |   50.53\n",
      "thrust   |    1151      39    8680 |    3619    3931    3727 |  -12348  -14661   -7736 |   14997   14843   15000\n",
      "norm_thrust |   10324 |    3536 |    2000 |   15000\n",
      "fuel     |     267 |      33 |     204 |     434\n",
      "rewards  |  -54.54 |   26.97 | -233.04 |  -27.63\n",
      "fuel_rewards |   -9.19 |    1.12 |  -14.89 |   -7.02\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.20 |    0.51 |    0.03 |    3.71\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   58.14 |   34.25 |   17.22 |  211.00\n",
      "tracking_rewards |  -45.35 |   26.01 | -218.15 |  -19.38\n",
      "steps    |     266 |      36 |     182 |     426\n",
      "***** Episode 17670, Mean R = -54.4  Std R = 26.1  Min R = -144.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -0.805\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 4.08e+06\n",
      "ValFuncLoss: 0.00123\n",
      "Variance: 0.215\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0168   0.7727   4.4361   7.1791   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0063   0.0029   0.0125   1.6645   0.7971   0.5555\n",
      "***** Episode 17701, Mean R = -51.3  Std R = 17.9  Min R = -127.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.884\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -0.802\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 7.84e+03\n",
      "TotalSteps: 4.09e+06\n",
      "ValFuncLoss: 0.00084\n",
      "Variance: 0.215\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6509   0.8784   4.4138   7.1791   2.8093   2.3200\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0012   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 17732, Mean R = -51.6  Std R = 21.0  Min R = -133.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.000965\n",
      "PolicyEntropy: -0.811\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 4.1e+06\n",
      "ValFuncLoss: 0.00108\n",
      "Variance: 0.215\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7521   3.4442   9.8966   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0085   0.0038   0.0174   1.6645   0.7971   0.5555\n",
      "***** Episode 17763, Mean R = -59.9  Std R = 30.9  Min R = -180.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.886\n",
      "KL: 0.000564\n",
      "PolicyEntropy: -0.813\n",
      "PolicyLoss: -0.00148\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 4.11e+06\n",
      "ValFuncLoss: 0.00144\n",
      "Variance: 0.215\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2610   0.7126   3.8768   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0009   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 17794, Mean R = -50.3  Std R = 17.5  Min R = -123.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.881\n",
      "KL: 0.000768\n",
      "PolicyEntropy: -0.817\n",
      "PolicyLoss: -0.0035\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 4.11e+06\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.215\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3526   0.3791   2.0186   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 17825, Mean R = -47.0  Std R = 12.0  Min R = -85.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000738\n",
      "PolicyEntropy: -0.819\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 7.77e+03\n",
      "TotalSteps: 4.12e+06\n",
      "ValFuncLoss: 0.000868\n",
      "Variance: 0.215\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.8818   0.2377   1.5409   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0032   0.0129   1.6645   0.7971   0.5555\n",
      "***** Episode 17856, Mean R = -65.1  Std R = 40.9  Min R = -236.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000791\n",
      "PolicyEntropy: -0.822\n",
      "PolicyLoss: -0.00211\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 4.13e+06\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.214\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1847   0.4012   2.1906   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0013   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 17887, Mean R = -50.0  Std R = 20.6  Min R = -149.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.905\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -0.835\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 7.83e+03\n",
      "TotalSteps: 4.14e+06\n",
      "ValFuncLoss: 0.00074\n",
      "Variance: 0.213\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7597   0.6761   3.1527   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 17918, Mean R = -52.3  Std R = 34.1  Min R = -220.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000844\n",
      "PolicyEntropy: -0.841\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 4.15e+06\n",
      "ValFuncLoss: 0.000741\n",
      "Variance: 0.213\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1545   0.4144   2.1244   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0016   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 17949, Mean R = -54.3  Std R = 37.0  Min R = -242.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -0.843\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 7.83e+03\n",
      "TotalSteps: 4.15e+06\n",
      "ValFuncLoss: 0.00105\n",
      "Variance: 0.213\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1788   1.1133   6.1974   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0049   0.0022   0.0092   1.6645   0.7971   0.5555\n",
      "Update Cnt = 580    ET =    174.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.8    -6.9    -0.7 |    35.1    54.0     0.5 |  -112.2  -173.3    -2.0 |   130.2   101.7    -0.0\n",
      "v_f      |   -7.72    1.11  -29.00 |    4.34    5.15    8.20 |  -20.82  -13.60  -46.67 |    7.52   22.17   -5.43\n",
      "vr_f     |     3.5 |     1.9 |     0.7 |    15.8\n",
      "r_i      |   985.8    11.7  2349.8 |   590.5   545.2    29.9 |     4.6  -997.1  2300.1 |  1998.9   993.4  2400.0\n",
      "v_i      |  -40.15   -0.51  -80.45 |   17.44   17.56    5.87 |  -69.29  -29.75  -89.92 |  -10.21   29.93  -70.15\n",
      "norm_rf  |    61.0 |    32.3 |     5.9 |   179.1\n",
      "norm_vf  |   30.79 |    8.18 |    6.31 |   48.56\n",
      "thrust   |    1207      56    8745 |    3711    3945    3675 |  -12243  -14214   -7944 |   14980   14501   15000\n",
      "norm_thrust |   10415 |    3507 |    2000 |   15000\n",
      "fuel     |     261 |      37 |     195 |     473\n",
      "rewards  |  -53.04 |   26.85 | -242.48 |  -30.33\n",
      "fuel_rewards |   -8.97 |    1.26 |  -16.24 |   -6.72\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.24 |    0.52 |    0.03 |    2.75\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   58.90 |   29.09 |   19.07 |  174.05\n",
      "tracking_rewards |  -44.07 |   25.76 | -226.82 |  -21.56\n",
      "steps    |     258 |      37 |     185 |     445\n",
      "***** Episode 17980, Mean R = -48.5  Std R = 11.9  Min R = -80.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.919\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.000899\n",
      "PolicyEntropy: -0.842\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 7.6e+03\n",
      "TotalSteps: 4.16e+06\n",
      "ValFuncLoss: 0.00057\n",
      "Variance: 0.213\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2454   1.0011   5.5223   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 18011, Mean R = -48.2  Std R = 12.2  Min R = -99.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.00118\n",
      "PolicyEntropy: -0.842\n",
      "PolicyLoss: -0.00404\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 4.17e+06\n",
      "ValFuncLoss: 0.000879\n",
      "Variance: 0.212\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3571   0.3988   1.9841   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0019   0.0080   1.6645   0.7971   0.5555\n",
      "***** Episode 18042, Mean R = -48.2  Std R = 11.5  Min R = -86.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.895\n",
      "ExplainedVarOld: 0.876\n",
      "KL: 0.000941\n",
      "PolicyEntropy: -0.851\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 4.18e+06\n",
      "ValFuncLoss: 0.000807\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.5654   0.2050   1.1849   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0120   0.0052   0.0245   1.6645   0.7971   0.5555\n",
      "***** Episode 18073, Mean R = -56.3  Std R = 33.7  Min R = -187.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.881\n",
      "KL: 0.00089\n",
      "PolicyEntropy: -0.852\n",
      "PolicyLoss: -0.0021\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 4.19e+06\n",
      "ValFuncLoss: 0.00149\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4557   0.5296   2.9755   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0026   0.0108   1.6645   0.7971   0.5555\n",
      "***** Episode 18104, Mean R = -50.9  Std R = 19.5  Min R = -125.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000643\n",
      "PolicyEntropy: -0.852\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 4.19e+06\n",
      "ValFuncLoss: 0.00106\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2122   0.5441   2.6577   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 18135, Mean R = -59.1  Std R = 32.2  Min R = -182.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -0.846\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 4.2e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6750   0.8988   4.8888   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 18166, Mean R = -51.7  Std R = 20.4  Min R = -137.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -0.851\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 4.21e+06\n",
      "ValFuncLoss: 0.00086\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5090   0.3309   2.5400   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0014   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 18197, Mean R = -52.7  Std R = 26.0  Min R = -161.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000854\n",
      "PolicyEntropy: -0.86\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 4.22e+06\n",
      "ValFuncLoss: 0.00157\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6780   0.8353   3.5927   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0021   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 18228, Mean R = -54.4  Std R = 28.4  Min R = -175.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000789\n",
      "PolicyEntropy: -0.861\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 4.23e+06\n",
      "ValFuncLoss: 0.00118\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1982   0.6770   3.4582   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0008   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 18259, Mean R = -45.2  Std R = 12.1  Min R = -97.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.899\n",
      "KL: 0.00073\n",
      "PolicyEntropy: -0.876\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 7.7e+03\n",
      "TotalSteps: 4.23e+06\n",
      "ValFuncLoss: 0.000872\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0912   0.3537   1.8131   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0026   0.0123   1.6645   0.7971   0.5555\n",
      "Update Cnt = 590    ET =    172.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.6    -5.6    -0.7 |    41.5    52.0     0.5 |  -120.9  -185.8    -2.1 |   145.4   151.8    -0.0\n",
      "v_f      |   -7.11    1.22  -27.70 |    4.26    4.68    7.71 |  -22.95  -13.01  -45.86 |    6.19   20.30   -3.72\n",
      "vr_f     |     4.0 |     5.1 |     0.4 |    77.3\n",
      "r_i      |   970.0   -30.4  2350.6 |   595.5   560.6    28.5 |     0.6  -998.4  2300.2 |  1999.7   993.6  2399.8\n",
      "v_i      |  -40.36    0.68  -79.79 |   17.49   17.46    5.91 |  -69.87  -29.88  -89.95 |  -10.45   29.99  -70.09\n",
      "norm_rf  |    61.8 |    32.6 |     4.4 |   196.8\n",
      "norm_vf  |   29.33 |    7.68 |    7.55 |   47.59\n",
      "thrust   |    1240      19    8736 |    3756    3889    3617 |  -13200  -14390   -8994 |   14977   14845   14999\n",
      "norm_thrust |   10392 |    3488 |    2000 |   15000\n",
      "fuel     |     260 |      32 |     209 |     446\n",
      "rewards  |  -51.56 |   23.40 | -187.23 |  -25.95\n",
      "fuel_rewards |   -8.92 |    1.10 |  -15.33 |   -7.18\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.26 |    0.52 |    0.03 |    3.11\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   59.04 |   30.09 |   16.97 |  191.76\n",
      "tracking_rewards |  -42.64 |   22.49 | -171.90 |  -17.50\n",
      "steps    |     257 |      35 |     160 |     411\n",
      "***** Episode 18290, Mean R = -48.8  Std R = 20.9  Min R = -143.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000693\n",
      "PolicyEntropy: -0.884\n",
      "PolicyLoss: -0.0024\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 4.24e+06\n",
      "ValFuncLoss: 0.000953\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8659   0.9844   4.3632   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0035   0.0147   1.6645   0.7971   0.5555\n",
      "***** Episode 18321, Mean R = -48.1  Std R = 18.5  Min R = -131.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000779\n",
      "PolicyEntropy: -0.884\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 4.25e+06\n",
      "ValFuncLoss: 0.000878\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7655   0.2129   1.4068   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0031   0.0151   1.6645   0.7971   0.5555\n",
      "***** Episode 18352, Mean R = -48.4  Std R = 14.8  Min R = -100.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.874\n",
      "ExplainedVarOld: 0.824\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -0.888\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 4.26e+06\n",
      "ValFuncLoss: 0.00135\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3339   0.3416   1.8889   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0020   0.0095   1.6645   0.7971   0.5555\n",
      "***** Episode 18383, Mean R = -50.7  Std R = 18.5  Min R = -103.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.000817\n",
      "PolicyEntropy: -0.899\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 4.27e+06\n",
      "ValFuncLoss: 0.000859\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9608   0.6235   2.9880   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0077   0.0042   0.0160   1.6645   0.7971   0.5555\n",
      "***** Episode 18414, Mean R = -59.7  Std R = 30.2  Min R = -176.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.91\n",
      "KL: 0.000808\n",
      "PolicyEntropy: -0.903\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 4.27e+06\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2568   0.4624   2.6161   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 18445, Mean R = -49.1  Std R = 14.7  Min R = -92.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000719\n",
      "PolicyEntropy: -0.912\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 4.28e+06\n",
      "ValFuncLoss: 0.00101\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5057   0.6527   3.4081   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 18476, Mean R = -47.5  Std R = 12.0  Min R = -81.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.922\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.000845\n",
      "PolicyEntropy: -0.906\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 4.29e+06\n",
      "ValFuncLoss: 0.000879\n",
      "Variance: 0.21\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0318   0.3146   1.7333   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 18507, Mean R = -46.1  Std R = 21.6  Min R = -137.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000721\n",
      "PolicyEntropy: -0.906\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 7.94e+03\n",
      "TotalSteps: 4.3e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.0035   0.2311   1.5705   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0018   0.0084   1.6645   0.7971   0.5555\n",
      "***** Episode 18538, Mean R = -47.3  Std R = 18.7  Min R = -121.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000658\n",
      "PolicyEntropy: -0.909\n",
      "PolicyLoss: -0.0024\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 4.31e+06\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5505   0.9072   3.8691   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0026   0.0128   1.6645   0.7971   0.5555\n",
      "***** Episode 18569, Mean R = -51.2  Std R = 21.2  Min R = -117.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.000977\n",
      "PolicyEntropy: -0.917\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 4.31e+06\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3968   0.9595   4.0235   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0071   0.0023   0.0117   1.6645   0.7971   0.5555\n",
      "Update Cnt = 600    ET =    175.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    18.8    -8.0    -0.7 |    39.3    45.9     0.5 |  -133.6  -227.1    -2.3 |   118.0    73.2    -0.0\n",
      "v_f      |   -6.85    1.33  -26.63 |    4.07    4.44    7.82 |  -18.02  -23.83  -48.68 |   11.64   14.77   -3.66\n",
      "vr_f     |     3.9 |     2.8 |     0.5 |    20.2\n",
      "r_i      |   969.9    24.0  2347.6 |   576.3   573.5    29.9 |     1.7  -994.8  2300.0 |  1984.2   993.4  2399.9\n",
      "v_i      |  -39.67   -1.53  -80.34 |   17.29   17.53    5.60 |  -69.96  -29.63  -89.97 |  -10.02   29.64  -70.06\n",
      "norm_rf  |    55.9 |    30.7 |     0.7 |   232.4\n",
      "norm_vf  |   28.21 |    7.71 |    6.91 |   50.57\n",
      "thrust   |    1195      99    8793 |    3704    3847    3593 |  -13752  -14707   -6357 |   14976   14521   15000\n",
      "norm_thrust |   10398 |    3476 |    2000 |   15000\n",
      "fuel     |     263 |      29 |     205 |     399\n",
      "rewards  |  -49.80 |   20.07 | -176.62 |  -26.76\n",
      "fuel_rewards |   -9.04 |    1.00 |  -13.70 |   -7.04\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.25 |    0.51 |    0.05 |    2.98\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   53.35 |   28.15 |   14.83 |  227.43\n",
      "tracking_rewards |  -40.76 |   19.26 | -162.92 |  -18.27\n",
      "steps    |     260 |      31 |     194 |     388\n",
      "***** Episode 18600, Mean R = -49.8  Std R = 21.3  Min R = -150.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.9\n",
      "ExplainedVarOld: 0.833\n",
      "KL: 0.000729\n",
      "PolicyEntropy: -0.92\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 7.83e+03\n",
      "TotalSteps: 4.32e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9444   1.7977   7.3110   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0011   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 18631, Mean R = -54.6  Std R = 39.6  Min R = -218.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000692\n",
      "PolicyEntropy: -0.917\n",
      "PolicyLoss: -0.00203\n",
      "Steps: 7.91e+03\n",
      "TotalSteps: 4.33e+06\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6112   0.6080   3.2024   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 18662, Mean R = -50.1  Std R = 18.0  Min R = -129.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000796\n",
      "PolicyEntropy: -0.919\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 4.34e+06\n",
      "ValFuncLoss: 0.00111\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7454   0.7743   3.4452   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 18693, Mean R = -51.4  Std R = 28.7  Min R = -199.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -0.928\n",
      "PolicyLoss: -0.00363\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 4.35e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6992   0.6450   3.6078   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0046   0.0025   0.0100   1.6645   0.7971   0.5555\n",
      "***** Episode 18724, Mean R = -48.8  Std R = 24.6  Min R = -175.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -0.933\n",
      "PolicyLoss: -0.00354\n",
      "Steps: 7.79e+03\n",
      "TotalSteps: 4.35e+06\n",
      "ValFuncLoss: 0.000807\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0207   0.8286   4.2315   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0016   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 18755, Mean R = -49.2  Std R = 16.1  Min R = -111.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.922\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.00069\n",
      "PolicyEntropy: -0.935\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 7.8e+03\n",
      "TotalSteps: 4.36e+06\n",
      "ValFuncLoss: 0.000782\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5330   0.5432   2.9850   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0011   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 18786, Mean R = -58.1  Std R = 45.9  Min R = -242.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -0.938\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 4.37e+06\n",
      "ValFuncLoss: 0.00126\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2093   0.9400   4.6782   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0015   0.0069   1.6645   0.7971   0.5555\n",
      "***** Episode 18817, Mean R = -43.6  Std R = 9.4  Min R = -72.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.92\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000781\n",
      "PolicyEntropy: -0.946\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8e+03\n",
      "TotalSteps: 4.38e+06\n",
      "ValFuncLoss: 0.000823\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2474   0.4856   2.7258   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0109   0.0055   0.0228   1.6645   0.7971   0.5555\n",
      "***** Episode 18848, Mean R = -54.8  Std R = 37.2  Min R = -214.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000604\n",
      "PolicyEntropy: -0.938\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 4.39e+06\n",
      "ValFuncLoss: 0.000973\n",
      "Variance: 0.209\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9623   0.6768   3.6387   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0020   0.0091   1.6645   0.7971   0.5555\n",
      "***** Episode 18879, Mean R = -50.8  Std R = 17.0  Min R = -116.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.896\n",
      "ExplainedVarOld: 0.857\n",
      "KL: 0.000688\n",
      "PolicyEntropy: -0.951\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 4.39e+06\n",
      "ValFuncLoss: 0.00117\n",
      "Variance: 0.207\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3729   0.4356   2.5049   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0070   0.0043   0.0168   1.6645   0.7971   0.5555\n",
      "Update Cnt = 610    ET =    174.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    26.8     0.2    -0.8 |    39.9    49.5     0.5 |  -143.9  -168.7    -2.1 |   136.4    89.7    -0.0\n",
      "v_f      |   -7.39    1.89  -28.85 |    3.74    4.39    6.67 |  -18.39  -11.80  -47.05 |    8.25   20.01   -4.08\n",
      "vr_f     |     4.0 |     3.1 |     0.3 |    35.0\n",
      "r_i      |  1000.4    43.8  2347.5 |   577.5   573.4    29.7 |     2.2  -995.2  2300.1 |  1978.5   999.0  2399.7\n",
      "v_i      |  -39.89    1.12  -79.72 |   17.65   17.64    5.77 |  -69.95  -29.87  -89.89 |  -10.75   29.82  -70.05\n",
      "norm_rf  |    61.1 |    32.1 |     3.4 |   171.0\n",
      "norm_vf  |   30.41 |    6.57 |    6.04 |   48.10\n",
      "thrust   |    1186      19    8708 |    3677    3854    3640 |  -13197  -14628   -6030 |   14999   14854   14999\n",
      "norm_thrust |   10320 |    3516 |    2000 |   15000\n",
      "fuel     |     260 |      35 |     209 |     476\n",
      "rewards  |  -51.12 |   28.19 | -241.97 |  -26.02\n",
      "fuel_rewards |   -8.94 |    1.20 |  -16.36 |   -7.19\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.25 |    0.48 |    0.02 |    2.91\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   58.95 |   28.80 |   19.31 |  165.99\n",
      "tracking_rewards |  -42.18 |   27.16 | -225.61 |  -17.15\n",
      "steps    |     259 |      36 |     190 |     440\n",
      "***** Episode 18910, Mean R = -49.8  Std R = 18.8  Min R = -99.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.00087\n",
      "PolicyEntropy: -0.958\n",
      "PolicyLoss: -0.00403\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 4.4e+06\n",
      "ValFuncLoss: 0.0012\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4269   0.9652   4.1428   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0086   0.0045   0.0186   1.6645   0.7971   0.5555\n",
      "***** Episode 18941, Mean R = -55.7  Std R = 33.1  Min R = -221.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000697\n",
      "PolicyEntropy: -0.967\n",
      "PolicyLoss: -0.00201\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 4.41e+06\n",
      "ValFuncLoss: 0.00106\n",
      "Variance: 0.207\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4829   0.5580   2.5828   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 18972, Mean R = -52.7  Std R = 28.9  Min R = -168.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -0.954\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 4.42e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.208\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4491   0.4400   2.3592   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0011   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 19003, Mean R = -55.2  Std R = 22.1  Min R = -126.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000707\n",
      "PolicyEntropy: -0.962\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 4.43e+06\n",
      "ValFuncLoss: 0.0012\n",
      "Variance: 0.207\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1802   0.4511   2.2581   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0008   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 19034, Mean R = -49.8  Std R = 20.0  Min R = -129.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.000675\n",
      "PolicyEntropy: -0.967\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 4.44e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.207\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8865   0.9709   5.2508   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 19065, Mean R = -43.3  Std R = 11.3  Min R = -86.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000968\n",
      "PolicyEntropy: -0.966\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 7.51e+03\n",
      "TotalSteps: 4.44e+06\n",
      "ValFuncLoss: 0.00155\n",
      "Variance: 0.207\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8323   0.6480   3.3650   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0020   0.0088   1.6645   0.7971   0.5555\n",
      "***** Episode 19096, Mean R = -49.2  Std R = 22.4  Min R = -154.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -0.984\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 4.45e+06\n",
      "ValFuncLoss: 0.000843\n",
      "Variance: 0.207\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.7786   0.3113   1.8837   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 19127, Mean R = -43.8  Std R = 11.5  Min R = -75.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.918\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.000711\n",
      "PolicyEntropy: -0.99\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 4.46e+06\n",
      "ValFuncLoss: 0.000824\n",
      "Variance: 0.207\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9375   0.2821   1.4851   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0026   0.0108   1.6645   0.7971   0.5555\n",
      "***** Episode 19158, Mean R = -45.9  Std R = 12.9  Min R = -91.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000763\n",
      "PolicyEntropy: -0.992\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 4.47e+06\n",
      "ValFuncLoss: 0.000652\n",
      "Variance: 0.206\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5898   0.6813   3.8547   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 19189, Mean R = -49.9  Std R = 18.0  Min R = -106.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000832\n",
      "PolicyEntropy: -0.993\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 4.47e+06\n",
      "ValFuncLoss: 0.000664\n",
      "Variance: 0.206\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4217   0.5555   3.0597   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0011   0.0055   1.6645   0.7971   0.5555\n",
      "Update Cnt = 620    ET =    175.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    26.4    -9.9    -0.8 |    34.9    48.2     0.4 |   -98.7  -166.9    -2.1 |   125.5    83.0    -0.0\n",
      "v_f      |   -7.36    1.67  -28.44 |    3.75    4.36    6.69 |  -19.33  -13.50  -46.07 |    8.89   21.02   -5.72\n",
      "vr_f     |     4.3 |     6.2 |     0.4 |    84.3\n",
      "r_i      |   998.1   -14.6  2349.2 |   582.8   561.7    28.6 |     4.7  -996.8  2300.2 |  1999.9   998.7  2399.9\n",
      "v_i      |  -39.19    0.14  -79.65 |   17.15   17.08    5.75 |  -69.99  -29.80  -89.86 |  -10.35   29.93  -70.01\n",
      "norm_rf  |    57.6 |    31.8 |     2.5 |   171.9\n",
      "norm_vf  |   29.99 |    6.65 |    8.91 |   48.48\n",
      "thrust   |    1161      63    8723 |    3683    3702    3592 |  -13003  -14532   -7095 |   14967   14796   15000\n",
      "norm_thrust |   10264 |    3500 |    2000 |   15000\n",
      "fuel     |     260 |      27 |     216 |     383\n",
      "rewards  |  -49.07 |   21.08 | -221.80 |  -25.97\n",
      "fuel_rewards |   -8.93 |    0.91 |  -13.17 |   -7.45\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.24 |    0.46 |    0.03 |    3.09\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   55.57 |   28.50 |   18.37 |  166.87\n",
      "tracking_rewards |  -40.14 |   20.35 | -209.10 |  -17.83\n",
      "steps    |     260 |      28 |     199 |     383\n",
      "***** Episode 19220, Mean R = -45.2  Std R = 13.9  Min R = -108.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.915\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -0.998\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 4.48e+06\n",
      "ValFuncLoss: 0.00094\n",
      "Variance: 0.206\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4718   0.8489   4.4866   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0023   0.0092   1.6645   0.7971   0.5555\n",
      "***** Episode 19251, Mean R = -48.7  Std R = 20.5  Min R = -125.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000905\n",
      "PolicyEntropy: -1\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 4.49e+06\n",
      "ValFuncLoss: 0.000889\n",
      "Variance: 0.205\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7657   0.9215   4.2603   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0014   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 19282, Mean R = -51.3  Std R = 22.8  Min R = -132.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.000969\n",
      "PolicyEntropy: -1\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 4.5e+06\n",
      "ValFuncLoss: 0.000996\n",
      "Variance: 0.205\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7054   0.5545   2.4824   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0011   0.0053   1.6645   0.7971   0.5555\n",
      "***** Episode 19313, Mean R = -54.8  Std R = 38.1  Min R = -224.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -0.995\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 4.51e+06\n",
      "ValFuncLoss: 0.000884\n",
      "Variance: 0.205\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0931   0.8152   4.3789   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 19344, Mean R = -44.2  Std R = 10.8  Min R = -82.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000865\n",
      "PolicyEntropy: -1.01\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 4.51e+06\n",
      "ValFuncLoss: 0.000509\n",
      "Variance: 0.203\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7425   0.6930   3.2197   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 19375, Mean R = -51.3  Std R = 30.3  Min R = -168.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000731\n",
      "PolicyEntropy: -1.02\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 4.52e+06\n",
      "ValFuncLoss: 0.000833\n",
      "Variance: 0.203\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8692   0.4920   2.9715   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0010   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 19406, Mean R = -58.8  Std R = 37.0  Min R = -187.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000974\n",
      "PolicyEntropy: -1.02\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 4.53e+06\n",
      "ValFuncLoss: 0.00102\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5003   1.0513   5.2290   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0014   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 19437, Mean R = -45.0  Std R = 12.0  Min R = -95.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -1.02\n",
      "PolicyLoss: -0.00404\n",
      "Steps: 7.66e+03\n",
      "TotalSteps: 4.54e+06\n",
      "ValFuncLoss: 0.000737\n",
      "Variance: 0.205\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5747   0.7880   3.8663   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0014   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 19468, Mean R = -49.5  Std R = 25.0  Min R = -140.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000733\n",
      "PolicyEntropy: -1.01\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 4.55e+06\n",
      "ValFuncLoss: 0.00101\n",
      "Variance: 0.206\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5775   0.4454   2.5791   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0007   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 19499, Mean R = -47.9  Std R = 19.4  Min R = -132.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000753\n",
      "PolicyEntropy: -1.02\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 4.56e+06\n",
      "ValFuncLoss: 0.00117\n",
      "Variance: 0.205\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3048   0.3703   2.4424   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0012   0.0047   1.6645   0.7971   0.5555\n",
      "Update Cnt = 630    ET =    175.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    25.5    -4.6    -0.7 |    31.0    44.1     0.5 |  -116.8  -246.6    -2.0 |    83.9    93.4    -0.0\n",
      "v_f      |   -7.11    1.33  -28.47 |    3.46    4.17    6.58 |  -16.88  -14.83  -46.65 |    2.88   14.05  -10.84\n",
      "vr_f     |     3.8 |     2.0 |     1.0 |    22.0\n",
      "r_i      |  1023.2    -9.2  2350.3 |   579.5   591.9    28.3 |     6.4  -994.4  2301.1 |  1985.7   997.2  2399.7\n",
      "v_i      |  -40.93   -1.62  -79.93 |   17.58   17.29    5.77 |  -69.74  -29.90  -89.91 |  -10.47   29.95  -70.14\n",
      "norm_rf  |    53.4 |    26.9 |     8.3 |   246.6\n",
      "norm_vf  |   29.84 |    6.70 |   11.35 |   48.40\n",
      "thrust   |    1214     114    8743 |    3690    3752    3575 |  -12934  -14919   -7295 |   14967   14493   14999\n",
      "norm_thrust |   10307 |    3489 |    2000 |   15000\n",
      "fuel     |     261 |      32 |     214 |     463\n",
      "rewards  |  -49.89 |   24.96 | -224.61 |  -24.76\n",
      "fuel_rewards |   -8.99 |    1.08 |  -15.92 |   -7.35\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.23 |    0.50 |    0.02 |    2.89\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   50.73 |   24.37 |   14.23 |  241.58\n",
      "tracking_rewards |  -40.90 |   24.02 | -209.69 |  -16.86\n",
      "steps    |     261 |      32 |     160 |     425\n",
      "***** Episode 19530, Mean R = -47.4  Std R = 10.7  Min R = -74.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000888\n",
      "PolicyEntropy: -1.02\n",
      "PolicyLoss: -0.00438\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 4.56e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.205\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5842   0.5365   2.9084   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 19561, Mean R = -47.0  Std R = 23.5  Min R = -156.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000995\n",
      "PolicyEntropy: -1.02\n",
      "PolicyLoss: -0.00347\n",
      "Steps: 7.82e+03\n",
      "TotalSteps: 4.57e+06\n",
      "ValFuncLoss: 0.00125\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1452   0.5117   2.7441   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 19592, Mean R = -48.4  Std R = 20.5  Min R = -119.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000576\n",
      "PolicyEntropy: -1.02\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 7.8e+03\n",
      "TotalSteps: 4.58e+06\n",
      "ValFuncLoss: 0.00102\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8291   0.6052   3.4240   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 19623, Mean R = -50.6  Std R = 19.4  Min R = -134.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00112\n",
      "PolicyEntropy: -1.03\n",
      "PolicyLoss: -0.00415\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 4.59e+06\n",
      "ValFuncLoss: 0.000946\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5992   0.6156   2.7415   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 19654, Mean R = -44.6  Std R = 15.4  Min R = -102.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000777\n",
      "PolicyEntropy: -1.03\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 7.69e+03\n",
      "TotalSteps: 4.6e+06\n",
      "ValFuncLoss: 0.000524\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.2577   0.5875   3.2965   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0061   0.0033   0.0126   1.6645   0.7971   0.5555\n",
      "***** Episode 19685, Mean R = -49.6  Std R = 17.1  Min R = -100.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.908\n",
      "KL: 0.000896\n",
      "PolicyEntropy: -1.03\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 4.6e+06\n",
      "ValFuncLoss: 0.00082\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7195   1.6270   7.3103   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0029   0.0117   1.6645   0.7971   0.5555\n",
      "***** Episode 19716, Mean R = -48.1  Std R = 12.1  Min R = -75.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000863\n",
      "PolicyEntropy: -1.04\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 4.61e+06\n",
      "ValFuncLoss: 0.000633\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.9805   0.3267   1.9367   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0013   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 19747, Mean R = -50.2  Std R = 27.3  Min R = -181.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.917\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.000666\n",
      "PolicyEntropy: -1.05\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 4.62e+06\n",
      "ValFuncLoss: 0.000975\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1084   0.4359   2.5060   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0018   0.0081   1.6645   0.7971   0.5555\n",
      "***** Episode 19778, Mean R = -45.3  Std R = 12.3  Min R = -87.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.000727\n",
      "PolicyEntropy: -1.05\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 4.63e+06\n",
      "ValFuncLoss: 0.000691\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8360   0.7945   3.9800   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0020   0.0086   1.6645   0.7971   0.5555\n",
      "***** Episode 19809, Mean R = -49.9  Std R = 14.5  Min R = -96.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.927\n",
      "ExplainedVarOld: 0.911\n",
      "KL: 0.000821\n",
      "PolicyEntropy: -1.06\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 4.64e+06\n",
      "ValFuncLoss: 0.00082\n",
      "Variance: 0.204\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9620   1.1298   5.1871   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "Update Cnt = 640    ET =    173.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    29.8     2.7    -0.7 |    35.2    41.6     0.4 |  -116.3  -142.7    -2.1 |   109.6   100.4    -0.0\n",
      "v_f      |   -6.89    1.25  -28.12 |    3.74    4.47    6.80 |  -18.50  -20.48  -46.64 |    7.84   13.14   -9.75\n",
      "vr_f     |     3.8 |     1.8 |     0.5 |    14.4\n",
      "r_i      |  1015.7    27.8  2349.5 |   586.3   577.7    28.6 |    10.4  -998.4  2300.1 |  1997.8   992.8  2399.7\n",
      "v_i      |  -39.90    0.76  -80.08 |   17.40   17.00    6.09 |  -69.81  -29.80  -89.99 |  -10.27   29.93  -70.02\n",
      "norm_rf  |    56.4 |    26.3 |     4.4 |   153.6\n",
      "norm_vf  |   29.57 |    6.78 |   11.07 |   48.42\n",
      "thrust   |    1190      17    8764 |    3621    3724    3551 |  -13327  -14378   -6361 |   14978   14348   15000\n",
      "norm_thrust |   10279 |    3488 |    2000 |   15000\n",
      "fuel     |     259 |      27 |     204 |     425\n",
      "rewards  |  -48.49 |   18.49 | -181.22 |  -27.69\n",
      "fuel_rewards |   -8.89 |    0.91 |  -14.61 |   -7.04\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.25 |    0.48 |    0.04 |    2.84\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   53.40 |   23.73 |   14.93 |  148.65\n",
      "tracking_rewards |  -39.60 |   17.77 | -166.61 |  -19.60\n",
      "steps    |     259 |      32 |     169 |     395\n",
      "***** Episode 19840, Mean R = -51.2  Std R = 15.5  Min R = -100.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.00118\n",
      "PolicyEntropy: -1.06\n",
      "PolicyLoss: -0.00397\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 4.64e+06\n",
      "ValFuncLoss: 0.000862\n",
      "Variance: 0.203\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2724   0.9340   4.7208   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 19871, Mean R = -48.9  Std R = 17.4  Min R = -109.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000926\n",
      "PolicyEntropy: -1.07\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 4.65e+06\n",
      "ValFuncLoss: 0.000864\n",
      "Variance: 0.202\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6516   1.4989   6.7492   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 19902, Mean R = -44.2  Std R = 10.6  Min R = -83.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000999\n",
      "PolicyEntropy: -1.09\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 7.62e+03\n",
      "TotalSteps: 4.66e+06\n",
      "ValFuncLoss: 0.000785\n",
      "Variance: 0.201\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1935   1.0520   4.9363   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 19933, Mean R = -44.9  Std R = 15.3  Min R = -100.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000884\n",
      "PolicyEntropy: -1.1\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 7.83e+03\n",
      "TotalSteps: 4.67e+06\n",
      "ValFuncLoss: 0.00131\n",
      "Variance: 0.201\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6425   1.0754   4.5782   9.8966   3.7521   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 19964, Mean R = -42.5  Std R = 9.4  Min R = -70.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.867\n",
      "ExplainedVarOld: 0.881\n",
      "KL: 0.00086\n",
      "PolicyEntropy: -1.11\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 4.68e+06\n",
      "ValFuncLoss: 0.00155\n",
      "Variance: 0.2\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0912   1.5260   6.6066   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 19995, Mean R = -40.6  Std R = 8.5  Min R = -65.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.909\n",
      "ExplainedVarOld: 0.908\n",
      "KL: 0.000894\n",
      "PolicyEntropy: -1.11\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 7.76e+03\n",
      "TotalSteps: 4.68e+06\n",
      "ValFuncLoss: 0.000881\n",
      "Variance: 0.2\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5362   1.0220   4.7090   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 20026, Mean R = -42.0  Std R = 10.9  Min R = -73.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.00066\n",
      "PolicyEntropy: -1.12\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 7.9e+03\n",
      "TotalSteps: 4.69e+06\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.199\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7914   0.6374   3.7984   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 20057, Mean R = -44.7  Std R = 13.5  Min R = -90.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000892\n",
      "PolicyEntropy: -1.13\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 4.7e+06\n",
      "ValFuncLoss: 0.000748\n",
      "Variance: 0.199\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7107   0.5033   3.0837   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 20088, Mean R = -44.1  Std R = 11.3  Min R = -78.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -1.14\n",
      "PolicyLoss: -0.00357\n",
      "Steps: 7.87e+03\n",
      "TotalSteps: 4.71e+06\n",
      "ValFuncLoss: 0.000749\n",
      "Variance: 0.198\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6110   0.5752   2.7252   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 20119, Mean R = -44.1  Std R = 12.5  Min R = -85.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.915\n",
      "KL: 0.000833\n",
      "PolicyEntropy: -1.13\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 4.71e+06\n",
      "ValFuncLoss: 0.000764\n",
      "Variance: 0.197\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5688   0.6522   3.4861   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "Update Cnt = 650    ET =    173.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    31.2     5.2    -0.7 |    37.1    38.9     0.5 |  -161.5  -146.9    -1.7 |   125.4    77.3    -0.0\n",
      "v_f      |   -7.55    1.60  -28.59 |    4.04    4.78    6.49 |  -17.11  -13.56  -61.96 |   27.20   46.50   -8.47\n",
      "vr_f     |     3.9 |     3.5 |     1.0 |    55.9\n",
      "r_i      |  1034.6    61.2  2351.4 |   571.5   547.5    29.2 |     3.9  -988.6  2301.0 |  1994.5   984.5  2399.9\n",
      "v_i      |  -39.92    0.16  -80.13 |   17.10   17.24    5.83 |  -69.69  -29.44  -89.90 |  -10.17   29.64  -70.01\n",
      "norm_rf  |    55.6 |    28.4 |     3.7 |   212.3\n",
      "norm_vf  |   30.14 |    7.05 |    9.06 |   82.11\n",
      "thrust   |    1191      34    8773 |    3484    3679    3471 |  -13102  -14949   -5863 |   14960   14675   15000\n",
      "norm_thrust |   10211 |    3442 |    2000 |   15000\n",
      "fuel     |     254 |      21 |     200 |     373\n",
      "rewards  |  -44.31 |   13.55 | -129.36 |  -24.98\n",
      "fuel_rewards |   -8.72 |    0.72 |  -12.80 |   -6.91\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.31 |    0.44 |    0.17 |    3.07\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   53.05 |   25.39 |   17.29 |  207.27\n",
      "tracking_rewards |  -35.60 |   13.10 | -116.56 |  -17.02\n",
      "steps    |     255 |      27 |     139 |     328\n",
      "***** Episode 20150, Mean R = -47.2  Std R = 19.7  Min R = -129.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.00082\n",
      "PolicyEntropy: -1.13\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 4.72e+06\n",
      "ValFuncLoss: 0.000412\n",
      "Variance: 0.197\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4416   0.9050   4.3086   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 20181, Mean R = -42.3  Std R = 9.2  Min R = -70.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.00099\n",
      "PolicyEntropy: -1.14\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 7.74e+03\n",
      "TotalSteps: 4.73e+06\n",
      "ValFuncLoss: 0.000397\n",
      "Variance: 0.197\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6601   0.6536   3.8049   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 20212, Mean R = -47.3  Std R = 19.1  Min R = -109.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.908\n",
      "KL: 0.000676\n",
      "PolicyEntropy: -1.13\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 7.94e+03\n",
      "TotalSteps: 4.74e+06\n",
      "ValFuncLoss: 0.000759\n",
      "Variance: 0.197\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9383   0.6769   4.2873   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 20243, Mean R = -48.6  Std R = 14.5  Min R = -92.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000787\n",
      "PolicyEntropy: -1.12\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 4.75e+06\n",
      "ValFuncLoss: 0.000766\n",
      "Variance: 0.198\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8332   0.5318   2.7962   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0010   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 20274, Mean R = -51.7  Std R = 27.7  Min R = -160.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000973\n",
      "PolicyEntropy: -1.14\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 4.75e+06\n",
      "ValFuncLoss: 0.000784\n",
      "Variance: 0.197\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6193   0.9607   5.2446   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 20305, Mean R = -46.2  Std R = 19.1  Min R = -110.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -1.14\n",
      "PolicyLoss: -0.00364\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 4.76e+06\n",
      "ValFuncLoss: 0.000561\n",
      "Variance: 0.197\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8925   0.9917   3.6783   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0078   0.0039   0.0179   1.6645   0.7971   0.5555\n",
      "***** Episode 20336, Mean R = -50.7  Std R = 32.3  Min R = -213.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.9\n",
      "ExplainedVarOld: 0.898\n",
      "KL: 0.000928\n",
      "PolicyEntropy: -1.15\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 4.77e+06\n",
      "ValFuncLoss: 0.00191\n",
      "Variance: 0.196\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9990   1.2508   6.7264   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0007   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 20367, Mean R = -45.6  Std R = 14.4  Min R = -105.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.908\n",
      "KL: 0.000978\n",
      "PolicyEntropy: -1.15\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 4.78e+06\n",
      "ValFuncLoss: 0.000744\n",
      "Variance: 0.195\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8058   0.8630   4.5802   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 20398, Mean R = -46.2  Std R = 13.2  Min R = -86.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000965\n",
      "PolicyEntropy: -1.16\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 7.78e+03\n",
      "TotalSteps: 4.79e+06\n",
      "ValFuncLoss: 0.000408\n",
      "Variance: 0.196\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9486   1.1580   4.9160   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0012   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 20429, Mean R = -45.2  Std R = 15.3  Min R = -115.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000973\n",
      "PolicyEntropy: -1.15\n",
      "PolicyLoss: -0.00387\n",
      "Steps: 7.54e+03\n",
      "TotalSteps: 4.79e+06\n",
      "ValFuncLoss: 0.000596\n",
      "Variance: 0.195\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8395   0.7408   4.3446   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "Update Cnt = 660    ET =    172.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    29.9    -0.5    -0.7 |    35.8    40.4     0.4 |   -78.0  -145.0    -2.0 |   126.2   128.3    -0.0\n",
      "v_f      |   -7.37    1.65  -27.20 |    3.82    4.45    6.72 |  -16.07  -14.79  -44.58 |    8.28   22.48   -4.02\n",
      "vr_f     |     3.5 |     1.7 |     0.6 |    13.4\n",
      "r_i      |  1014.1    12.5  2353.9 |   576.4   575.5    28.1 |    27.0  -998.5  2300.2 |  1995.7   995.1  2399.7\n",
      "v_i      |  -42.23   -0.54  -80.06 |   16.67   17.86    5.85 |  -69.90  -29.86  -89.99 |  -10.23   29.94  -70.04\n",
      "norm_rf  |    55.2 |    27.5 |     8.5 |   145.4\n",
      "norm_vf  |   28.81 |    6.80 |    5.19 |   46.28\n",
      "thrust   |    1279      74    8821 |    3564    3744    3445 |  -13276  -14224   -6559 |   14996   14208   15000\n",
      "norm_thrust |   10305 |    3442 |    2000 |   15000\n",
      "fuel     |     256 |      27 |     209 |     465\n",
      "rewards  |  -46.92 |   19.39 | -213.00 |  -25.04\n",
      "fuel_rewards |   -8.80 |    0.92 |  -15.96 |   -7.20\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.27 |    0.45 |    0.04 |    2.89\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   52.74 |   24.76 |   17.73 |  140.43\n",
      "tracking_rewards |  -38.12 |   18.67 | -197.04 |  -16.62\n",
      "steps    |     255 |      29 |     189 |     421\n",
      "***** Episode 20460, Mean R = -45.3  Std R = 15.5  Min R = -102.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000877\n",
      "PolicyEntropy: -1.15\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 7.96e+03\n",
      "TotalSteps: 4.8e+06\n",
      "ValFuncLoss: 0.000452\n",
      "Variance: 0.194\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5196   0.7198   3.4584   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0048   0.0027   0.0100   1.6645   0.7971   0.5555\n",
      "***** Episode 20491, Mean R = -42.5  Std R = 10.5  Min R = -73.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.933\n",
      "ExplainedVarOld: 0.915\n",
      "KL: 0.000795\n",
      "PolicyEntropy: -1.15\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 4.81e+06\n",
      "ValFuncLoss: 0.000512\n",
      "Variance: 0.194\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5344   0.4692   2.3874   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0065   0.0036   0.0131   1.6645   0.7971   0.5555\n",
      "***** Episode 20522, Mean R = -48.6  Std R = 17.0  Min R = -120.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.00087\n",
      "PolicyEntropy: -1.15\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 7.62e+03\n",
      "TotalSteps: 4.82e+06\n",
      "ValFuncLoss: 0.00061\n",
      "Variance: 0.194\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8662   1.5831   5.8709   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 20553, Mean R = -48.5  Std R = 18.6  Min R = -112.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -1.16\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 7.77e+03\n",
      "TotalSteps: 4.83e+06\n",
      "ValFuncLoss: 0.000633\n",
      "Variance: 0.193\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5902   0.4181   2.8046   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 20584, Mean R = -42.5  Std R = 9.0  Min R = -68.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.916\n",
      "ExplainedVarOld: 0.887\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -1.16\n",
      "PolicyLoss: -0.00377\n",
      "Steps: 7.78e+03\n",
      "TotalSteps: 4.83e+06\n",
      "ValFuncLoss: 0.000593\n",
      "Variance: 0.193\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4640   0.3708   2.3269   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 20615, Mean R = -48.6  Std R = 19.9  Min R = -115.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -1.16\n",
      "PolicyLoss: -0.00357\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 4.84e+06\n",
      "ValFuncLoss: 0.000717\n",
      "Variance: 0.192\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3944   1.0654   4.8945   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 20646, Mean R = -41.9  Std R = 8.3  Min R = -62.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.905\n",
      "KL: 0.000839\n",
      "PolicyEntropy: -1.16\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 4.85e+06\n",
      "ValFuncLoss: 0.00036\n",
      "Variance: 0.192\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8660   0.8111   3.8008   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0046   0.0023   0.0092   1.6645   0.7971   0.5555\n",
      "***** Episode 20677, Mean R = -48.7  Std R = 19.0  Min R = -102.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.918\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -1.17\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 4.86e+06\n",
      "ValFuncLoss: 0.000621\n",
      "Variance: 0.192\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6577   0.5812   2.8129   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 20708, Mean R = -43.8  Std R = 10.9  Min R = -77.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -1.18\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 4.87e+06\n",
      "ValFuncLoss: 0.000536\n",
      "Variance: 0.192\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6644   0.7532   3.6676   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 20739, Mean R = -42.1  Std R = 12.2  Min R = -89.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000984\n",
      "PolicyEntropy: -1.2\n",
      "PolicyLoss: -0.00363\n",
      "Steps: 7.82e+03\n",
      "TotalSteps: 4.87e+06\n",
      "ValFuncLoss: 0.000578\n",
      "Variance: 0.19\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5745   0.5441   2.7922   9.8966   4.0912   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0047   1.6645   0.7971   0.5555\n",
      "Update Cnt = 670    ET =    171.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    22.8     3.3    -0.7 |    30.6    42.3     0.4 |  -110.1  -135.0    -1.9 |   109.3    98.6    -0.0\n",
      "v_f      |   -7.00    1.56  -26.63 |    3.22    3.58    6.07 |  -16.25  -12.35  -49.65 |    6.58   12.71   -4.07\n",
      "vr_f     |     3.8 |     2.8 |     0.6 |    35.5\n",
      "r_i      |   953.5   -17.4  2348.5 |   561.3   565.3    29.7 |    11.9  -996.5  2300.5 |  1992.5   989.1  2399.8\n",
      "v_i      |  -40.13    1.73  -79.76 |   16.77   17.42    5.88 |  -69.27  -29.79  -89.96 |  -10.03   29.96  -70.00\n",
      "norm_rf  |    50.4 |    26.8 |     3.0 |   143.4\n",
      "norm_vf  |   28.00 |    6.08 |    7.73 |   51.32\n",
      "thrust   |    1231     -19    8810 |    3490    3728    3354 |  -12478  -14282   -7945 |   14960   14526   15000\n",
      "norm_thrust |   10246 |    3388 |    2000 |   15000\n",
      "fuel     |     255 |      23 |     200 |     364\n",
      "rewards  |  -44.99 |   14.67 | -120.04 |  -23.60\n",
      "fuel_rewards |   -8.76 |    0.77 |  -12.52 |   -6.86\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.34 |    0.49 |    0.09 |    3.52\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   48.52 |   23.37 |   15.57 |  138.44\n",
      "tracking_rewards |  -36.24 |   14.16 | -108.28 |  -15.32\n",
      "steps    |     256 |      29 |     190 |     320\n",
      "***** Episode 20770, Mean R = -42.6  Std R = 11.9  Min R = -83.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000769\n",
      "PolicyEntropy: -1.21\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 7.79e+03\n",
      "TotalSteps: 4.88e+06\n",
      "ValFuncLoss: 0.000459\n",
      "Variance: 0.189\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1354   1.7606   7.8777   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 20801, Mean R = -43.9  Std R = 10.8  Min R = -79.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.00125\n",
      "PolicyEntropy: -1.21\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 4.89e+06\n",
      "ValFuncLoss: 0.00052\n",
      "Variance: 0.19\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3193   0.8016   3.6655   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 20832, Mean R = -48.5  Std R = 22.8  Min R = -157.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000671\n",
      "PolicyEntropy: -1.21\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 4.9e+06\n",
      "ValFuncLoss: 0.000534\n",
      "Variance: 0.19\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3358   0.3687   2.3459   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0007   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 20863, Mean R = -40.5  Std R = 11.5  Min R = -94.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.916\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -1.21\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 4.91e+06\n",
      "ValFuncLoss: 0.000689\n",
      "Variance: 0.189\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2062   1.3760   6.7463   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0009   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 20894, Mean R = -41.6  Std R = 18.1  Min R = -128.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.00132\n",
      "PolicyEntropy: -1.21\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 7.75e+03\n",
      "TotalSteps: 4.91e+06\n",
      "ValFuncLoss: 0.000529\n",
      "Variance: 0.188\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7899   0.8380   4.3891   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 20925, Mean R = -44.7  Std R = 20.8  Min R = -130.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00087\n",
      "PolicyEntropy: -1.23\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 7.81e+03\n",
      "TotalSteps: 4.92e+06\n",
      "ValFuncLoss: 0.000516\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6787   0.8976   4.6036   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 20956, Mean R = -40.7  Std R = 6.7  Min R = -54.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000762\n",
      "PolicyEntropy: -1.23\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 4.93e+06\n",
      "ValFuncLoss: 0.000373\n",
      "Variance: 0.186\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6605   0.7018   3.5193   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0015   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 20987, Mean R = -44.4  Std R = 11.2  Min R = -73.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000793\n",
      "PolicyEntropy: -1.24\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 4.94e+06\n",
      "ValFuncLoss: 0.000373\n",
      "Variance: 0.186\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3203   0.3245   1.9773   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0016   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 21018, Mean R = -52.0  Std R = 24.8  Min R = -154.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000789\n",
      "PolicyEntropy: -1.25\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 4.95e+06\n",
      "ValFuncLoss: 0.000482\n",
      "Variance: 0.186\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0012   0.5512   3.2107   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 21049, Mean R = -45.9  Std R = 16.2  Min R = -113.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000701\n",
      "PolicyEntropy: -1.26\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 4.95e+06\n",
      "ValFuncLoss: 0.000352\n",
      "Variance: 0.185\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8789   0.4319   2.4963   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0056   0.0019   0.0089   1.6645   0.7971   0.5555\n",
      "Update Cnt = 680    ET =    173.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    26.6     3.5    -0.7 |    32.3    35.1     0.4 |   -95.3  -126.4    -1.7 |   124.8   115.3    -0.0\n",
      "v_f      |   -7.12    2.10  -26.37 |    3.49    3.60    5.52 |  -17.87  -10.96  -40.48 |    5.03   15.37   -5.80\n",
      "vr_f     |     3.9 |     4.3 |     0.8 |    57.8\n",
      "r_i      |   997.7   -27.8  2349.1 |   578.1   584.5    28.9 |     2.2  -998.2  2300.5 |  1998.8   991.9  2399.9\n",
      "v_i      |  -39.40   -0.11  -79.58 |   16.53   17.21    5.77 |  -69.69  -29.69  -89.88 |  -10.02   29.96  -70.21\n",
      "norm_rf  |    49.0 |    24.3 |     2.5 |   149.6\n",
      "norm_vf  |   27.81 |    5.71 |    8.70 |   42.92\n",
      "thrust   |    1186      80    8797 |    3490    3665    3322 |  -12087  -14527   -6841 |   14994   14593   15000\n",
      "norm_thrust |   10203 |    3367 |    2000 |   15000\n",
      "fuel     |     256 |      24 |     211 |     412\n",
      "rewards  |  -44.22 |   16.72 | -156.97 |  -24.55\n",
      "fuel_rewards |   -8.78 |    0.81 |  -14.16 |   -7.28\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.33 |    0.50 |    0.03 |    3.17\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   46.69 |   21.15 |   13.52 |  144.55\n",
      "tracking_rewards |  -35.43 |   16.09 | -142.82 |  -16.34\n",
      "steps    |     258 |      27 |     186 |     370\n",
      "***** Episode 21080, Mean R = -39.9  Std R = 9.2  Min R = -67.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.919\n",
      "KL: 0.000853\n",
      "PolicyEntropy: -1.25\n",
      "PolicyLoss: -0.00338\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 4.96e+06\n",
      "ValFuncLoss: 0.000519\n",
      "Variance: 0.186\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1938   0.3801   1.9632   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 21111, Mean R = -43.0  Std R = 15.7  Min R = -122.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000668\n",
      "PolicyEntropy: -1.25\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.03e+03\n",
      "TotalSteps: 4.97e+06\n",
      "ValFuncLoss: 0.000366\n",
      "Variance: 0.186\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2203   0.9913   5.2071   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0014   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 21142, Mean R = -43.5  Std R = 11.9  Min R = -94.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.000887\n",
      "PolicyEntropy: -1.25\n",
      "PolicyLoss: -0.00345\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 4.98e+06\n",
      "ValFuncLoss: 0.000298\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5647   0.5298   2.4826   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0014   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 21173, Mean R = -47.0  Std R = 20.8  Min R = -133.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.00074\n",
      "PolicyEntropy: -1.26\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 4.99e+06\n",
      "ValFuncLoss: 0.000368\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7673   0.4552   2.4799   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0009   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 21204, Mean R = -44.6  Std R = 18.9  Min R = -113.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.00111\n",
      "PolicyEntropy: -1.26\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 4.99e+06\n",
      "ValFuncLoss: 0.000481\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0666   0.6722   3.8681   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0010   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 21235, Mean R = -44.9  Std R = 12.3  Min R = -97.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000998\n",
      "PolicyEntropy: -1.27\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 7.85e+03\n",
      "TotalSteps: 5e+06\n",
      "ValFuncLoss: 0.000328\n",
      "Variance: 0.186\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3541   0.4720   2.7629   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0022   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 21266, Mean R = -42.7  Std R = 16.8  Min R = -115.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.000899\n",
      "PolicyEntropy: -1.26\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 5.01e+06\n",
      "ValFuncLoss: 0.000477\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0605   0.7432   3.1933   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0054   0.0027   0.0100   1.6645   0.7971   0.5555\n",
      "***** Episode 21297, Mean R = -42.7  Std R = 11.9  Min R = -81.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000829\n",
      "PolicyEntropy: -1.27\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 7.75e+03\n",
      "TotalSteps: 5.02e+06\n",
      "ValFuncLoss: 0.000698\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9380   1.2163   5.2072   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0013   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 21328, Mean R = -44.0  Std R = 10.2  Min R = -73.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.001\n",
      "PolicyEntropy: -1.27\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 5.03e+06\n",
      "ValFuncLoss: 0.00047\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4104   1.3321   5.7028   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0022   0.0081   1.6645   0.7971   0.5555\n",
      "***** Episode 21359, Mean R = -54.1  Std R = 40.7  Min R = -189.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -1.26\n",
      "PolicyLoss: -0.0021\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 5.03e+06\n",
      "ValFuncLoss: 0.00086\n",
      "Variance: 0.188\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5580   1.0990   5.3586   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0014   0.0052   1.6645   0.7971   0.5555\n",
      "Update Cnt = 690    ET =    172.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.8     4.5    -0.7 |    29.4    31.3     0.4 |   -51.4   -96.0    -1.8 |   112.0    95.7    -0.0\n",
      "v_f      |   -6.73    1.67  -26.45 |    3.28    3.55    5.66 |  -15.73  -11.48  -38.39 |    5.77   13.89   -2.88\n",
      "vr_f     |     4.4 |     5.1 |     0.5 |    63.5\n",
      "r_i      |   985.9    23.5  2352.6 |   581.8   560.2    29.4 |    14.1  -994.7  2300.0 |  1990.0   999.6  2399.3\n",
      "v_i      |  -40.32    0.19  -80.43 |   17.78   17.54    5.48 |  -69.92  -29.94  -89.98 |  -10.06   29.99  -70.27\n",
      "norm_rf  |    44.2 |    21.9 |     0.2 |   113.4\n",
      "norm_vf  |   27.77 |    5.65 |    3.48 |   40.54\n",
      "thrust   |    1232      70    8839 |    3538    3631    3352 |  -12893  -13957   -5984 |   14981   14218   15000\n",
      "norm_thrust |   10247 |    3402 |    2000 |   15000\n",
      "fuel     |     257 |      28 |     209 |     422\n",
      "rewards  |  -44.96 |   20.33 | -189.58 |  -26.09\n",
      "fuel_rewards |   -8.83 |    0.97 |  -14.50 |   -7.20\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.32 |    0.54 |    0.03 |    3.86\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   42.66 |   18.07 |   15.60 |  108.35\n",
      "tracking_rewards |  -36.13 |   19.52 | -175.24 |  -17.47\n",
      "steps    |     258 |      30 |     190 |     393\n",
      "***** Episode 21390, Mean R = -43.1  Std R = 22.6  Min R = -159.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000704\n",
      "PolicyEntropy: -1.27\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 7.86e+03\n",
      "TotalSteps: 5.04e+06\n",
      "ValFuncLoss: 0.000826\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9654   1.0591   5.5084   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 21421, Mean R = -43.6  Std R = 15.8  Min R = -93.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000988\n",
      "PolicyEntropy: -1.27\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8e+03\n",
      "TotalSteps: 5.05e+06\n",
      "ValFuncLoss: 0.000734\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1090   1.5027   7.0028   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 21452, Mean R = -39.7  Std R = 10.3  Min R = -73.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -1.28\n",
      "PolicyLoss: -0.00372\n",
      "Steps: 7.78e+03\n",
      "TotalSteps: 5.06e+06\n",
      "ValFuncLoss: 0.000478\n",
      "Variance: 0.187\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9243   1.3460   5.6083   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 21483, Mean R = -40.2  Std R = 11.3  Min R = -73.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -1.3\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 5.07e+06\n",
      "ValFuncLoss: 0.00046\n",
      "Variance: 0.185\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2345   0.8779   3.7186   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0016   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 21514, Mean R = -38.5  Std R = 7.7  Min R = -64.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.00089\n",
      "PolicyEntropy: -1.31\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.03e+03\n",
      "TotalSteps: 5.07e+06\n",
      "ValFuncLoss: 0.000483\n",
      "Variance: 0.185\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8734   0.8387   4.3847   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 21545, Mean R = -45.2  Std R = 13.2  Min R = -87.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.929\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000839\n",
      "PolicyEntropy: -1.33\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 5.08e+06\n",
      "ValFuncLoss: 0.000953\n",
      "Variance: 0.184\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3402   0.7872   3.8360   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0054   0.0030   0.0114   1.6645   0.7971   0.5555\n",
      "***** Episode 21576, Mean R = -45.4  Std R = 14.5  Min R = -93.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000868\n",
      "PolicyEntropy: -1.33\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 7.78e+03\n",
      "TotalSteps: 5.09e+06\n",
      "ValFuncLoss: 0.000877\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5145   0.3177   1.9760   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0017   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 21607, Mean R = -43.0  Std R = 10.5  Min R = -82.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000822\n",
      "PolicyEntropy: -1.34\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 5.1e+06\n",
      "ValFuncLoss: 0.000661\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3806   0.7282   4.0496   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0017   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 21638, Mean R = -43.7  Std R = 11.0  Min R = -81.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000892\n",
      "PolicyEntropy: -1.33\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 5.11e+06\n",
      "ValFuncLoss: 0.000724\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3505   1.1817   5.6748   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 21669, Mean R = -41.6  Std R = 11.9  Min R = -79.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000658\n",
      "PolicyEntropy: -1.34\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 5.11e+06\n",
      "ValFuncLoss: 0.000456\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6758   0.4505   3.0171   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0031   0.0100   1.6645   0.7971   0.5555\n",
      "Update Cnt = 700    ET =    173.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    22.1     3.5    -0.6 |    30.0    32.6     0.4 |   -50.5  -107.6    -1.6 |   111.2    80.2    -0.0\n",
      "v_f      |   -6.73    1.54  -25.54 |    3.45    3.07    5.00 |  -16.44   -6.36  -40.24 |    6.98   12.85   -8.42\n",
      "vr_f     |     3.8 |     1.9 |     1.1 |    17.2\n",
      "r_i      |   975.9     4.6  2347.8 |   552.2   574.4    28.4 |     1.4  -992.1  2300.3 |  1987.1   999.6  2399.8\n",
      "v_i      |  -38.11    1.03  -80.06 |   17.15   17.29    5.77 |  -69.78  -30.00  -89.93 |  -10.21   29.99  -70.00\n",
      "norm_rf  |    44.2 |    22.5 |     1.9 |   117.9\n",
      "norm_vf  |   26.84 |    5.09 |    9.00 |   42.01\n",
      "thrust   |    1169      -4    8879 |    3415    3531    3300 |  -11188  -14856   -5586 |   14987   14577   14999\n",
      "norm_thrust |   10203 |    3336 |    2000 |   15000\n",
      "fuel     |     255 |      21 |     219 |     368\n",
      "rewards  |  -42.63 |   13.67 | -154.19 |  -22.88\n",
      "fuel_rewards |   -8.77 |    0.72 |  -12.65 |   -7.53\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.55 |    0.07 |    4.03\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   42.73 |   18.79 |   15.37 |  112.90\n",
      "tracking_rewards |  -33.86 |   13.15 | -141.55 |  -14.84\n",
      "steps    |     257 |      27 |     194 |     347\n",
      "***** Episode 21700, Mean R = -45.6  Std R = 22.5  Min R = -154.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000707\n",
      "PolicyEntropy: -1.34\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 7.77e+03\n",
      "TotalSteps: 5.12e+06\n",
      "ValFuncLoss: 0.000564\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9413   1.2952   5.9379   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0009   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 21731, Mean R = -48.0  Std R = 15.2  Min R = -90.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.914\n",
      "KL: 0.000905\n",
      "PolicyEntropy: -1.34\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.03e+03\n",
      "TotalSteps: 5.13e+06\n",
      "ValFuncLoss: 0.000667\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3272   0.7655   4.5931   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 21762, Mean R = -39.4  Std R = 8.6  Min R = -60.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -1.35\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 5.14e+06\n",
      "ValFuncLoss: 0.000459\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3744   0.4004   2.4443   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 21793, Mean R = -39.4  Std R = 10.1  Min R = -72.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000702\n",
      "PolicyEntropy: -1.35\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8e+03\n",
      "TotalSteps: 5.15e+06\n",
      "ValFuncLoss: 0.000487\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2007   0.8308   3.8640   9.8966   4.1354   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 21824, Mean R = -40.7  Std R = 9.3  Min R = -68.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000855\n",
      "PolicyEntropy: -1.36\n",
      "PolicyLoss: -0.00359\n",
      "Steps: 7.77e+03\n",
      "TotalSteps: 5.15e+06\n",
      "ValFuncLoss: 0.000456\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6923   2.4029   9.4063   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 21855, Mean R = -42.2  Std R = 10.0  Min R = -67.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.000703\n",
      "PolicyEntropy: -1.36\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 5.16e+06\n",
      "ValFuncLoss: 0.000401\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3449   1.0766   5.3513   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 21886, Mean R = -42.8  Std R = 12.2  Min R = -92.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -1.35\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 7.96e+03\n",
      "TotalSteps: 5.17e+06\n",
      "ValFuncLoss: 0.000307\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9163   1.2108   5.3176   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0029   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 21917, Mean R = -37.6  Std R = 12.2  Min R = -85.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.0012\n",
      "PolicyEntropy: -1.36\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 7.9e+03\n",
      "TotalSteps: 5.18e+06\n",
      "ValFuncLoss: 0.000281\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4255   0.6277   3.8165   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0061   0.0030   0.0112   1.6645   0.7971   0.5555\n",
      "***** Episode 21948, Mean R = -46.8  Std R = 19.7  Min R = -116.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00091\n",
      "PolicyEntropy: -1.35\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 5.18e+06\n",
      "ValFuncLoss: 0.00057\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1151   1.2464   6.0447   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0017   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 21979, Mean R = -44.6  Std R = 20.8  Min R = -124.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000854\n",
      "PolicyEntropy: -1.35\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 5.19e+06\n",
      "ValFuncLoss: 0.000555\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9459   1.2734   5.6612   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0048   1.6645   0.7971   0.5555\n",
      "Update Cnt = 710    ET =    170.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.6     2.0    -0.6 |    26.7    32.7     0.4 |   -38.9  -105.3    -1.6 |   108.6    87.3    -0.0\n",
      "v_f      |   -6.07    1.55  -24.79 |    3.25    3.01    5.56 |  -14.95   -7.56  -40.46 |    4.25   12.69   -6.75\n",
      "vr_f     |     4.2 |     2.5 |     1.5 |    31.1\n",
      "r_i      |   968.4   -16.6  2351.6 |   549.9   557.2    28.3 |     2.4  -998.3  2300.9 |  1991.0   984.3  2400.0\n",
      "v_i      |  -42.14   -0.29  -79.46 |   17.34   16.93    5.79 |  -69.64  -29.48  -89.87 |  -10.09   29.73  -70.01\n",
      "norm_rf  |    41.7 |    22.7 |     2.5 |   129.2\n",
      "norm_vf  |   25.91 |    5.74 |    7.02 |   42.15\n",
      "thrust   |    1348      75    8825 |    3466    3445    3260 |  -11960  -14404   -7238 |   14998   14388   15000\n",
      "norm_thrust |   10154 |    3334 |    2000 |   15000\n",
      "fuel     |     254 |      20 |     208 |     339\n",
      "rewards  |  -42.04 |   13.78 | -124.34 |  -23.92\n",
      "fuel_rewards |   -8.73 |    0.69 |  -11.66 |   -7.17\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.35 |    0.51 |    0.03 |    3.74\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   40.05 |   19.39 |   11.56 |  124.17\n",
      "tracking_rewards |  -33.30 |   13.31 | -112.67 |  -15.60\n",
      "steps    |     257 |      25 |     194 |     326\n",
      "***** Episode 22010, Mean R = -38.7  Std R = 8.6  Min R = -68.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.00106\n",
      "PolicyEntropy: -1.35\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 7.70e+03\n",
      "TotalSteps: 5.2e+06\n",
      "ValFuncLoss: 0.000448\n",
      "Variance: 0.184\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7396   1.1850   5.2684   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 22041, Mean R = -38.3  Std R = 7.1  Min R = -53.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000861\n",
      "PolicyEntropy: -1.36\n",
      "PolicyLoss: -0.00352\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 5.21e+06\n",
      "ValFuncLoss: 0.000473\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3096   1.1793   5.0034   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0018   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 22072, Mean R = -40.4  Std R = 11.2  Min R = -70.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.000991\n",
      "PolicyEntropy: -1.37\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 5.22e+06\n",
      "ValFuncLoss: 0.000419\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8466   0.9978   4.2191   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 22103, Mean R = -44.3  Std R = 15.5  Min R = -114.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000628\n",
      "PolicyEntropy: -1.38\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 5.23e+06\n",
      "ValFuncLoss: 0.000358\n",
      "Variance: 0.183\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.6154   0.5763   3.0136   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0015   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 22134, Mean R = -45.6  Std R = 23.0  Min R = -154.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000796\n",
      "PolicyEntropy: -1.39\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.30e+03\n",
      "TotalSteps: 5.23e+06\n",
      "ValFuncLoss: 0.000488\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4333   1.0191   4.6681   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0011   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 22165, Mean R = -43.7  Std R = 17.1  Min R = -99.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -1.4\n",
      "PolicyLoss: -0.00352\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 5.24e+06\n",
      "ValFuncLoss: 0.000624\n",
      "Variance: 0.182\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8433   0.6460   4.0074   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 22196, Mean R = -44.6  Std R = 31.7  Min R = -211.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000945\n",
      "PolicyEntropy: -1.4\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 5.25e+06\n",
      "ValFuncLoss: 0.000506\n",
      "Variance: 0.181\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.4318   0.5343   2.9041   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 22227, Mean R = -40.2  Std R = 10.6  Min R = -70.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00084\n",
      "PolicyEntropy: -1.4\n",
      "PolicyLoss: -0.00387\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 5.26e+06\n",
      "ValFuncLoss: 0.000426\n",
      "Variance: 0.181\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6345   1.0687   4.7174   9.8966   4.6923   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 22258, Mean R = -43.2  Std R = 9.7  Min R = -62.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.00124\n",
      "PolicyEntropy: -1.41\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 5.27e+06\n",
      "ValFuncLoss: 0.000532\n",
      "Variance: 0.181\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9310   2.4466  11.2028  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 22289, Mean R = -42.2  Std R = 11.0  Min R = -69.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.00155\n",
      "PolicyEntropy: -1.4\n",
      "PolicyLoss: -0.00198\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 5.27e+06\n",
      "ValFuncLoss: 0.000463\n",
      "Variance: 0.181\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7601   1.4483   7.6410  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "Update Cnt = 720    ET =    176.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    19.1     8.7    -0.6 |    27.2    31.4     0.4 |   -36.4  -116.2    -1.9 |   100.9   103.1    -0.0\n",
      "v_f      |   -6.13    1.70  -23.58 |    3.19    2.85    5.55 |  -18.40   -6.34  -41.01 |    2.22   13.20   -4.39\n",
      "vr_f     |     3.9 |     2.1 |     1.1 |    16.4\n",
      "r_i      |   956.3    28.8  2351.0 |   551.2   574.0    28.9 |     3.1  -989.8  2300.2 |  1991.9   997.1  2398.3\n",
      "v_i      |  -39.46   -0.34  -79.96 |   17.41   17.22    5.81 |  -69.78  -29.56  -89.99 |  -10.12   29.80  -70.05\n",
      "norm_rf  |    40.4 |    23.1 |     1.7 |   142.1\n",
      "norm_vf  |   24.76 |    5.71 |    4.65 |   42.73\n",
      "thrust   |    1222      73    8916 |    3386    3464    3251 |  -12156  -14225   -4713 |   14979   14417   15000\n",
      "norm_thrust |   10200 |    3316 |    2000 |   15000\n",
      "fuel     |     259 |      20 |     205 |     382\n",
      "rewards  |  -42.36 |   16.39 | -211.03 |  -22.57\n",
      "fuel_rewards |   -8.89 |    0.70 |  -13.12 |   -7.07\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.49 |    0.12 |    3.38\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   38.95 |   19.63 |   12.52 |  137.11\n",
      "tracking_rewards |  -33.46 |   15.89 | -197.91 |  -14.25\n",
      "steps    |     261 |      26 |     192 |     384\n",
      "***** Episode 22320, Mean R = -41.1  Std R = 8.4  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000865\n",
      "PolicyEntropy: -1.41\n",
      "PolicyLoss: -0.00361\n",
      "Steps: 7.89e+03\n",
      "TotalSteps: 5.28e+06\n",
      "ValFuncLoss: 0.000436\n",
      "Variance: 0.179\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6493   0.9806   4.6056  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 22351, Mean R = -43.2  Std R = 13.6  Min R = -95.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000862\n",
      "PolicyEntropy: -1.41\n",
      "PolicyLoss: -0.00372\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 5.29e+06\n",
      "ValFuncLoss: 0.000539\n",
      "Variance: 0.18\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8930   0.4432   2.6238  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 22382, Mean R = -42.4  Std R = 13.0  Min R = -90.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000911\n",
      "PolicyEntropy: -1.43\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 5.3e+06\n",
      "ValFuncLoss: 0.000337\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5132   1.2386   5.6742  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0017   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 22413, Mean R = -46.0  Std R = 18.3  Min R = -104.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.00088\n",
      "PolicyEntropy: -1.44\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 5.31e+06\n",
      "ValFuncLoss: 0.000522\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9730   0.5414   3.3071  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 22444, Mean R = -46.6  Std R = 20.5  Min R = -131.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000883\n",
      "PolicyEntropy: -1.43\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 5.31e+06\n",
      "ValFuncLoss: 0.000466\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4730   0.9634   4.2061  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 22475, Mean R = -45.1  Std R = 19.6  Min R = -110.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.0007\n",
      "PolicyEntropy: -1.44\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 5.32e+06\n",
      "ValFuncLoss: 0.000582\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3670   0.5063   2.9665  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0017   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 22506, Mean R = -42.1  Std R = 27.1  Min R = -187.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.00077\n",
      "PolicyEntropy: -1.44\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.02e+03\n",
      "TotalSteps: 5.33e+06\n",
      "ValFuncLoss: 0.000509\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4309   1.3614   6.1224  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 22537, Mean R = -47.4  Std R = 22.2  Min R = -114.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000658\n",
      "PolicyEntropy: -1.44\n",
      "PolicyLoss: -0.00242\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 5.34e+06\n",
      "ValFuncLoss: 0.00103\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4942   1.3840   6.8211  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0005   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 22568, Mean R = -43.6  Std R = 20.3  Min R = -141.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00107\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 5.35e+06\n",
      "ValFuncLoss: 0.000543\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4914   0.8637   4.3849  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 22599, Mean R = -42.4  Std R = 10.1  Min R = -77.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000667\n",
      "PolicyEntropy: -1.46\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 7.9e+03\n",
      "TotalSteps: 5.35e+06\n",
      "ValFuncLoss: 0.000479\n",
      "Variance: 0.176\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5801   0.9252   4.2960  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "Update Cnt = 730    ET =    174.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.3     9.1    -0.6 |    25.2    27.3     0.4 |   -53.4   -83.3    -1.7 |    87.9    82.5    -0.0\n",
      "v_f      |   -6.09    2.22  -24.20 |    3.46    2.88    4.96 |  -18.04   -6.47  -39.28 |   10.37   12.37   -9.54\n",
      "vr_f     |     4.0 |     2.3 |     0.9 |    17.0\n",
      "r_i      |   958.6   -27.9  2350.1 |   584.2   566.4    29.8 |     2.1  -987.5  2300.0 |  1996.0   999.5  2399.9\n",
      "v_i      |  -38.67    0.79  -80.38 |   16.96   17.45    5.64 |  -69.98  -29.79  -89.79 |  -10.26   29.63  -70.08\n",
      "norm_rf  |    37.7 |    21.4 |     2.5 |   107.8\n",
      "norm_vf  |   25.44 |    5.03 |   10.56 |   39.94\n",
      "thrust   |    1202      72    8920 |    3434    3524    3248 |  -11619  -14481   -6683 |   14988   14290   15000\n",
      "norm_thrust |   10230 |    3335 |    2000 |   15000\n",
      "fuel     |     260 |      25 |     218 |     397\n",
      "rewards  |  -44.32 |   19.89 | -187.06 |  -23.80\n",
      "fuel_rewards |   -8.92 |    0.87 |  -13.65 |   -7.50\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.34 |    0.53 |    0.02 |    3.30\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   37.15 |   17.12 |   10.82 |  102.82\n",
      "tracking_rewards |  -35.40 |   19.19 | -174.47 |  -15.42\n",
      "steps    |     261 |      27 |     201 |     381\n",
      "***** Episode 22630, Mean R = -44.4  Std R = 26.3  Min R = -180.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 7.88e+03\n",
      "TotalSteps: 5.36e+06\n",
      "ValFuncLoss: 0.000504\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8454   1.0440   4.7136  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 22661, Mean R = -43.7  Std R = 16.1  Min R = -109.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000744\n",
      "PolicyEntropy: -1.46\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 5.37e+06\n",
      "ValFuncLoss: 0.000709\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9842   1.1435   4.7745  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 22692, Mean R = -38.4  Std R = 7.5  Min R = -53.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.93\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000887\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00362\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 5.38e+06\n",
      "ValFuncLoss: 0.0005\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3685   1.0530   5.7597  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 22723, Mean R = -43.2  Std R = 14.7  Min R = -116.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00086\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 7.83e+03\n",
      "TotalSteps: 5.39e+06\n",
      "ValFuncLoss: 0.000624\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0908   1.2690   5.6459  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0012   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 22754, Mean R = -48.1  Std R = 22.6  Min R = -130.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000871\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 5.39e+06\n",
      "ValFuncLoss: 0.000683\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5502   1.9331   8.6766  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0024   0.0090   1.6645   0.7971   0.5555\n",
      "***** Episode 22785, Mean R = -43.1  Std R = 12.8  Min R = -97.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00384\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 5.4e+06\n",
      "ValFuncLoss: 0.000476\n",
      "Variance: 0.179\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4826   0.7494   3.9545  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 22816, Mean R = -44.6  Std R = 12.1  Min R = -95.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000817\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 5.41e+06\n",
      "ValFuncLoss: 0.000425\n",
      "Variance: 0.179\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9588   1.5679   7.7193  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 22847, Mean R = -41.7  Std R = 9.9  Min R = -64.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -1.45\n",
      "PolicyLoss: -0.00359\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 5.42e+06\n",
      "ValFuncLoss: 0.000449\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0939   1.4594   7.0118  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 22878, Mean R = -42.6  Std R = 10.9  Min R = -73.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -1.46\n",
      "PolicyLoss: -0.00221\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 5.43e+06\n",
      "ValFuncLoss: 0.000349\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2699   0.9489   3.9468  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 22909, Mean R = -44.6  Std R = 11.9  Min R = -74.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -1.47\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 5.44e+06\n",
      "ValFuncLoss: 0.000541\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6143   0.9854   4.9219  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0022   0.0089   1.6645   0.7971   0.5555\n",
      "Update Cnt = 740    ET =    175.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.9     9.9    -0.6 |    26.5    26.7     0.4 |   -87.2   -78.6    -1.9 |   113.3    79.8    -0.0\n",
      "v_f      |   -6.25    1.96  -24.56 |    3.52    3.05    5.83 |  -18.89   -6.99  -41.84 |    6.99   12.25   -6.93\n",
      "vr_f     |     4.1 |     2.3 |     0.9 |    16.5\n",
      "r_i      |   992.6    41.6  2351.6 |   596.1   570.6    27.5 |     3.4  -989.9  2300.2 |  1992.9   999.2  2400.0\n",
      "v_i      |  -40.27    0.34  -79.51 |   16.78   17.79    5.73 |  -69.49  -29.97  -89.93 |  -10.35   29.89  -70.13\n",
      "norm_rf  |    37.7 |    20.4 |     3.1 |   118.2\n",
      "norm_vf  |   25.80 |    6.00 |    9.68 |   43.92\n",
      "thrust   |    1255      67    8844 |    3401    3509    3254 |  -11252  -14615   -6418 |   14993   14287   15000\n",
      "norm_thrust |   10149 |    3356 |    2000 |   15000\n",
      "fuel     |     257 |      21 |     205 |     342\n",
      "rewards  |  -43.52 |   14.48 | -130.55 |  -25.21\n",
      "fuel_rewards |   -8.82 |    0.72 |  -11.77 |   -7.08\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.31 |    0.49 |    0.09 |    2.93\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   36.35 |   17.05 |   11.24 |  113.20\n",
      "tracking_rewards |  -34.70 |   13.98 | -119.44 |  -16.24\n",
      "steps    |     260 |      26 |     196 |     338\n",
      "***** Episode 22940, Mean R = -45.3  Std R = 18.0  Min R = -113.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000641\n",
      "PolicyEntropy: -1.47\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.03e+03\n",
      "TotalSteps: 5.44e+06\n",
      "ValFuncLoss: 0.000827\n",
      "Variance: 0.178\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9612   0.6526   3.2040  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0046   0.0025   0.0091   1.6645   0.7971   0.5555\n",
      "***** Episode 22971, Mean R = -40.4  Std R = 10.8  Min R = -77.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000853\n",
      "PolicyEntropy: -1.48\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 5.45e+06\n",
      "ValFuncLoss: 0.000678\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0573   1.0020   5.2110  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0079   0.0036   0.0144   1.6645   0.7971   0.5555\n",
      "***** Episode 23002, Mean R = -49.8  Std R = 29.3  Min R = -170.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -1.49\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 5.46e+06\n",
      "ValFuncLoss: 0.000641\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0904   1.6496   6.9869  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0018   0.0080   1.6645   0.7971   0.5555\n",
      "***** Episode 23033, Mean R = -40.3  Std R = 15.7  Min R = -112.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000816\n",
      "PolicyEntropy: -1.49\n",
      "PolicyLoss: -0.00229\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 5.47e+06\n",
      "ValFuncLoss: 0.000353\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0287   0.7151   4.2526  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0068   0.0038   0.0120   1.6645   0.7971   0.5555\n",
      "***** Episode 23064, Mean R = -46.3  Std R = 20.8  Min R = -114.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000966\n",
      "PolicyEntropy: -1.5\n",
      "PolicyLoss: -0.0035\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 5.48e+06\n",
      "ValFuncLoss: 0.000521\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3861   0.9573   4.1693  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0022   0.0099   1.6645   0.7971   0.5555\n",
      "***** Episode 23095, Mean R = -39.9  Std R = 8.5  Min R = -55.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -1.49\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.09e+03\n",
      "TotalSteps: 5.48e+06\n",
      "ValFuncLoss: 0.000394\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7466   0.7710   4.0364  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 23126, Mean R = -43.1  Std R = 10.7  Min R = -80.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.00113\n",
      "PolicyEntropy: -1.5\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 5.49e+06\n",
      "ValFuncLoss: 0.000388\n",
      "Variance: 0.177\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7660   0.8921   5.0673  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0026   0.0100   1.6645   0.7971   0.5555\n",
      "***** Episode 23157, Mean R = -46.0  Std R = 23.9  Min R = -153.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.001\n",
      "PolicyEntropy: -1.52\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 5.5e+06\n",
      "ValFuncLoss: 0.000457\n",
      "Variance: 0.176\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3564   0.8823   4.1663  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0013   0.0072   1.6645   0.7971   0.5555\n",
      "***** Episode 23188, Mean R = -42.0  Std R = 12.5  Min R = -75.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.00088\n",
      "PolicyEntropy: -1.53\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 5.51e+06\n",
      "ValFuncLoss: 0.000359\n",
      "Variance: 0.175\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3291   0.7494   4.7349  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 23219, Mean R = -41.0  Std R = 12.3  Min R = -92.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.929\n",
      "KL: 0.000867\n",
      "PolicyEntropy: -1.54\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 5.52e+06\n",
      "ValFuncLoss: 0.000368\n",
      "Variance: 0.175\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9837   1.0900   5.5650  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0034   1.6645   0.7971   0.5555\n",
      "Update Cnt = 750    ET =    178.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    18.6     4.6    -0.6 |    22.7    24.9     0.4 |   -32.9   -70.2    -1.8 |    96.7    65.6    -0.0\n",
      "v_f      |   -5.54    1.67  -23.69 |    2.67    2.78    4.94 |  -13.37   -5.12  -41.02 |    0.25   12.05  -10.54\n",
      "vr_f     |     4.5 |     4.1 |     1.5 |    61.3\n",
      "r_i      |  1003.1     1.2  2347.8 |   586.2   582.5    28.0 |     6.8  -992.2  2300.2 |  1994.1  1000.0  2399.9\n",
      "v_i      |  -41.18   -0.49  -80.26 |   16.92   17.41    5.90 |  -69.88  -29.91  -89.89 |  -10.01   29.93  -70.10\n",
      "norm_rf  |    34.6 |    17.5 |     2.4 |   112.2\n",
      "norm_vf  |   24.68 |    5.01 |   11.44 |   42.65\n",
      "thrust   |    1259      84    8863 |    3316    3450    3234 |  -12138  -14206   -7790 |   14986   14557   15000\n",
      "norm_thrust |   10117 |    3340 |    2000 |   15000\n",
      "fuel     |     262 |      21 |     216 |     375\n",
      "rewards  |  -44.01 |   19.53 | -178.90 |  -23.37\n",
      "fuel_rewards |   -9.00 |    0.73 |  -12.89 |   -7.44\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.32 |    0.51 |    0.06 |    3.22\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   33.53 |   13.54 |   11.54 |  107.24\n",
      "tracking_rewards |  -35.01 |   18.95 | -166.01 |  -14.56\n",
      "steps    |     266 |      26 |     197 |     358\n",
      "***** Episode 23250, Mean R = -51.4  Std R = 30.6  Min R = -178.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00129\n",
      "PolicyEntropy: -1.53\n",
      "PolicyLoss: -0.00356\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 5.53e+06\n",
      "ValFuncLoss: 0.000646\n",
      "Variance: 0.175\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.1000   0.2741   1.7665  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 23281, Mean R = -41.2  Std R = 7.5  Min R = -58.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.913\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.000649\n",
      "PolicyEntropy: -1.54\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 5.53e+06\n",
      "ValFuncLoss: 0.000465\n",
      "Variance: 0.175\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7539   1.3587   6.8470  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0014   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 23312, Mean R = -45.9  Std R = 16.2  Min R = -104.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -1.54\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 5.54e+06\n",
      "ValFuncLoss: 0.000479\n",
      "Variance: 0.175\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5292   1.3633   6.5010  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0009   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 23343, Mean R = -46.7  Std R = 29.7  Min R = -158.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.00131\n",
      "PolicyEntropy: -1.55\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 5.55e+06\n",
      "ValFuncLoss: 0.000456\n",
      "Variance: 0.174\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7381   0.4375   2.6440  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0055   0.0023   0.0089   1.6645   0.7971   0.5555\n",
      "***** Episode 23374, Mean R = -39.7  Std R = 8.8  Min R = -72.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -1.54\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 5.56e+06\n",
      "ValFuncLoss: 0.00057\n",
      "Variance: 0.174\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.3131   0.4201   2.1520  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 23405, Mean R = -41.1  Std R = 14.9  Min R = -106.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000766\n",
      "PolicyEntropy: -1.55\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 7.95e+03\n",
      "TotalSteps: 5.57e+06\n",
      "ValFuncLoss: 0.000585\n",
      "Variance: 0.173\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6831   1.1594   5.6873  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 23436, Mean R = -43.8  Std R = 14.4  Min R = -100.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000834\n",
      "PolicyEntropy: -1.54\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 5.57e+06\n",
      "ValFuncLoss: 0.000518\n",
      "Variance: 0.174\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4411   1.3380   6.2445  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 23467, Mean R = -41.0  Std R = 10.4  Min R = -77.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.889\n",
      "KL: 0.000867\n",
      "PolicyEntropy: -1.55\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 7.87e+03\n",
      "TotalSteps: 5.58e+06\n",
      "ValFuncLoss: 0.000711\n",
      "Variance: 0.173\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9860   1.7429   8.5446  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 23498, Mean R = -42.6  Std R = 20.8  Min R = -128.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000958\n",
      "PolicyEntropy: -1.56\n",
      "PolicyLoss: -0.00379\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 5.59e+06\n",
      "ValFuncLoss: 0.000786\n",
      "Variance: 0.173\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3477   2.0119   6.9390  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 23529, Mean R = -42.0  Std R = 10.2  Min R = -79.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -1.56\n",
      "PolicyLoss: -0.00341\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 5.6e+06\n",
      "ValFuncLoss: 0.000738\n",
      "Variance: 0.173\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1847   0.7750   4.6979  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "Update Cnt = 760    ET =    173.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.7     2.0    -0.6 |    27.3    30.6     0.3 |   -39.6   -94.1    -1.5 |   102.0    94.3    -0.0\n",
      "v_f      |   -5.84    1.76  -23.17 |    3.08    3.17    4.58 |  -16.82   -7.93  -36.22 |    2.96   14.21  -10.17\n",
      "vr_f     |     4.2 |     2.8 |     1.1 |    25.2\n",
      "r_i      |   993.7   -72.3  2350.6 |   591.5   579.3    29.2 |     6.3  -999.3  2300.0 |  1984.8   997.0  2399.6\n",
      "v_i      |  -39.34    0.54  -80.09 |   17.30   17.41    5.94 |  -69.80  -29.96  -90.00 |  -10.19   29.93  -70.15\n",
      "norm_rf  |    39.6 |    20.9 |     3.5 |   104.8\n",
      "norm_vf  |   24.33 |    4.73 |   10.93 |   38.62\n",
      "thrust   |    1215      49    8904 |    3380    3424    3179 |  -11802  -14165   -7210 |   14992   14111   15000\n",
      "norm_thrust |   10155 |    3300 |    2000 |   15000\n",
      "fuel     |     258 |      21 |     210 |     359\n",
      "rewards  |  -42.80 |   17.01 | -158.92 |  -24.65\n",
      "fuel_rewards |   -8.88 |    0.72 |  -12.36 |   -7.24\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.35 |    0.52 |    0.02 |    3.67\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   37.47 |   17.84 |   13.56 |   99.82\n",
      "tracking_rewards |  -33.92 |   16.46 | -146.56 |  -16.19\n",
      "steps    |     262 |      24 |     199 |     341\n",
      "***** Episode 23560, Mean R = -44.2  Std R = 22.1  Min R = -151.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.00098\n",
      "PolicyEntropy: -1.57\n",
      "PolicyLoss: -0.00214\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 5.61e+06\n",
      "ValFuncLoss: 0.00105\n",
      "Variance: 0.172\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8956   0.5093   2.9331  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0007   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 23591, Mean R = -41.5  Std R = 16.6  Min R = -122.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00083\n",
      "PolicyEntropy: -1.58\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 5.62e+06\n",
      "ValFuncLoss: 0.000888\n",
      "Variance: 0.172\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9068   2.3328   9.1717  11.2028   5.9310   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0010   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 23622, Mean R = -39.3  Std R = 12.5  Min R = -81.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.0011\n",
      "PolicyEntropy: -1.58\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 5.62e+06\n",
      "ValFuncLoss: 0.000663\n",
      "Variance: 0.172\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2945   3.1932  12.5079  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 23653, Mean R = -40.8  Std R = 10.5  Min R = -72.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.934\n",
      "KL: 0.000915\n",
      "PolicyEntropy: -1.58\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 5.63e+06\n",
      "ValFuncLoss: 0.000957\n",
      "Variance: 0.172\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0528   2.1739   9.2456  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0002   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 23684, Mean R = -39.3  Std R = 10.8  Min R = -83.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00125\n",
      "PolicyEntropy: -1.59\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 5.64e+06\n",
      "ValFuncLoss: 0.000818\n",
      "Variance: 0.171\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8257   2.4926  10.3735  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0013   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 23715, Mean R = -42.7  Std R = 15.9  Min R = -96.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.00112\n",
      "PolicyEntropy: -1.59\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 5.65e+06\n",
      "ValFuncLoss: 0.000914\n",
      "Variance: 0.171\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9431   1.0871   4.7609  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 23746, Mean R = -41.9  Std R = 19.3  Min R = -118.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000729\n",
      "PolicyEntropy: -1.6\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 5.66e+06\n",
      "ValFuncLoss: 0.00104\n",
      "Variance: 0.171\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4245   1.2992   6.8213  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 23777, Mean R = -44.2  Std R = 14.7  Min R = -106.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000841\n",
      "PolicyEntropy: -1.6\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 5.66e+06\n",
      "ValFuncLoss: 0.000731\n",
      "Variance: 0.171\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7558   1.4204   6.5051  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 23808, Mean R = -45.9  Std R = 24.9  Min R = -155.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00124\n",
      "PolicyEntropy: -1.6\n",
      "PolicyLoss: -0.00225\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 5.67e+06\n",
      "ValFuncLoss: 0.000754\n",
      "Variance: 0.171\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0474   1.8929   9.4765  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0012   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 23839, Mean R = -42.5  Std R = 11.9  Min R = -85.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.00115\n",
      "PolicyEntropy: -1.59\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 5.68e+06\n",
      "ValFuncLoss: 0.000594\n",
      "Variance: 0.171\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5952   1.4826   7.2730  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0044   1.6645   0.7971   0.5555\n",
      "Update Cnt = 770    ET =    177.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.0     0.2    -0.6 |    26.0    28.9     0.4 |   -41.0   -97.4    -1.6 |   120.5    64.1    -0.0\n",
      "v_f      |   -5.81    1.91  -23.74 |    3.21    2.87    4.44 |  -15.84   -5.90  -36.90 |    4.00    9.76  -12.00\n",
      "vr_f     |     4.5 |     6.1 |     1.4 |    97.3\n",
      "r_i      |   975.6    46.1  2349.8 |   593.0   554.3    28.4 |     4.8  -996.7  2300.3 |  1990.4   999.8  2399.8\n",
      "v_i      |  -38.54   -0.98  -79.99 |   17.16   17.24    5.89 |  -69.70  -29.89  -89.96 |  -10.21   29.97  -70.11\n",
      "norm_rf  |    37.7 |    22.2 |     1.6 |   123.6\n",
      "norm_vf  |   24.86 |    4.62 |   12.20 |   38.34\n",
      "thrust   |    1152     104    8842 |    3336    3378    3164 |  -13256  -14224   -6453 |   14983   14348   15000\n",
      "norm_thrust |   10057 |    3305 |    2000 |   15000\n",
      "fuel     |     258 |      20 |     217 |     333\n",
      "rewards  |  -42.44 |   16.28 | -155.08 |  -23.28\n",
      "fuel_rewards |   -8.86 |    0.67 |  -11.43 |   -7.45\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.53 |    0.09 |    3.28\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   36.48 |   18.91 |   13.01 |  118.59\n",
      "tracking_rewards |  -33.58 |   15.83 | -144.02 |  -15.32\n",
      "steps    |     264 |      26 |     206 |     327\n",
      "***** Episode 23870, Mean R = -46.3  Std R = 18.3  Min R = -128.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000949\n",
      "PolicyEntropy: -1.61\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8e+03\n",
      "TotalSteps: 5.69e+06\n",
      "ValFuncLoss: 0.00106\n",
      "Variance: 0.17\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8349   1.0127   5.6829  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 23901, Mean R = -41.5  Std R = 8.5  Min R = -64.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000839\n",
      "PolicyEntropy: -1.61\n",
      "PolicyLoss: -0.00387\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 5.7e+06\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.17\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7035   1.2662   5.4011  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 23932, Mean R = -41.1  Std R = 12.4  Min R = -85.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.000837\n",
      "PolicyEntropy: -1.61\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 5.7e+06\n",
      "ValFuncLoss: 0.000969\n",
      "Variance: 0.169\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9179   2.0855   8.9179  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 23963, Mean R = -38.9  Std R = 7.6  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000796\n",
      "PolicyEntropy: -1.62\n",
      "PolicyLoss: -0.00203\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 5.71e+06\n",
      "ValFuncLoss: 0.001\n",
      "Variance: 0.17\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0805   0.8427   3.4289  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 23994, Mean R = -43.0  Std R = 18.9  Min R = -122.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000733\n",
      "PolicyEntropy: -1.62\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8e+03\n",
      "TotalSteps: 5.72e+06\n",
      "ValFuncLoss: 0.000693\n",
      "Variance: 0.169\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7392   1.3421   6.1712  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 24025, Mean R = -37.6  Std R = 7.1  Min R = -52.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000682\n",
      "PolicyEntropy: -1.63\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 5.73e+06\n",
      "ValFuncLoss: 0.000471\n",
      "Variance: 0.169\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7118   1.3495   6.3328  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 24056, Mean R = -41.9  Std R = 13.6  Min R = -103.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -1.64\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.11e+03\n",
      "TotalSteps: 5.74e+06\n",
      "ValFuncLoss: 0.000673\n",
      "Variance: 0.169\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2298   0.7258   4.5402  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 24087, Mean R = -40.6  Std R = 11.7  Min R = -87.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000797\n",
      "PolicyEntropy: -1.64\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8e+03\n",
      "TotalSteps: 5.74e+06\n",
      "ValFuncLoss: 0.000877\n",
      "Variance: 0.168\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1697   1.5975   6.4759  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 24118, Mean R = -39.6  Std R = 11.6  Min R = -83.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000967\n",
      "PolicyEntropy: -1.64\n",
      "PolicyLoss: -0.00184\n",
      "Steps: 8.11e+03\n",
      "TotalSteps: 5.75e+06\n",
      "ValFuncLoss: 0.0011\n",
      "Variance: 0.168\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9823   1.0506   6.6541  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0016   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 24149, Mean R = -46.6  Std R = 23.8  Min R = -145.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -1.65\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 5.76e+06\n",
      "ValFuncLoss: 0.000839\n",
      "Variance: 0.168\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0118   0.6967   4.0289  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0015   0.0056   1.6645   0.7971   0.5555\n",
      "Update Cnt = 780    ET =    174.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    25.9     3.0    -0.6 |    26.4    25.0     0.4 |   -39.1   -79.1    -1.6 |   103.5    69.4    -0.0\n",
      "v_f      |   -6.36    1.96  -24.10 |    3.26    2.63    4.34 |  -17.36   -5.33  -41.18 |    4.36   10.59  -10.43\n",
      "vr_f     |     4.1 |     3.2 |     1.4 |    40.8\n",
      "r_i      |  1066.6   -11.6  2349.3 |   572.2   562.4    29.1 |     8.9  -983.3  2300.6 |  1999.4   997.9  2399.8\n",
      "v_i      |  -39.72   -0.37  -80.19 |   17.43   17.15    5.75 |  -69.93  -29.93  -89.90 |  -10.14   29.87  -70.00\n",
      "norm_rf  |    39.3 |    21.3 |     1.5 |   107.8\n",
      "norm_vf  |   25.33 |    4.44 |   10.44 |   42.44\n",
      "thrust   |    1216      81    8894 |    3235    3350    3130 |  -11939  -14528   -5745 |   14949   14792   15000\n",
      "norm_thrust |   10077 |    3245 |    2000 |   15000\n",
      "fuel     |     254 |      20 |     211 |     350\n",
      "rewards  |  -40.80 |   13.56 | -145.67 |  -24.49\n",
      "fuel_rewards |   -8.73 |    0.68 |  -12.03 |   -7.24\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.34 |    0.52 |    0.24 |    3.09\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   38.05 |   17.44 |   14.62 |  102.85\n",
      "tracking_rewards |  -32.07 |   13.09 | -134.28 |  -15.82\n",
      "steps    |     259 |      24 |     202 |     331\n",
      "***** Episode 24180, Mean R = -37.2  Std R = 7.4  Min R = -55.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000739\n",
      "PolicyEntropy: -1.66\n",
      "PolicyLoss: -0.0037\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 5.77e+06\n",
      "ValFuncLoss: 0.000823\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1436   1.0101   5.0669  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 24211, Mean R = -39.4  Std R = 10.4  Min R = -71.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000891\n",
      "PolicyEntropy: -1.67\n",
      "PolicyLoss: -0.00348\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 5.78e+06\n",
      "ValFuncLoss: 0.00097\n",
      "Variance: 0.166\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5194   0.3157   2.3249  12.5079   6.2945   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 24242, Mean R = -42.7  Std R = 25.9  Min R = -180.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000846\n",
      "PolicyEntropy: -1.68\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 5.79e+06\n",
      "ValFuncLoss: 0.00119\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1497   2.9322  13.2323  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 24273, Mean R = -37.3  Std R = 8.2  Min R = -60.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.00163\n",
      "PolicyEntropy: -1.68\n",
      "PolicyLoss: -0.00151\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 5.79e+06\n",
      "ValFuncLoss: 0.00156\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5705   1.8612   7.0949  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 24304, Mean R = -45.6  Std R = 26.5  Min R = -169.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000706\n",
      "PolicyEntropy: -1.68\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 7.92e+03\n",
      "TotalSteps: 5.8e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0161   0.5965   3.0034  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 24335, Mean R = -44.7  Std R = 24.1  Min R = -169.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000887\n",
      "PolicyEntropy: -1.68\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 7.94e+03\n",
      "TotalSteps: 5.81e+06\n",
      "ValFuncLoss: 0.00113\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3625   0.6871   3.9925  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0012   0.0053   1.6645   0.7971   0.5555\n",
      "***** Episode 24366, Mean R = -42.9  Std R = 14.4  Min R = -89.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.915\n",
      "KL: 0.000762\n",
      "PolicyEntropy: -1.67\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 5.82e+06\n",
      "ValFuncLoss: 0.00117\n",
      "Variance: 0.168\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2445   0.5295   3.3539  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0013   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 24397, Mean R = -45.5  Std R = 21.4  Min R = -124.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000806\n",
      "PolicyEntropy: -1.67\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 5.83e+06\n",
      "ValFuncLoss: 0.0014\n",
      "Variance: 0.169\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1902   0.6030   3.4337  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0022   0.0091   1.6645   0.7971   0.5555\n",
      "***** Episode 24428, Mean R = -43.5  Std R = 21.8  Min R = -139.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000941\n",
      "PolicyEntropy: -1.68\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 5.83e+06\n",
      "ValFuncLoss: 0.00185\n",
      "Variance: 0.168\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1427   0.8196   4.2253  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0019   0.0082   1.6645   0.7971   0.5555\n",
      "***** Episode 24459, Mean R = -39.4  Std R = 10.0  Min R = -69.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000914\n",
      "PolicyEntropy: -1.69\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 5.84e+06\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7358   0.9401   4.7297  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "Update Cnt = 790    ET =    174.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.4     0.1    -0.6 |    29.3    28.2     0.4 |  -153.3   -74.9    -1.5 |   117.1    99.4    -0.0\n",
      "v_f      |   -5.46    1.62  -22.77 |    3.58    2.72    4.75 |  -20.35   -7.55  -35.06 |   10.68   10.83   -3.02\n",
      "vr_f     |     4.4 |     2.6 |     0.3 |    20.2\n",
      "r_i      |   950.2   -13.9  2350.1 |   583.3   572.0    28.8 |     2.4  -995.8  2300.2 |  1997.6   976.9  2399.9\n",
      "v_i      |  -39.54   -0.68  -80.29 |   17.99   16.37    5.52 |  -69.99  -29.93  -89.97 |  -10.07   29.57  -70.28\n",
      "norm_rf  |    40.2 |    22.4 |     3.3 |   182.7\n",
      "norm_vf  |   23.87 |    4.90 |   10.64 |   37.39\n",
      "thrust   |    1255     102    8946 |    3446    3307    3098 |  -12124  -13756   -5182 |   14957   14291   15000\n",
      "norm_thrust |   10166 |    3265 |    2000 |   15000\n",
      "fuel     |     257 |      21 |     222 |     384\n",
      "rewards  |  -42.24 |   19.26 | -180.05 |  -24.43\n",
      "fuel_rewards |   -8.84 |    0.73 |  -13.19 |   -7.65\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.55 |    0.07 |    3.20\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   37.95 |   19.59 |   11.30 |  177.67\n",
      "tracking_rewards |  -33.40 |   18.69 | -167.51 |  -16.17\n",
      "steps    |     260 |      25 |     202 |     358\n",
      "***** Episode 24490, Mean R = -41.4  Std R = 16.4  Min R = -121.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.000992\n",
      "PolicyEntropy: -1.7\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 5.85e+06\n",
      "ValFuncLoss: 0.00103\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1586   1.6209   6.9841  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0060   0.0033   0.0122   1.6645   0.7971   0.5555\n",
      "***** Episode 24521, Mean R = -37.0  Std R = 8.4  Min R = -66.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.94\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000682\n",
      "PolicyEntropy: -1.7\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 5.86e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.167\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7919   1.3481   6.2600  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0061   0.0033   0.0126   1.6645   0.7971   0.5555\n",
      "***** Episode 24552, Mean R = -40.3  Std R = 11.8  Min R = -86.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -1.72\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.11e+03\n",
      "TotalSteps: 5.87e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7439   1.2090   5.2350  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0059   0.0026   0.0114   1.6645   0.7971   0.5555\n",
      "***** Episode 24583, Mean R = -40.0  Std R = 13.7  Min R = -89.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000716\n",
      "PolicyEntropy: -1.72\n",
      "PolicyLoss: -0.00252\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 5.87e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9222   1.9516   7.9461  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0013   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 24614, Mean R = -44.0  Std R = 17.8  Min R = -122.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -1.71\n",
      "PolicyLoss: -0.00241\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 5.88e+06\n",
      "ValFuncLoss: 0.000907\n",
      "Variance: 0.166\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8740   1.2095   6.1787  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 24645, Mean R = -40.6  Std R = 13.4  Min R = -98.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -1.72\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 7.97e+03\n",
      "TotalSteps: 5.89e+06\n",
      "ValFuncLoss: 0.00124\n",
      "Variance: 0.166\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2163   1.2238   7.0234  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 24676, Mean R = -41.4  Std R = 15.6  Min R = -92.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.00123\n",
      "PolicyEntropy: -1.72\n",
      "PolicyLoss: -0.00386\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 5.9e+06\n",
      "ValFuncLoss: 0.000982\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7304   0.4556   2.6550  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0010   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 24707, Mean R = -38.7  Std R = 10.9  Min R = -84.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000883\n",
      "PolicyEntropy: -1.72\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 5.91e+06\n",
      "ValFuncLoss: 0.000797\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7945   0.5793   2.8892  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 24738, Mean R = -42.7  Std R = 12.6  Min R = -74.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000937\n",
      "PolicyEntropy: -1.73\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 5.91e+06\n",
      "ValFuncLoss: 0.00105\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6170   1.7315   7.2221  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 24769, Mean R = -38.4  Std R = 10.4  Min R = -68.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000803\n",
      "PolicyEntropy: -1.73\n",
      "PolicyLoss: -0.0024\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 5.92e+06\n",
      "ValFuncLoss: 0.000807\n",
      "Variance: 0.164\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9687   0.7570   3.9216  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0013   0.0055   1.6645   0.7971   0.5555\n",
      "Update Cnt = 800    ET =    176.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.1     3.6    -0.5 |    26.4    28.6     0.3 |   -33.5  -100.5    -1.4 |    83.8    65.5    -0.0\n",
      "v_f      |   -5.98    1.38  -22.32 |    3.19    2.72    4.27 |  -15.41   -7.28  -32.59 |    2.80    8.94  -10.36\n",
      "vr_f     |     4.3 |     7.3 |     1.0 |   123.9\n",
      "r_i      |  1006.3    37.8  2349.7 |   592.4   556.0    27.8 |    11.5  -999.6  2300.4 |  1998.9   994.8  2399.6\n",
      "v_i      |  -40.47    1.40  -79.92 |   16.74   17.28    5.74 |  -69.74  -29.89  -90.00 |  -10.42   30.00  -70.07\n",
      "norm_rf  |    39.0 |    20.2 |     3.7 |   102.7\n",
      "norm_vf  |   23.49 |    4.45 |   10.94 |   34.56\n",
      "thrust   |    1258       1    8902 |    3247    3376    3067 |  -13614  -14154   -5790 |   14987   14038   15000\n",
      "norm_thrust |   10086 |    3233 |    2000 |   15000\n",
      "fuel     |     256 |      20 |     213 |     431\n",
      "rewards  |  -40.80 |   16.47 | -191.52 |  -23.33\n",
      "fuel_rewards |   -8.80 |    0.70 |  -14.81 |   -7.31\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.57 |    0.07 |    4.56\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   36.77 |   17.28 |    9.56 |   97.71\n",
      "tracking_rewards |  -32.00 |   15.92 | -176.72 |  -15.30\n",
      "steps    |     261 |      23 |     215 |     403\n",
      "***** Episode 24800, Mean R = -45.0  Std R = 33.7  Min R = -191.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -1.74\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 5.93e+06\n",
      "ValFuncLoss: 0.000755\n",
      "Variance: 0.164\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9748   1.6653   6.9979  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 24831, Mean R = -39.6  Std R = 7.8  Min R = -55.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.00112\n",
      "PolicyEntropy: -1.74\n",
      "PolicyLoss: -0.00404\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 5.94e+06\n",
      "ValFuncLoss: 0.00091\n",
      "Variance: 0.164\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5586   1.2389   5.2561  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 24862, Mean R = -39.8  Std R = 9.2  Min R = -74.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000963\n",
      "PolicyEntropy: -1.74\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 8.04e+03\n",
      "TotalSteps: 5.95e+06\n",
      "ValFuncLoss: 0.000734\n",
      "Variance: 0.164\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6062   0.6451   3.9993  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 24893, Mean R = -46.3  Std R = 24.4  Min R = -155.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -1.74\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 5.96e+06\n",
      "ValFuncLoss: 0.000743\n",
      "Variance: 0.164\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5449   1.5263   8.1947  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 24924, Mean R = -40.1  Std R = 10.9  Min R = -69.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.00119\n",
      "PolicyEntropy: -1.75\n",
      "PolicyLoss: -0.00233\n",
      "Steps: 8e+03\n",
      "TotalSteps: 5.96e+06\n",
      "ValFuncLoss: 0.00074\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4145   2.3732   9.5817  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 24955, Mean R = -39.8  Std R = 11.0  Min R = -75.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.00089\n",
      "PolicyEntropy: -1.75\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 5.97e+06\n",
      "ValFuncLoss: 0.000577\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6223   1.3676   7.1131  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0011   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 24986, Mean R = -42.9  Std R = 27.6  Min R = -185.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000914\n",
      "PolicyEntropy: -1.76\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 5.98e+06\n",
      "ValFuncLoss: 0.000564\n",
      "Variance: 0.165\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8208   0.8572   4.5463  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 25017, Mean R = -38.2  Std R = 8.6  Min R = -70.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -1.78\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 5.99e+06\n",
      "ValFuncLoss: 0.000556\n",
      "Variance: 0.164\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2425   0.7252   3.3457  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 25048, Mean R = -39.7  Std R = 12.6  Min R = -92.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -1.79\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 6e+06\n",
      "ValFuncLoss: 0.000751\n",
      "Variance: 0.164\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5706   1.2876   6.0046  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 25079, Mean R = -42.7  Std R = 12.4  Min R = -78.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000877\n",
      "PolicyEntropy: -1.79\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 6e+06\n",
      "ValFuncLoss: 0.000769\n",
      "Variance: 0.163\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8764   0.7000   3.4492  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0013   0.0057   1.6645   0.7971   0.5555\n",
      "Update Cnt = 810    ET =    174.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    16.0     2.2    -0.5 |    26.2    28.4     0.3 |   -73.4   -80.9    -1.3 |   121.0    72.6    -0.0\n",
      "v_f      |   -5.50    1.52  -21.42 |    3.12    2.86    4.85 |  -15.77   -6.50  -34.01 |   11.05   10.28   -3.02\n",
      "vr_f     |     3.9 |     2.1 |     0.7 |    17.7\n",
      "r_i      |  1002.2   -31.2  2350.8 |   575.6   591.6    28.6 |     7.1  -995.8  2300.1 |  1997.5   993.8  2398.7\n",
      "v_i      |  -40.25   -0.68  -79.45 |   17.20   17.75    5.91 |  -69.76  -29.99  -89.97 |  -11.10   29.82  -70.06\n",
      "norm_rf  |    36.8 |    20.1 |     1.7 |   135.7\n",
      "norm_vf  |   22.52 |    5.08 |    5.19 |   35.77\n",
      "thrust   |    1229      78    8886 |    3226    3422    3037 |  -12443  -14756   -5551 |   14989   14286   15000\n",
      "norm_thrust |   10071 |    3225 |    2000 |   15000\n",
      "fuel     |     258 |      20 |     213 |     392\n",
      "rewards  |  -41.50 |   16.83 | -185.16 |  -21.40\n",
      "fuel_rewards |   -8.88 |    0.68 |  -13.46 |   -7.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.35 |    0.53 |    0.03 |    3.92\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   34.54 |   17.34 |   11.22 |  130.71\n",
      "tracking_rewards |  -32.62 |   16.33 | -171.70 |  -12.98\n",
      "steps    |     264 |      24 |     203 |     375\n",
      "***** Episode 25110, Mean R = -46.0  Std R = 25.2  Min R = -156.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.906\n",
      "KL: 0.000683\n",
      "PolicyEntropy: -1.78\n",
      "PolicyLoss: -0.0018\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 6.01e+06\n",
      "ValFuncLoss: 0.000892\n",
      "Variance: 0.162\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9651   1.4635   6.2444  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 25141, Mean R = -41.2  Std R = 23.0  Min R = -152.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -1.79\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 6.02e+06\n",
      "ValFuncLoss: 0.000858\n",
      "Variance: 0.161\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3513   0.9046   4.2718  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 25172, Mean R = -50.6  Std R = 29.5  Min R = -172.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000942\n",
      "PolicyEntropy: -1.79\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 6.03e+06\n",
      "ValFuncLoss: 0.000795\n",
      "Variance: 0.161\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0324   1.5593   6.6469  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0019   0.0086   1.6645   0.7971   0.5555\n",
      "***** Episode 25203, Mean R = -41.6  Std R = 23.3  Min R = -129.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00096\n",
      "PolicyEntropy: -1.8\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 6.04e+06\n",
      "ValFuncLoss: 0.000389\n",
      "Variance: 0.161\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6796   0.9124   4.7661  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0015   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 25234, Mean R = -38.7  Std R = 9.4  Min R = -65.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000849\n",
      "PolicyEntropy: -1.8\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8e+03\n",
      "TotalSteps: 6.05e+06\n",
      "ValFuncLoss: 0.000405\n",
      "Variance: 0.161\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4216   0.8461   4.3148  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0014   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 25265, Mean R = -41.8  Std R = 12.9  Min R = -99.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.00084\n",
      "PolicyEntropy: -1.8\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 6.05e+06\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3640   1.4256   6.5364  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0016   0.0076   1.6645   0.7971   0.5555\n",
      "***** Episode 25296, Mean R = -41.7  Std R = 20.0  Min R = -132.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.00093\n",
      "PolicyEntropy: -1.81\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 6.06e+06\n",
      "ValFuncLoss: 0.000773\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1269   1.4606   8.4367  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 25327, Mean R = -39.5  Std R = 9.4  Min R = -71.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.928\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.00119\n",
      "PolicyEntropy: -1.81\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 6.07e+06\n",
      "ValFuncLoss: 0.000798\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5483   1.1274   6.7606  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 25358, Mean R = -43.2  Std R = 16.6  Min R = -102.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000992\n",
      "PolicyEntropy: -1.82\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 6.08e+06\n",
      "ValFuncLoss: 0.000989\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5038   0.8508   4.9398  13.2323   7.1497   3.4442\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0013   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 25389, Mean R = -40.0  Std R = 10.0  Min R = -65.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000908\n",
      "PolicyEntropy: -1.83\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 6.09e+06\n",
      "ValFuncLoss: 0.000934\n",
      "Variance: 0.159\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2915   4.5498  15.4724  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "Update Cnt = 820    ET =    177.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    22.8     6.9    -0.5 |    24.4    25.0     0.3 |   -34.9   -67.8    -1.4 |   107.1    63.3    -0.0\n",
      "v_f      |   -6.20    1.86  -21.80 |    3.16    2.53    4.01 |  -17.99   -5.86  -32.65 |    1.44   10.98   -9.27\n",
      "vr_f     |     3.7 |     2.2 |     1.4 |    27.2\n",
      "r_i      |  1056.3   -13.6  2349.3 |   582.5   568.8    29.3 |     2.9  -997.2  2300.2 |  1999.1   983.1  2399.9\n",
      "v_i      |  -38.94    0.51  -80.40 |   16.78   17.26    5.81 |  -69.37  -29.89  -89.78 |  -10.01   29.84  -70.09\n",
      "norm_rf  |    37.6 |    19.4 |     0.9 |   112.5\n",
      "norm_vf  |   23.04 |    4.33 |   10.01 |   34.64\n",
      "thrust   |    1147      55    8918 |    3202    3264    3040 |  -11492  -14133   -5264 |   14943   14453   14999\n",
      "norm_thrust |   10034 |    3211 |    2000 |   15000\n",
      "fuel     |     259 |      19 |     225 |     370\n",
      "rewards  |  -41.62 |   18.40 | -172.09 |  -22.34\n",
      "fuel_rewards |   -8.90 |    0.65 |  -12.72 |   -7.73\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.34 |    0.51 |    0.09 |    3.20\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   34.94 |   16.92 |   11.02 |  107.54\n",
      "tracking_rewards |  -32.72 |   17.87 | -159.37 |  -13.99\n",
      "steps    |     265 |      22 |     209 |     355\n",
      "***** Episode 25420, Mean R = -37.9  Std R = 14.6  Min R = -111.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -1.83\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 6.09e+06\n",
      "ValFuncLoss: 0.00086\n",
      "Variance: 0.158\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4248   2.7796  10.2612  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0058   0.0027   0.0107   1.6645   0.7971   0.5555\n",
      "***** Episode 25451, Mean R = -44.2  Std R = 29.3  Min R = -184.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000688\n",
      "PolicyEntropy: -1.83\n",
      "PolicyLoss: -0.0023\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 6.1e+06\n",
      "ValFuncLoss: 0.000712\n",
      "Variance: 0.159\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5347   1.4389   6.6810  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0022   0.0080   1.6645   0.7971   0.5555\n",
      "***** Episode 25482, Mean R = -40.4  Std R = 9.1  Min R = -66.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000833\n",
      "PolicyEntropy: -1.84\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 6.11e+06\n",
      "ValFuncLoss: 0.00052\n",
      "Variance: 0.159\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4081   0.9652   5.1845  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0023   0.0082   1.6645   0.7971   0.5555\n",
      "***** Episode 25513, Mean R = -46.9  Std R = 24.1  Min R = -156.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000609\n",
      "PolicyEntropy: -1.84\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 6.12e+06\n",
      "ValFuncLoss: 0.000835\n",
      "Variance: 0.159\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2299   2.8704  12.4862  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 25544, Mean R = -40.3  Std R = 9.1  Min R = -61.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000886\n",
      "PolicyEntropy: -1.85\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 6.13e+06\n",
      "ValFuncLoss: 0.000796\n",
      "Variance: 0.159\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8114   1.0798   5.7432  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 25575, Mean R = -42.2  Std R = 14.4  Min R = -84.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000746\n",
      "PolicyEntropy: -1.85\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 6.14e+06\n",
      "ValFuncLoss: 0.000928\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6874   1.3356   5.9946  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 25606, Mean R = -42.8  Std R = 18.0  Min R = -119.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000678\n",
      "PolicyEntropy: -1.85\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.09e+03\n",
      "TotalSteps: 6.14e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7219   0.6501   3.1694  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0013   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 25637, Mean R = -37.7  Std R = 8.7  Min R = -59.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -1.86\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 6.15e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.161\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8929   2.6768  11.4020  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0005   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 25668, Mean R = -38.9  Std R = 7.8  Min R = -59.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -1.87\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 6.16e+06\n",
      "ValFuncLoss: 0.000774\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3119   0.7939   4.1152  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0064   0.0025   0.0130   1.6645   0.7971   0.5555\n",
      "***** Episode 25699, Mean R = -44.0  Std R = 23.5  Min R = -162.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000805\n",
      "PolicyEntropy: -1.86\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 7.90e+03\n",
      "TotalSteps: 6.17e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.16\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0474   1.3886   7.0942  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0009   0.0044   1.6645   0.7971   0.5555\n",
      "Update Cnt = 830    ET =    177.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.6     8.7    -0.5 |    26.4    28.6     0.3 |   -30.2   -79.3    -1.4 |   127.1    72.4    -0.0\n",
      "v_f      |   -5.88    1.47  -21.77 |    3.37    2.86    4.44 |  -19.47   -5.82  -34.34 |    3.22   12.79   -9.65\n",
      "vr_f     |     4.0 |     3.1 |     1.3 |    31.1\n",
      "r_i      |  1012.3   -22.3  2353.2 |   591.5   601.0    28.0 |     5.9  -986.6  2300.2 |  1994.4   999.3  2399.9\n",
      "v_i      |  -41.23    0.44  -79.94 |   17.38   17.36    5.75 |  -69.71  -29.96  -89.96 |  -10.19   29.88  -70.12\n",
      "norm_rf  |    39.7 |    21.8 |     1.3 |   144.6\n",
      "norm_vf  |   22.95 |    4.81 |    9.71 |   35.72\n",
      "thrust   |    1263      76    8925 |    3277    3289    3027 |  -11148  -14149   -6126 |   14959   14553   15000\n",
      "norm_thrust |   10077 |    3227 |    2000 |   15000\n",
      "fuel     |     260 |      21 |     221 |     368\n",
      "rewards  |  -42.57 |   19.74 | -184.32 |  -23.29\n",
      "fuel_rewards |   -8.92 |    0.70 |  -12.65 |   -7.62\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.32 |    0.49 |    0.06 |    3.72\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   37.01 |   19.43 |    7.71 |  139.64\n",
      "tracking_rewards |  -33.65 |   19.20 | -171.67 |  -14.66\n",
      "steps    |     265 |      25 |     221 |     356\n",
      "***** Episode 25730, Mean R = -48.2  Std R = 31.2  Min R = -167.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000791\n",
      "PolicyEntropy: -1.86\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 6.18e+06\n",
      "ValFuncLoss: 0.00105\n",
      "Variance: 0.159\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3544   0.7587   3.5074  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0014   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 25761, Mean R = -37.2  Std R = 10.7  Min R = -78.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00099\n",
      "PolicyEntropy: -1.87\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 6.19e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.158\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0305   0.9634   4.3605  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 25792, Mean R = -37.8  Std R = 8.4  Min R = -62.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.000905\n",
      "PolicyEntropy: -1.88\n",
      "PolicyLoss: -0.00353\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 6.19e+06\n",
      "ValFuncLoss: 0.00109\n",
      "Variance: 0.158\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1569   1.2011   5.8615  15.4724   8.2915   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0009   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 25823, Mean R = -35.1  Std R = 8.1  Min R = -51.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00248\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.2e+06\n",
      "ValFuncLoss: 0.0012\n",
      "Variance: 0.157\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.4093   3.1382  15.8746  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0010   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 25854, Mean R = -40.0  Std R = 9.8  Min R = -66.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.00187\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -2.1e-06\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 6.21e+06\n",
      "ValFuncLoss: 0.00128\n",
      "Variance: 0.157\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9799   3.3081  13.6484  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 25885, Mean R = -42.9  Std R = 14.7  Min R = -93.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.000854\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 6.22e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.158\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1485   0.7120   4.2902  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0014   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 25916, Mean R = -44.4  Std R = 26.0  Min R = -172.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000611\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 6.23e+06\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.157\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2645   0.7863   4.4380  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 25947, Mean R = -46.1  Std R = 23.0  Min R = -153.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000695\n",
      "PolicyEntropy: -1.88\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 6.23e+06\n",
      "ValFuncLoss: 0.000852\n",
      "Variance: 0.157\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2696   1.4177   6.7542  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 25978, Mean R = -38.6  Std R = 9.5  Min R = -70.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00376\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 6.24e+06\n",
      "ValFuncLoss: 0.000821\n",
      "Variance: 0.156\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4926   1.9948   8.8762  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 26009, Mean R = -37.5  Std R = 8.3  Min R = -60.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.000855\n",
      "PolicyEntropy: -1.9\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 7.94e+03\n",
      "TotalSteps: 6.25e+06\n",
      "ValFuncLoss: 0.000843\n",
      "Variance: 0.156\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3209   1.1353   6.0116  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0036   1.6645   0.7971   0.5555\n",
      "Update Cnt = 840    ET =    177.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.0     4.6    -0.6 |    24.6    26.1     0.3 |   -34.4   -78.7    -1.6 |   102.4    77.1    -0.0\n",
      "v_f      |   -5.73    1.48  -22.34 |    3.15    2.69    4.17 |  -15.04   -7.24  -35.57 |    4.32   10.77   -6.72\n",
      "vr_f     |     4.3 |     4.0 |     1.5 |    63.4\n",
      "r_i      |  1011.0    18.3  2348.3 |   591.0   563.7    28.4 |    22.1  -992.9  2300.1 |  1992.1   998.6  2399.6\n",
      "v_i      |  -39.44   -0.22  -79.60 |   17.23   17.54    5.88 |  -69.91  -29.99  -89.83 |  -10.11   29.92  -70.05\n",
      "norm_rf  |    37.1 |    19.2 |     1.6 |   111.7\n",
      "norm_vf  |   23.42 |    4.47 |    7.65 |   36.98\n",
      "thrust   |    1208      89    8938 |    3269    3235    2999 |  -11697  -14317   -6927 |   14971   14414   14999\n",
      "norm_thrust |   10063 |    3200 |    2000 |   15000\n",
      "fuel     |     257 |      18 |     224 |     393\n",
      "rewards  |  -39.71 |   14.43 | -172.16 |  -22.98\n",
      "fuel_rewards |   -8.84 |    0.63 |  -13.49 |   -7.71\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.53 |    0.08 |    3.31\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   34.89 |   16.21 |   12.05 |  106.72\n",
      "tracking_rewards |  -30.87 |   13.96 | -158.67 |  -14.73\n",
      "steps    |     263 |      23 |     192 |     367\n",
      "***** Episode 26040, Mean R = -37.4  Std R = 6.1  Min R = -53.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000777\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00378\n",
      "Steps: 7.83e+03\n",
      "TotalSteps: 6.26e+06\n",
      "ValFuncLoss: 0.000912\n",
      "Variance: 0.156\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6017   1.2502   5.7095  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0014   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 26071, Mean R = -46.7  Std R = 26.4  Min R = -149.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -1.88\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 6.27e+06\n",
      "ValFuncLoss: 0.00208\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3022   1.4769   6.7102  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 26102, Mean R = -40.2  Std R = 16.1  Min R = -100.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000673\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 6.27e+06\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1476   2.2961  11.5795  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0016   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 26133, Mean R = -39.8  Std R = 7.9  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000777\n",
      "PolicyEntropy: -1.88\n",
      "PolicyLoss: -0.00221\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 6.28e+06\n",
      "ValFuncLoss: 0.00137\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1402   0.9393   4.7151  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 26164, Mean R = -37.6  Std R = 8.3  Min R = -58.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000656\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 6.29e+06\n",
      "ValFuncLoss: 0.00128\n",
      "Variance: 0.156\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8475   1.2519   6.0655  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 26195, Mean R = -40.2  Std R = 18.0  Min R = -128.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000802\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 6.3e+06\n",
      "ValFuncLoss: 0.00124\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4982   1.5942   7.9350  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 26226, Mean R = -38.4  Std R = 10.7  Min R = -74.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00386\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 6.31e+06\n",
      "ValFuncLoss: 0.00122\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2518   0.9855   5.5340  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 26257, Mean R = -40.8  Std R = 16.1  Min R = -99.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000899\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.32e+06\n",
      "ValFuncLoss: 0.00102\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5530   1.2760   6.5915  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0067   0.0035   0.0133   1.6645   0.7971   0.5555\n",
      "***** Episode 26288, Mean R = -43.4  Std R = 25.1  Min R = -168.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.00073\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 6.32e+06\n",
      "ValFuncLoss: 0.0012\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1110   0.8203   4.4941  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0017   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 26319, Mean R = -41.4  Std R = 11.5  Min R = -76.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000832\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 6.33e+06\n",
      "ValFuncLoss: 0.00101\n",
      "Variance: 0.156\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6977   0.7958   4.0381  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0034   1.6645   0.7971   0.5555\n",
      "Update Cnt = 850    ET =    177.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    22.0     3.6    -0.5 |    23.4    26.0     0.3 |   -30.7   -75.0    -1.5 |    74.4    59.7    -0.0\n",
      "v_f      |   -5.83    1.75  -22.06 |    2.63    2.56    4.50 |  -14.05   -4.69  -35.60 |    1.38   13.23   -5.33\n",
      "vr_f     |     3.9 |     2.2 |     1.5 |    27.6\n",
      "r_i      |  1027.1   -27.2  2351.6 |   598.5   568.0    29.0 |     0.7  -996.3  2300.7 |  1996.6   999.9  2399.8\n",
      "v_i      |  -38.53    0.73  -79.09 |   17.57   17.68    5.78 |  -69.55  -29.86  -89.82 |  -10.22   29.88  -70.04\n",
      "norm_rf  |    37.8 |    17.3 |     1.7 |    85.7\n",
      "norm_vf  |   23.15 |    4.68 |    6.25 |   37.70\n",
      "thrust   |    1171      38    8884 |    3195    3242    2985 |  -12186  -14287   -6585 |   14998   14536   14999\n",
      "norm_thrust |    9992 |    3177 |    2000 |   15000\n",
      "fuel     |     258 |      19 |     214 |     356\n",
      "rewards  |  -40.88 |   16.45 | -168.65 |  -23.85\n",
      "fuel_rewards |   -8.85 |    0.65 |  -12.23 |   -7.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.36 |    0.54 |    0.04 |    4.45\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   35.14 |   14.54 |   10.37 |   80.66\n",
      "tracking_rewards |  -32.03 |   15.98 | -156.41 |  -15.32\n",
      "steps    |     265 |      24 |     204 |     347\n",
      "***** Episode 26350, Mean R = -40.2  Std R = 9.9  Min R = -65.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000995\n",
      "PolicyEntropy: -1.89\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 7.89e+03\n",
      "TotalSteps: 6.34e+06\n",
      "ValFuncLoss: 0.00158\n",
      "Variance: 0.156\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5572   1.1439   5.5025  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 26381, Mean R = -40.2  Std R = 12.1  Min R = -77.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.00113\n",
      "PolicyEntropy: -1.91\n",
      "PolicyLoss: -0.00352\n",
      "Steps: 8.11e+03\n",
      "TotalSteps: 6.35e+06\n",
      "ValFuncLoss: 0.00133\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6339   1.9110   8.5508  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 26412, Mean R = -39.4  Std R = 13.2  Min R = -93.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.00097\n",
      "PolicyEntropy: -1.92\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.36e+06\n",
      "ValFuncLoss: 0.00135\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9580   0.9568   4.7800  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 26443, Mean R = -38.7  Std R = 8.1  Min R = -60.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000939\n",
      "PolicyEntropy: -1.92\n",
      "PolicyLoss: -0.00406\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 6.36e+06\n",
      "ValFuncLoss: 0.00145\n",
      "Variance: 0.155\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7577   1.5752   8.5916  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 26474, Mean R = -42.4  Std R = 20.2  Min R = -126.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00121\n",
      "PolicyEntropy: -1.93\n",
      "PolicyLoss: -0.00369\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 6.37e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.154\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1652   1.3297   5.7879  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 26505, Mean R = -38.4  Std R = 7.9  Min R = -54.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.000708\n",
      "PolicyEntropy: -1.95\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 7.93e+03\n",
      "TotalSteps: 6.38e+06\n",
      "ValFuncLoss: 0.00134\n",
      "Variance: 0.153\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4356   1.7229   8.6455  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0013   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 26536, Mean R = -37.1  Std R = 13.8  Min R = -98.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.00114\n",
      "PolicyEntropy: -1.95\n",
      "PolicyLoss: -0.00363\n",
      "Steps: 7.89e+03\n",
      "TotalSteps: 6.39e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.152\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3877   1.3029   5.4500  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 26567, Mean R = -38.3  Std R = 7.9  Min R = -58.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000935\n",
      "PolicyEntropy: -1.95\n",
      "PolicyLoss: -0.00413\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 6.4e+06\n",
      "ValFuncLoss: 0.00126\n",
      "Variance: 0.152\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6517   2.9046  12.9419  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 26598, Mean R = -40.6  Std R = 10.7  Min R = -72.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.00139\n",
      "PolicyEntropy: -1.95\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.11e+03\n",
      "TotalSteps: 6.41e+06\n",
      "ValFuncLoss: 0.00163\n",
      "Variance: 0.152\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9015   2.5094  10.6604  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 26629, Mean R = -40.4  Std R = 14.8  Min R = -104.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00168\n",
      "PolicyEntropy: -1.97\n",
      "PolicyLoss: -0.000136\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 6.41e+06\n",
      "ValFuncLoss: 0.00125\n",
      "Variance: 0.152\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7027   1.8499   9.3156  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0015   0.0054   1.6645   0.7971   0.5555\n",
      "Update Cnt = 860    ET =    174.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    22.0     1.5    -0.5 |    23.8    24.5     0.3 |   -47.2   -66.5    -1.3 |    83.4    71.8    -0.0\n",
      "v_f      |   -5.81    1.46  -21.59 |    2.59    2.66    4.00 |  -14.61   -7.62  -32.88 |    1.90   14.08  -11.61\n",
      "vr_f     |     4.0 |     2.9 |     1.4 |    34.4\n",
      "r_i      |  1013.5    -8.7  2349.7 |   578.2   560.1    28.2 |    21.2  -999.5  2300.3 |  1998.9   988.6  2399.8\n",
      "v_i      |  -40.00    1.10  -80.16 |   17.62   16.86    5.86 |  -69.91  -29.70  -89.99 |  -10.02   29.86  -70.09\n",
      "norm_rf  |    36.5 |    18.0 |     1.8 |    85.7\n",
      "norm_vf  |   22.69 |    4.13 |   12.23 |   36.09\n",
      "thrust   |    1238      19    8968 |    3220    3153    2943 |  -13571  -14006   -6244 |   14965   14491   15000\n",
      "norm_thrust |   10054 |    3140 |    2000 |   15000\n",
      "fuel     |     255 |      18 |     217 |     322\n",
      "rewards  |  -39.36 |   13.01 | -126.03 |  -23.23\n",
      "fuel_rewards |   -8.75 |    0.62 |  -11.05 |   -7.48\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.38 |    0.52 |    0.51 |    3.44\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   34.22 |   14.97 |   11.06 |   80.69\n",
      "tracking_rewards |  -30.60 |   12.62 | -115.21 |  -15.15\n",
      "steps    |     261 |      24 |     205 |     319\n",
      "***** Episode 26660, Mean R = -38.1  Std R = 15.1  Min R = -107.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00126\n",
      "PolicyEntropy: -1.97\n",
      "PolicyLoss: -0.000837\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 6.42e+06\n",
      "ValFuncLoss: 0.00108\n",
      "Variance: 0.151\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0390   2.5171  10.8258  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 26691, Mean R = -37.6  Std R = 8.7  Min R = -58.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000966\n",
      "PolicyEntropy: -1.98\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 6.43e+06\n",
      "ValFuncLoss: 0.00106\n",
      "Variance: 0.152\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3007   1.6208   7.6759  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 26722, Mean R = -39.6  Std R = 12.1  Min R = -80.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000996\n",
      "PolicyEntropy: -1.99\n",
      "PolicyLoss: -0.00359\n",
      "Steps: 8e+03\n",
      "TotalSteps: 6.44e+06\n",
      "ValFuncLoss: 0.00153\n",
      "Variance: 0.15\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7378   0.9678   5.3049  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0011   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 26753, Mean R = -42.2  Std R = 14.7  Min R = -102.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000909\n",
      "PolicyEntropy: -1.99\n",
      "PolicyLoss: -0.00391\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 6.45e+06\n",
      "ValFuncLoss: 0.00111\n",
      "Variance: 0.149\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9492   2.0722  10.0613  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 26784, Mean R = -39.1  Std R = 10.6  Min R = -72.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000891\n",
      "PolicyEntropy: -2\n",
      "PolicyLoss: -0.00216\n",
      "Steps: 8.03e+03\n",
      "TotalSteps: 6.45e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.149\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2795   1.5136   6.9881  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 26815, Mean R = -36.9  Std R = 6.7  Min R = -59.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.000743\n",
      "PolicyEntropy: -2\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 6.46e+06\n",
      "ValFuncLoss: 0.00133\n",
      "Variance: 0.149\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9964   0.5267   3.1723  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 26846, Mean R = -36.5  Std R = 7.5  Min R = -63.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.00076\n",
      "PolicyEntropy: -2\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 6.47e+06\n",
      "ValFuncLoss: 0.00127\n",
      "Variance: 0.149\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7434   1.8317   8.1615  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 26877, Mean R = -40.8  Std R = 14.8  Min R = -95.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000989\n",
      "PolicyEntropy: -2\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 7.99e+03\n",
      "TotalSteps: 6.48e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.149\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7287   2.1529   8.6592  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 26908, Mean R = -40.4  Std R = 17.2  Min R = -115.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000936\n",
      "PolicyEntropy: -2.01\n",
      "PolicyLoss: -0.00362\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 6.49e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.148\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3826   1.8127   7.4158  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0016   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 26939, Mean R = -38.6  Std R = 13.7  Min R = -82.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000616\n",
      "PolicyEntropy: -2\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 6.49e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.148\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7496   1.3016   6.1911  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0019   0.0089   1.6645   0.7971   0.5555\n",
      "Update Cnt = 870    ET =    175.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.6     3.4    -0.5 |    23.5    26.0     0.3 |   -45.8   -72.6    -1.5 |   100.9    71.7    -0.0\n",
      "v_f      |   -5.91    1.45  -20.95 |    2.66    2.51    4.25 |  -13.36   -6.38  -31.50 |    0.39    9.15   -7.20\n",
      "vr_f     |     3.6 |     1.8 |     1.3 |    12.1\n",
      "r_i      |  1003.5    20.0  2348.8 |   572.2   593.6    30.4 |     2.1  -993.4  2300.7 |  1999.2   994.8  2399.4\n",
      "v_i      |  -39.87   -0.03  -79.47 |   16.97   17.10    5.84 |  -69.93  -29.99  -89.98 |  -10.24   29.91  -70.04\n",
      "norm_rf  |    36.4 |    18.5 |     3.5 |   112.5\n",
      "norm_vf  |   22.09 |    4.42 |    7.87 |   32.93\n",
      "thrust   |    1249      53    9015 |    3170    3222    2895 |  -12789  -13981   -6044 |   14994   14730   15000\n",
      "norm_thrust |   10100 |    3105 |    2000 |   15000\n",
      "fuel     |     256 |      19 |     222 |     329\n",
      "rewards  |  -39.60 |   13.66 | -130.87 |  -20.08\n",
      "fuel_rewards |   -8.80 |    0.64 |  -11.33 |   -7.63\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.38 |    0.50 |    0.45 |    3.58\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   33.97 |   15.73 |   13.43 |  107.45\n",
      "tracking_rewards |  -30.80 |   13.22 | -119.62 |  -11.52\n",
      "steps    |     261 |      23 |     211 |     318\n",
      "***** Episode 26970, Mean R = -44.3  Std R = 21.3  Min R = -130.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -2.02\n",
      "PolicyLoss: -0.00248\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 6.5e+06\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.147\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9629   1.1501   5.4565  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 27001, Mean R = -38.2  Std R = 13.4  Min R = -93.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000763\n",
      "PolicyEntropy: -2.02\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 6.51e+06\n",
      "ValFuncLoss: 0.000981\n",
      "Variance: 0.147\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4528   2.3396   9.1315  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 27032, Mean R = -35.5  Std R = 7.6  Min R = -52.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -2.02\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 6.52e+06\n",
      "ValFuncLoss: 0.0012\n",
      "Variance: 0.147\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3354   0.7951   3.9336  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 27063, Mean R = -35.5  Std R = 10.1  Min R = -78.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000833\n",
      "PolicyEntropy: -2.03\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 6.53e+06\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.147\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4656   1.0317   5.6231  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 27094, Mean R = -41.5  Std R = 12.0  Min R = -85.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.00107\n",
      "PolicyEntropy: -2.04\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 6.54e+06\n",
      "ValFuncLoss: 0.00128\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9202   0.8427   4.5011  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 27125, Mean R = -42.0  Std R = 18.5  Min R = -130.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000817\n",
      "PolicyEntropy: -2.03\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 6.54e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.147\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9753   2.4219   9.0730  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0027   0.0099   1.6645   0.7971   0.5555\n",
      "***** Episode 27156, Mean R = -41.5  Std R = 12.4  Min R = -77.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.0012\n",
      "PolicyEntropy: -2.04\n",
      "PolicyLoss: -0.00201\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 6.55e+06\n",
      "ValFuncLoss: 0.000861\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7555   1.7106   8.2929  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0017   0.0075   1.6645   0.7971   0.5555\n",
      "***** Episode 27187, Mean R = -41.7  Std R = 22.0  Min R = -150.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000797\n",
      "PolicyEntropy: -2.05\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 6.56e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0040   1.4558   7.1875  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0012   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 27218, Mean R = -37.0  Std R = 7.6  Min R = -55.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00123\n",
      "PolicyEntropy: -2.06\n",
      "PolicyLoss: -0.00348\n",
      "Steps: 8.09e+03\n",
      "TotalSteps: 6.57e+06\n",
      "ValFuncLoss: 0.000874\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5982   1.1927   6.4721  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 27249, Mean R = -39.8  Std R = 10.3  Min R = -71.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00056\n",
      "PolicyEntropy: -2.06\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 6.58e+06\n",
      "ValFuncLoss: 0.00127\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3659   1.5649   8.3219  15.8746   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "Update Cnt = 880    ET =    177.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.9     7.1    -0.5 |    21.8    27.0     0.3 |   -32.6   -92.3    -1.3 |    75.3   102.5    -0.0\n",
      "v_f      |   -5.61    1.47  -20.45 |    2.54    2.76    4.01 |  -13.62   -7.51  -31.53 |    2.12   11.86   -7.96\n",
      "vr_f     |     3.6 |     1.5 |     1.5 |    12.8\n",
      "r_i      |  1031.3    -3.8  2350.2 |   580.0   566.8    29.3 |     4.9  -987.8  2300.6 |  1998.6   992.0  2399.1\n",
      "v_i      |  -39.94    1.24  -80.11 |   16.85   17.52    5.73 |  -69.57  -29.99  -89.94 |  -10.42   29.88  -70.10\n",
      "norm_rf  |    37.3 |    18.5 |     1.5 |   104.8\n",
      "norm_vf  |   21.54 |    4.22 |    8.15 |   32.98\n",
      "thrust   |    1234      19    8969 |    3191    3159    2855 |  -11445  -14645   -6691 |   14986   14538   15000\n",
      "norm_thrust |   10037 |    3090 |    2000 |   15000\n",
      "fuel     |     258 |      17 |     223 |     328\n",
      "rewards  |  -39.41 |   14.25 | -150.72 |  -20.93\n",
      "fuel_rewards |   -8.87 |    0.59 |  -11.26 |   -7.66\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.51 |    0.53 |    4.36\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   34.61 |   15.86 |    9.79 |   99.77\n",
      "tracking_rewards |  -30.54 |   13.82 | -139.53 |  -12.38\n",
      "steps    |     265 |      22 |     209 |     327\n",
      "***** Episode 27280, Mean R = -41.4  Std R = 18.5  Min R = -121.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.0011\n",
      "PolicyEntropy: -2.06\n",
      "PolicyLoss: -0.00341\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 6.58e+06\n",
      "ValFuncLoss: 0.00137\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8396   4.4365  18.3978  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 27311, Mean R = -39.9  Std R = 12.8  Min R = -75.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000938\n",
      "PolicyEntropy: -2.06\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.59e+06\n",
      "ValFuncLoss: 0.00131\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9702   0.8704   5.0427  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 27342, Mean R = -36.0  Std R = 8.2  Min R = -58.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000739\n",
      "PolicyEntropy: -2.07\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 6.6e+06\n",
      "ValFuncLoss: 0.0011\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2157   2.1080   9.2042  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 27373, Mean R = -39.7  Std R = 19.4  Min R = -137.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00118\n",
      "PolicyEntropy: -2.07\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.09e+03\n",
      "TotalSteps: 6.61e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.147\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3717   3.4519  15.0958  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 27404, Mean R = -35.7  Std R = 8.6  Min R = -68.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000696\n",
      "PolicyEntropy: -2.07\n",
      "PolicyLoss: -0.0038\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 6.62e+06\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9879   1.5690   7.8254  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 27435, Mean R = -37.3  Std R = 10.4  Min R = -82.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -2.08\n",
      "PolicyLoss: -0.00446\n",
      "Steps: 8.03e+03\n",
      "TotalSteps: 6.62e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4197   1.7600   8.6003  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 27466, Mean R = -40.1  Std R = 15.8  Min R = -109.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000916\n",
      "PolicyEntropy: -2.08\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.63e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4542   1.7144   7.8615  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0012   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 27497, Mean R = -38.9  Std R = 15.1  Min R = -89.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000866\n",
      "PolicyEntropy: -2.08\n",
      "PolicyLoss: -0.00348\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 6.64e+06\n",
      "ValFuncLoss: 0.00129\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5646   2.9611  12.3627  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0017   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 27528, Mean R = -35.7  Std R = 8.1  Min R = -62.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.00109\n",
      "PolicyEntropy: -2.09\n",
      "PolicyLoss: -0.00428\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.65e+06\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.146\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0301   1.5696   7.1874  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0069   0.0033   0.0132   1.6645   0.7971   0.5555\n",
      "***** Episode 27559, Mean R = -40.4  Std R = 15.9  Min R = -93.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000798\n",
      "PolicyEntropy: -2.09\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 6.66e+06\n",
      "ValFuncLoss: 0.00114\n",
      "Variance: 0.145\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9401   1.2109   7.0743  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "Update Cnt = 890    ET =    176.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.3     7.8    -0.5 |    23.3    24.2     0.3 |   -36.2   -52.2    -1.3 |    94.6    73.6    -0.0\n",
      "v_f      |   -5.55    1.49  -20.52 |    2.69    2.69    3.73 |  -16.31   -7.01  -29.10 |    1.99   12.96   -9.25\n",
      "vr_f     |     3.9 |     3.1 |     1.4 |    49.2\n",
      "r_i      |   990.5    53.9  2351.3 |   569.3   575.4    29.1 |    12.6  -990.9  2300.5 |  1992.1   996.2  2399.3\n",
      "v_i      |  -41.36   -0.17  -79.98 |   17.12   16.83    5.44 |  -69.99  -29.76  -89.94 |  -10.11   29.85  -70.07\n",
      "norm_rf  |    36.8 |    17.1 |     4.3 |   113.6\n",
      "norm_vf  |   21.60 |    3.99 |    9.90 |   30.83\n",
      "thrust   |    1299      74    8974 |    3246    3123    2821 |  -11233  -14328   -5657 |   14990   14673   14999\n",
      "norm_thrust |   10052 |    3072 |    2000 |   15000\n",
      "fuel     |     256 |      17 |     226 |     322\n",
      "rewards  |  -38.43 |   14.00 | -137.50 |  -21.89\n",
      "fuel_rewards |   -8.80 |    0.57 |  -11.07 |   -7.76\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.47 |    0.12 |    3.30\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   33.72 |   14.82 |    9.24 |  108.63\n",
      "tracking_rewards |  -29.63 |   13.60 | -126.44 |  -14.00\n",
      "steps    |     262 |      21 |     216 |     315\n",
      "***** Episode 27590, Mean R = -40.6  Std R = 18.4  Min R = -127.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000781\n",
      "PolicyEntropy: -2.1\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 6.67e+06\n",
      "ValFuncLoss: 0.00112\n",
      "Variance: 0.145\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9249   0.4327   2.6779  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 27621, Mean R = -42.7  Std R = 22.5  Min R = -159.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000972\n",
      "PolicyEntropy: -2.11\n",
      "PolicyLoss: -0.00231\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 6.67e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.145\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7899   0.8063   4.5444  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 27652, Mean R = -42.1  Std R = 11.4  Min R = -79.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -2.12\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 6.68e+06\n",
      "ValFuncLoss: 0.00141\n",
      "Variance: 0.144\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2120   3.6440  14.0820  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 27683, Mean R = -38.7  Std R = 10.4  Min R = -71.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000989\n",
      "PolicyEntropy: -2.12\n",
      "PolicyLoss: -0.0022\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.69e+06\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.143\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7682   2.3734  11.1996  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 27714, Mean R = -40.1  Std R = 10.3  Min R = -78.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.00085\n",
      "PolicyEntropy: -2.14\n",
      "PolicyLoss: -0.00371\n",
      "Steps: 7.98e+03\n",
      "TotalSteps: 6.7e+06\n",
      "ValFuncLoss: 0.00159\n",
      "Variance: 0.142\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8285   1.3384   6.4479  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 27745, Mean R = -44.4  Std R = 16.3  Min R = -104.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -2.15\n",
      "PolicyLoss: -0.00353\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 6.71e+06\n",
      "ValFuncLoss: 0.00204\n",
      "Variance: 0.142\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7958   0.9493   4.2269  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 27776, Mean R = -41.2  Std R = 16.9  Min R = -108.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.00069\n",
      "PolicyEntropy: -2.16\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 6.71e+06\n",
      "ValFuncLoss: 0.00197\n",
      "Variance: 0.142\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8944   3.6822  14.8747  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 27807, Mean R = -36.5  Std R = 8.4  Min R = -60.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.00117\n",
      "PolicyEntropy: -2.17\n",
      "PolicyLoss: -0.00221\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 6.72e+06\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.141\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3626   1.3888   7.6237  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 27838, Mean R = -44.4  Std R = 32.3  Min R = -193.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00117\n",
      "PolicyEntropy: -2.18\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 6.73e+06\n",
      "ValFuncLoss: 0.00144\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5086   3.0631  14.2447  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 27869, Mean R = -41.8  Std R = 12.9  Min R = -81.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.00132\n",
      "PolicyEntropy: -2.18\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 6.74e+06\n",
      "ValFuncLoss: 0.00172\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3587   3.0958  15.7244  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0027   0.0101   1.6645   0.7971   0.5555\n",
      "Update Cnt = 900    ET =    176.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    23.3     0.7    -0.5 |    21.5    24.2     0.3 |   -26.4   -61.3    -1.3 |    87.3    55.0    -0.0\n",
      "v_f      |   -5.47    1.87  -20.40 |    2.44    2.38    3.71 |  -13.24   -4.90  -30.92 |    2.83    9.91  -10.26\n",
      "vr_f     |     3.7 |     1.7 |     1.4 |    12.4\n",
      "r_i      |   986.7     3.7  2350.5 |   553.8   596.9    29.0 |     2.2  -996.2  2300.3 |  1997.7   996.7  2399.8\n",
      "v_i      |  -41.61   -0.88  -80.21 |   18.86   17.48    5.93 |  -69.89  -29.94  -89.89 |  -10.09   29.88  -70.03\n",
      "norm_rf  |    36.6 |    15.9 |     3.9 |    87.5\n",
      "norm_vf  |   21.45 |    3.89 |   10.85 |   31.99\n",
      "thrust   |    1284     103    8997 |    3309    3226    2828 |  -12129  -14709   -6101 |   14997   14691   14999\n",
      "norm_thrust |   10109 |    3122 |    2000 |   15000\n",
      "fuel     |     260 |      20 |     223 |     387\n",
      "rewards  |  -41.72 |   18.49 | -193.55 |  -21.91\n",
      "fuel_rewards |   -8.95 |    0.69 |  -13.27 |   -7.66\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.53 |    0.05 |    4.32\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   33.33 |   13.76 |    9.98 |   82.45\n",
      "tracking_rewards |  -32.77 |   17.95 | -180.28 |  -13.76\n",
      "steps    |     265 |      22 |     208 |     370\n",
      "***** Episode 27900, Mean R = -45.2  Std R = 25.9  Min R = -135.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.0009\n",
      "PolicyEntropy: -2.17\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 6.75e+06\n",
      "ValFuncLoss: 0.00151\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1418   3.6180  13.8049  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 27931, Mean R = -45.0  Std R = 27.1  Min R = -147.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.00072\n",
      "PolicyEntropy: -2.16\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 6.76e+06\n",
      "ValFuncLoss: 0.00144\n",
      "Variance: 0.141\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7285   0.8288   4.2922  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 27962, Mean R = -37.2  Std R = 9.3  Min R = -74.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -2.18\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 6.76e+06\n",
      "ValFuncLoss: 0.00139\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5772   1.1603   6.0972  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0085   0.0041   0.0167   1.6645   0.7971   0.5555\n",
      "***** Episode 27993, Mean R = -45.8  Std R = 17.1  Min R = -95.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000673\n",
      "PolicyEntropy: -2.18\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 6.77e+06\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.141\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9297   1.0018   4.5742  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0057   0.0027   0.0124   1.6645   0.7971   0.5555\n",
      "***** Episode 28024, Mean R = -44.5  Std R = 26.7  Min R = -171.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000837\n",
      "PolicyEntropy: -2.17\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 6.78e+06\n",
      "ValFuncLoss: 0.00156\n",
      "Variance: 0.141\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2290   1.5041   7.8518  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 28055, Mean R = -44.8  Std R = 28.9  Min R = -165.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000958\n",
      "PolicyEntropy: -2.17\n",
      "PolicyLoss: -0.0024\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 6.79e+06\n",
      "ValFuncLoss: 0.0019\n",
      "Variance: 0.141\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2426   2.6519   9.2251  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 28086, Mean R = -41.0  Std R = 26.4  Min R = -180.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000891\n",
      "PolicyEntropy: -2.19\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.01e+03\n",
      "TotalSteps: 6.8e+06\n",
      "ValFuncLoss: 0.00182\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2360   2.2319  10.0871  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 28117, Mean R = -36.2  Std R = 12.8  Min R = -82.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000878\n",
      "PolicyEntropy: -2.2\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 6.81e+06\n",
      "ValFuncLoss: 0.00163\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3671   2.4026  11.8351  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 28148, Mean R = -42.3  Std R = 18.2  Min R = -113.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.00129\n",
      "PolicyEntropy: -2.22\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 6.81e+06\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3328   2.1107   9.8562  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 28179, Mean R = -40.9  Std R = 18.7  Min R = -97.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000807\n",
      "PolicyEntropy: -2.23\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 6.82e+06\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7095   2.1035   9.9416  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0020   0.0073   1.6645   0.7971   0.5555\n",
      "Update Cnt = 910    ET =    179.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    19.9     2.1    -0.5 |    22.4    25.7     0.3 |   -39.8   -67.6    -1.2 |    95.9    67.0    -0.0\n",
      "v_f      |   -5.18    1.54  -19.23 |    2.58    2.57    3.90 |  -14.02   -6.24  -29.33 |    6.14    8.94   -5.60\n",
      "vr_f     |     3.8 |     2.8 |     1.4 |    40.7\n",
      "r_i      |   961.9   -13.5  2350.5 |   576.0   591.6    29.2 |     4.5  -997.9  2300.3 |  1999.3  1000.0  2399.3\n",
      "v_i      |  -40.42   -0.67  -80.22 |   17.29   16.92    5.79 |  -69.93  -29.70  -89.97 |  -10.04   29.83  -70.13\n",
      "norm_rf  |    35.4 |    17.4 |     5.0 |   108.2\n",
      "norm_vf  |   20.27 |    4.05 |    6.17 |   29.89\n",
      "thrust   |    1270      72    9000 |    3259    3160    2816 |  -12407  -14700   -5775 |   14982   14560   15000\n",
      "norm_thrust |   10079 |    3095 |    2000 |   15000\n",
      "fuel     |     261 |      21 |     229 |     343\n",
      "rewards  |  -41.44 |   21.08 | -180.46 |  -21.76\n",
      "fuel_rewards |   -8.96 |    0.72 |  -11.79 |   -7.87\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.51 |    0.06 |    3.53\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   32.28 |   15.40 |    7.07 |  103.23\n",
      "tracking_rewards |  -32.47 |   20.50 | -168.72 |  -13.56\n",
      "steps    |     266 |      23 |     215 |     337\n",
      "***** Episode 28210, Mean R = -36.7  Std R = 11.0  Min R = -79.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.00122\n",
      "PolicyEntropy: -2.22\n",
      "PolicyLoss: -0.00169\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 6.83e+06\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0566   1.6098   8.7916  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0054   0.0030   0.0117   1.6645   0.7971   0.5555\n",
      "***** Episode 28241, Mean R = -38.6  Std R = 18.1  Min R = -128.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000968\n",
      "PolicyEntropy: -2.23\n",
      "PolicyLoss: -0.00218\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 6.84e+06\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.139\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3343   3.2031  13.7904  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 28272, Mean R = -36.5  Std R = 12.1  Min R = -83.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000891\n",
      "PolicyEntropy: -2.23\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 6.85e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.139\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2992   1.2917   5.8393  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 28303, Mean R = -38.0  Std R = 12.5  Min R = -92.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -2.24\n",
      "PolicyLoss: -0.00359\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 6.85e+06\n",
      "ValFuncLoss: 0.00157\n",
      "Variance: 0.139\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7665   1.0790   6.5791  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0023   0.0079   1.6645   0.7971   0.5555\n",
      "***** Episode 28334, Mean R = -41.0  Std R = 12.7  Min R = -85.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -2.25\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 6.86e+06\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0902   2.1833  10.6061  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 28365, Mean R = -39.9  Std R = 10.1  Min R = -65.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.00133\n",
      "PolicyEntropy: -2.25\n",
      "PolicyLoss: -0.00345\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 6.87e+06\n",
      "ValFuncLoss: 0.00171\n",
      "Variance: 0.139\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0947   3.5100  14.0907  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0012   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 28396, Mean R = -34.8  Std R = 10.6  Min R = -85.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.0012\n",
      "PolicyEntropy: -2.26\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 6.88e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.139\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6471   3.2741  13.0993  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 28427, Mean R = -37.9  Std R = 13.4  Min R = -93.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00131\n",
      "PolicyEntropy: -2.26\n",
      "PolicyLoss: -0.00213\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 6.89e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4349   1.5333   8.7012  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0044   0.0023   0.0096   1.6645   0.7971   0.5555\n",
      "***** Episode 28458, Mean R = -40.4  Std R = 14.3  Min R = -94.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.925\n",
      "KL: 0.000858\n",
      "PolicyEntropy: -2.26\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 6.9e+06\n",
      "ValFuncLoss: 0.00126\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5977   0.9651   5.1725  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0016   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 28489, Mean R = -35.7  Std R = 10.3  Min R = -68.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -2.28\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 6.9e+06\n",
      "ValFuncLoss: 0.00163\n",
      "Variance: 0.14\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0672   0.8861   4.4870  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0011   0.0053   1.6645   0.7971   0.5555\n",
      "Update Cnt = 920    ET =    179.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.0     5.4    -0.5 |    20.4    23.6     0.3 |   -30.0   -71.4    -1.4 |    67.8    62.4    -0.0\n",
      "v_f      |   -5.49    1.60  -19.50 |    2.48    2.54    3.81 |  -12.06   -6.67  -29.83 |    2.81    8.75   -6.42\n",
      "vr_f     |     3.9 |     3.2 |     1.3 |    35.9\n",
      "r_i      |  1018.3    75.8  2350.4 |   567.1   573.8    28.6 |    14.7  -991.6  2300.5 |  1997.2   998.4  2399.6\n",
      "v_i      |  -38.68   -1.28  -79.40 |   16.87   17.24    5.41 |  -69.82  -29.99  -89.80 |  -10.01   29.84  -70.05\n",
      "norm_rf  |    34.3 |    15.2 |     1.0 |    76.5\n",
      "norm_vf  |   20.60 |    3.97 |    6.61 |   31.16\n",
      "thrust   |    1196     102    8999 |    3108    3147    2785 |  -12104  -14450   -5155 |   14917   14705   14999\n",
      "norm_thrust |   10022 |    3049 |    2000 |   15000\n",
      "fuel     |     259 |      17 |     222 |     361\n",
      "rewards  |  -38.37 |   14.55 | -155.41 |  -21.15\n",
      "fuel_rewards |   -8.91 |    0.59 |  -12.39 |   -7.63\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.50 |    0.06 |    3.68\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   31.03 |   12.99 |    9.08 |   71.48\n",
      "tracking_rewards |  -29.46 |   14.14 | -143.02 |  -12.68\n",
      "steps    |     266 |      21 |     214 |     332\n",
      "***** Episode 28520, Mean R = -41.0  Std R = 24.1  Min R = -155.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000873\n",
      "PolicyEntropy: -2.29\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 6.91e+06\n",
      "ValFuncLoss: 0.0012\n",
      "Variance: 0.139\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3831   0.7734   3.8373  18.3978   9.4093   4.5498\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 28551, Mean R = -40.0  Std R = 12.6  Min R = -86.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -2.29\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 6.92e+06\n",
      "ValFuncLoss: 0.00108\n",
      "Variance: 0.138\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4978   5.2496  19.4057  19.4057  10.4978   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 28582, Mean R = -38.8  Std R = 10.9  Min R = -64.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000848\n",
      "PolicyEntropy: -2.29\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 6.93e+06\n",
      "ValFuncLoss: 0.000887\n",
      "Variance: 0.138\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.2745   3.1160  16.0614  19.4057  10.4978   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 28613, Mean R = -38.2  Std R = 10.6  Min R = -64.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000791\n",
      "PolicyEntropy: -2.29\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 6.94e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.138\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6548   3.3348  14.9972  19.4057  10.4978   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 28644, Mean R = -38.1  Std R = 14.2  Min R = -94.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.001\n",
      "PolicyEntropy: -2.29\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 6.95e+06\n",
      "ValFuncLoss: 0.00165\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8937   1.5518   7.4211  19.4057  10.4978   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 28675, Mean R = -40.9  Std R = 17.9  Min R = -103.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000773\n",
      "PolicyEntropy: -2.29\n",
      "PolicyLoss: -0.00329\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 6.95e+06\n",
      "ValFuncLoss: 0.00132\n",
      "Variance: 0.138\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7838   2.9303  12.3889  19.4057  10.4978   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 28706, Mean R = -34.4  Std R = 7.2  Min R = -48.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.00126\n",
      "PolicyEntropy: -2.29\n",
      "PolicyLoss: -0.00181\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 6.96e+06\n",
      "ValFuncLoss: 0.00117\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.5032   4.3342  19.5277  19.5277  10.5032   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 28737, Mean R = -35.2  Std R = 8.3  Min R = -65.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -2.3\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 6.97e+06\n",
      "ValFuncLoss: 0.00158\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2714   1.7776   7.1720  19.5277  10.5032   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0017   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 28768, Mean R = -42.8  Std R = 20.4  Min R = -112.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -2.31\n",
      "PolicyLoss: -0.00232\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 6.98e+06\n",
      "ValFuncLoss: 0.00126\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7217   0.6964   4.6421  19.5277  10.5032   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0018   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 28799, Mean R = -38.8  Std R = 13.6  Min R = -76.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.001\n",
      "PolicyEntropy: -2.32\n",
      "PolicyLoss: -0.00372\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 6.99e+06\n",
      "ValFuncLoss: 0.00134\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8102   0.9213   5.4373  19.5277  10.5032   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "Update Cnt = 930    ET =    179.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    18.2     5.9    -0.4 |    21.8    23.6     0.3 |   -34.4   -53.6    -1.2 |    81.0    88.2    -0.0\n",
      "v_f      |   -5.09    1.36  -17.69 |    2.71    2.32    4.29 |  -13.87   -5.76  -29.30 |    3.17    8.14   -4.45\n",
      "vr_f     |     3.7 |     3.8 |     1.1 |    61.1\n",
      "r_i      |   999.1   -38.3  2349.1 |   586.4   575.5    28.8 |     4.0  -999.2  2300.2 |  1993.3   989.9  2399.3\n",
      "v_i      |  -40.50    1.62  -79.92 |   16.61   16.49    5.80 |  -69.90  -29.62  -89.94 |  -10.68   29.87  -70.05\n",
      "norm_rf  |    34.0 |    15.7 |     0.6 |    96.6\n",
      "norm_vf  |   18.74 |    4.54 |    6.21 |   30.71\n",
      "thrust   |    1269     -10    9042 |    3114    3040    2751 |  -11217  -14292   -6298 |   14997   14664   15000\n",
      "norm_thrust |   10041 |    3007 |    2000 |   15000\n",
      "fuel     |     262 |      18 |     228 |     343\n",
      "rewards  |  -38.71 |   13.85 | -112.94 |  -21.96\n",
      "fuel_rewards |   -8.99 |    0.60 |  -11.79 |   -7.84\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.49 |    0.07 |    3.52\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   30.29 |   14.14 |    4.21 |   91.62\n",
      "tracking_rewards |  -29.72 |   13.41 | -101.48 |  -13.22\n",
      "steps    |     268 |      21 |     213 |     328\n",
      "***** Episode 28830, Mean R = -39.8  Std R = 15.2  Min R = -88.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000891\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 7e+06\n",
      "ValFuncLoss: 0.000969\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8822   2.4269  10.3310  19.5277  10.5032   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0025   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 28861, Mean R = -41.0  Std R = 14.5  Min R = -82.7\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.002\n",
      "PolicyEntropy: -2.33\n",
      "PolicyLoss: -0.00147\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 7e+06\n",
      "ValFuncLoss: 0.00111\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.9116   5.1746  22.2693  22.2693  13.9116   5.2496\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0015   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 28892, Mean R = -37.6  Std R = 11.3  Min R = -70.3\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.00126\n",
      "PolicyEntropy: -2.33\n",
      "PolicyLoss: 0.00137\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 7.01e+06\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  19.5418  12.1108  30.9166  30.9166  19.5418  12.1108\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 28923, Mean R = -39.9  Std R = 11.9  Min R = -80.3\n",
      "Beta: 0.0296\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.00638\n",
      "PolicyEntropy: -2.33\n",
      "PolicyLoss: 0.0159\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 7.02e+06\n",
      "ValFuncLoss: 0.00155\n",
      "Variance: 0.137\n",
      "lr_multiplier: 1\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  22.3427  13.6948  32.1246  32.1246  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 28954, Mean R = -41.4  Std R = 13.9  Min R = -78.6\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.0056\n",
      "PolicyEntropy: -2.33\n",
      "PolicyLoss: 0.0163\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 7.03e+06\n",
      "ValFuncLoss: 0.00105\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.667\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  21.2838   6.3879  33.4160  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 28985, Mean R = -37.6  Std R = 8.4  Min R = -62.9\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.00055\n",
      "PolicyEntropy: -2.33\n",
      "PolicyLoss: 0.0024\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 7.04e+06\n",
      "ValFuncLoss: 0.00109\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.667\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  17.0356   6.2749  26.8069  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0022   0.0090   1.6645   0.7971   0.5555\n",
      "***** Episode 29016, Mean R = -41.6  Std R = 13.6  Min R = -105.4\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.00059\n",
      "PolicyEntropy: -2.33\n",
      "PolicyLoss: 0.00241\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.05e+06\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.667\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  18.0936   6.4716  30.7239  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 29047, Mean R = -36.2  Std R = 8.2  Min R = -60.7\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00124\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: 0.00603\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 7.05e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.667\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  17.9529   5.8803  25.1637  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 29078, Mean R = -37.1  Std R = 10.2  Min R = -66.1\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.00113\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: 0.0064\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 7.06e+06\n",
      "ValFuncLoss: 0.00134\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.667\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.4520  10.4817  23.9337  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 29109, Mean R = -40.4  Std R = 11.9  Min R = -87.0\n",
      "Beta: 0.0132\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00473\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: 0.0185\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.07e+06\n",
      "ValFuncLoss: 0.00122\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.1500   4.3068  20.1584  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "Update Cnt = 940    ET =    173.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    18.4     6.7    -0.5 |    20.7    23.7     0.3 |   -80.5   -67.2    -1.3 |    69.8   183.3    -0.0\n",
      "v_f      |   -5.40    1.53  -18.77 |    2.60    2.40    3.82 |  -14.75  -10.05  -26.04 |    1.31   10.25   -5.29\n",
      "vr_f     |     3.7 |     2.4 |     1.0 |    24.1\n",
      "r_i      |   975.1    24.8  2350.6 |   596.7   584.8    27.7 |    12.3  -996.0  2300.4 |  1997.7   996.3  2399.8\n",
      "v_i      |  -39.55    2.39  -79.64 |   16.65   17.55    6.03 |  -69.81  -29.83  -89.99 |  -10.10   29.97  -70.07\n",
      "norm_rf  |    31.9 |    18.9 |     1.6 |   200.2\n",
      "norm_vf  |   19.87 |    4.05 |    7.06 |   27.80\n",
      "thrust   |    1223     -47    8996 |    3160    3156    2772 |  -11926  -14370   -6904 |   14992   14353   15000\n",
      "norm_thrust |   10036 |    3056 |    2000 |   15000\n",
      "fuel     |     261 |      17 |     229 |     381\n",
      "rewards  |  -39.92 |   15.58 | -186.81 |  -22.40\n",
      "fuel_rewards |   -8.97 |    0.58 |  -13.11 |   -7.88\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.50 |    0.08 |    3.22\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   29.31 |   16.65 |    6.95 |  195.23\n",
      "tracking_rewards |  -30.95 |   15.16 | -173.69 |  -13.77\n",
      "steps    |     268 |      22 |     175 |     366\n",
      "***** Episode 29140, Mean R = -46.5  Std R = 33.2  Min R = -186.8\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 9.67e-05\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: 0.000269\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 7.08e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.4653   3.9015  16.9986  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 29171, Mean R = -37.7  Std R = 11.3  Min R = -72.8\n",
      "Beta: 0.0296\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.921\n",
      "KL: 0.000127\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: -0.000547\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 7.09e+06\n",
      "ValFuncLoss: 0.00101\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1380   1.4728   8.4569  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 29202, Mean R = -37.8  Std R = 9.4  Min R = -64.7\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000158\n",
      "PolicyEntropy: -2.33\n",
      "PolicyLoss: -0.00141\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 7.1e+06\n",
      "ValFuncLoss: 0.000722\n",
      "Variance: 0.137\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2073   0.9163   4.0036  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 29233, Mean R = -41.1  Std R = 26.7  Min R = -167.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000465\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: -0.00197\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 7.1e+06\n",
      "ValFuncLoss: 0.00144\n",
      "Variance: 0.136\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0200   1.2113   5.4761  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0025   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 29264, Mean R = -37.3  Std R = 9.1  Min R = -60.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.939\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000787\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 7.11e+06\n",
      "ValFuncLoss: 0.00116\n",
      "Variance: 0.136\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2607   1.0849   6.4651  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 29295, Mean R = -40.2  Std R = 15.8  Min R = -95.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00075\n",
      "PolicyEntropy: -2.35\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 7.12e+06\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.136\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8023   1.0972   5.6887  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 29326, Mean R = -41.6  Std R = 18.1  Min R = -127.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.00069\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 7.13e+06\n",
      "ValFuncLoss: 0.00153\n",
      "Variance: 0.136\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5238   0.8550   4.8766  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 29357, Mean R = -47.0  Std R = 26.8  Min R = -154.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00076\n",
      "PolicyEntropy: -2.34\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 7.14e+06\n",
      "ValFuncLoss: 0.0019\n",
      "Variance: 0.135\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6478   1.2534   6.0649  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 29388, Mean R = -38.6  Std R = 8.5  Min R = -58.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000848\n",
      "PolicyEntropy: -2.35\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 7.15e+06\n",
      "ValFuncLoss: 0.00158\n",
      "Variance: 0.135\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7334   0.8533   5.0903  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0017   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 29419, Mean R = -37.6  Std R = 11.0  Min R = -81.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000903\n",
      "PolicyEntropy: -2.36\n",
      "PolicyLoss: -0.00325\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 7.15e+06\n",
      "ValFuncLoss: 0.00172\n",
      "Variance: 0.134\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4965   1.8812   8.8993  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0015   0.0061   1.6645   0.7971   0.5555\n",
      "Update Cnt = 950    ET =    180.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.7     6.2    -0.5 |    20.5    22.6     0.3 |   -28.4   -59.2    -1.2 |    76.9    56.2    -0.0\n",
      "v_f      |   -5.20    1.49  -18.12 |    2.61    2.26    3.93 |  -13.78   -4.61  -28.74 |    1.40    9.75   -4.44\n",
      "vr_f     |     3.8 |     3.0 |     1.1 |    41.9\n",
      "r_i      |   966.9    10.5  2351.7 |   611.5   558.0    28.1 |     1.9  -996.3  2300.5 |  1989.4   977.9  2399.7\n",
      "v_i      |  -41.72    0.36  -79.42 |   16.88   17.79    5.58 |  -69.73  -29.98  -89.94 |  -10.20   29.92  -70.04\n",
      "norm_rf  |    32.4 |    15.3 |     3.0 |    95.2\n",
      "norm_vf  |   19.17 |    4.18 |    5.21 |   30.23\n",
      "thrust   |    1282      51    8977 |    3192    3144    2744 |  -10783  -14261   -7070 |   14998   14272   15000\n",
      "norm_thrust |   10027 |    3051 |    2000 |   15000\n",
      "fuel     |     262 |      18 |     224 |     358\n",
      "rewards  |  -39.64 |   16.42 | -167.41 |  -21.37\n",
      "fuel_rewards |   -8.99 |    0.63 |  -12.30 |   -7.70\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.36 |    0.51 |    0.05 |    2.99\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   29.02 |   13.39 |    9.24 |   90.20\n",
      "tracking_rewards |  -30.65 |   15.92 | -155.53 |  -12.65\n",
      "steps    |     268 |      20 |     224 |     335\n",
      "***** Episode 29450, Mean R = -37.5  Std R = 10.7  Min R = -76.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000913\n",
      "PolicyEntropy: -2.36\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 7.16e+06\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.134\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6555   0.8429   4.6209  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 29481, Mean R = -36.4  Std R = 6.6  Min R = -57.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000789\n",
      "PolicyEntropy: -2.36\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.11e+03\n",
      "TotalSteps: 7.17e+06\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9310   0.7306   4.4190  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0015   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 29512, Mean R = -40.1  Std R = 15.5  Min R = -97.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000665\n",
      "PolicyEntropy: -2.37\n",
      "PolicyLoss: -0.00214\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 7.18e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9149   0.7236   3.9644  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 29543, Mean R = -36.9  Std R = 8.9  Min R = -57.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000626\n",
      "PolicyEntropy: -2.37\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 7.19e+06\n",
      "ValFuncLoss: 0.00147\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4480   0.6381   3.7067  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0020   0.0083   1.6645   0.7971   0.5555\n",
      "***** Episode 29574, Mean R = -39.2  Std R = 19.0  Min R = -124.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000765\n",
      "PolicyEntropy: -2.38\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 7.19e+06\n",
      "ValFuncLoss: 0.00135\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3913   0.7873   4.0276  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0027   0.0115   1.6645   0.7971   0.5555\n",
      "***** Episode 29605, Mean R = -35.6  Std R = 7.9  Min R = -58.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000658\n",
      "PolicyEntropy: -2.39\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 7.2e+06\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.1325   0.5181   3.1411  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 29636, Mean R = -36.8  Std R = 11.4  Min R = -72.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000685\n",
      "PolicyEntropy: -2.38\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 7.21e+06\n",
      "ValFuncLoss: 0.00143\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2542   0.7220   3.6402  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 29667, Mean R = -40.3  Std R = 17.3  Min R = -109.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000523\n",
      "PolicyEntropy: -2.38\n",
      "PolicyLoss: -0.00232\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 7.22e+06\n",
      "ValFuncLoss: 0.0019\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.7076   0.4692   2.6454  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 29698, Mean R = -42.3  Std R = 24.4  Min R = -163.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -2.37\n",
      "PolicyLoss: -0.00231\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 7.23e+06\n",
      "ValFuncLoss: 0.0023\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4361   0.6755   3.7328  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 29729, Mean R = -40.3  Std R = 11.2  Min R = -73.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000523\n",
      "PolicyEntropy: -2.38\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 7.24e+06\n",
      "ValFuncLoss: 0.00171\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3431   0.9296   4.7215  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "Update Cnt = 960    ET =    177.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.2     4.5    -0.5 |    21.2    24.0     0.3 |   -30.4   -61.9    -1.3 |    97.4    92.0    -0.0\n",
      "v_f      |   -5.51    1.28  -17.89 |    2.61    2.46    3.74 |  -15.90   -6.07  -27.24 |    0.52    8.26   -2.12\n",
      "vr_f     |     3.5 |     2.8 |     0.9 |    30.9\n",
      "r_i      |  1033.3   -50.1  2350.0 |   579.8   593.2    29.2 |    18.5  -996.1  2300.3 |  1996.0   989.5  2399.9\n",
      "v_i      |  -39.95   -0.89  -80.21 |   17.83   17.21    5.83 |  -70.00  -29.78  -89.96 |  -10.13   29.11  -70.20\n",
      "norm_rf  |    34.1 |    17.1 |     1.5 |   134.0\n",
      "norm_vf  |   19.06 |    3.97 |    2.62 |   28.92\n",
      "thrust   |    1246     100    9063 |    3100    3167    2720 |  -11302  -14196   -6223 |   14967   14630   15000\n",
      "norm_thrust |   10088 |    2998 |    2000 |   15000\n",
      "fuel     |     259 |      17 |     224 |     349\n",
      "rewards  |  -38.73 |   14.53 | -163.36 |  -21.00\n",
      "fuel_rewards |   -8.89 |    0.59 |  -12.00 |   -7.69\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.52 |    0.07 |    3.37\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   30.84 |   15.16 |    9.25 |  128.96\n",
      "tracking_rewards |  -29.84 |   14.08 | -151.36 |  -12.62\n",
      "steps    |     264 |      21 |     216 |     331\n",
      "***** Episode 29760, Mean R = -39.4  Std R = 11.5  Min R = -79.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000607\n",
      "PolicyEntropy: -2.39\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.09e+03\n",
      "TotalSteps: 7.24e+06\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3442   0.6238   3.9298  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0017   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 29791, Mean R = -43.6  Std R = 21.9  Min R = -146.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000677\n",
      "PolicyEntropy: -2.39\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 7.25e+06\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.5585   0.3864   2.5016  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0017   0.0085   1.6645   0.7971   0.5555\n",
      "***** Episode 29822, Mean R = -38.8  Std R = 17.0  Min R = -103.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -2.39\n",
      "PolicyLoss: -0.00201\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 7.26e+06\n",
      "ValFuncLoss: 0.0011\n",
      "Variance: 0.133\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0290   1.1460   5.9874  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 29853, Mean R = -35.9  Std R = 9.2  Min R = -68.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.00059\n",
      "PolicyEntropy: -2.39\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 7.27e+06\n",
      "ValFuncLoss: 0.00137\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5187   1.0314   5.4285  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 29884, Mean R = -35.7  Std R = 7.3  Min R = -63.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000824\n",
      "PolicyEntropy: -2.4\n",
      "PolicyLoss: -0.00382\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 7.28e+06\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0876   0.5564   3.7576  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 29915, Mean R = -36.7  Std R = 10.3  Min R = -65.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000698\n",
      "PolicyEntropy: -2.39\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 7.28e+06\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2627   0.9728   5.3789  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 29946, Mean R = -37.1  Std R = 9.4  Min R = -66.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -2.39\n",
      "PolicyLoss: -0.00358\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 7.29e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2510   0.8031   4.9877  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 29977, Mean R = -39.7  Std R = 7.9  Min R = -59.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000676\n",
      "PolicyEntropy: -2.4\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 7.3e+06\n",
      "ValFuncLoss: 0.00213\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3907   0.6289   3.8979  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0009   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 30008, Mean R = -42.4  Std R = 16.1  Min R = -84.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000929\n",
      "PolicyEntropy: -2.41\n",
      "PolicyLoss: -0.00361\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 7.31e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9036   1.0814   5.9138  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 30039, Mean R = -38.2  Std R = 12.7  Min R = -92.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000627\n",
      "PolicyEntropy: -2.42\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 7.32e+06\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.132\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8790   0.5956   3.3244  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0015   0.0058   1.6645   0.7971   0.5555\n",
      "Update Cnt = 970    ET =    177.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    15.8     0.5    -0.4 |    19.3    21.3     0.3 |   -33.5   -60.4    -1.2 |    60.4    71.5    -0.0\n",
      "v_f      |   -5.03    1.57  -17.77 |    2.26    2.43    3.52 |  -12.45   -6.39  -28.27 |    1.67    9.66   -2.89\n",
      "vr_f     |     3.6 |     2.3 |     0.8 |    31.6\n",
      "r_i      |   959.3   -73.0  2349.7 |   597.4   581.1    29.1 |     1.7  -978.3  2300.1 |  1998.2   988.3  2397.6\n",
      "v_i      |  -40.21    1.18  -79.95 |   17.17   17.36    5.78 |  -69.92  -29.69  -89.88 |  -10.35   29.79  -70.08\n",
      "norm_rf  |    29.5 |    14.4 |     2.7 |    75.2\n",
      "norm_vf  |   18.81 |    3.66 |    4.45 |   30.92\n",
      "thrust   |    1236      22    9037 |    3104    3157    2710 |  -11057  -13719   -5979 |   14993   14332   14999\n",
      "norm_thrust |   10057 |    2999 |    2000 |   15000\n",
      "fuel     |     260 |      17 |     230 |     322\n",
      "rewards  |  -38.88 |   14.28 | -145.99 |  -21.55\n",
      "fuel_rewards |   -8.93 |    0.59 |  -11.07 |   -7.92\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.51 |    0.13 |    3.37\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   27.06 |   11.67 |    6.31 |   70.23\n",
      "tracking_rewards |  -29.95 |   13.86 | -134.92 |  -12.73\n",
      "steps    |     266 |      19 |     226 |     320\n",
      "***** Episode 30070, Mean R = -40.5  Std R = 19.7  Min R = -119.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -2.43\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 7.33e+06\n",
      "ValFuncLoss: 0.00123\n",
      "Variance: 0.131\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1677   1.5217   6.9371  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 30101, Mean R = -35.9  Std R = 9.3  Min R = -63.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000723\n",
      "PolicyEntropy: -2.43\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 7.33e+06\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.131\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6223   1.3825   5.8784  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 30132, Mean R = -34.8  Std R = 8.4  Min R = -57.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000695\n",
      "PolicyEntropy: -2.44\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 7.34e+06\n",
      "ValFuncLoss: 0.00139\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4262   0.7725   3.5495  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 30163, Mean R = -43.4  Std R = 21.7  Min R = -151.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000707\n",
      "PolicyEntropy: -2.44\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 7.35e+06\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4207   1.7140   8.2769  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 30194, Mean R = -37.2  Std R = 11.7  Min R = -73.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.0009\n",
      "PolicyEntropy: -2.44\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.36e+06\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4564   1.3983   6.3147  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 30225, Mean R = -38.3  Std R = 9.4  Min R = -58.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000923\n",
      "PolicyEntropy: -2.44\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.37e+06\n",
      "ValFuncLoss: 0.0014\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8186   0.9295   4.6978  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 30256, Mean R = -34.5  Std R = 9.1  Min R = -61.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -2.44\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 7.38e+06\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6432   0.7727   4.1822  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 30287, Mean R = -37.9  Std R = 12.1  Min R = -86.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000802\n",
      "PolicyEntropy: -2.45\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 7.38e+06\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3090   1.1890   5.2117  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 30318, Mean R = -37.2  Std R = 11.2  Min R = -70.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000703\n",
      "PolicyEntropy: -2.46\n",
      "PolicyLoss: -0.0025\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 7.39e+06\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8886   0.7020   4.3501  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 30349, Mean R = -35.6  Std R = 13.8  Min R = -85.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000545\n",
      "PolicyEntropy: -2.47\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.4e+06\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9356   0.9090   5.3543  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0002   0.0012   1.6645   0.7971   0.5555\n",
      "Update Cnt = 980    ET =    179.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    14.7     3.1    -0.4 |    18.0    20.7     0.3 |   -39.3   -58.0    -1.2 |    60.7    70.8    -0.0\n",
      "v_f      |   -4.98    1.34  -16.97 |    2.27    2.12    3.58 |  -11.61   -6.40  -27.25 |    0.99    9.75   -4.72\n",
      "vr_f     |     3.5 |     2.0 |     1.1 |    26.9\n",
      "r_i      |   947.7     6.2  2348.0 |   580.9   570.7    28.3 |     1.5  -998.0  2300.2 |  1969.9   996.8  2400.0\n",
      "v_i      |  -38.15    0.54  -79.98 |   17.31   16.65    5.40 |  -69.84  -29.95  -89.94 |  -10.16   29.97  -70.03\n",
      "norm_rf  |    27.9 |    14.1 |     1.7 |    81.0\n",
      "norm_vf  |   17.96 |    3.79 |    4.86 |   28.17\n",
      "thrust   |    1183      28    9064 |    3099    3014    2691 |  -11595  -14195   -6055 |   14957   14101   14999\n",
      "norm_thrust |   10037 |    2955 |    2000 |   15000\n",
      "fuel     |     260 |      16 |     226 |     337\n",
      "rewards  |  -37.08 |   12.57 | -151.45 |  -20.57\n",
      "fuel_rewards |   -8.94 |    0.54 |  -11.58 |   -7.76\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.56 |    0.38 |    3.54\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   25.07 |   11.84 |    6.73 |   75.98\n",
      "tracking_rewards |  -28.14 |   12.23 | -139.88 |  -11.83\n",
      "steps    |     266 |      21 |     211 |     328\n",
      "***** Episode 30380, Mean R = -35.9  Std R = 11.0  Min R = -79.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000701\n",
      "PolicyEntropy: -2.47\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 7.41e+06\n",
      "ValFuncLoss: 0.00182\n",
      "Variance: 0.13\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4310   0.5776   3.4776  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 30411, Mean R = -34.7  Std R = 6.6  Min R = -48.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000708\n",
      "PolicyEntropy: -2.48\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 7.42e+06\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.129\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2706   1.5312   6.9962  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 30442, Mean R = -35.8  Std R = 8.2  Min R = -58.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.937\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000744\n",
      "PolicyEntropy: -2.48\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 7.43e+06\n",
      "ValFuncLoss: 0.00162\n",
      "Variance: 0.129\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5145   1.2607   6.1882  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 30473, Mean R = -37.8  Std R = 16.7  Min R = -118.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00065\n",
      "PolicyEntropy: -2.49\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 7.43e+06\n",
      "ValFuncLoss: 0.00225\n",
      "Variance: 0.129\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6475   1.1206   6.1102  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0008   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 30504, Mean R = -37.1  Std R = 10.2  Min R = -74.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000742\n",
      "PolicyEntropy: -2.49\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 7.44e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.129\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1872   1.6287   8.0465  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 30535, Mean R = -40.2  Std R = 16.2  Min R = -110.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000746\n",
      "PolicyEntropy: -2.5\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 7.45e+06\n",
      "ValFuncLoss: 0.00224\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5579   0.7636   4.1779  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 30566, Mean R = -37.1  Std R = 12.1  Min R = -88.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000699\n",
      "PolicyEntropy: -2.5\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 7.46e+06\n",
      "ValFuncLoss: 0.00247\n",
      "Variance: 0.129\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3854   1.2080   6.1767  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 30597, Mean R = -34.1  Std R = 7.2  Min R = -49.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000807\n",
      "PolicyEntropy: -2.5\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 7.47e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6927   2.4745  11.8593  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 30628, Mean R = -37.9  Std R = 7.5  Min R = -61.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000675\n",
      "PolicyEntropy: -2.5\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 7.48e+06\n",
      "ValFuncLoss: 0.00223\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8004   1.1283   5.3832  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 30659, Mean R = -38.1  Std R = 9.7  Min R = -62.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.00068\n",
      "PolicyEntropy: -2.51\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 7.48e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.129\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7540   2.0321  11.0562  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0010   0.0044   1.6645   0.7971   0.5555\n",
      "Update Cnt = 990    ET =    182.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.1     4.2    -0.4 |    18.1    21.0     0.3 |   -31.4   -53.2    -1.2 |    69.4    68.1    -0.0\n",
      "v_f      |   -4.95    1.19  -15.86 |    2.21    2.19    3.98 |  -11.31   -5.32  -25.33 |    1.78    9.27   -3.55\n",
      "vr_f     |     3.2 |     1.4 |     1.3 |    12.1\n",
      "r_i      |  1048.0    -9.0  2350.0 |   565.5   605.0    30.1 |    20.2  -999.3  2300.0 |  1993.3   998.0  2399.5\n",
      "v_i      |  -40.58    0.57  -79.64 |   17.00   17.93    5.59 |  -69.79  -29.60  -89.89 |  -10.11   29.99  -70.19\n",
      "norm_rf  |    29.8 |    13.9 |     2.6 |    75.0\n",
      "norm_vf  |   16.89 |    4.19 |    4.22 |   26.81\n",
      "thrust   |    1246      26    9021 |    2939    3080    2665 |  -10756  -14048   -6803 |   14935   14117   15000\n",
      "norm_thrust |    9973 |    2951 |    2000 |   15000\n",
      "fuel     |     263 |      15 |     230 |     338\n",
      "rewards  |  -37.33 |   11.77 | -118.36 |  -21.18\n",
      "fuel_rewards |   -9.04 |    0.52 |  -11.61 |   -7.94\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.36 |    0.47 |    0.21 |    3.33\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   26.38 |   11.99 |    3.30 |   70.00\n",
      "tracking_rewards |  -28.29 |   11.44 | -107.54 |  -12.37\n",
      "steps    |     271 |      22 |     216 |     325\n",
      "***** Episode 30690, Mean R = -40.5  Std R = 15.6  Min R = -88.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -2.51\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 7.49e+06\n",
      "ValFuncLoss: 0.00215\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1011   0.7408   4.6322  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 30721, Mean R = -37.7  Std R = 11.7  Min R = -84.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000744\n",
      "PolicyEntropy: -2.52\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 7.5e+06\n",
      "ValFuncLoss: 0.00241\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1192   0.8347   4.7956  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 30752, Mean R = -36.9  Std R = 12.0  Min R = -89.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000723\n",
      "PolicyEntropy: -2.52\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 7.51e+06\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6696   0.8111   5.0182  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0024   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 30783, Mean R = -48.0  Std R = 38.9  Min R = -206.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000589\n",
      "PolicyEntropy: -2.52\n",
      "PolicyLoss: -0.00229\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 7.52e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6028   0.8433   4.7084  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 30814, Mean R = -37.9  Std R = 9.1  Min R = -61.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.928\n",
      "KL: 0.000719\n",
      "PolicyEntropy: -2.52\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 7.53e+06\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3951   0.6204   3.7229  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 30845, Mean R = -35.4  Std R = 5.5  Min R = -47.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.00058\n",
      "PolicyEntropy: -2.53\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 7.53e+06\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7190   0.9029   4.6886  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 30876, Mean R = -39.4  Std R = 15.2  Min R = -102.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000601\n",
      "PolicyEntropy: -2.53\n",
      "PolicyLoss: -0.00235\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 7.54e+06\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8350   1.9421   7.9254  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 30907, Mean R = -34.3  Std R = 7.5  Min R = -53.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.938\n",
      "KL: 0.000674\n",
      "PolicyEntropy: -2.53\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 7.55e+06\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1121   1.1018   6.5607  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0013   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 30938, Mean R = -39.7  Std R = 14.4  Min R = -88.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00073\n",
      "PolicyEntropy: -2.53\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 7.56e+06\n",
      "ValFuncLoss: 0.00235\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4954   0.7244   4.4303  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 30969, Mean R = -40.2  Std R = 25.0  Min R = -166.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000755\n",
      "PolicyEntropy: -2.53\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 7.57e+06\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7796   1.2811   6.5588  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1000    ET =    180.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    18.6     3.4    -0.4 |    20.0    23.0     0.3 |   -33.2   -48.4    -1.2 |    61.7    63.1    -0.0\n",
      "v_f      |   -5.23    1.27  -16.88 |    2.55    2.39    3.51 |  -12.21   -4.73  -25.42 |    6.24    8.46   -6.24\n",
      "vr_f     |     3.5 |     2.6 |     1.3 |    34.2\n",
      "r_i      |  1000.4    -7.7  2350.7 |   559.4   573.6    29.4 |     6.3  -982.9  2300.1 |  1995.9   994.2  2399.9\n",
      "v_i      |  -40.59   -0.85  -79.57 |   17.48   17.07    5.55 |  -69.88  -29.92  -89.98 |  -10.27   29.89  -70.02\n",
      "norm_rf  |    32.6 |    15.1 |     2.9 |    76.2\n",
      "norm_vf  |   18.01 |    3.76 |    6.89 |   26.09\n",
      "thrust   |    1254      87    9053 |    3055    3013    2687 |  -11234  -14134   -5514 |   14999   14638   15000\n",
      "norm_thrust |   10018 |    2968 |    2000 |   15000\n",
      "fuel     |     261 |      18 |     228 |     420\n",
      "rewards  |  -38.35 |   18.02 | -206.07 |  -21.41\n",
      "fuel_rewards |   -8.96 |    0.63 |  -14.44 |   -7.84\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.49 |    0.05 |    3.80\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   28.99 |   13.34 |    7.60 |   71.16\n",
      "tracking_rewards |  -29.38 |   17.52 | -191.64 |  -12.86\n",
      "steps    |     268 |      22 |     212 |     398\n",
      "***** Episode 31000, Mean R = -33.9  Std R = 8.4  Min R = -55.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000544\n",
      "PolicyEntropy: -2.54\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 7.58e+06\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.129\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0646   1.4813   7.8450  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 31031, Mean R = -35.8  Std R = 10.5  Min R = -73.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000686\n",
      "PolicyEntropy: -2.54\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 7.58e+06\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3211   0.5891   3.3459  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0011   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 31062, Mean R = -43.8  Std R = 23.1  Min R = -134.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -2.54\n",
      "PolicyLoss: -0.00188\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 7.59e+06\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4933   1.9571   8.4126  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 31093, Mean R = -37.8  Std R = 9.6  Min R = -66.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000915\n",
      "PolicyEntropy: -2.55\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 7.6e+06\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8442   1.4526   6.8367  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 31124, Mean R = -36.1  Std R = 12.1  Min R = -68.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000805\n",
      "PolicyEntropy: -2.56\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 7.61e+06\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2211   1.5084   9.5318  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 31155, Mean R = -37.0  Std R = 9.7  Min R = -64.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000978\n",
      "PolicyEntropy: -2.57\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 7.62e+06\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9477   1.4405   7.9647  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0005   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 31186, Mean R = -43.3  Std R = 29.0  Min R = -192.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000565\n",
      "PolicyEntropy: -2.56\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 7.63e+06\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1979   1.3526   6.7525  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 31217, Mean R = -36.1  Std R = 7.9  Min R = -58.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.947\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000857\n",
      "PolicyEntropy: -2.56\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 7.63e+06\n",
      "ValFuncLoss: 0.00247\n",
      "Variance: 0.128\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.9725   0.6093   3.3178  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0010   0.0053   1.6645   0.7971   0.5555\n",
      "***** Episode 31248, Mean R = -37.2  Std R = 19.7  Min R = -130.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000826\n",
      "PolicyEntropy: -2.57\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 7.64e+06\n",
      "ValFuncLoss: 0.00196\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6795   0.8245   4.5274  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 31279, Mean R = -37.7  Std R = 11.3  Min R = -83.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000527\n",
      "PolicyEntropy: -2.57\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 7.65e+06\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4902   1.7775   7.9575  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0014   0.0057   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1010    ET =    177.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    15.4     6.3    -0.4 |    20.6    23.9     0.3 |   -48.0   -58.7    -1.2 |    68.5    69.9    -0.0\n",
      "v_f      |   -5.52    1.56  -17.61 |    2.34    2.57    4.06 |  -14.65   -7.64  -30.40 |   -0.02    8.26   -5.15\n",
      "vr_f     |     3.1 |     1.5 |     1.1 |    16.8\n",
      "r_i      |  1002.2     2.9  2351.8 |   573.4   561.1    30.0 |    11.3  -990.6  2300.2 |  1999.4   997.4  2399.6\n",
      "v_i      |  -38.45   -1.40  -79.87 |   16.99   17.27    6.03 |  -69.96  -29.89  -89.97 |  -10.09   29.50  -70.02\n",
      "norm_rf  |    32.3 |    15.1 |     1.3 |    90.6\n",
      "norm_vf  |   18.79 |    4.29 |    6.09 |   31.14\n",
      "thrust   |    1179     100    9027 |    2969    3021    2705 |  -11239  -14442   -6091 |   14998   14309   15000\n",
      "norm_thrust |    9962 |    2984 |    2000 |   15000\n",
      "fuel     |     259 |      17 |     226 |     369\n",
      "rewards  |  -38.21 |   16.09 | -192.62 |  -20.43\n",
      "fuel_rewards |   -8.91 |    0.59 |  -12.69 |   -7.78\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.55 |    0.10 |    3.60\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   28.81 |   13.32 |    6.49 |   85.63\n",
      "tracking_rewards |  -29.30 |   15.70 | -179.93 |  -11.75\n",
      "steps    |     268 |      24 |     219 |     360\n",
      "***** Episode 31310, Mean R = -37.4  Std R = 11.1  Min R = -76.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000709\n",
      "PolicyEntropy: -2.58\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.66e+06\n",
      "ValFuncLoss: 0.00258\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0809   3.1786  16.1049  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 31341, Mean R = -35.5  Std R = 10.9  Min R = -68.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000941\n",
      "PolicyEntropy: -2.58\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 7.67e+06\n",
      "ValFuncLoss: 0.00244\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6526   2.4231   9.9469  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0012   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 31372, Mean R = -40.3  Std R = 17.5  Min R = -113.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -2.58\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 7.68e+06\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1917   2.1773  10.3200  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 31403, Mean R = -33.9  Std R = 8.1  Min R = -54.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.934\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000595\n",
      "PolicyEntropy: -2.59\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 7.68e+06\n",
      "ValFuncLoss: 0.00285\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.7277   0.7483   4.1880  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 31434, Mean R = -37.7  Std R = 13.3  Min R = -86.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00064\n",
      "PolicyEntropy: -2.59\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 7.69e+06\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9653   2.1427  10.6162  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 31465, Mean R = -36.2  Std R = 10.9  Min R = -71.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000773\n",
      "PolicyEntropy: -2.59\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 7.7e+06\n",
      "ValFuncLoss: 0.00247\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5902   1.3119   7.3091  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 31496, Mean R = -37.1  Std R = 8.3  Min R = -59.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -2.59\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.50e+03\n",
      "TotalSteps: 7.71e+06\n",
      "ValFuncLoss: 0.00256\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6713   0.7958   5.0256  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 31527, Mean R = -40.3  Std R = 18.3  Min R = -115.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -2.6\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 7.72e+06\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.126\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0594   1.7519   9.1712  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 31558, Mean R = -36.1  Std R = 8.3  Min R = -64.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.947\n",
      "KL: 0.000948\n",
      "PolicyEntropy: -2.59\n",
      "PolicyLoss: -0.00356\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 7.73e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.126\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5792   0.8481   5.7622  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 31589, Mean R = -34.0  Std R = 5.3  Min R = -43.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000587\n",
      "PolicyEntropy: -2.6\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 7.73e+06\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.126\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9027   2.1411  11.4362  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0041   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1020    ET =    181.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    20.1     4.5    -0.5 |    18.4    22.2     0.3 |   -25.8   -57.0    -1.2 |    71.9    78.9    -0.0\n",
      "v_f      |   -5.64    1.86  -17.88 |    2.40    2.00    3.62 |  -12.66   -3.78  -30.19 |    0.97    7.86   -7.50\n",
      "vr_f     |     3.2 |     1.4 |     1.3 |    10.3\n",
      "r_i      |  1015.4   -10.5  2349.0 |   577.0   542.5    29.5 |     4.9  -992.0  2300.8 |  1989.3   988.0  2399.3\n",
      "v_i      |  -38.54   -1.25  -79.94 |   16.56   17.01    5.65 |  -69.67  -29.51  -89.94 |  -10.02   29.83  -70.04\n",
      "norm_rf  |    32.0 |    15.1 |     2.3 |    94.8\n",
      "norm_vf  |   19.06 |    3.82 |    7.96 |   32.69\n",
      "thrust   |    1153     105    9034 |    2944    2925    2669 |  -11383  -13808   -5829 |   14999   14318   14999\n",
      "norm_thrust |    9927 |    2958 |    2000 |   15000\n",
      "fuel     |     258 |      14 |     232 |     319\n",
      "rewards  |  -36.81 |   12.06 | -115.37 |  -21.35\n",
      "fuel_rewards |   -8.88 |    0.47 |  -10.95 |   -7.96\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.53 |    0.60 |    3.42\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   28.71 |   13.13 |    7.00 |   89.79\n",
      "tracking_rewards |  -27.93 |   11.77 | -104.42 |  -13.13\n",
      "steps    |     268 |      20 |     215 |     320\n",
      "***** Episode 31620, Mean R = -37.3  Std R = 11.1  Min R = -69.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000815\n",
      "PolicyEntropy: -2.6\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 7.74e+06\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3142   1.0771   6.7661  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 31651, Mean R = -33.5  Std R = 5.6  Min R = -52.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -2.59\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 7.75e+06\n",
      "ValFuncLoss: 0.00174\n",
      "Variance: 0.127\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7890   1.6267   7.8741  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0019   0.0070   1.6645   0.7971   0.5555\n",
      "***** Episode 31682, Mean R = -42.5  Std R = 21.3  Min R = -138.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000946\n",
      "PolicyEntropy: -2.59\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 7.76e+06\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.126\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0504   1.0229   5.9204  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 31713, Mean R = -44.5  Std R = 27.7  Min R = -170.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000847\n",
      "PolicyEntropy: -2.6\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 7.77e+06\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.126\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8289   1.3276   6.3704  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0020   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 31744, Mean R = -36.1  Std R = 8.5  Min R = -55.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000827\n",
      "PolicyEntropy: -2.6\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 7.78e+06\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4375   1.0239   5.2891  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 31775, Mean R = -35.3  Std R = 9.9  Min R = -65.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000887\n",
      "PolicyEntropy: -2.61\n",
      "PolicyLoss: -0.00358\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 7.78e+06\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2787   0.9488   5.5889  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 31806, Mean R = -38.8  Std R = 13.6  Min R = -91.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.001\n",
      "PolicyEntropy: -2.6\n",
      "PolicyLoss: -0.00372\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 7.79e+06\n",
      "ValFuncLoss: 0.00192\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8023   1.8651  10.1487  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0024   0.0098   1.6645   0.7971   0.5555\n",
      "***** Episode 31837, Mean R = -36.3  Std R = 15.2  Min R = -101.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -2.61\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 7.8e+06\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.2063   0.4233   3.0582  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0016   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 31868, Mean R = -37.6  Std R = 11.5  Min R = -70.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.932\n",
      "ExplainedVarOld: 0.892\n",
      "KL: 0.000978\n",
      "PolicyEntropy: -2.61\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 7.81e+06\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2387   1.0072   5.6146  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 31899, Mean R = -33.3  Std R = 6.9  Min R = -47.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -2.6\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 7.82e+06\n",
      "ValFuncLoss: 0.00267\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2962   2.3271  10.6971  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0022   0.0082   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1030    ET =    181.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.2     2.3    -0.4 |    19.5    22.4     0.3 |   -37.1   -54.4    -1.1 |    74.2    67.7    -0.0\n",
      "v_f      |   -5.48    1.74  -17.25 |    2.36    2.08    3.59 |  -12.71   -4.78  -27.07 |    1.13    8.09   -2.03\n",
      "vr_f     |     3.2 |     1.5 |     0.3 |    13.2\n",
      "r_i      |  1047.4   -41.6  2349.3 |   601.9   552.0    27.8 |     4.5  -986.1  2300.4 |  1999.5   982.2  2400.0\n",
      "v_i      |  -41.35   -0.80  -79.86 |   17.14   16.21    5.74 |  -69.88  -29.05  -89.98 |  -10.10   29.97  -70.10\n",
      "norm_rf  |    30.9 |    14.9 |     2.4 |    78.9\n",
      "norm_vf  |   18.41 |    3.84 |    2.20 |   28.35\n",
      "thrust   |    1245      97    9018 |    3007    2886    2665 |  -11125  -14436   -5835 |   14979   13802   15000\n",
      "norm_thrust |    9931 |    2955 |    2000 |   15000\n",
      "fuel     |     260 |      16 |     234 |     331\n",
      "rewards  |  -37.49 |   15.30 | -170.33 |  -20.37\n",
      "fuel_rewards |   -8.95 |    0.53 |  -11.40 |   -8.05\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.55 |    0.10 |    3.92\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   27.88 |   12.62 |    9.32 |   73.86\n",
      "tracking_rewards |  -28.54 |   14.93 | -158.93 |  -12.12\n",
      "steps    |     270 |      20 |     220 |     335\n",
      "***** Episode 31930, Mean R = -36.9  Std R = 14.4  Min R = -98.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000837\n",
      "PolicyEntropy: -2.61\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 7.83e+06\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3093   1.1623   6.4313  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0013   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 31961, Mean R = -41.5  Std R = 13.4  Min R = -74.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000767\n",
      "PolicyEntropy: -2.61\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 7.83e+06\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.125\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1418   0.9072   4.8769  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0021   0.0106   1.6645   0.7971   0.5555\n",
      "***** Episode 31992, Mean R = -37.5  Std R = 10.7  Min R = -74.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.837\n",
      "KL: 0.000819\n",
      "PolicyEntropy: -2.62\n",
      "PolicyLoss: -0.00208\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 7.84e+06\n",
      "ValFuncLoss: 0.00287\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8864   1.0978   5.3207  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 32023, Mean R = -34.1  Std R = 10.0  Min R = -74.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000718\n",
      "PolicyEntropy: -2.63\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.85e+06\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.123\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9911   1.0636   5.4329  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 32054, Mean R = -37.0  Std R = 11.3  Min R = -67.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000875\n",
      "PolicyEntropy: -2.63\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.20e+03\n",
      "TotalSteps: 7.86e+06\n",
      "ValFuncLoss: 0.00269\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4360   0.7594   4.5288  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 32085, Mean R = -38.6  Std R = 15.0  Min R = -100.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000673\n",
      "PolicyEntropy: -2.64\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 7.87e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.123\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3568   2.1307   9.8355  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 32116, Mean R = -34.0  Std R = 7.3  Min R = -54.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.001\n",
      "PolicyEntropy: -2.64\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 7.87e+06\n",
      "ValFuncLoss: 0.00176\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3238   2.2896  12.6152  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 32147, Mean R = -34.3  Std R = 7.6  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000783\n",
      "PolicyEntropy: -2.65\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 7.88e+06\n",
      "ValFuncLoss: 0.00173\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5302   1.7840   8.9264  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0020   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 32178, Mean R = -37.9  Std R = 12.5  Min R = -72.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000705\n",
      "PolicyEntropy: -2.65\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.05e+03\n",
      "TotalSteps: 7.89e+06\n",
      "ValFuncLoss: 0.00224\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0309   0.8434   5.4428  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 32209, Mean R = -36.2  Std R = 10.2  Min R = -72.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000903\n",
      "PolicyEntropy: -2.65\n",
      "PolicyLoss: -0.00366\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 7.9e+06\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0106   1.0181   6.0610  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0039   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1040    ET =    177.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    15.4     4.0    -0.5 |    19.4    22.2     0.3 |   -28.8   -64.1    -1.3 |    73.9    63.1    -0.0\n",
      "v_f      |   -5.25    1.64  -17.36 |    2.34    2.18    3.78 |  -12.71   -5.23  -30.20 |    0.63    8.39   -1.91\n",
      "vr_f     |     3.4 |     1.9 |     1.0 |    20.4\n",
      "r_i      |   980.6   -32.2  2350.0 |   569.9   579.3    29.9 |     5.4  -991.2  2300.0 |  1994.0   999.9  2399.7\n",
      "v_i      |  -38.58    0.13  -79.75 |   17.61   16.99    5.49 |  -69.99  -29.71  -89.91 |  -10.13   29.94  -70.01\n",
      "norm_rf  |    29.6 |    15.8 |     1.2 |    80.1\n",
      "norm_vf  |   18.44 |    3.97 |    2.37 |   31.45\n",
      "thrust   |    1179      74    9072 |    3007    3025    2613 |  -10212  -14169   -5417 |   14990   14527   14999\n",
      "norm_thrust |   10008 |    2928 |    2000 |   15000\n",
      "fuel     |     259 |      15 |     230 |     326\n",
      "rewards  |  -36.70 |   11.23 | -100.89 |  -20.83\n",
      "fuel_rewards |   -8.89 |    0.52 |  -11.23 |   -7.92\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.55 |    0.54 |    3.69\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   27.28 |   12.79 |    7.66 |   75.10\n",
      "tracking_rewards |  -27.81 |   10.90 |  -90.98 |  -12.01\n",
      "steps    |     266 |      21 |     215 |     330\n",
      "***** Episode 32240, Mean R = -35.9  Std R = 9.8  Min R = -67.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000854\n",
      "PolicyEntropy: -2.65\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 7.91e+06\n",
      "ValFuncLoss: 0.00185\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4442   1.9628   8.4770  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 32271, Mean R = -39.3  Std R = 23.8  Min R = -167.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.00089\n",
      "PolicyEntropy: -2.65\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 7.92e+06\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.124\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1780   1.2103   6.2748  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 32302, Mean R = -35.7  Std R = 9.6  Min R = -76.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.907\n",
      "KL: 0.000799\n",
      "PolicyEntropy: -2.66\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 7.92e+06\n",
      "ValFuncLoss: 0.00139\n",
      "Variance: 0.123\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3642   1.1932   6.1869  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 32333, Mean R = -35.1  Std R = 9.5  Min R = -69.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -2.66\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 7.93e+06\n",
      "ValFuncLoss: 0.00188\n",
      "Variance: 0.123\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5103   0.8778   4.8473  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 32364, Mean R = -31.9  Std R = 5.3  Min R = -47.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000842\n",
      "PolicyEntropy: -2.66\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 7.94e+06\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.123\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7828   1.2360   6.8664  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 32395, Mean R = -37.8  Std R = 11.7  Min R = -81.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000696\n",
      "PolicyEntropy: -2.66\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 7.95e+06\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.123\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4053   1.1506   5.9254  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 32426, Mean R = -38.7  Std R = 17.2  Min R = -107.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000744\n",
      "PolicyEntropy: -2.67\n",
      "PolicyLoss: -0.00348\n",
      "Steps: 8.11e+03\n",
      "TotalSteps: 7.96e+06\n",
      "ValFuncLoss: 0.00208\n",
      "Variance: 0.122\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3050   2.1507  10.7625  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0013   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 32457, Mean R = -42.3  Std R = 26.7  Min R = -158.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00073\n",
      "PolicyEntropy: -2.67\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 7.97e+06\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.122\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9248   1.5186   8.7903  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 32488, Mean R = -36.6  Std R = 8.4  Min R = -58.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -2.68\n",
      "PolicyLoss: -0.00421\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 7.97e+06\n",
      "ValFuncLoss: 0.00182\n",
      "Variance: 0.122\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3268   1.8771   8.0171  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 32519, Mean R = -35.1  Std R = 11.6  Min R = -82.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000935\n",
      "PolicyEntropy: -2.68\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 7.98e+06\n",
      "ValFuncLoss: 0.00149\n",
      "Variance: 0.121\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5283   0.9571   4.3428  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1050    ET =    178.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    21.5     6.2    -0.4 |    20.4    21.1     0.3 |   -26.1   -56.2    -1.4 |    88.9    60.8    -0.0\n",
      "v_f      |   -5.77    1.48  -17.78 |    2.61    2.10    3.73 |  -14.72   -4.86  -28.61 |    1.69   10.08   -6.27\n",
      "vr_f     |     3.3 |     1.4 |     1.1 |     8.8\n",
      "r_i      |  1064.0    55.3  2349.8 |   591.6   538.3    27.4 |    15.7  -980.5  2300.0 |  1998.5   999.3  2399.9\n",
      "v_i      |  -39.52   -0.25  -80.27 |   17.83   17.04    5.88 |  -69.77  -30.00  -89.96 |  -10.23   29.99  -70.14\n",
      "norm_rf  |    32.8 |    16.9 |     1.2 |   103.2\n",
      "norm_vf  |   18.99 |    4.05 |    6.57 |   30.75\n",
      "thrust   |    1196      66    9057 |    2983    2880    2667 |  -11107  -14407   -6398 |   14993   14290   14999\n",
      "norm_thrust |    9955 |    2945 |    2000 |   15000\n",
      "fuel     |     258 |      15 |     230 |     351\n",
      "rewards  |  -37.34 |   17.02 | -176.93 |  -21.86\n",
      "fuel_rewards |   -8.88 |    0.53 |  -12.05 |   -7.90\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.38 |    0.53 |    0.06 |    3.31\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   29.61 |   14.90 |    4.57 |   98.16\n",
      "tracking_rewards |  -28.46 |   16.62 | -165.49 |  -13.93\n",
      "steps    |     267 |      20 |     219 |     333\n",
      "***** Episode 32550, Mean R = -40.8  Std R = 26.0  Min R = -176.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000718\n",
      "PolicyEntropy: -2.69\n",
      "PolicyLoss: -0.00219\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 7.99e+06\n",
      "ValFuncLoss: 0.00131\n",
      "Variance: 0.12\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7497   1.2616   6.5845  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0007   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 32581, Mean R = -34.9  Std R = 9.7  Min R = -62.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000571\n",
      "PolicyEntropy: -2.7\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 8e+06\n",
      "ValFuncLoss: 0.00153\n",
      "Variance: 0.12\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.0261   0.4218   2.8900  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 32612, Mean R = -45.3  Std R = 27.8  Min R = -153.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000725\n",
      "PolicyEntropy: -2.71\n",
      "PolicyLoss: -0.00223\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 8.01e+06\n",
      "ValFuncLoss: 0.00204\n",
      "Variance: 0.12\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4644   1.3128   6.7398  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0019   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 32643, Mean R = -34.0  Std R = 7.1  Min R = -50.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -2.72\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 8.02e+06\n",
      "ValFuncLoss: 0.00199\n",
      "Variance: 0.119\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7070   1.0545   6.8199  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0021   0.0089   1.6645   0.7971   0.5555\n",
      "***** Episode 32674, Mean R = -39.4  Std R = 12.1  Min R = -83.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000581\n",
      "PolicyEntropy: -2.72\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 8.02e+06\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.119\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9312   1.3965   7.3305  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 32705, Mean R = -36.3  Std R = 10.9  Min R = -72.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000594\n",
      "PolicyEntropy: -2.72\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 8.03e+06\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.119\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6548   1.1439   6.8099  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 32736, Mean R = -40.1  Std R = 23.9  Min R = -162.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000745\n",
      "PolicyEntropy: -2.73\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 8.04e+06\n",
      "ValFuncLoss: 0.00173\n",
      "Variance: 0.119\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2522   2.4019  10.5819  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 32767, Mean R = -39.3  Std R = 19.3  Min R = -120.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.0012\n",
      "PolicyEntropy: -2.74\n",
      "PolicyLoss: -0.0019\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 8.05e+06\n",
      "ValFuncLoss: 0.00178\n",
      "Variance: 0.119\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8819   1.6029   8.1303  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 32798, Mean R = -39.4  Std R = 14.8  Min R = -87.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000653\n",
      "PolicyEntropy: -2.74\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 8.06e+06\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.118\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3177   1.2670   5.9565  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 32829, Mean R = -36.3  Std R = 8.6  Min R = -58.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.000827\n",
      "PolicyEntropy: -2.75\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 8.06e+06\n",
      "ValFuncLoss: 0.00218\n",
      "Variance: 0.118\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3458   2.5462  11.3987  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0013   0.0057   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1060    ET =    178.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    15.9     3.1    -0.4 |    18.2    21.3     0.3 |   -27.0   -65.1    -1.2 |    74.2    62.4    -0.0\n",
      "v_f      |   -5.27    1.41  -17.59 |    2.22    2.11    3.52 |  -12.62   -5.40  -26.54 |    0.69   10.90   -3.55\n",
      "vr_f     |     3.5 |     1.7 |     0.8 |    17.6\n",
      "r_i      |   983.8     2.1  2348.7 |   563.4   568.5    28.9 |    11.9  -996.0  2300.6 |  1986.5   999.0  2399.9\n",
      "v_i      |  -40.84   -0.42  -80.13 |   17.35   18.09    5.72 |  -69.95  -30.00  -90.00 |  -10.02   29.93  -70.02\n",
      "norm_rf  |    29.1 |    14.1 |     1.2 |    78.1\n",
      "norm_vf  |   18.62 |    3.75 |    6.14 |   28.05\n",
      "thrust   |    1266      72    9061 |    3053    3003    2606 |  -10599  -14110   -5900 |   14998   13955   15000\n",
      "norm_thrust |   10011 |    2935 |    2000 |   15000\n",
      "fuel     |     259 |      16 |     229 |     352\n",
      "rewards  |  -37.78 |   16.04 | -162.02 |  -20.78\n",
      "fuel_rewards |   -8.89 |    0.55 |  -12.09 |   -7.85\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.49 |    0.07 |    3.23\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   26.38 |   11.65 |    7.52 |   73.10\n",
      "tracking_rewards |  -28.88 |   15.62 | -149.93 |  -12.44\n",
      "steps    |     266 |      20 |     216 |     333\n",
      "***** Episode 32860, Mean R = -32.7  Std R = 5.7  Min R = -49.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000903\n",
      "PolicyEntropy: -2.75\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 8.07e+06\n",
      "ValFuncLoss: 0.00217\n",
      "Variance: 0.118\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1369   0.8508   5.1882  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0016   0.0090   1.6645   0.7971   0.5555\n",
      "***** Episode 32891, Mean R = -37.2  Std R = 11.4  Min R = -88.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.931\n",
      "ExplainedVarOld: 0.89\n",
      "KL: 0.0011\n",
      "PolicyEntropy: -2.76\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 8.08e+06\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.118\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1703   1.2301   7.6325  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 32922, Mean R = -39.4  Std R = 10.1  Min R = -65.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.953\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000713\n",
      "PolicyEntropy: -2.76\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 8.09e+06\n",
      "ValFuncLoss: 0.00229\n",
      "Variance: 0.117\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2132   0.9170   5.6496  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 32953, Mean R = -36.8  Std R = 12.8  Min R = -91.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000656\n",
      "PolicyEntropy: -2.77\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 8.1e+06\n",
      "ValFuncLoss: 0.00215\n",
      "Variance: 0.117\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7449   2.2696  10.4112  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0013   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 32984, Mean R = -35.0  Std R = 10.1  Min R = -72.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000625\n",
      "PolicyEntropy: -2.77\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 8.11e+06\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.117\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7533   1.4734   7.3634  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 33015, Mean R = -44.0  Std R = 26.4  Min R = -168.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000984\n",
      "PolicyEntropy: -2.78\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 8.11e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.116\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0068   2.3340  10.1196  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0021   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 33046, Mean R = -38.4  Std R = 15.9  Min R = -88.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000885\n",
      "PolicyEntropy: -2.77\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 8.06e+03\n",
      "TotalSteps: 8.12e+06\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.116\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5423   2.7835  13.1486  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0014   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 33077, Mean R = -37.2  Std R = 10.9  Min R = -84.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000896\n",
      "PolicyEntropy: -2.78\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 8.13e+06\n",
      "ValFuncLoss: 0.00172\n",
      "Variance: 0.116\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1103   1.1317   5.2928  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 33108, Mean R = -36.4  Std R = 11.7  Min R = -71.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000719\n",
      "PolicyEntropy: -2.78\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 8.14e+06\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.116\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0262   2.1960   9.8704  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 33139, Mean R = -36.6  Std R = 12.2  Min R = -78.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000744\n",
      "PolicyEntropy: -2.79\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 8.15e+06\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.115\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8152   2.7924  11.4148  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1070    ET =    179.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    17.6     2.4    -0.4 |    19.8    22.7     0.3 |   -27.3   -82.9    -1.1 |    62.1    55.7    -0.0\n",
      "v_f      |   -5.53    1.64  -17.22 |    2.39    2.15    3.54 |  -13.17   -5.79  -25.77 |    3.40    9.63   -2.02\n",
      "vr_f     |     3.3 |     3.1 |     1.1 |    52.2\n",
      "r_i      |   999.3   -35.1  2350.9 |   567.8   577.2    28.5 |     3.8  -997.8  2300.4 |  1993.3   997.7  2399.9\n",
      "v_i      |  -39.79   -0.61  -80.16 |   16.94   17.89    5.80 |  -69.95  -29.85  -89.93 |  -10.27   29.91  -70.08\n",
      "norm_rf  |    31.6 |    15.1 |     2.1 |    83.3\n",
      "norm_vf  |   18.41 |    3.72 |    3.07 |   28.01\n",
      "thrust   |    1228      85    9066 |    2929    3051    2592 |  -10643  -14278   -6575 |   14980   14408   15000\n",
      "norm_thrust |    9992 |    2910 |    2000 |   15000\n",
      "fuel     |     259 |      15 |     230 |     340\n",
      "rewards  |  -37.67 |   14.26 | -168.18 |  -20.19\n",
      "fuel_rewards |   -8.90 |    0.52 |  -11.67 |   -7.90\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.51 |    0.07 |    4.39\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   28.48 |   12.86 |    8.74 |   78.34\n",
      "tracking_rewards |  -28.78 |   13.89 | -156.51 |  -11.73\n",
      "steps    |     266 |      19 |     221 |     329\n",
      "***** Episode 33170, Mean R = -35.8  Std R = 10.9  Min R = -68.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000929\n",
      "PolicyEntropy: -2.79\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 8.16e+06\n",
      "ValFuncLoss: 0.00256\n",
      "Variance: 0.115\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7209   1.6340   7.5307  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 33201, Mean R = -41.5  Std R = 22.2  Min R = -152.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000768\n",
      "PolicyEntropy: -2.8\n",
      "PolicyLoss: -0.00388\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 8.16e+06\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.115\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5003   1.4440   8.4546  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 33232, Mean R = -40.0  Std R = 18.4  Min R = -121.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000847\n",
      "PolicyEntropy: -2.8\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 8.17e+06\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.115\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2076   1.3291   7.1149  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 33263, Mean R = -38.7  Std R = 15.0  Min R = -81.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000819\n",
      "PolicyEntropy: -2.81\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 8.18e+06\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.114\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4525   1.0144   6.8951  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 33294, Mean R = -42.4  Std R = 17.4  Min R = -105.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000965\n",
      "PolicyEntropy: -2.82\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 8.19e+06\n",
      "ValFuncLoss: 0.00198\n",
      "Variance: 0.114\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5341   1.4731   7.2349  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 33325, Mean R = -35.7  Std R = 8.3  Min R = -62.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000787\n",
      "PolicyEntropy: -2.82\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 8.2e+06\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0838   1.6177   6.7275  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 33356, Mean R = -35.8  Std R = 9.7  Min R = -66.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000844\n",
      "PolicyEntropy: -2.83\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 8.21e+06\n",
      "ValFuncLoss: 0.0019\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7297   2.0441  10.9560  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0020   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 33387, Mean R = -39.2  Std R = 8.8  Min R = -63.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -2.83\n",
      "PolicyLoss: -0.00329\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 8.21e+06\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6416   1.3138   6.2734  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 33418, Mean R = -39.0  Std R = 13.7  Min R = -77.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000793\n",
      "PolicyEntropy: -2.84\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 8.22e+06\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9051   0.7883   4.6125  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0007   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 33449, Mean R = -41.2  Std R = 24.2  Min R = -133.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000954\n",
      "PolicyEntropy: -2.84\n",
      "PolicyLoss: -0.00219\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 8.23e+06\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4656   3.4045  15.8588  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0038   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1080    ET =    185.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    14.5     5.3    -0.4 |    20.3    23.9     0.3 |   -35.0   -58.1    -1.1 |    63.4    66.1    -0.0\n",
      "v_f      |   -5.50    1.29  -16.97 |    2.53    2.36    3.78 |  -13.53   -5.34  -28.21 |    0.15    9.41   -5.42\n",
      "vr_f     |     3.5 |     3.9 |     1.0 |    62.4\n",
      "r_i      |   979.5    24.5  2349.9 |   584.7   586.8    29.6 |     2.4  -993.7  2300.0 |  1992.7   983.9  2399.6\n",
      "v_i      |  -41.46    1.36  -79.68 |   17.27   16.90    5.76 |  -69.95  -29.76  -89.99 |  -10.16   29.66  -70.05\n",
      "norm_rf  |    31.5 |    15.2 |     0.7 |    82.5\n",
      "norm_vf  |   18.15 |    4.08 |    5.99 |   29.34\n",
      "thrust   |    1266       4    9076 |    3074    2952    2588 |  -10380  -14426   -5882 |   14984   14611   14999\n",
      "norm_thrust |   10015 |    2919 |    2000 |   15000\n",
      "fuel     |     260 |      15 |     233 |     326\n",
      "rewards  |  -38.95 |   15.93 | -152.93 |  -21.54\n",
      "fuel_rewards |   -8.95 |    0.50 |  -11.20 |   -7.99\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.36 |    0.50 |    0.07 |    3.35\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   28.07 |   13.25 |    6.09 |   77.50\n",
      "tracking_rewards |  -30.01 |   15.56 | -141.85 |  -12.67\n",
      "steps    |     267 |      19 |     210 |     319\n",
      "***** Episode 33480, Mean R = -36.1  Std R = 10.4  Min R = -71.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00075\n",
      "PolicyEntropy: -2.84\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 8.24e+06\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6216   1.0319   6.4492  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 33511, Mean R = -38.2  Std R = 16.5  Min R = -116.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000891\n",
      "PolicyEntropy: -2.84\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 8.25e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3820   1.7986   8.8128  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0016   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 33542, Mean R = -37.2  Std R = 10.1  Min R = -73.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000785\n",
      "PolicyEntropy: -2.85\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 8.25e+06\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.113\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5506   1.7335   9.0410  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 33573, Mean R = -35.2  Std R = 8.9  Min R = -67.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.941\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000851\n",
      "PolicyEntropy: -2.86\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 8.26e+06\n",
      "ValFuncLoss: 0.00309\n",
      "Variance: 0.112\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4857   1.3464   7.7770  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0016   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 33604, Mean R = -37.3  Std R = 9.9  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -2.87\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 8.27e+06\n",
      "ValFuncLoss: 0.00285\n",
      "Variance: 0.112\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2025   1.4762   8.5662  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 33635, Mean R = -35.4  Std R = 7.7  Min R = -55.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.000824\n",
      "PolicyEntropy: -2.87\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 8.28e+06\n",
      "ValFuncLoss: 0.00293\n",
      "Variance: 0.112\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4664   1.6827   7.6141  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0013   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 33666, Mean R = -39.2  Std R = 10.4  Min R = -73.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000693\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 8.29e+06\n",
      "ValFuncLoss: 0.00204\n",
      "Variance: 0.112\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2161   1.8146   9.2262  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 33697, Mean R = -37.3  Std R = 14.8  Min R = -95.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000855\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00232\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 8.3e+06\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7894   1.4462   6.7258  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 33728, Mean R = -37.1  Std R = 8.2  Min R = -66.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000778\n",
      "PolicyEntropy: -2.89\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 8.3e+06\n",
      "ValFuncLoss: 0.00204\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8826   0.6300   3.2577  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 33759, Mean R = -37.6  Std R = 14.1  Min R = -104.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000616\n",
      "PolicyEntropy: -2.89\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 8.08e+03\n",
      "TotalSteps: 8.31e+06\n",
      "ValFuncLoss: 0.00199\n",
      "Variance: 0.112\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0390   0.8492   4.7394  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0014   0.0055   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1090    ET =    185.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.2     5.1    -0.4 |    19.3    21.1     0.3 |   -48.4   -48.1    -1.2 |    68.2    63.0    -0.0\n",
      "v_f      |   -5.03    1.13  -15.72 |    2.36    2.15    4.12 |  -11.61   -5.65  -27.21 |    3.11    8.68   -2.26\n",
      "vr_f     |     3.2 |     1.4 |     1.3 |    10.4\n",
      "r_i      |   955.0   -46.2  2353.0 |   570.5   577.1    28.4 |     1.9  -999.3  2300.7 |  1976.3   999.7  2399.7\n",
      "v_i      |  -39.30   -0.97  -80.54 |   16.89   17.51    5.85 |  -69.62  -29.98  -89.92 |  -10.03   29.69  -70.03\n",
      "norm_rf  |    27.6 |    14.6 |     1.2 |    79.4\n",
      "norm_vf  |   16.78 |    4.39 |    2.55 |   29.14\n",
      "thrust   |    1221      98    9134 |    2956    3031    2529 |  -10597  -13899   -6465 |   14992   14526   15000\n",
      "norm_thrust |   10052 |    2867 |    2000 |   15000\n",
      "fuel     |     260 |      15 |     230 |     327\n",
      "rewards  |  -37.29 |   11.88 | -116.65 |  -19.52\n",
      "fuel_rewards |   -8.95 |    0.53 |  -11.24 |   -7.90\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.47 |    0.56 |    0.57 |    3.80\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   24.54 |   12.53 |    6.03 |   74.44\n",
      "tracking_rewards |  -28.34 |   11.54 | -106.05 |  -11.02\n",
      "steps    |     266 |      20 |     222 |     323\n",
      "***** Episode 33790, Mean R = -38.2  Std R = 14.0  Min R = -94.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000791\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 8.32e+06\n",
      "ValFuncLoss: 0.00327\n",
      "Variance: 0.112\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5754   3.0465  11.7392  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0018   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 33821, Mean R = -36.7  Std R = 9.6  Min R = -61.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.00128\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00215\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 8.33e+06\n",
      "ValFuncLoss: 0.00317\n",
      "Variance: 0.112\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1338   1.5058   7.3778  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 33852, Mean R = -36.4  Std R = 7.8  Min R = -59.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 8.34e+06\n",
      "ValFuncLoss: 0.00265\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8806   1.9039   9.2472  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0023   0.0093   1.6645   0.7971   0.5555\n",
      "***** Episode 33883, Mean R = -37.8  Std R = 13.3  Min R = -89.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000943\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00366\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 8.35e+06\n",
      "ValFuncLoss: 0.00248\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6263   0.6782   3.8771  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 33914, Mean R = -39.2  Std R = 13.9  Min R = -88.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000722\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00338\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 8.35e+06\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6463   1.3662   7.0799  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0012   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 33945, Mean R = -40.3  Std R = 24.0  Min R = -161.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000807\n",
      "PolicyEntropy: -2.88\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 8.36e+06\n",
      "ValFuncLoss: 0.00204\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8309   1.3884   8.5947  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0013   0.0053   1.6645   0.7971   0.5555\n",
      "***** Episode 33976, Mean R = -36.0  Std R = 9.9  Min R = -74.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000753\n",
      "PolicyEntropy: -2.89\n",
      "PolicyLoss: -0.00353\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 8.37e+06\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6587   1.4053   7.3824  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 34007, Mean R = -37.8  Std R = 24.6  Min R = -159.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000974\n",
      "PolicyEntropy: -2.89\n",
      "PolicyLoss: -0.00386\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 8.38e+06\n",
      "ValFuncLoss: 0.00171\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7783   1.2161   7.4689  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 34038, Mean R = -36.4  Std R = 11.3  Min R = -75.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -2.9\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 8.39e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.111\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0007   2.0061   9.1877  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0023   0.0076   1.6645   0.7971   0.5555\n",
      "***** Episode 34069, Mean R = -39.3  Std R = 12.5  Min R = -74.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -2.9\n",
      "PolicyLoss: -0.00388\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 8.4e+06\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.11\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6069   1.1778   5.8683  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0020   0.0082   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1100    ET =    184.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    12.1     5.4    -0.4 |    18.5    21.2     0.3 |   -39.8   -58.4    -1.3 |    58.5    55.0    -0.0\n",
      "v_f      |   -5.30    1.45  -16.54 |    2.32    2.21    3.39 |  -11.62   -4.85  -26.38 |    1.86    9.89   -6.41\n",
      "vr_f     |     3.3 |     1.7 |     1.3 |    18.5\n",
      "r_i      |   982.2    31.6  2347.0 |   583.1   594.6    27.9 |    19.9  -997.8  2300.1 |  1997.1   999.6  2399.8\n",
      "v_i      |  -41.30    0.15  -80.29 |   16.12   17.48    5.68 |  -69.82  -29.94  -90.00 |  -10.06   29.84  -70.09\n",
      "norm_rf  |    28.2 |    13.1 |     2.2 |    67.5\n",
      "norm_vf  |   17.67 |    3.69 |    7.37 |   27.57\n",
      "thrust   |    1282      59    9096 |    2993    3019    2548 |   -9986  -14508   -5654 |   14999   13739   14999\n",
      "norm_thrust |   10030 |    2889 |    2000 |   15000\n",
      "fuel     |     260 |      16 |     231 |     357\n",
      "rewards  |  -37.61 |   14.85 | -161.82 |  -20.59\n",
      "fuel_rewards |   -8.93 |    0.55 |  -12.28 |   -7.97\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.47 |    0.05 |    3.69\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   25.00 |   11.09 |    8.57 |   62.47\n",
      "tracking_rewards |  -28.68 |   14.45 | -149.54 |  -12.46\n",
      "steps    |     267 |      20 |     223 |     339\n",
      "***** Episode 34100, Mean R = -36.2  Std R = 9.9  Min R = -57.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000613\n",
      "PolicyEntropy: -2.9\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 8.4e+06\n",
      "ValFuncLoss: 0.00144\n",
      "Variance: 0.11\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5135   0.9488   5.3626  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 34131, Mean R = -33.6  Std R = 10.2  Min R = -69.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000964\n",
      "PolicyEntropy: -2.9\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 8.41e+06\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.11\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0774   1.3954   5.8781  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 34162, Mean R = -36.8  Std R = 10.8  Min R = -72.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -2.9\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.42e+06\n",
      "ValFuncLoss: 0.00146\n",
      "Variance: 0.11\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6493   1.3297   6.6007  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0012   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 34193, Mean R = -35.1  Std R = 9.8  Min R = -72.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -2.9\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 8.43e+06\n",
      "ValFuncLoss: 0.00129\n",
      "Variance: 0.11\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3204   1.5704   9.5147  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 34224, Mean R = -37.1  Std R = 10.1  Min R = -69.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000676\n",
      "PolicyEntropy: -2.9\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 8.44e+06\n",
      "ValFuncLoss: 0.00158\n",
      "Variance: 0.11\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1353   1.8855  10.6225  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 34255, Mean R = -34.3  Std R = 6.2  Min R = -51.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -2.91\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 8.45e+06\n",
      "ValFuncLoss: 0.0014\n",
      "Variance: 0.11\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5664   0.8349   5.5833  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 34286, Mean R = -36.9  Std R = 13.1  Min R = -80.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -2.93\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 8.45e+06\n",
      "ValFuncLoss: 0.00172\n",
      "Variance: 0.109\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4052   0.8808   5.0944  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 34317, Mean R = -43.4  Std R = 25.2  Min R = -144.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000791\n",
      "PolicyEntropy: -2.93\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 8.46e+06\n",
      "ValFuncLoss: 0.00208\n",
      "Variance: 0.109\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2581   3.1603  12.7132  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 34348, Mean R = -41.3  Std R = 18.8  Min R = -112.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00119\n",
      "PolicyEntropy: -2.93\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 8.47e+06\n",
      "ValFuncLoss: 0.00213\n",
      "Variance: 0.109\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4779   1.5729   6.9557  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0016   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 34379, Mean R = -36.0  Std R = 8.9  Min R = -64.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000863\n",
      "PolicyEntropy: -2.93\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 8.48e+06\n",
      "ValFuncLoss: 0.00217\n",
      "Variance: 0.109\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6007   3.3541  14.5163  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1110    ET =    182.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.6     5.2    -0.4 |    17.8    20.2     0.3 |   -31.4   -61.3    -1.1 |    55.9    60.2    -0.0\n",
      "v_f      |   -5.07    1.36  -15.70 |    2.18    2.14    3.79 |  -11.65   -6.59  -27.66 |    0.01    9.65   -4.34\n",
      "vr_f     |     3.2 |     1.8 |     1.3 |    16.1\n",
      "r_i      |   977.9    16.2  2350.0 |   569.6   578.1    29.2 |     2.0  -985.4  2300.2 |  1992.4   988.7  2399.5\n",
      "v_i      |  -40.28    0.11  -79.92 |   17.52   17.46    5.55 |  -69.95  -29.90  -89.85 |  -10.26   29.59  -70.14\n",
      "norm_rf  |    26.3 |    13.1 |     0.9 |    69.1\n",
      "norm_vf  |   16.78 |    4.04 |    4.84 |   30.14\n",
      "thrust   |    1243      52    9106 |    2973    2967    2504 |  -10749  -14152   -6665 |   14998   13943   15000\n",
      "norm_thrust |   10014 |    2845 |    2000 |   15000\n",
      "fuel     |     262 |      15 |     233 |     358\n",
      "rewards  |  -37.29 |   14.12 | -144.50 |  -21.88\n",
      "fuel_rewards |   -9.01 |    0.52 |  -12.30 |   -8.02\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.51 |    0.09 |    3.55\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   23.21 |   11.09 |    4.70 |   64.06\n",
      "tracking_rewards |  -28.29 |   13.77 | -132.20 |  -13.25\n",
      "steps    |     269 |      20 |     216 |     332\n",
      "***** Episode 34410, Mean R = -38.4  Std R = 14.5  Min R = -96.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000565\n",
      "PolicyEntropy: -2.93\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 8.49e+06\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.109\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0724   3.5743  14.1563  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 34441, Mean R = -37.3  Std R = 10.6  Min R = -68.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000812\n",
      "PolicyEntropy: -2.93\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 8.5e+06\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.109\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7928   3.1315  13.5581  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 34472, Mean R = -36.4  Std R = 10.2  Min R = -76.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000617\n",
      "PolicyEntropy: -2.93\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 8.5e+06\n",
      "ValFuncLoss: 0.00208\n",
      "Variance: 0.108\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3589   2.0553  10.7541  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 34503, Mean R = -34.0  Std R = 7.0  Min R = -53.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.00084\n",
      "PolicyEntropy: -2.94\n",
      "PolicyLoss: -0.00351\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 8.51e+06\n",
      "ValFuncLoss: 0.00178\n",
      "Variance: 0.108\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8920   2.0443   9.4778  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 34534, Mean R = -39.3  Std R = 15.6  Min R = -109.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000851\n",
      "PolicyEntropy: -2.94\n",
      "PolicyLoss: -0.00361\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 8.52e+06\n",
      "ValFuncLoss: 0.00198\n",
      "Variance: 0.108\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2988   1.3271   7.0672  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 34565, Mean R = -32.9  Std R = 8.6  Min R = -66.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000818\n",
      "PolicyEntropy: -2.94\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 8.53e+06\n",
      "ValFuncLoss: 0.00178\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7714   2.4355  11.5962  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 34596, Mean R = -36.3  Std R = 10.5  Min R = -60.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.936\n",
      "KL: 0.000811\n",
      "PolicyEntropy: -2.95\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.40e+03\n",
      "TotalSteps: 8.54e+06\n",
      "ValFuncLoss: 0.0019\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1536   1.1411   6.1357  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 34627, Mean R = -36.1  Std R = 11.6  Min R = -76.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000721\n",
      "PolicyEntropy: -2.95\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 8.55e+06\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0363   1.1762   6.3328  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0026   0.0107   1.6645   0.7971   0.5555\n",
      "***** Episode 34658, Mean R = -41.1  Std R = 28.2  Min R = -153.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.926\n",
      "KL: 0.0008\n",
      "PolicyEntropy: -2.96\n",
      "PolicyLoss: -0.00191\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 8.55e+06\n",
      "ValFuncLoss: 0.00372\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1030   0.7821   4.4364  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0023   0.0085   1.6645   0.7971   0.5555\n",
      "***** Episode 34689, Mean R = -35.2  Std R = 10.4  Min R = -70.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.893\n",
      "KL: 0.00069\n",
      "PolicyEntropy: -2.96\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.56e+06\n",
      "ValFuncLoss: 0.00262\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8294   1.5847   7.2015  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0051   0.0018   0.0102   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1120    ET =    189.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.8     6.7    -0.4 |    17.6    19.4     0.2 |   -26.7   -51.9    -1.1 |    54.2    55.2    -0.0\n",
      "v_f      |   -5.04    1.21  -14.97 |    2.15    1.94    3.55 |  -11.59   -4.11  -23.54 |    0.86    9.23   -4.53\n",
      "vr_f     |     3.0 |     1.1 |     1.3 |     8.7\n",
      "r_i      |  1013.2    34.8  2352.4 |   557.0   562.3    28.8 |     1.4  -998.0  2300.1 |  1993.2   998.7  2400.0\n",
      "v_i      |  -40.58    0.01  -79.93 |   16.70   17.62    5.73 |  -69.55  -29.77  -89.98 |  -10.26   29.83  -70.13\n",
      "norm_rf  |    26.2 |    12.7 |     1.2 |    69.2\n",
      "norm_vf  |   16.05 |    3.79 |    4.90 |   25.33\n",
      "thrust   |    1255      40    9072 |    2817    2956    2478 |  -10760  -14515   -7539 |   14898   14229   14999\n",
      "norm_thrust |    9936 |    2821 |    2000 |   15000\n",
      "fuel     |     262 |      14 |     232 |     332\n",
      "rewards  |  -36.39 |   13.70 | -153.04 |  -20.32\n",
      "fuel_rewards |   -9.00 |    0.47 |  -11.43 |   -7.99\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.52 |    0.08 |    3.87\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.87 |   10.90 |    6.47 |   64.16\n",
      "tracking_rewards |  -27.39 |   13.38 | -141.62 |  -11.78\n",
      "steps    |     271 |      20 |     226 |     333\n",
      "***** Episode 34720, Mean R = -35.2  Std R = 9.7  Min R = -60.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000576\n",
      "PolicyEntropy: -2.96\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 8.57e+06\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8639   0.7392   4.4843  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0010   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 34751, Mean R = -35.6  Std R = 14.8  Min R = -94.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.924\n",
      "KL: 0.000955\n",
      "PolicyEntropy: -2.96\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 8.58e+06\n",
      "ValFuncLoss: 0.00217\n",
      "Variance: 0.108\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5741   1.1818   6.5155  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 34782, Mean R = -37.0  Std R = 13.1  Min R = -94.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.946\n",
      "KL: 0.000655\n",
      "PolicyEntropy: -2.97\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 8.59e+06\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.108\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0832   2.1185   9.9669  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0013   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 34813, Mean R = -34.5  Std R = 9.2  Min R = -58.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -2.97\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 8.6e+06\n",
      "ValFuncLoss: 0.00174\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4714   4.3440  20.0274  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 34844, Mean R = -34.9  Std R = 9.0  Min R = -56.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.0007\n",
      "PolicyEntropy: -2.98\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 8.6e+06\n",
      "ValFuncLoss: 0.00185\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7668   1.3328   6.8705  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 34875, Mean R = -36.3  Std R = 9.9  Min R = -73.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000558\n",
      "PolicyEntropy: -2.97\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 8.61e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0159   2.5860  12.3896  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0015   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 34906, Mean R = -35.1  Std R = 10.2  Min R = -68.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.00064\n",
      "PolicyEntropy: -2.97\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 8.62e+06\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1702   1.6275   8.3665  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 34937, Mean R = -35.6  Std R = 11.7  Min R = -66.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000656\n",
      "PolicyEntropy: -2.98\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 8.63e+06\n",
      "ValFuncLoss: 0.00143\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6435   3.6233  15.4404  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 34968, Mean R = -37.2  Std R = 11.6  Min R = -84.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000795\n",
      "PolicyEntropy: -2.98\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 8.64e+06\n",
      "ValFuncLoss: 0.00197\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4877   1.5426   9.0823  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0014   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 34999, Mean R = -39.1  Std R = 12.6  Min R = -78.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000887\n",
      "PolicyEntropy: -2.99\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 8.65e+06\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5076   1.4735   8.0710  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1130    ET =    185.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    13.8     3.4    -0.4 |    18.2    19.8     0.2 |   -22.7   -56.2    -1.1 |    66.2    58.6    -0.0\n",
      "v_f      |   -5.23    1.09  -15.07 |    2.52    1.90    3.75 |  -14.86   -5.47  -24.67 |    1.64    6.59   -1.02\n",
      "vr_f     |     3.0 |     1.5 |     1.0 |    15.3\n",
      "r_i      |  1013.2   -18.5  2350.4 |   583.6   567.8    29.4 |     9.8  -994.8  2300.4 |  1992.7   990.0  2399.8\n",
      "v_i      |  -39.78    0.41  -80.27 |   16.54   17.88    5.93 |  -68.82  -29.87  -89.99 |  -10.09   29.94  -70.10\n",
      "norm_rf  |    27.0 |    14.0 |     2.0 |    76.9\n",
      "norm_vf  |   16.21 |    4.10 |    2.15 |   28.13\n",
      "thrust   |    1210      32    9122 |    2860    3011    2468 |  -11028  -14680   -6593 |   14996   13939   14999\n",
      "norm_thrust |   10004 |    2815 |    2000 |   15000\n",
      "fuel     |     262 |      14 |     234 |     313\n",
      "rewards  |  -36.25 |   11.64 |  -94.92 |  -20.14\n",
      "fuel_rewards |   -9.01 |    0.47 |  -10.76 |   -8.05\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.49 |    0.32 |    3.01\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   23.76 |   12.12 |    5.23 |   71.92\n",
      "tracking_rewards |  -27.24 |   11.31 |  -84.76 |  -11.53\n",
      "steps    |     270 |      19 |     221 |     354\n",
      "***** Episode 35030, Mean R = -37.1  Std R = 12.1  Min R = -84.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000838\n",
      "PolicyEntropy: -2.99\n",
      "PolicyLoss: -0.00369\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 8.65e+06\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0247   1.1430   6.0840  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 35061, Mean R = -36.3  Std R = 6.9  Min R = -56.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -2.99\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 8.66e+06\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6226   1.9134  10.6664  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 35092, Mean R = -38.5  Std R = 12.1  Min R = -74.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000833\n",
      "PolicyEntropy: -2.99\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 8.67e+06\n",
      "ValFuncLoss: 0.00177\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5125   1.5780   8.3238  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 35123, Mean R = -35.7  Std R = 9.1  Min R = -65.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -3\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.68e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0240   1.8856   8.5974  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 35154, Mean R = -37.1  Std R = 14.7  Min R = -93.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000661\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 8.69e+06\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8343   1.1038   5.2037  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 35185, Mean R = -37.0  Std R = 18.8  Min R = -124.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000626\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.00213\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.7e+06\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6484   2.1948   8.9653  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 35216, Mean R = -39.7  Std R = 19.7  Min R = -117.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 8.7e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0966   2.5022  10.9402  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 35247, Mean R = -34.7  Std R = 9.9  Min R = -76.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.000866\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 8.71e+06\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6286   1.6663   9.9590  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 35278, Mean R = -37.4  Std R = 17.6  Min R = -124.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00074\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.00373\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 8.72e+06\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2048   2.0728  10.8824  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0007   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 35309, Mean R = -36.6  Std R = 18.6  Min R = -125.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.00093\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 8.73e+06\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8666   1.4347   7.8057  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1140    ET =    186.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.7     5.9    -0.4 |    16.5    20.0     0.2 |   -36.5   -44.9    -1.0 |    67.1    64.7    -0.0\n",
      "v_f      |   -5.23    1.09  -15.54 |    2.19    1.95    3.46 |  -12.35   -6.09  -25.44 |    0.40    9.62   -1.00\n",
      "vr_f     |     3.1 |     1.4 |     0.5 |    11.6\n",
      "r_i      |  1004.5    57.6  2350.0 |   556.4   571.0    28.2 |     8.4  -997.6  2300.1 |  1984.9   989.4  2399.9\n",
      "v_i      |  -39.64    0.85  -79.77 |   18.33   17.17    5.90 |  -69.39  -29.27  -89.98 |  -10.01   29.68  -70.04\n",
      "norm_rf  |    25.6 |    12.9 |     2.1 |    75.1\n",
      "norm_vf  |   16.63 |    3.78 |    1.07 |   27.40\n",
      "thrust   |    1218       9    9081 |    2956    2900    2480 |  -10373  -14314   -7172 |   14993   14528   15000\n",
      "norm_thrust |    9959 |    2839 |    2000 |   15000\n",
      "fuel     |     262 |      15 |     231 |     339\n",
      "rewards  |  -36.98 |   14.56 | -125.15 |  -18.48\n",
      "fuel_rewards |   -9.01 |    0.52 |  -11.66 |   -7.92\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.50 |    0.05 |    3.10\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.56 |   11.03 |    4.96 |   70.06\n",
      "tracking_rewards |  -27.97 |   14.20 | -113.88 |   -9.83\n",
      "steps    |     271 |      19 |     223 |     322\n",
      "***** Episode 35340, Mean R = -36.6  Std R = 10.7  Min R = -66.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000819\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.74e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9615   1.9733   9.1679  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 35371, Mean R = -33.6  Std R = 7.1  Min R = -53.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000963\n",
      "PolicyEntropy: -3.01\n",
      "PolicyLoss: -0.00364\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 8.75e+06\n",
      "ValFuncLoss: 0.00151\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0076   2.3815  10.8101  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 35402, Mean R = -34.7  Std R = 7.6  Min R = -55.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000909\n",
      "PolicyEntropy: -3.02\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.76e+06\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5526   1.7508   8.9501  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 35433, Mean R = -32.6  Std R = 9.7  Min R = -59.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000963\n",
      "PolicyEntropy: -3.02\n",
      "PolicyLoss: -0.00379\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 8.76e+06\n",
      "ValFuncLoss: 0.00182\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7563   1.5128   9.3796  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 35464, Mean R = -34.4  Std R = 7.6  Min R = -53.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00063\n",
      "PolicyEntropy: -3.02\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 8.77e+06\n",
      "ValFuncLoss: 0.00146\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2512   1.7618   8.5278  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 35495, Mean R = -39.2  Std R = 12.6  Min R = -75.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000662\n",
      "PolicyEntropy: -3.02\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 8.78e+06\n",
      "ValFuncLoss: 0.00115\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1572   3.4616  15.1786  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 35526, Mean R = -36.1  Std R = 10.9  Min R = -73.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000731\n",
      "PolicyEntropy: -3.03\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 8.79e+06\n",
      "ValFuncLoss: 0.00157\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6027   1.8923  11.4981  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 35557, Mean R = -36.6  Std R = 7.8  Min R = -56.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00084\n",
      "PolicyEntropy: -3.04\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 8.8e+06\n",
      "ValFuncLoss: 0.00138\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3041   2.1775  10.3619  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 35588, Mean R = -34.4  Std R = 10.9  Min R = -83.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000894\n",
      "PolicyEntropy: -3.04\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 8.81e+06\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.107\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.2170   5.3180  20.1936  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 35619, Mean R = -36.5  Std R = 11.4  Min R = -79.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000746\n",
      "PolicyEntropy: -3.05\n",
      "PolicyLoss: -0.00235\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 8.81e+06\n",
      "ValFuncLoss: 0.00174\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4103   2.8849  12.6698  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1150    ET =    188.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.1     6.7    -0.4 |    17.7    19.5     0.2 |   -38.4   -80.1    -1.1 |    54.1    56.1    -0.0\n",
      "v_f      |   -5.14    0.88  -15.18 |    2.01    1.90    3.44 |  -12.13   -6.07  -26.43 |   -0.39   10.10   -5.20\n",
      "vr_f     |     3.0 |     1.1 |     1.2 |     9.0\n",
      "r_i      |  1036.7    37.8  2350.7 |   572.5   542.2    29.4 |     1.4  -999.9  2300.1 |  1994.4   999.8  2399.4\n",
      "v_i      |  -40.50   -0.34  -79.71 |   17.87   17.22    5.81 |  -69.93  -29.88  -89.95 |  -10.05   29.88  -70.12\n",
      "norm_rf  |    25.9 |    13.1 |     1.8 |    80.3\n",
      "norm_vf  |   16.25 |    3.65 |    5.75 |   27.86\n",
      "thrust   |    1236      37    9095 |    2901    2864    2462 |  -11630  -14018   -5806 |   14973   13894   14999\n",
      "norm_thrust |    9951 |    2812 |    2000 |   15000\n",
      "fuel     |     261 |      13 |     234 |     303\n",
      "rewards  |  -35.49 |   10.27 |  -90.78 |  -19.41\n",
      "fuel_rewards |   -8.98 |    0.43 |  -10.43 |   -8.06\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.49 |    0.53 |    3.54\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.71 |   11.18 |    5.21 |   75.26\n",
      "tracking_rewards |  -26.51 |   10.04 |  -80.35 |  -10.61\n",
      "steps    |     270 |      22 |     217 |     329\n",
      "***** Episode 35650, Mean R = -36.8  Std R = 13.2  Min R = -90.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000878\n",
      "PolicyEntropy: -3.05\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 8.82e+06\n",
      "ValFuncLoss: 0.00149\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8660   1.5037   6.9282  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0009   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 35681, Mean R = -40.5  Std R = 19.3  Min R = -113.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000679\n",
      "PolicyEntropy: -3.05\n",
      "PolicyLoss: -0.00202\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 8.83e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1519   2.0200  10.0095  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 35712, Mean R = -37.4  Std R = 17.3  Min R = -110.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.00075\n",
      "PolicyEntropy: -3.05\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 8.84e+06\n",
      "ValFuncLoss: 0.00229\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1699   1.3318   7.0712  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 35743, Mean R = -37.5  Std R = 17.4  Min R = -107.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000695\n",
      "PolicyEntropy: -3.05\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 8.85e+06\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5681   1.0234   6.2559  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 35774, Mean R = -37.8  Std R = 15.6  Min R = -100.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -3.04\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 8.86e+06\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8862   3.7355  15.1787  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 35805, Mean R = -34.5  Std R = 6.7  Min R = -48.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -3.04\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 8.86e+06\n",
      "ValFuncLoss: 0.00257\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1997   1.5906   8.0902  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 35836, Mean R = -32.7  Std R = 9.2  Min R = -64.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.953\n",
      "KL: 0.00079\n",
      "PolicyEntropy: -3.04\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 8.87e+06\n",
      "ValFuncLoss: 0.00191\n",
      "Variance: 0.106\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3573   1.6910   9.1980  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 35867, Mean R = -34.8  Std R = 8.5  Min R = -55.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000678\n",
      "PolicyEntropy: -3.05\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 8.88e+06\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.105\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.6579   5.1926  17.3034  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 35898, Mean R = -35.6  Std R = 10.7  Min R = -66.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000802\n",
      "PolicyEntropy: -3.05\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 8.89e+06\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.105\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5293   1.9792   9.5318  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0015   0.0066   1.6645   0.7971   0.5555\n",
      "***** Episode 35929, Mean R = -36.1  Std R = 8.5  Min R = -63.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000727\n",
      "PolicyEntropy: -3.06\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 8.9e+06\n",
      "ValFuncLoss: 0.00248\n",
      "Variance: 0.104\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0738   1.6575   8.0216  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0044   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1160    ET =    186.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.5     5.8    -0.4 |    17.5    19.7     0.2 |   -31.4   -60.0    -1.0 |    61.3    58.5    -0.0\n",
      "v_f      |   -5.28    1.16  -14.73 |    2.12    1.74    3.66 |  -11.68   -5.03  -24.09 |    1.85    7.24   -2.75\n",
      "vr_f     |     2.9 |     1.8 |     1.0 |    22.8\n",
      "r_i      |  1009.6    13.7  2351.8 |   561.0   579.0    28.7 |     6.9  -993.6  2300.2 |  1996.5   998.4  2398.7\n",
      "v_i      |  -38.93    2.06  -80.24 |   17.04   16.21    5.72 |  -69.46  -29.81  -89.90 |  -10.35   29.71  -70.14\n",
      "norm_rf  |    25.5 |    12.3 |     2.9 |    77.3\n",
      "norm_vf  |   15.87 |    3.89 |    3.13 |   26.69\n",
      "thrust   |    1163     -37    9096 |    2807    2893    2476 |  -11358  -14168   -6503 |   14994   14511   15000\n",
      "norm_thrust |    9928 |    2812 |    2000 |   15000\n",
      "fuel     |     262 |      14 |     234 |     311\n",
      "rewards  |  -36.17 |   13.20 | -113.88 |  -20.25\n",
      "fuel_rewards |   -9.01 |    0.47 |  -10.69 |   -8.06\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.48 |    0.53 |    3.29\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.14 |   10.61 |    5.95 |   72.29\n",
      "tracking_rewards |  -27.16 |   12.91 | -103.85 |  -11.59\n",
      "steps    |     272 |      20 |     230 |     327\n",
      "***** Episode 35960, Mean R = -34.9  Std R = 9.8  Min R = -65.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000677\n",
      "PolicyEntropy: -3.06\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 8.91e+06\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.104\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4058   0.8441   6.0567  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0011   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 35991, Mean R = -36.8  Std R = 10.3  Min R = -61.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000721\n",
      "PolicyEntropy: -3.06\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 8.91e+06\n",
      "ValFuncLoss: 0.00199\n",
      "Variance: 0.104\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6400   0.7664   4.6977  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0037   0.0016   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 36022, Mean R = -41.8  Std R = 19.0  Min R = -119.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000626\n",
      "PolicyEntropy: -3.07\n",
      "PolicyLoss: -0.00213\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 8.92e+06\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.104\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3930   2.3343   9.7497  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 36053, Mean R = -37.6  Std R = 16.7  Min R = -101.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00058\n",
      "PolicyEntropy: -3.07\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 8.93e+06\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.103\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8539   1.9866   9.8053  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 36084, Mean R = -41.0  Std R = 12.8  Min R = -75.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.948\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000923\n",
      "PolicyEntropy: -3.08\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 8.94e+06\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.103\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7709   1.3975   7.0869  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0007   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 36115, Mean R = -37.6  Std R = 15.8  Min R = -97.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00071\n",
      "PolicyEntropy: -3.09\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.95e+06\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9609   1.5002   7.9456  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 36146, Mean R = -38.4  Std R = 17.2  Min R = -119.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.942\n",
      "KL: 0.000566\n",
      "PolicyEntropy: -3.09\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 8.96e+06\n",
      "ValFuncLoss: 0.0029\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8528   1.5720   6.6978  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 36177, Mean R = -39.0  Std R = 14.4  Min R = -94.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000702\n",
      "PolicyEntropy: -3.09\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 8.97e+06\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3224   1.0184   5.3814  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0014   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 36208, Mean R = -35.1  Std R = 9.6  Min R = -66.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000609\n",
      "PolicyEntropy: -3.09\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 8.97e+06\n",
      "ValFuncLoss: 0.00268\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0994   2.0340  10.0836  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0018   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 36239, Mean R = -35.7  Std R = 13.5  Min R = -86.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000692\n",
      "PolicyEntropy: -3.1\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 8.98e+06\n",
      "ValFuncLoss: 0.00296\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3417   1.0815   5.5668  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1170    ET =    186.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     7.8     7.5    -0.4 |    19.0    20.6     0.2 |   -33.3   -50.5    -1.0 |    66.5    53.6    -0.0\n",
      "v_f      |   -5.01    1.31  -14.06 |    2.29    1.85    3.84 |  -12.67   -4.29  -25.27 |    1.94    7.71   -1.61\n",
      "vr_f     |     2.9 |     1.9 |     0.7 |    23.0\n",
      "r_i      |   968.3    45.6  2347.7 |   580.1   594.1    28.2 |     3.5  -998.9  2300.2 |  1990.0   997.9  2399.5\n",
      "v_i      |  -39.35   -2.92  -80.12 |   17.56   17.79    5.67 |  -69.97  -29.99  -89.98 |  -10.04   29.93  -70.00\n",
      "norm_rf  |    27.1 |    13.0 |     1.8 |    68.0\n",
      "norm_vf  |   15.22 |    4.06 |    2.13 |   26.67\n",
      "thrust   |    1171     143    9104 |    2947    3026    2471 |  -11805  -14246   -5778 |   14986   14338   15000\n",
      "norm_thrust |   10003 |    2856 |    2000 |   15000\n",
      "fuel     |     265 |      15 |     236 |     356\n",
      "rewards  |  -38.34 |   15.11 | -119.77 |  -21.53\n",
      "fuel_rewards |   -9.11 |    0.53 |  -12.22 |   -8.10\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.36 |    0.47 |    0.04 |    3.29\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   23.57 |   11.26 |    6.17 |   62.95\n",
      "tracking_rewards |  -29.23 |   14.71 | -108.99 |  -13.03\n",
      "steps    |     273 |      19 |     230 |     339\n",
      "***** Episode 36270, Mean R = -40.5  Std R = 17.3  Min R = -96.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000771\n",
      "PolicyEntropy: -3.1\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 8.99e+06\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8500   2.0076  10.0941  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0011   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 36301, Mean R = -40.0  Std R = 15.4  Min R = -112.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000543\n",
      "PolicyEntropy: -3.1\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 9e+06\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8730   1.5225   8.6745  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 36332, Mean R = -34.6  Std R = 10.2  Min R = -72.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000795\n",
      "PolicyEntropy: -3.1\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 9.01e+06\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5382   1.9007   8.9895  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 36363, Mean R = -34.1  Std R = 9.5  Min R = -61.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000634\n",
      "PolicyEntropy: -3.1\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.87e+03\n",
      "TotalSteps: 9.02e+06\n",
      "ValFuncLoss: 0.00192\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9214   1.6257   8.5607  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0009   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 36394, Mean R = -33.0  Std R = 6.4  Min R = -50.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.941\n",
      "KL: 0.000834\n",
      "PolicyEntropy: -3.11\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 9.03e+06\n",
      "ValFuncLoss: 0.0033\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6480   1.2894   7.8576  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0011   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 36425, Mean R = -34.9  Std R = 12.5  Min R = -71.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.942\n",
      "ExplainedVarOld: 0.917\n",
      "KL: 0.000933\n",
      "PolicyEntropy: -3.11\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 9.03e+06\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0469   1.0689   6.7565  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0017   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 36456, Mean R = -38.9  Std R = 11.1  Min R = -77.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.949\n",
      "KL: 0.000755\n",
      "PolicyEntropy: -3.11\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.72e+03\n",
      "TotalSteps: 9.04e+06\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2766   1.6403   7.0110  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0009   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 36487, Mean R = -35.3  Std R = 9.6  Min R = -70.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000701\n",
      "PolicyEntropy: -3.12\n",
      "PolicyLoss: -0.00211\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 9.05e+06\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8283   3.1462  14.2608  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 36518, Mean R = -39.5  Std R = 11.7  Min R = -68.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000713\n",
      "PolicyEntropy: -3.12\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.71e+03\n",
      "TotalSteps: 9.06e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0840   2.0316  11.0014  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0015   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 36549, Mean R = -31.2  Std R = 7.5  Min R = -45.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000735\n",
      "PolicyEntropy: -3.11\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 9.07e+06\n",
      "ValFuncLoss: 0.00225\n",
      "Variance: 0.102\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1546   0.8706   4.6547  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0008   0.0041   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1180    ET =    191.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.2     6.9    -0.3 |    18.1    19.1     0.2 |   -37.0   -43.7    -1.0 |    59.4    57.2    -0.0\n",
      "v_f      |   -4.80    1.13  -13.89 |    2.23    1.72    3.76 |  -11.84   -6.61  -22.12 |    3.23    6.96   -1.69\n",
      "vr_f     |     3.0 |     1.3 |     0.6 |     9.8\n",
      "r_i      |  1006.6    15.8  2350.6 |   568.0   584.5    28.8 |     0.3  -997.8  2300.4 |  1995.4   992.6  2399.6\n",
      "v_i      |  -37.83    0.56  -79.15 |   17.10   17.17    5.90 |  -69.92  -29.56  -89.93 |  -10.01   29.84  -70.13\n",
      "norm_rf  |    25.4 |    12.5 |     1.8 |    62.8\n",
      "norm_vf  |   14.93 |    4.03 |    1.83 |   23.80\n",
      "thrust   |    1129      36    9032 |    2843    2951    2405 |  -11019  -14594   -5517 |   14977   14114   14999\n",
      "norm_thrust |    9882 |    2790 |    2000 |   15000\n",
      "fuel     |     265 |      14 |     234 |     308\n",
      "rewards  |  -35.95 |   11.31 | -112.15 |  -18.66\n",
      "fuel_rewards |   -9.13 |    0.49 |  -10.60 |   -8.06\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.48 |    0.17 |    3.40\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   21.87 |   11.00 |    5.41 |   57.76\n",
      "tracking_rewards |  -26.82 |   10.98 | -101.55 |  -10.23\n",
      "steps    |     276 |      21 |     220 |     336\n",
      "***** Episode 36580, Mean R = -38.0  Std R = 12.7  Min R = -77.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000943\n",
      "PolicyEntropy: -3.12\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 9.08e+06\n",
      "ValFuncLoss: 0.00227\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5483   1.3479   6.3923  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 36611, Mean R = -38.3  Std R = 7.9  Min R = -60.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -3.13\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 9.09e+06\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0261   1.7456   8.7696  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 36642, Mean R = -32.2  Std R = 7.2  Min R = -58.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000815\n",
      "PolicyEntropy: -3.14\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 9.09e+06\n",
      "ValFuncLoss: 0.00244\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9676   2.2494  11.5709  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 36673, Mean R = -36.3  Std R = 14.2  Min R = -82.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000803\n",
      "PolicyEntropy: -3.13\n",
      "PolicyLoss: -0.00381\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 9.1e+06\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3204   1.8995  10.0768  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0011   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 36704, Mean R = -41.3  Std R = 23.7  Min R = -153.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000709\n",
      "PolicyEntropy: -3.13\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 9.11e+06\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2869   2.2731  10.8908  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0010   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 36735, Mean R = -35.0  Std R = 8.1  Min R = -50.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000583\n",
      "PolicyEntropy: -3.13\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 9.12e+06\n",
      "ValFuncLoss: 0.00241\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6899   1.5539   8.5805  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 36766, Mean R = -36.0  Std R = 13.0  Min R = -90.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000666\n",
      "PolicyEntropy: -3.14\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 9.13e+06\n",
      "ValFuncLoss: 0.00245\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5529   1.5011   7.5426  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 36797, Mean R = -33.8  Std R = 12.1  Min R = -92.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000778\n",
      "PolicyEntropy: -3.14\n",
      "PolicyLoss: -0.00334\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 9.14e+06\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.101\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7598   1.0781   5.6663  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 36828, Mean R = -34.6  Std R = 10.2  Min R = -64.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000775\n",
      "PolicyEntropy: -3.15\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 9.14e+06\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.1\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3090   1.4064   8.3940  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 36859, Mean R = -36.1  Std R = 10.8  Min R = -65.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000839\n",
      "PolicyEntropy: -3.14\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 9.15e+06\n",
      "ValFuncLoss: 0.0026\n",
      "Variance: 0.0999\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9271   4.1696  17.0522  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1190    ET =    188.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.2     6.4    -0.4 |    18.5    19.1     0.2 |   -32.7   -67.8    -1.0 |    60.5    48.2    -0.0\n",
      "v_f      |   -4.90    1.28  -14.33 |    2.25    1.82    3.42 |  -12.00   -4.91  -21.92 |    1.81    7.85   -2.18\n",
      "vr_f     |     3.0 |     1.3 |     1.1 |    11.6\n",
      "r_i      |  1008.5     5.9  2351.8 |   594.0   593.1    28.4 |     3.2  -997.3  2300.1 |  1999.6   997.5  2399.6\n",
      "v_i      |  -38.15    0.08  -79.76 |   17.20   17.12    5.99 |  -69.96  -29.90  -89.98 |  -10.06   29.88  -70.08\n",
      "norm_rf  |    26.4 |    12.4 |     2.3 |    74.8\n",
      "norm_vf  |   15.40 |    3.71 |    2.36 |   23.25\n",
      "thrust   |    1150      46    9115 |    2899    2927    2424 |  -11119  -14536   -5848 |   14975   13917   15000\n",
      "norm_thrust |    9976 |    2783 |    2000 |   15000\n",
      "fuel     |     264 |      14 |     234 |     327\n",
      "rewards  |  -36.35 |   12.97 | -153.60 |  -20.30\n",
      "fuel_rewards |   -9.07 |    0.47 |  -11.24 |   -8.05\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.38 |    0.46 |    0.06 |    3.48\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.72 |   10.93 |    5.84 |   69.84\n",
      "tracking_rewards |  -27.28 |   12.67 | -142.37 |  -11.76\n",
      "steps    |     272 |      21 |     222 |     323\n",
      "***** Episode 36890, Mean R = -40.0  Std R = 11.6  Min R = -77.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000759\n",
      "PolicyEntropy: -3.14\n",
      "PolicyLoss: -0.00202\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 9.16e+06\n",
      "ValFuncLoss: 0.0032\n",
      "Variance: 0.0997\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6531   2.8094  14.3833  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0015   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 36921, Mean R = -39.9  Std R = 21.6  Min R = -140.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000716\n",
      "PolicyEntropy: -3.14\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 9.17e+06\n",
      "ValFuncLoss: 0.0036\n",
      "Variance: 0.0999\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8743   1.4530   6.9118  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 36952, Mean R = -35.2  Std R = 8.3  Min R = -58.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.000566\n",
      "PolicyEntropy: -3.15\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 9.18e+06\n",
      "ValFuncLoss: 0.00385\n",
      "Variance: 0.0996\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1568   2.1841  10.3466  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 36983, Mean R = -34.9  Std R = 8.8  Min R = -63.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -3.16\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.50e+03\n",
      "TotalSteps: 9.19e+06\n",
      "ValFuncLoss: 0.0035\n",
      "Variance: 0.0995\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8635   1.4030   6.7271  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 37014, Mean R = -40.3  Std R = 17.0  Min R = -86.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000763\n",
      "PolicyEntropy: -3.16\n",
      "PolicyLoss: -0.00233\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 9.19e+06\n",
      "ValFuncLoss: 0.00344\n",
      "Variance: 0.0999\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7624   2.9336  11.9210  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0009   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 37045, Mean R = -33.1  Std R = 9.2  Min R = -69.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.0008\n",
      "PolicyEntropy: -3.17\n",
      "PolicyLoss: -0.00223\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 9.2e+06\n",
      "ValFuncLoss: 0.00334\n",
      "Variance: 0.0997\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0142   4.4536  18.8158  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 37076, Mean R = -36.4  Std R = 10.7  Min R = -68.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000974\n",
      "PolicyEntropy: -3.17\n",
      "PolicyLoss: -0.00357\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 9.21e+06\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0997\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2046   0.8711   5.1022  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 37107, Mean R = -36.6  Std R = 6.9  Min R = -51.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.951\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000802\n",
      "PolicyEntropy: -3.17\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 9.22e+06\n",
      "ValFuncLoss: 0.00328\n",
      "Variance: 0.0996\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2114   1.3401   7.3595  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 37138, Mean R = -38.9  Std R = 18.4  Min R = -100.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000807\n",
      "PolicyEntropy: -3.17\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 9.23e+06\n",
      "ValFuncLoss: 0.00342\n",
      "Variance: 0.0997\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5269   1.7454  10.1369  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0019   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 37169, Mean R = -41.0  Std R = 20.9  Min R = -120.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000792\n",
      "PolicyEntropy: -3.16\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 9.24e+06\n",
      "ValFuncLoss: 0.00267\n",
      "Variance: 0.0997\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1158   2.7468  14.6792  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0039   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1200    ET =    187.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    13.3     4.8    -0.4 |    17.2    19.3     0.2 |   -31.6   -50.6    -1.0 |    59.1    59.6    -0.0\n",
      "v_f      |   -4.84    1.02  -14.48 |    2.33    1.94    3.46 |  -11.48   -5.84  -22.60 |    2.31    7.94   -3.63\n",
      "vr_f     |     3.2 |     1.9 |     1.1 |    21.9\n",
      "r_i      |  1041.1    -7.5  2351.8 |   583.3   569.7    27.9 |     4.2  -995.7  2300.2 |  1996.7   995.2  2400.0\n",
      "v_i      |  -41.25    0.83  -79.78 |   17.65   17.63    5.61 |  -69.99  -29.98  -89.77 |  -10.36   29.91  -70.06\n",
      "norm_rf  |    26.6 |    12.6 |     1.8 |    63.0\n",
      "norm_vf  |   15.52 |    3.79 |    4.02 |   24.43\n",
      "thrust   |    1258      10    9128 |    2889    2960    2400 |  -11334  -13810   -5821 |   14997   14064   15000\n",
      "norm_thrust |   10003 |    2775 |    2000 |   15000\n",
      "fuel     |     265 |      14 |     230 |     347\n",
      "rewards  |  -37.26 |   14.51 | -140.02 |  -19.83\n",
      "fuel_rewards |   -9.11 |    0.49 |  -11.93 |   -7.91\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.36 |    0.45 |    0.17 |    3.21\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.86 |   11.14 |    5.45 |   58.04\n",
      "tracking_rewards |  -28.15 |   14.16 | -129.29 |  -11.11\n",
      "steps    |     272 |      19 |     224 |     333\n",
      "***** Episode 37200, Mean R = -36.4  Std R = 11.0  Min R = -67.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -3.16\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 9.25e+06\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.0997\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.8965   0.9612   5.2997  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0021   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 37231, Mean R = -38.2  Std R = 17.3  Min R = -126.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000635\n",
      "PolicyEntropy: -3.16\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 9.25e+06\n",
      "ValFuncLoss: 0.00331\n",
      "Variance: 0.0996\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5512   2.2718  11.2829  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0013   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 37262, Mean R = -34.1  Std R = 10.1  Min R = -68.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000974\n",
      "PolicyEntropy: -3.15\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 9.26e+06\n",
      "ValFuncLoss: 0.00313\n",
      "Variance: 0.0996\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8445   3.6163  13.4708  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 37293, Mean R = -36.5  Std R = 11.1  Min R = -71.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000904\n",
      "PolicyEntropy: -3.16\n",
      "PolicyLoss: -0.00379\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 9.27e+06\n",
      "ValFuncLoss: 0.00353\n",
      "Variance: 0.0991\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4629   1.7376   8.5616  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 37324, Mean R = -34.0  Std R = 8.3  Min R = -54.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000875\n",
      "PolicyEntropy: -3.17\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 9.28e+06\n",
      "ValFuncLoss: 0.00376\n",
      "Variance: 0.099\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6424   1.8398  11.1647  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0040   0.0018   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 37355, Mean R = -37.3  Std R = 11.8  Min R = -71.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.936\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000915\n",
      "PolicyEntropy: -3.17\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 9.29e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.0993\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9694   2.8623  12.0247  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0011   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 37386, Mean R = -34.2  Std R = 10.9  Min R = -82.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00135\n",
      "PolicyEntropy: -3.18\n",
      "PolicyLoss: -0.00208\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 9.3e+06\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.0996\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1998   2.6861  13.7295  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 37417, Mean R = -32.8  Std R = 9.1  Min R = -68.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000614\n",
      "PolicyEntropy: -3.18\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 9.3e+06\n",
      "ValFuncLoss: 0.00227\n",
      "Variance: 0.0995\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4344   1.3957   6.7108  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 37448, Mean R = -30.8  Std R = 5.5  Min R = -41.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -3.19\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 9.31e+06\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.0993\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0676   1.1733   7.5218  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0019   0.0072   1.6645   0.7971   0.5555\n",
      "***** Episode 37479, Mean R = -38.3  Std R = 8.4  Min R = -60.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.915\n",
      "KL: 0.000793\n",
      "PolicyEntropy: -3.19\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 9.32e+06\n",
      "ValFuncLoss: 0.00292\n",
      "Variance: 0.0993\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9866   2.1898  10.3974  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1210    ET =    189.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    13.1     4.8    -0.4 |    17.0    19.3     0.2 |   -28.7   -45.7    -1.2 |    55.5    51.5    -0.0\n",
      "v_f      |   -4.90    0.92  -14.32 |    2.45    1.75    3.83 |  -11.75   -4.40  -24.78 |    1.74    7.78   -1.91\n",
      "vr_f     |     3.1 |     1.4 |     0.8 |    11.6\n",
      "r_i      |   992.8    15.8  2350.2 |   583.5   602.5    28.3 |     0.7  -992.2  2300.0 |  1986.4   995.0  2399.1\n",
      "v_i      |  -39.10   -0.41  -80.30 |   17.41   16.88    5.64 |  -69.95  -29.81  -89.81 |  -10.21   29.21  -70.00\n",
      "norm_rf  |    26.5 |    12.3 |     2.6 |    72.5\n",
      "norm_vf  |   15.37 |    4.17 |    2.80 |   25.52\n",
      "thrust   |    1179      56    9108 |    2849    2936    2383 |  -10541  -14235   -5563 |   14993   13856   15000\n",
      "norm_thrust |    9960 |    2751 |    2000 |   15000\n",
      "fuel     |     262 |      13 |     238 |     343\n",
      "rewards  |  -35.44 |   11.10 | -126.08 |  -18.40\n",
      "fuel_rewards |   -9.01 |    0.43 |  -11.79 |   -8.17\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.53 |    0.05 |    3.72\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.81 |   10.85 |    2.53 |   67.52\n",
      "tracking_rewards |  -26.44 |   10.80 | -114.28 |  -10.11\n",
      "steps    |     271 |      18 |     233 |     324\n",
      "***** Episode 37510, Mean R = -38.3  Std R = 11.5  Min R = -79.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.93\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -3.19\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 9.33e+06\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.099\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7479   2.3089  12.8774  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 37541, Mean R = -38.2  Std R = 17.3  Min R = -115.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000743\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 9.34e+06\n",
      "ValFuncLoss: 0.00223\n",
      "Variance: 0.0986\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6079   3.6847  15.7325  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0005   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 37572, Mean R = -38.3  Std R = 12.3  Min R = -83.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000921\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 9.35e+06\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.0984\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.4146   4.6636  20.4529  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0015   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 37603, Mean R = -35.7  Std R = 14.3  Min R = -91.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00125\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00112\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 9.35e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.0982\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.9111   3.4475  15.8650  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 37634, Mean R = -34.8  Std R = 7.8  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8e+03\n",
      "TotalSteps: 9.36e+06\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.0982\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4408   2.5713  12.4807  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 37665, Mean R = -39.4  Std R = 9.6  Min R = -62.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000842\n",
      "PolicyEntropy: -3.19\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 9.37e+06\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.0981\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5994   1.1418   6.6305  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 37696, Mean R = -34.5  Std R = 8.7  Min R = -56.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000937\n",
      "PolicyEntropy: -3.19\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 9.38e+06\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.0979\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1582   1.6450   9.0598  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 37727, Mean R = -32.4  Std R = 9.0  Min R = -63.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -3.19\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 9.39e+06\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.0979\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2814   1.6767   8.0527  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 37758, Mean R = -36.6  Std R = 10.6  Min R = -74.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000698\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 9.4e+06\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.0978\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9205   2.1850  11.6357  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 37789, Mean R = -35.3  Std R = 9.0  Min R = -56.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000787\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 9.4e+06\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.0977\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2162   2.9452  13.1826  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1220    ET =    186.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    12.2     4.8    -0.4 |    16.2    17.5     0.2 |   -24.9   -46.4    -1.1 |    68.6    60.3    -0.0\n",
      "v_f      |   -5.09    0.87  -15.08 |    2.19    1.79    3.34 |  -11.93   -4.61  -22.72 |   -0.35    7.72   -5.21\n",
      "vr_f     |     3.1 |     1.1 |     1.5 |     8.4\n",
      "r_i      |   978.2    -7.1  2352.3 |   542.0   573.1    28.5 |    13.3  -992.1  2300.1 |  1998.9   992.6  2399.6\n",
      "v_i      |  -39.78    1.41  -79.46 |   18.01   17.61    5.93 |  -69.97  -29.60  -89.97 |  -10.04   29.86  -70.02\n",
      "norm_rf  |    24.2 |    12.6 |     2.0 |    71.4\n",
      "norm_vf  |   16.11 |    3.68 |    5.64 |   23.97\n",
      "thrust   |    1231     -16    9143 |    2925    2966    2348 |  -11533  -14178   -5680 |   14985   14071   15000\n",
      "norm_thrust |   10024 |    2739 |    2000 |   15000\n",
      "fuel     |     261 |      13 |     237 |     320\n",
      "rewards  |  -36.48 |   11.79 | -115.33 |  -20.17\n",
      "fuel_rewards |   -8.96 |    0.43 |  -11.02 |   -8.15\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.48 |    0.58 |    3.50\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   21.42 |   10.39 |    5.16 |   66.36\n",
      "tracking_rewards |  -27.53 |   11.53 | -104.99 |  -11.59\n",
      "steps    |     267 |      18 |     210 |     333\n",
      "***** Episode 37820, Mean R = -39.7  Std R = 13.5  Min R = -71.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000967\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 9.41e+06\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.0977\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7860   4.2362  19.2328  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 37851, Mean R = -34.2  Std R = 13.3  Min R = -75.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000612\n",
      "PolicyEntropy: -3.2\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 9.42e+06\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.0975\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7699   2.7376  11.9420  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 37882, Mean R = -36.6  Std R = 10.4  Min R = -61.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000673\n",
      "PolicyEntropy: -3.21\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 9.43e+06\n",
      "ValFuncLoss: 0.0019\n",
      "Variance: 0.0975\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8802   2.3213  10.3407  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 37913, Mean R = -33.6  Std R = 9.1  Min R = -59.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -3.22\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 9.44e+06\n",
      "ValFuncLoss: 0.00229\n",
      "Variance: 0.0971\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4614   1.9924   9.2521  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 37944, Mean R = -36.2  Std R = 10.7  Min R = -72.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000786\n",
      "PolicyEntropy: -3.22\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 9.45e+06\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0967\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8165   1.4948   8.4300  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0011   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 37975, Mean R = -37.2  Std R = 18.9  Min R = -128.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -3.22\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 9.45e+06\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0967\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2900   1.3291   7.0239  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 38006, Mean R = -37.3  Std R = 10.0  Min R = -64.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00066\n",
      "PolicyEntropy: -3.22\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 9.46e+06\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.097\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7079   3.0174  12.1340  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 38037, Mean R = -34.9  Std R = 8.0  Min R = -59.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000721\n",
      "PolicyEntropy: -3.22\n",
      "PolicyLoss: -0.00362\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 9.47e+06\n",
      "ValFuncLoss: 0.00332\n",
      "Variance: 0.097\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5118   2.5420  12.5107  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 38068, Mean R = -33.9  Std R = 7.8  Min R = -61.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000779\n",
      "PolicyEntropy: -3.23\n",
      "PolicyLoss: -0.00354\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 9.48e+06\n",
      "ValFuncLoss: 0.00359\n",
      "Variance: 0.0969\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0447   1.2984   9.2128  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 38099, Mean R = -39.5  Std R = 24.6  Min R = -164.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000693\n",
      "PolicyEntropy: -3.23\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 9.49e+06\n",
      "ValFuncLoss: 0.00354\n",
      "Variance: 0.0968\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3952   1.1402   7.0299  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0043   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1230    ET =    185.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    13.6     1.9    -0.4 |    15.9    18.8     0.2 |   -36.7   -48.2    -1.1 |    52.7    52.2    -0.0\n",
      "v_f      |   -5.10    0.95  -14.62 |    2.17    1.72    3.36 |  -11.62   -4.49  -23.36 |    1.21    6.17   -1.91\n",
      "vr_f     |     3.0 |     1.2 |     0.7 |    10.2\n",
      "r_i      |  1039.7    -3.3  2351.1 |   554.9   593.6    28.1 |     8.0  -996.4  2300.1 |  1994.5   983.0  2399.8\n",
      "v_i      |  -40.51    0.50  -79.77 |   17.09   17.40    5.77 |  -69.56  -29.95  -89.97 |  -10.05   29.96  -70.04\n",
      "norm_rf  |    25.4 |    12.1 |     1.8 |    59.1\n",
      "norm_vf  |   15.69 |    3.66 |    3.11 |   25.82\n",
      "thrust   |    1233      24    9118 |    2809    2957    2355 |  -10453  -14303   -5437 |   14895   14037   14999\n",
      "norm_thrust |    9967 |    2738 |    2000 |   15000\n",
      "fuel     |     263 |      15 |     235 |     337\n",
      "rewards  |  -35.84 |   13.55 | -163.96 |  -18.02\n",
      "fuel_rewards |   -9.04 |    0.52 |  -11.58 |   -8.08\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.47 |    0.08 |    3.34\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.02 |   10.44 |    6.37 |   54.07\n",
      "tracking_rewards |  -26.80 |   13.19 | -152.37 |   -9.45\n",
      "steps    |     271 |      20 |     221 |     326\n",
      "***** Episode 38130, Mean R = -35.1  Std R = 11.6  Min R = -69.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000685\n",
      "PolicyEntropy: -3.23\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 9.5e+06\n",
      "ValFuncLoss: 0.00357\n",
      "Variance: 0.0967\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0084   2.4132   9.3171  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 38161, Mean R = -32.9  Std R = 7.0  Min R = -56.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000647\n",
      "PolicyEntropy: -3.24\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 9.5e+06\n",
      "ValFuncLoss: 0.00304\n",
      "Variance: 0.0963\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6976   1.5132   8.4271  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 38192, Mean R = -36.9  Std R = 17.5  Min R = -116.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000723\n",
      "PolicyEntropy: -3.24\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 9.51e+06\n",
      "ValFuncLoss: 0.00322\n",
      "Variance: 0.0964\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9716   2.0432  10.6836  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 38223, Mean R = -33.8  Std R = 7.4  Min R = -54.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -3.25\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 9.52e+06\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.096\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2295   1.5549   8.9562  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0017   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 38254, Mean R = -39.4  Std R = 10.2  Min R = -72.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000832\n",
      "PolicyEntropy: -3.25\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 8.68e+03\n",
      "TotalSteps: 9.53e+06\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0958\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4290   3.9640  14.7928  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0023   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 38285, Mean R = -33.4  Std R = 9.4  Min R = -64.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000753\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.002\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 9.54e+06\n",
      "ValFuncLoss: 0.00305\n",
      "Variance: 0.0955\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0919   3.8537  14.8469  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0017   0.0094   1.6645   0.7971   0.5555\n",
      "***** Episode 38316, Mean R = -40.2  Std R = 20.7  Min R = -128.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000831\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00242\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 9.55e+06\n",
      "ValFuncLoss: 0.00326\n",
      "Variance: 0.0954\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2129   1.7631   9.2103  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0080   0.0049   0.0147   1.6645   0.7971   0.5555\n",
      "***** Episode 38347, Mean R = -35.6  Std R = 10.9  Min R = -76.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.911\n",
      "ExplainedVarOld: 0.844\n",
      "KL: 0.00119\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 9.56e+06\n",
      "ValFuncLoss: 0.00305\n",
      "Variance: 0.0952\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1423   2.1052  10.7774  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 38378, Mean R = -35.8  Std R = 9.7  Min R = -61.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.933\n",
      "KL: 0.000708\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 9.56e+06\n",
      "ValFuncLoss: 0.00317\n",
      "Variance: 0.0949\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9506   1.8470   9.0963  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 38409, Mean R = -33.9  Std R = 11.1  Min R = -77.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000858\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 9.57e+06\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0948\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8675   2.1520  10.8806  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1240    ET =    196.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    15.4     3.7    -0.4 |    16.6    20.1     0.2 |   -21.8   -53.7    -1.1 |    55.4    52.7    -0.0\n",
      "v_f      |   -5.18    0.92  -14.92 |    2.27    1.76    3.40 |  -11.68   -3.92  -22.88 |    1.78    6.45   -4.34\n",
      "vr_f     |     3.2 |     3.4 |     1.3 |    59.6\n",
      "r_i      |  1063.6    42.9  2353.6 |   586.9   617.2    28.0 |     5.3  -995.5  2300.1 |  1998.6   997.1  2399.1\n",
      "v_i      |  -41.41    0.06  -79.66 |   17.54   17.47    5.91 |  -69.68  -29.97  -89.92 |  -10.02   29.55  -70.02\n",
      "norm_rf  |    27.6 |    13.0 |     1.6 |    71.6\n",
      "norm_vf  |   16.00 |    3.73 |    4.76 |   24.82\n",
      "thrust   |    1258      27    9088 |    2837    2965    2363 |  -10508  -14344   -6086 |   14974   14048   14999\n",
      "norm_thrust |    9949 |    2762 |    2000 |   15000\n",
      "fuel     |     263 |      14 |     233 |     322\n",
      "rewards  |  -36.19 |   13.34 | -128.63 |  -20.12\n",
      "fuel_rewards |   -9.04 |    0.49 |  -11.08 |   -8.01\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.38 |    0.53 |    0.22 |    4.03\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   24.00 |   11.44 |    5.85 |   66.60\n",
      "tracking_rewards |  -27.14 |   13.00 | -117.75 |  -11.88\n",
      "steps    |     272 |      20 |     226 |     341\n",
      "***** Episode 38440, Mean R = -40.0  Std R = 18.5  Min R = -95.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 9.58e+06\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.0949\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3863   2.8597  13.9026  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 38471, Mean R = -34.4  Std R = 6.8  Min R = -50.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.938\n",
      "ExplainedVarOld: 0.95\n",
      "KL: 0.000819\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00229\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 9.59e+06\n",
      "ValFuncLoss: 0.00226\n",
      "Variance: 0.0948\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4512   1.8994   9.3082  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0006   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 38502, Mean R = -36.2  Std R = 14.0  Min R = -88.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000653\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 9.6e+06\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.0945\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7981   2.5193  12.2641  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 38533, Mean R = -33.5  Std R = 10.9  Min R = -73.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000559\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 9.61e+06\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.0945\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9325   2.5715  11.3962  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 38564, Mean R = -34.8  Std R = 7.5  Min R = -63.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 9.61e+06\n",
      "ValFuncLoss: 0.00191\n",
      "Variance: 0.0945\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0696   1.1255   6.8593  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 38595, Mean R = -34.1  Std R = 11.8  Min R = -71.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.0007\n",
      "PolicyEntropy: -3.25\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 9.62e+06\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.0944\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6944   2.9099  12.3511  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 38626, Mean R = -35.9  Std R = 11.6  Min R = -70.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -3.25\n",
      "PolicyLoss: -0.00193\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 9.63e+06\n",
      "ValFuncLoss: 0.00277\n",
      "Variance: 0.0946\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2596   3.1032  10.2634  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0006   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 38657, Mean R = -37.0  Std R = 11.3  Min R = -72.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00077\n",
      "PolicyEntropy: -3.25\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 9.64e+06\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.0945\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3362   3.5426  19.4871  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0010   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 38688, Mean R = -31.2  Std R = 5.4  Min R = -41.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000675\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 9.65e+06\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.0943\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.7461   4.3573  20.6819  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 38719, Mean R = -34.4  Std R = 7.2  Min R = -51.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.00124\n",
      "PolicyEntropy: -3.26\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 9.66e+06\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0941\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.7621   4.9528  18.4845  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1250    ET =    228.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    13.1     8.5    -0.4 |    16.8    19.2     0.2 |   -25.3   -45.6    -1.2 |    71.8    60.8    -0.0\n",
      "v_f      |   -5.18    0.85  -15.38 |    2.28    1.84    3.11 |  -13.74   -5.11  -23.84 |    2.38    9.46   -5.87\n",
      "vr_f     |     3.2 |     2.1 |     1.2 |    31.6\n",
      "r_i      |  1013.3    57.9  2347.7 |   568.7   570.1    28.9 |     0.1  -993.7  2300.3 |  1998.9   998.1  2399.5\n",
      "v_i      |  -41.20    0.38  -79.85 |   17.40   17.36    5.62 |  -69.99  -29.81  -89.95 |  -10.25   29.99  -70.09\n",
      "norm_rf  |    26.6 |    13.8 |     0.4 |    77.7\n",
      "norm_vf  |   16.46 |    3.38 |    6.59 |   24.72\n",
      "thrust   |    1289      18    9112 |    2828    2954    2330 |  -11090  -14332   -5277 |   14993   14143   14999\n",
      "norm_thrust |    9971 |    2724 |    2000 |   15000\n",
      "fuel     |     258 |      13 |     233 |     317\n",
      "rewards  |  -34.92 |   10.34 |  -88.55 |  -18.72\n",
      "fuel_rewards |   -8.87 |    0.44 |  -10.90 |   -8.01\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.46 |    0.61 |    3.45\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   23.47 |   11.78 |    4.97 |   72.66\n",
      "tracking_rewards |  -26.04 |   10.06 |  -78.23 |  -10.44\n",
      "steps    |     266 |      20 |     202 |     322\n",
      "***** Episode 38750, Mean R = -37.6  Std R = 11.7  Min R = -77.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 9.66e+06\n",
      "ValFuncLoss: 0.00253\n",
      "Variance: 0.0936\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5622   2.8617  11.4512  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 38781, Mean R = -36.2  Std R = 7.6  Min R = -61.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 9.67e+06\n",
      "ValFuncLoss: 0.00235\n",
      "Variance: 0.0936\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9592   3.0280  11.9328  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 38812, Mean R = -39.3  Std R = 15.7  Min R = -82.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000875\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 9.68e+06\n",
      "ValFuncLoss: 0.00246\n",
      "Variance: 0.0934\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.7158   4.4469  17.9689  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 38843, Mean R = -36.0  Std R = 8.7  Min R = -60.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000775\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00378\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 9.69e+06\n",
      "ValFuncLoss: 0.00248\n",
      "Variance: 0.0932\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8849   1.6896   9.3855  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 38874, Mean R = -33.7  Std R = 12.6  Min R = -83.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000766\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 9.7e+06\n",
      "ValFuncLoss: 0.00245\n",
      "Variance: 0.0932\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6949   3.1637  13.0788  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0017   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 38905, Mean R = -33.6  Std R = 7.0  Min R = -49.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00079\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00356\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 9.7e+06\n",
      "ValFuncLoss: 0.00297\n",
      "Variance: 0.0932\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2958   1.4178   8.3606  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 38936, Mean R = -34.4  Std R = 10.7  Min R = -62.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000878\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 9.71e+06\n",
      "ValFuncLoss: 0.00316\n",
      "Variance: 0.0933\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5647   1.1359   6.1383  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 38967, Mean R = -35.7  Std R = 8.2  Min R = -53.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 9.72e+06\n",
      "ValFuncLoss: 0.00262\n",
      "Variance: 0.093\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.6176   0.9034   5.7987  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 38998, Mean R = -37.3  Std R = 14.4  Min R = -93.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.00067\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 9.73e+06\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.0931\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9529   1.6289   9.6261  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 39029, Mean R = -33.9  Std R = 9.2  Min R = -68.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000853\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 9.74e+06\n",
      "ValFuncLoss: 0.00334\n",
      "Variance: 0.0934\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2532   2.5572  12.0502  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1260    ET =    231.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.9     4.5    -0.3 |    16.6    17.2     0.2 |   -30.6   -45.9    -0.9 |    55.0    44.1    -0.0\n",
      "v_f      |   -4.94    1.16  -14.36 |    2.26    1.76    3.85 |  -11.48   -4.03  -22.10 |    1.15    7.59   -2.00\n",
      "vr_f     |     3.0 |     1.7 |     0.9 |    22.6\n",
      "r_i      |   991.0   -58.6  2350.0 |   583.4   575.8    29.1 |     2.3  -998.5  2300.1 |  1999.5   997.4  2399.3\n",
      "v_i      |  -39.63   -1.19  -79.77 |   17.05   16.89    5.77 |  -69.94  -29.16  -89.98 |  -10.00   29.95  -70.10\n",
      "norm_rf  |    24.1 |    12.4 |     3.2 |    59.3\n",
      "norm_vf  |   15.41 |    4.17 |    2.92 |   23.22\n",
      "thrust   |    1228      99    9180 |    2875    2934    2335 |  -11051  -14275   -5157 |   14971   14344   15000\n",
      "norm_thrust |   10036 |    2720 |    2000 |   15000\n",
      "fuel     |     262 |      14 |     233 |     321\n",
      "rewards  |  -35.60 |   11.53 | -100.61 |  -20.12\n",
      "fuel_rewards |   -9.02 |    0.49 |  -11.04 |   -8.01\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.49 |    0.49 |    3.28\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   21.18 |   10.37 |    2.93 |   54.25\n",
      "tracking_rewards |  -26.58 |   11.21 |  -89.56 |  -11.60\n",
      "steps    |     269 |      20 |     218 |     327\n",
      "***** Episode 39060, Mean R = -36.1  Std R = 15.4  Min R = -100.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000706\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 9.75e+06\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.0936\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3291   1.4814   9.0199  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 39091, Mean R = -33.4  Std R = 7.4  Min R = -59.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.931\n",
      "KL: 0.000872\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 9.75e+06\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.0936\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0344   3.6856  13.7094  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 39122, Mean R = -33.4  Std R = 11.9  Min R = -79.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00079\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 9.76e+06\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.0935\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1920   2.3249  10.6215  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 39153, Mean R = -35.5  Std R = 12.4  Min R = -81.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000686\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 9.77e+06\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.0935\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4730   1.8762  10.5884  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 39184, Mean R = -34.8  Std R = 8.2  Min R = -53.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000667\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 9.78e+06\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.0935\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1322   3.3863  16.8787  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 39215, Mean R = -35.4  Std R = 10.5  Min R = -68.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000901\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 9.79e+06\n",
      "ValFuncLoss: 0.00215\n",
      "Variance: 0.0932\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5640   2.2376  12.6532  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 39246, Mean R = -36.0  Std R = 10.6  Min R = -75.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000593\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 9.8e+06\n",
      "ValFuncLoss: 0.00213\n",
      "Variance: 0.0929\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   1.8605   0.6913   4.2074  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0014   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 39277, Mean R = -36.7  Std R = 18.8  Min R = -109.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.923\n",
      "ExplainedVarOld: 0.844\n",
      "KL: 0.000641\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00141\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 9.81e+06\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.0926\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4258   1.2560   6.1704  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0004   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 39308, Mean R = -36.9  Std R = 16.1  Min R = -117.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000701\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 9.81e+06\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.0928\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2041   1.6395   9.5122  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 39339, Mean R = -34.4  Std R = 8.9  Min R = -54.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -3.27\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 9.82e+06\n",
      "ValFuncLoss: 0.00386\n",
      "Variance: 0.093\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6900   3.0304  11.7829  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1270    ET =    228.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.0     5.7    -0.4 |    18.6    17.7     0.2 |   -34.5   -39.5    -1.0 |    73.0    50.0    -0.0\n",
      "v_f      |   -4.96    1.08  -14.53 |    2.44    1.52    3.82 |  -12.67   -5.18  -22.98 |    1.00    5.61   -1.55\n",
      "vr_f     |     3.4 |     4.3 |     1.4 |    69.0\n",
      "r_i      |   971.9     3.5  2347.5 |   562.6   560.8    28.5 |     3.2  -992.0  2300.3 |  1975.8   994.0  2399.9\n",
      "v_i      |  -39.96    0.45  -79.94 |   17.15   16.84    5.66 |  -69.98  -29.88  -89.97 |  -10.16   29.48  -70.15\n",
      "norm_rf  |    24.9 |    13.1 |     2.0 |    77.3\n",
      "norm_vf  |   15.56 |    4.18 |    1.64 |   24.50\n",
      "thrust   |    1246      31    9128 |    2826    2856    2311 |  -11013  -14243   -6056 |   14985   14050   15000\n",
      "norm_thrust |    9955 |    2693 |    2000 |   15000\n",
      "fuel     |     262 |      13 |     238 |     314\n",
      "rewards  |  -34.93 |   12.26 | -117.61 |  -19.00\n",
      "fuel_rewards |   -9.00 |    0.45 |  -10.81 |   -8.20\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.48 |    0.15 |    3.35\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   21.69 |   11.38 |    5.17 |   72.34\n",
      "tracking_rewards |  -25.94 |   11.91 | -106.80 |  -10.73\n",
      "steps    |     270 |      18 |     225 |     322\n",
      "***** Episode 39370, Mean R = -32.9  Std R = 12.4  Min R = -86.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000659\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 9.83e+06\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.0927\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6872   1.4729   7.9988  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 39401, Mean R = -36.9  Std R = 14.9  Min R = -98.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000611\n",
      "PolicyEntropy: -3.29\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 9.84e+06\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.0924\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4178   1.5350   7.3883  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 39432, Mean R = -38.7  Std R = 20.9  Min R = -140.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00227\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 9.85e+06\n",
      "ValFuncLoss: 0.00321\n",
      "Variance: 0.0922\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0239   1.6508   8.3441  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 39463, Mean R = -37.6  Std R = 12.1  Min R = -67.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000682\n",
      "PolicyEntropy: -3.29\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 9.86e+06\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.0921\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5880   2.3833  10.9276  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 39494, Mean R = -35.3  Std R = 8.7  Min R = -55.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000799\n",
      "PolicyEntropy: -3.29\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 9.86e+06\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.0923\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6321   1.2825   7.9107  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0011   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 39525, Mean R = -35.3  Std R = 13.9  Min R = -94.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 9.87e+06\n",
      "ValFuncLoss: 0.00241\n",
      "Variance: 0.0924\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.5428   0.6433   4.5639  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 39556, Mean R = -33.2  Std R = 7.3  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000721\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 9.88e+06\n",
      "ValFuncLoss: 0.00293\n",
      "Variance: 0.0924\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4614   1.8845  10.3951  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 39587, Mean R = -38.6  Std R = 13.9  Min R = -79.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 9.89e+06\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0925\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5767   1.1066   7.0707  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 39618, Mean R = -41.8  Std R = 18.2  Min R = -114.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.945\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000685\n",
      "PolicyEntropy: -3.28\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.67e+03\n",
      "TotalSteps: 9.9e+06\n",
      "ValFuncLoss: 0.00258\n",
      "Variance: 0.0928\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6902   2.2249  11.8507  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0017   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 39649, Mean R = -36.8  Std R = 16.8  Min R = -108.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000705\n",
      "PolicyEntropy: -3.29\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 9.91e+06\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0926\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6434   1.2275   7.2443  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1280    ET =    232.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.4     6.4    -0.4 |    18.4    19.9     0.2 |   -36.1   -52.9    -1.0 |    72.3    56.4    -0.0\n",
      "v_f      |   -4.99    1.06  -14.38 |    2.51    1.73    3.92 |  -12.14   -4.83  -23.64 |    4.70    7.01   -2.02\n",
      "vr_f     |     3.1 |     2.1 |     1.1 |    32.5\n",
      "r_i      |   995.0   -47.3  2349.4 |   597.9   581.6    28.0 |    13.1  -998.0  2300.1 |  1997.4   980.8  2400.0\n",
      "v_i      |  -39.03   -0.14  -79.93 |   17.55   17.47    5.88 |  -69.46  -29.74  -89.77 |  -10.14   29.91  -70.18\n",
      "norm_rf  |    26.2 |    14.0 |     1.8 |    77.0\n",
      "norm_vf  |   15.47 |    4.25 |    2.15 |   24.54\n",
      "thrust   |    1196      33    9130 |    2914    2939    2346 |  -11436  -14221   -5521 |   14984   14023   15000\n",
      "norm_thrust |    9995 |    2743 |    2000 |   15000\n",
      "fuel     |     265 |      15 |     235 |     319\n",
      "rewards  |  -36.93 |   14.43 | -140.74 |  -20.50\n",
      "fuel_rewards |   -9.11 |    0.50 |  -10.98 |   -8.10\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.38 |    0.47 |    0.07 |    3.22\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.94 |   12.15 |    3.91 |   72.03\n",
      "tracking_rewards |  -27.82 |   14.05 | -129.76 |  -11.77\n",
      "steps    |     273 |      19 |     225 |     343\n",
      "***** Episode 39680, Mean R = -35.0  Std R = 9.6  Min R = -64.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000831\n",
      "PolicyEntropy: -3.29\n",
      "PolicyLoss: -0.00345\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 9.91e+06\n",
      "ValFuncLoss: 0.00268\n",
      "Variance: 0.092\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.2781   6.4353  22.5796  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 39711, Mean R = -34.3  Std R = 5.2  Min R = -47.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -3.3\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 9.92e+06\n",
      "ValFuncLoss: 0.00319\n",
      "Variance: 0.0916\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0485   5.0989  17.8517  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 39742, Mean R = -35.3  Std R = 12.4  Min R = -80.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000966\n",
      "PolicyEntropy: -3.3\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 9.93e+06\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0915\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0314   4.4120  16.9574  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0019   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 39773, Mean R = -35.2  Std R = 6.2  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000815\n",
      "PolicyEntropy: -3.31\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 9.94e+06\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.0912\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4195   3.4012  15.0727  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 39804, Mean R = -33.6  Std R = 11.0  Min R = -71.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000649\n",
      "PolicyEntropy: -3.31\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 9.95e+06\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0909\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3756   2.1867  11.5684  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0011   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 39835, Mean R = -37.2  Std R = 14.6  Min R = -102.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.0007\n",
      "PolicyEntropy: -3.31\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 9.96e+06\n",
      "ValFuncLoss: 0.00265\n",
      "Variance: 0.0908\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0579   1.5190   9.8317  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 39866, Mean R = -36.5  Std R = 16.5  Min R = -102.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -3.3\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 9.97e+06\n",
      "ValFuncLoss: 0.00307\n",
      "Variance: 0.0913\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9720   1.8903  10.8199  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 39897, Mean R = -34.8  Std R = 9.7  Min R = -59.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000979\n",
      "PolicyEntropy: -3.3\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 9.97e+06\n",
      "ValFuncLoss: 0.00384\n",
      "Variance: 0.0914\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1627   1.5882   7.9293  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 39928, Mean R = -37.9  Std R = 12.1  Min R = -73.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000649\n",
      "PolicyEntropy: -3.3\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 9.98e+06\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0915\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3070   2.1714  10.4227  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0018   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 39959, Mean R = -33.1  Std R = 11.9  Min R = -88.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000688\n",
      "PolicyEntropy: -3.3\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 9.99e+06\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.0915\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.9826   1.4468   7.1372  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1290    ET =    226.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.6     7.9    -0.4 |    18.7    19.7     0.2 |   -36.3   -44.4    -1.0 |    56.0    63.1    -0.0\n",
      "v_f      |   -4.97    0.91  -14.49 |    2.33    1.62    3.83 |  -11.37   -3.91  -27.30 |    2.98    7.85   -1.77\n",
      "vr_f     |     3.0 |     1.3 |     0.8 |    12.5\n",
      "r_i      |   986.2     5.7  2349.1 |   552.2   568.8    28.5 |     4.8  -995.9  2300.1 |  1980.7   987.7  2399.8\n",
      "v_i      |  -40.23    0.94  -80.03 |   17.21   17.52    6.01 |  -69.55  -29.81  -89.95 |  -10.15   29.78  -70.08\n",
      "norm_rf  |    27.4 |    13.6 |     1.3 |    80.5\n",
      "norm_vf  |   15.53 |    4.15 |    3.08 |   28.20\n",
      "thrust   |    1214       8    9114 |    2761    2996    2289 |   -9998  -14522   -6251 |   14984   13849   15000\n",
      "norm_thrust |    9953 |    2704 |    2000 |   15000\n",
      "fuel     |     261 |      13 |     238 |     300\n",
      "rewards  |  -35.30 |   11.71 | -102.63 |  -18.89\n",
      "fuel_rewards |   -8.98 |    0.43 |  -10.32 |   -8.17\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.43 |    0.39 |    3.02\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   23.71 |   12.15 |    5.89 |   75.46\n",
      "tracking_rewards |  -26.31 |   11.42 |  -92.60 |  -10.49\n",
      "steps    |     270 |      18 |     223 |     319\n",
      "***** Episode 39990, Mean R = -35.2  Std R = 12.0  Min R = -81.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000713\n",
      "PolicyEntropy: -3.31\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1e+07\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0917\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6436   3.5697  14.1106  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0012   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 40021, Mean R = -33.7  Std R = 7.2  Min R = -55.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.000582\n",
      "PolicyEntropy: -3.31\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1e+07\n",
      "ValFuncLoss: 0.00311\n",
      "Variance: 0.0919\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3930   1.6700   8.9301  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0009   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 40052, Mean R = -37.4  Std R = 19.9  Min R = -134.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -3.31\n",
      "PolicyLoss: -0.00345\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1e+07\n",
      "ValFuncLoss: 0.00352\n",
      "Variance: 0.0919\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8111   1.8275  10.7614  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 40083, Mean R = -35.1  Std R = 12.9  Min R = -87.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000692\n",
      "PolicyEntropy: -3.31\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1e+07\n",
      "ValFuncLoss: 0.00366\n",
      "Variance: 0.0923\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6992   1.6606   7.9272  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 40114, Mean R = -38.2  Std R = 20.7  Min R = -124.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000706\n",
      "PolicyEntropy: -3.32\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1e+07\n",
      "ValFuncLoss: 0.00369\n",
      "Variance: 0.0922\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2204   1.4652   9.2563  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 40145, Mean R = -36.3  Std R = 11.9  Min R = -70.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000853\n",
      "PolicyEntropy: -3.32\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1e+07\n",
      "ValFuncLoss: 0.0038\n",
      "Variance: 0.0923\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3358   3.8551  15.9029  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0014   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 40176, Mean R = -34.4  Std R = 9.7  Min R = -60.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00086\n",
      "PolicyEntropy: -3.32\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 1e+07\n",
      "ValFuncLoss: 0.00431\n",
      "Variance: 0.0921\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1742   2.1245  10.6539  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0014   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 40207, Mean R = -34.3  Std R = 8.4  Min R = -53.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000802\n",
      "PolicyEntropy: -3.32\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00402\n",
      "Variance: 0.0921\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5014   3.5095  16.7047  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0016   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 40238, Mean R = -34.5  Std R = 8.6  Min R = -57.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000951\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00208\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00342\n",
      "Variance: 0.0919\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.8263   4.9993  19.4793  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 40269, Mean R = -34.6  Std R = 13.2  Min R = -86.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000769\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00415\n",
      "Variance: 0.0919\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5850   2.6309  11.4788  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0046   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1300    ET =    234.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    12.9     3.7    -0.4 |    18.6    17.9     0.2 |   -26.4   -55.7    -1.1 |    69.8    57.9    -0.0\n",
      "v_f      |   -4.92    0.87  -14.92 |    2.54    1.69    3.44 |  -12.29   -4.06  -25.51 |    3.61    6.59   -3.91\n",
      "vr_f     |     3.5 |     2.8 |     1.3 |    30.9\n",
      "r_i      |   999.7   -29.0  2347.5 |   588.1   577.2    29.0 |     7.6  -998.9  2300.2 |  1995.3   999.4  2399.8\n",
      "v_i      |  -40.84    1.63  -80.26 |   17.62   17.35    6.04 |  -69.93  -29.67  -89.98 |  -10.00   29.97  -70.16\n",
      "norm_rf  |    25.9 |    13.2 |     1.5 |    79.5\n",
      "norm_vf  |   15.94 |    3.83 |    4.16 |   27.67\n",
      "thrust   |    1260     -15    9121 |    2894    2911    2335 |  -10739  -14331   -5294 |   14988   14231   15000\n",
      "norm_thrust |    9981 |    2731 |    2000 |   15000\n",
      "fuel     |     260 |      14 |     232 |     322\n",
      "rewards  |  -35.48 |   13.49 | -134.22 |  -19.61\n",
      "fuel_rewards |   -8.93 |    0.49 |  -11.09 |   -7.98\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.55 |    0.16 |    4.27\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.52 |   11.51 |    4.77 |   74.48\n",
      "tracking_rewards |  -26.55 |   13.12 | -123.29 |  -11.37\n",
      "steps    |     268 |      18 |     225 |     318\n",
      "***** Episode 40300, Mean R = -36.3  Std R = 14.4  Min R = -98.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00329\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00397\n",
      "Variance: 0.0916\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0190   3.4833  15.8658  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 40331, Mean R = -33.2  Std R = 7.8  Min R = -56.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000964\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00372\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00457\n",
      "Variance: 0.0918\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4638   3.0245  14.3817  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 40362, Mean R = -36.3  Std R = 16.4  Min R = -82.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000687\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00302\n",
      "Variance: 0.0922\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8096   1.2761   6.5891  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 40393, Mean R = -37.0  Std R = 22.2  Min R = -148.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.000803\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00487\n",
      "Variance: 0.0924\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3412   1.5519   7.9045  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 40424, Mean R = -36.7  Std R = 12.5  Min R = -84.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000682\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00458\n",
      "Variance: 0.0923\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2391   3.4103  18.4070  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 40455, Mean R = -32.2  Std R = 6.0  Min R = -47.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000917\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00451\n",
      "Variance: 0.0922\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0206   1.8292  11.2506  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 40486, Mean R = -35.2  Std R = 13.6  Min R = -97.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.954\n",
      "KL: 0.00071\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00458\n",
      "Variance: 0.0921\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8951   4.1211  18.4614  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0011   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 40517, Mean R = -35.0  Std R = 11.7  Min R = -83.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000791\n",
      "PolicyEntropy: -3.34\n",
      "PolicyLoss: -0.00359\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.004\n",
      "Variance: 0.0922\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6744   2.7723  11.8856  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0014   0.0053   1.6645   0.7971   0.5555\n",
      "***** Episode 40548, Mean R = -37.0  Std R = 17.0  Min R = -109.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000755\n",
      "PolicyEntropy: -3.34\n",
      "PolicyLoss: -0.00242\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.01e+07\n",
      "ValFuncLoss: 0.00369\n",
      "Variance: 0.0927\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0835   2.3917  12.4590  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 40579, Mean R = -33.1  Std R = 8.6  Min R = -61.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -3.33\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00397\n",
      "Variance: 0.0929\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9906   3.6343  15.3278  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0045   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1310    ET =    221.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    13.2     2.4    -0.4 |    17.0    17.4     0.2 |   -27.3   -52.0    -1.0 |    58.7    41.5    -0.0\n",
      "v_f      |   -4.69    1.05  -14.84 |    2.25    1.76    2.98 |  -11.79   -4.80  -23.19 |    1.14    7.18   -4.34\n",
      "vr_f     |     3.6 |     2.8 |     1.4 |    31.1\n",
      "r_i      |   959.6    38.3  2348.9 |   573.9   580.3    28.4 |     3.9  -990.7  2300.5 |  1999.6   993.7  2399.5\n",
      "v_i      |  -40.27    0.58  -80.15 |   17.23   16.75    5.72 |  -69.67  -29.82  -89.94 |  -10.40   29.99  -70.00\n",
      "norm_rf  |    24.9 |    12.3 |     1.4 |    64.9\n",
      "norm_vf  |   15.80 |    3.29 |    4.35 |   24.27\n",
      "thrust   |    1252      26    9140 |    2898    2919    2323 |  -11133  -14198   -5917 |   14991   13828   15000\n",
      "norm_thrust |   10002 |    2717 |    2000 |   15000\n",
      "fuel     |     260 |      13 |     235 |     311\n",
      "rewards  |  -34.91 |   13.56 | -148.65 |  -20.49\n",
      "fuel_rewards |   -8.92 |    0.46 |  -10.68 |   -8.06\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.52 |    0.06 |    3.67\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   21.78 |   10.20 |    5.70 |   59.85\n",
      "tracking_rewards |  -25.99 |   13.23 | -137.98 |  -11.87\n",
      "steps    |     267 |      18 |     225 |     321\n",
      "***** Episode 40610, Mean R = -33.4  Std R = 10.6  Min R = -80.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -3.34\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.07e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00449\n",
      "Variance: 0.0925\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8035   2.0767   9.8949  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0010   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 40641, Mean R = -39.2  Std R = 14.9  Min R = -90.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000933\n",
      "PolicyEntropy: -3.34\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.0035\n",
      "Variance: 0.0923\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1933   2.3538  10.9128  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0019   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 40672, Mean R = -33.7  Std R = 12.1  Min R = -79.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.0008\n",
      "PolicyEntropy: -3.35\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00348\n",
      "Variance: 0.0919\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0984   3.5864  19.2811  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0015   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 40703, Mean R = -33.3  Std R = 15.5  Min R = -110.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -3.36\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00371\n",
      "Variance: 0.0913\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7077   2.2726  14.5871  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0016   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 40734, Mean R = -38.4  Std R = 11.6  Min R = -74.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.946\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000817\n",
      "PolicyEntropy: -3.36\n",
      "PolicyLoss: -0.0035\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.0913\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4638   2.0432   8.9426  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0007   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 40765, Mean R = -38.9  Std R = 15.7  Min R = -95.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.935\n",
      "ExplainedVarOld: 0.923\n",
      "KL: 0.00074\n",
      "PolicyEntropy: -3.35\n",
      "PolicyLoss: -0.00218\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00367\n",
      "Variance: 0.0915\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3550   1.6477   9.5506  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 40796, Mean R = -35.3  Std R = 8.5  Min R = -57.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -3.36\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00352\n",
      "Variance: 0.0911\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4488   1.9327  10.3758  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 40827, Mean R = -34.7  Std R = 15.1  Min R = -88.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.00078\n",
      "PolicyEntropy: -3.37\n",
      "PolicyLoss: -0.00247\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00357\n",
      "Variance: 0.0906\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.1884   1.2915   7.3180  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 40858, Mean R = -35.1  Std R = 8.4  Min R = -64.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000956\n",
      "PolicyEntropy: -3.37\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00378\n",
      "Variance: 0.0905\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7942   1.6494   9.4773  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 40889, Mean R = -34.2  Std R = 12.4  Min R = -82.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000675\n",
      "PolicyEntropy: -3.37\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0906\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5290   1.5388   6.8628  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1320    ET =    234.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.5     1.5    -0.4 |    17.3    17.7     0.2 |   -27.5   -42.9    -0.9 |    52.3    53.7    -0.0\n",
      "v_f      |   -4.45    0.98  -13.79 |    2.45    1.76    3.28 |  -11.43   -6.15  -21.41 |    2.73    7.07   -2.55\n",
      "vr_f     |     3.3 |     1.8 |     0.8 |    15.4\n",
      "r_i      |   941.4   -25.9  2352.2 |   574.0   604.4    29.4 |     0.3  -998.3  2300.2 |  1987.9   996.1  2399.8\n",
      "v_i      |  -40.57    0.62  -80.09 |   17.59   17.73    5.88 |  -69.69  -29.88  -89.94 |  -10.07   29.95  -70.07\n",
      "norm_rf  |    24.4 |    12.2 |     1.7 |    60.2\n",
      "norm_vf  |   14.76 |    3.60 |    4.46 |   22.07\n",
      "thrust   |    1264      49    9112 |    2954    2977    2316 |  -11758  -14204   -5307 |   14920   13972   14999\n",
      "norm_thrust |   10003 |    2742 |    2000 |   15000\n",
      "fuel     |     263 |      15 |     235 |     331\n",
      "rewards  |  -36.45 |   14.21 | -110.02 |  -19.44\n",
      "fuel_rewards |   -9.04 |    0.50 |  -11.36 |   -8.11\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.48 |    0.16 |    3.29\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   21.16 |   10.37 |    6.30 |   55.21\n",
      "tracking_rewards |  -27.40 |   13.80 |  -99.25 |  -10.65\n",
      "steps    |     271 |      19 |     230 |     355\n",
      "***** Episode 40920, Mean R = -41.6  Std R = 20.8  Min R = -104.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000607\n",
      "PolicyEntropy: -3.36\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.02e+07\n",
      "ValFuncLoss: 0.00346\n",
      "Variance: 0.0905\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6746   2.2687  12.9561  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 40951, Mean R = -36.1  Std R = 12.2  Min R = -74.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000611\n",
      "PolicyEntropy: -3.36\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00324\n",
      "Variance: 0.0905\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6288   1.6795   8.5441  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 40982, Mean R = -31.9  Std R = 6.3  Min R = -44.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000677\n",
      "PolicyEntropy: -3.37\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00309\n",
      "Variance: 0.0903\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0605   1.6734   8.7566  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 41013, Mean R = -33.0  Std R = 10.2  Min R = -63.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -3.37\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00328\n",
      "Variance: 0.0901\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1320   3.2853  15.4436  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 41044, Mean R = -35.7  Std R = 9.3  Min R = -58.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000754\n",
      "PolicyEntropy: -3.37\n",
      "PolicyLoss: -0.00366\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00372\n",
      "Variance: 0.0901\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1979   4.1501  17.0792  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0012   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 41075, Mean R = -36.9  Std R = 12.4  Min R = -79.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00142\n",
      "PolicyEntropy: -3.38\n",
      "PolicyLoss: -0.00194\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00295\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1853   4.8430  18.1919  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 41106, Mean R = -34.2  Std R = 9.8  Min R = -73.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -3.38\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00343\n",
      "Variance: 0.0896\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0587   3.4753  15.5373  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 41137, Mean R = -38.2  Std R = 11.9  Min R = -71.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000555\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00377\n",
      "Variance: 0.0897\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9948   2.9670  12.8268  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 41168, Mean R = -33.5  Std R = 9.0  Min R = -66.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000774\n",
      "PolicyEntropy: -3.38\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00382\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1311   2.2922  10.3258  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 41199, Mean R = -33.6  Std R = 8.4  Min R = -60.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000792\n",
      "PolicyEntropy: -3.38\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00338\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4800   1.4772   8.4953  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0022   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1330    ET =    230.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    15.1     5.8    -0.4 |    17.0    16.1     0.2 |   -38.9   -38.4    -1.0 |    66.5    52.0    -0.0\n",
      "v_f      |   -5.00    0.95  -14.78 |    2.21    1.66    2.90 |  -10.66   -6.26  -23.53 |   -0.14    5.98   -5.72\n",
      "vr_f     |     3.3 |     2.2 |     1.5 |    24.2\n",
      "r_i      |  1059.5    15.6  2353.0 |   573.5   566.0    29.5 |     1.4  -997.3  2300.6 |  1991.9   998.0  2399.6\n",
      "v_i      |  -40.80    0.82  -80.51 |   17.58   17.31    5.48 |  -69.68  -29.99  -89.88 |  -10.07   29.90  -70.08\n",
      "norm_rf  |    25.8 |    12.0 |     2.0 |    68.5\n",
      "norm_vf  |   15.82 |    3.18 |    5.80 |   23.92\n",
      "thrust   |    1238      22    9126 |    2867    2855    2277 |  -10308  -14336   -6075 |   14982   14464   15000\n",
      "norm_thrust |    9957 |    2691 |    2204 |   15000\n",
      "fuel     |     261 |      13 |     235 |     303\n",
      "rewards  |  -34.78 |   10.31 |  -79.10 |  -19.73\n",
      "fuel_rewards |   -8.98 |    0.44 |  -10.40 |   -8.08\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.52 |    0.59 |    3.84\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   22.30 |   10.33 |    7.05 |   63.45\n",
      "tracking_rewards |  -25.79 |   10.01 |  -68.77 |  -11.06\n",
      "steps    |     270 |      20 |     218 |     334\n",
      "***** Episode 41230, Mean R = -34.7  Std R = 10.3  Min R = -64.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00349\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3805   1.4571   8.9145  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 41261, Mean R = -37.3  Std R = 11.0  Min R = -77.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000766\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00347\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00368\n",
      "Variance: 0.0896\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2729   1.8120  10.4922  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 41292, Mean R = -40.1  Std R = 18.8  Min R = -124.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000659\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.03e+07\n",
      "ValFuncLoss: 0.00338\n",
      "Variance: 0.0896\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.3697   4.2030  21.2657  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 41323, Mean R = -34.5  Std R = 9.0  Min R = -57.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000904\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.0899\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6450   1.9729  11.6790  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 41354, Mean R = -35.0  Std R = 9.5  Min R = -68.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00377\n",
      "Steps: 8.16e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8289   1.5520   9.1403  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 41385, Mean R = -36.4  Std R = 9.9  Min R = -79.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000733\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00264\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1084   4.8263  19.0773  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 41416, Mean R = -33.6  Std R = 8.6  Min R = -63.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000964\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00215\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00313\n",
      "Variance: 0.09\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5341   1.6992  10.3849  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 41447, Mean R = -35.3  Std R = 8.9  Min R = -53.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.926\n",
      "ExplainedVarOld: 0.904\n",
      "KL: 0.000652\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00347\n",
      "Variance: 0.0902\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2752   1.3934   7.9369  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 41478, Mean R = -35.3  Std R = 7.6  Min R = -54.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000922\n",
      "PolicyEntropy: -3.38\n",
      "PolicyLoss: -0.00351\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0906\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6772   2.2716  10.4342  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 41509, Mean R = -36.8  Std R = 13.7  Min R = -93.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000872\n",
      "PolicyEntropy: -3.38\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.0906\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5707   1.2528   7.7235  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1340    ET =    221.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.0     5.0    -0.4 |    16.1    16.7     0.2 |   -30.3   -48.1    -1.1 |    65.6    50.9    -0.0\n",
      "v_f      |   -4.72    0.79  -14.09 |    2.16    1.61    3.24 |  -12.48   -4.33  -23.36 |    2.77    7.09   -0.52\n",
      "vr_f     |     3.2 |     1.6 |     0.6 |    14.5\n",
      "r_i      |   983.8    23.3  2347.2 |   580.5   599.3    29.0 |     1.0  -988.6  2300.0 |  1999.0   999.4  2399.3\n",
      "v_i      |  -38.16   -0.48  -79.94 |   17.84   17.04    5.45 |  -69.83  -29.99  -89.95 |  -10.01   29.45  -70.00\n",
      "norm_rf  |    23.0 |    11.6 |     3.5 |    68.9\n",
      "norm_vf  |   15.06 |    3.52 |    1.80 |   25.48\n",
      "thrust   |    1200      62    9162 |    2895    2990    2300 |  -10705  -14422   -5980 |   14981   14102   14998\n",
      "norm_thrust |   10029 |    2722 |    2000 |   15000\n",
      "fuel     |     263 |      14 |     231 |     310\n",
      "rewards  |  -35.98 |   11.35 | -124.74 |  -18.77\n",
      "fuel_rewards |   -9.04 |    0.48 |  -10.67 |   -7.92\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.51 |    0.56 |    3.28\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.00 |    9.75 |    6.08 |   63.87\n",
      "tracking_rewards |  -26.94 |   11.05 | -114.07 |  -10.10\n",
      "steps    |     270 |      20 |     225 |     318\n",
      "***** Episode 41540, Mean R = -35.4  Std R = 10.7  Min R = -64.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000592\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.0905\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4110   2.0413  13.1750  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 41571, Mean R = -35.3  Std R = 13.4  Min R = -69.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.0029\n",
      "Variance: 0.0908\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8803   3.2228  13.5340  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 41602, Mean R = -34.9  Std R = 10.8  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00314\n",
      "Variance: 0.0908\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.3191   0.6385   4.4191  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 41633, Mean R = -35.0  Std R = 11.5  Min R = -86.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.943\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000808\n",
      "PolicyEntropy: -3.39\n",
      "PolicyLoss: -0.00224\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.00269\n",
      "Variance: 0.0904\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8622   1.7344   9.7243  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 41664, Mean R = -32.8  Std R = 7.9  Min R = -54.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000578\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.04e+07\n",
      "ValFuncLoss: 0.0026\n",
      "Variance: 0.0903\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8417   2.1385  10.4740  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 41695, Mean R = -34.0  Std R = 9.4  Min R = -57.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000947\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00259\n",
      "Variance: 0.0902\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.7069   1.3622   6.7425  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 41726, Mean R = -38.1  Std R = 18.8  Min R = -128.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00067\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00243\n",
      "Variance: 0.0899\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7125   2.3796  12.4476  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 41757, Mean R = -33.4  Std R = 8.3  Min R = -63.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.00076\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.09\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9415   4.4105  17.8893  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 41788, Mean R = -33.3  Std R = 9.6  Min R = -60.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000878\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00186\n",
      "Variance: 0.0901\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  16.6422   7.7840  29.2956  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 41819, Mean R = -33.0  Std R = 8.6  Min R = -65.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.00191\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.0017\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00327\n",
      "Variance: 0.09\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4343   3.5810  16.6665  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0015   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1350    ET =    237.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.8     3.4    -0.3 |    15.6    15.7     0.2 |   -30.5   -37.4    -0.8 |    47.9    58.4    -0.0\n",
      "v_f      |   -4.73    0.65  -13.80 |    2.05    1.52    3.17 |  -10.56   -4.74  -24.49 |    1.48    7.23   -2.92\n",
      "vr_f     |     3.1 |     1.5 |     1.3 |    20.6\n",
      "r_i      |   996.8    10.3  2352.0 |   583.7   550.9    28.5 |     2.6  -996.6  2300.1 |  1999.6   998.8  2399.8\n",
      "v_i      |  -39.16    0.69  -80.32 |   17.25   17.05    6.03 |  -69.93  -29.88  -89.98 |  -10.03   29.80  -70.06\n",
      "norm_rf  |    22.9 |    10.8 |     1.7 |    62.1\n",
      "norm_vf  |   14.77 |    3.44 |    3.12 |   25.65\n",
      "thrust   |    1198       1    9131 |    2729    2846    2307 |  -10767  -14228   -6734 |   14997   14118   14999\n",
      "norm_thrust |    9925 |    2679 |    2000 |   15000\n",
      "fuel     |     261 |      13 |     232 |     333\n",
      "rewards  |  -34.51 |   11.44 | -128.65 |  -19.50\n",
      "fuel_rewards |   -8.98 |    0.44 |  -11.47 |   -7.99\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.52 |    0.06 |    3.29\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.77 |    8.84 |    4.03 |   57.05\n",
      "tracking_rewards |  -25.52 |   11.15 | -117.18 |  -10.73\n",
      "steps    |     271 |      21 |     231 |     327\n",
      "***** Episode 41850, Mean R = -35.2  Std R = 10.9  Min R = -71.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000647\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00247\n",
      "Variance: 0.0901\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0024   1.5249   8.8879  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 41881, Mean R = -34.8  Std R = 8.6  Min R = -59.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.00354\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.0901\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3439   1.3036   7.5703  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0014   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 41912, Mean R = -35.4  Std R = 11.4  Min R = -76.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.924\n",
      "ExplainedVarOld: 0.9\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00231\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.0903\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9297   2.6649  11.1129  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0012   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 41943, Mean R = -34.9  Std R = 9.1  Min R = -58.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.0902\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6395   3.6916  18.1986  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0007   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 41974, Mean R = -35.2  Std R = 9.7  Min R = -62.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000762\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00229\n",
      "Steps: 8.14e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.0902\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5706   1.8079   8.5379  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0023   0.0088   1.6645   0.7971   0.5555\n",
      "***** Episode 42005, Mean R = -39.0  Std R = 15.6  Min R = -100.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.945\n",
      "KL: 0.000767\n",
      "PolicyEntropy: -3.4\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.09\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1365   2.3530  12.1218  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0010   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 42036, Mean R = -36.1  Std R = 10.1  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000637\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.05e+07\n",
      "ValFuncLoss: 0.00246\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8319   1.8964   9.2768  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 42067, Mean R = -33.5  Std R = 9.1  Min R = -58.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000648\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00243\n",
      "Variance: 0.0894\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0560   1.0378   5.2825  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 42098, Mean R = -37.2  Std R = 14.5  Min R = -80.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.903\n",
      "KL: 0.000859\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.002\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00343\n",
      "Variance: 0.0895\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0844   2.1277  10.6798  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 42129, Mean R = -33.2  Std R = 9.1  Min R = -59.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000671\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.0893\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5737   1.3949   7.7261  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0018   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1360    ET =    229.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.4    -0.6    -0.3 |    15.2    16.2     0.2 |   -24.4   -48.3    -1.0 |    55.1    45.8    -0.0\n",
      "v_f      |   -4.67    0.99  -13.73 |    2.14    1.64    3.16 |  -11.74   -3.67  -21.13 |    1.85    8.96   -2.16\n",
      "vr_f     |     3.1 |     1.4 |     0.8 |    10.8\n",
      "r_i      |  1012.9  -102.6  2350.8 |   591.8   589.9    28.1 |    28.8  -994.4  2300.3 |  1998.1   997.4  2399.8\n",
      "v_i      |  -40.33   -0.32  -80.02 |   17.52   16.91    5.78 |  -69.95  -29.64  -89.98 |  -10.24   29.09  -70.03\n",
      "norm_rf  |    22.2 |    11.4 |     1.8 |    69.2\n",
      "norm_vf  |   14.72 |    3.46 |    2.70 |   23.89\n",
      "thrust   |    1236      45    9157 |    2896    2940    2280 |  -10570  -14362   -5457 |   14999   14363   14999\n",
      "norm_thrust |   10015 |    2704 |    2000 |   15000\n",
      "fuel     |     264 |      13 |     240 |     307\n",
      "rewards  |  -35.27 |   11.30 | -100.76 |  -18.42\n",
      "fuel_rewards |   -9.06 |    0.44 |  -10.58 |   -8.24\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.54 |    0.15 |    3.94\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.20 |    9.51 |    4.31 |   64.23\n",
      "tracking_rewards |  -26.21 |   11.00 |  -90.89 |   -9.85\n",
      "steps    |     271 |      19 |     224 |     320\n",
      "***** Episode 42160, Mean R = -33.6  Std R = 12.0  Min R = -88.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000702\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00315\n",
      "Variance: 0.0896\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8559   0.9805   5.5724  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 42191, Mean R = -35.2  Std R = 11.6  Min R = -70.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000719\n",
      "PolicyEntropy: -3.41\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00286\n",
      "Variance: 0.0898\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.7457   4.3030  16.7878  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 42222, Mean R = -33.7  Std R = 9.5  Min R = -60.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000984\n",
      "PolicyEntropy: -3.42\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.0894\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.7627   5.6109  19.4170  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 42253, Mean R = -36.1  Std R = 10.9  Min R = -70.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000913\n",
      "PolicyEntropy: -3.43\n",
      "PolicyLoss: -0.00157\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00327\n",
      "Variance: 0.0891\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3597   2.3961  11.1530  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0015   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 42284, Mean R = -33.0  Std R = 7.4  Min R = -51.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.956\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000818\n",
      "PolicyEntropy: -3.43\n",
      "PolicyLoss: -0.00325\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00302\n",
      "Variance: 0.0891\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.4486   2.2909  12.0765  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 42315, Mean R = -34.4  Std R = 9.1  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000982\n",
      "PolicyEntropy: -3.43\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.089\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7780   1.5310   8.1510  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 42346, Mean R = -35.5  Std R = 14.6  Min R = -98.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000902\n",
      "PolicyEntropy: -3.43\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00358\n",
      "Variance: 0.089\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5236   1.5364   8.5093  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 42377, Mean R = -33.6  Std R = 8.6  Min R = -52.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000702\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.06e+07\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.089\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5786   1.4801   7.9889  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 42408, Mean R = -37.9  Std R = 16.4  Min R = -118.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000564\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.0891\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2231   2.0267   9.4719  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 42439, Mean R = -35.8  Std R = 10.0  Min R = -71.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000947\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00327\n",
      "Variance: 0.0892\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2874   1.0065   5.2095  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0013   0.0060   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1370    ET =    228.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.4     4.1    -0.4 |    16.1    16.7     0.2 |   -31.5   -55.2    -0.9 |    48.4    53.0    -0.0\n",
      "v_f      |   -4.87    0.82  -13.81 |    2.36    1.41    3.42 |  -11.36   -4.54  -22.29 |    7.81    4.62   -1.09\n",
      "vr_f     |     3.1 |     2.0 |     0.7 |    29.7\n",
      "r_i      |  1012.6    49.9  2349.3 |   588.7   601.3    29.4 |     1.7  -997.0  2300.1 |  1994.7   989.6  2399.4\n",
      "v_i      |  -39.80   -0.85  -79.89 |   17.80   16.98    5.78 |  -69.92  -29.77  -89.96 |  -10.10   29.73  -70.01\n",
      "norm_rf  |    22.7 |    11.3 |     1.8 |    66.7\n",
      "norm_vf  |   14.84 |    3.74 |    1.52 |   25.06\n",
      "thrust   |    1217      84    9109 |    2846    2872    2312 |  -10492  -14215   -4953 |   14984   13908   15000\n",
      "norm_thrust |    9942 |    2705 |    2000 |   15000\n",
      "fuel     |     262 |      14 |     232 |     327\n",
      "rewards  |  -35.23 |   12.00 | -118.54 |  -19.27\n",
      "fuel_rewards |   -9.00 |    0.46 |  -11.23 |   -7.99\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.54 |    0.03 |    3.97\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.77 |    9.29 |    4.42 |   61.73\n",
      "tracking_rewards |  -26.23 |   11.66 | -107.92 |  -10.64\n",
      "steps    |     271 |      19 |     220 |     336\n",
      "***** Episode 42470, Mean R = -37.1  Std R = 16.8  Min R = -106.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.949\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000774\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.0892\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8679   3.3890  15.3803  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 42501, Mean R = -36.4  Std R = 10.1  Min R = -58.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00074\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.0893\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.8344   4.3296  19.8452  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 42532, Mean R = -31.9  Std R = 7.4  Min R = -47.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.958\n",
      "KL: 0.000876\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.0895\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8195   2.9627  14.6511  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 42563, Mean R = -33.9  Std R = 8.4  Min R = -54.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000876\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00246\n",
      "Variance: 0.0893\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5085   2.2086  10.5881  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 42594, Mean R = -31.9  Std R = 7.0  Min R = -53.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000844\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00335\n",
      "Variance: 0.0892\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.7666   6.3159  22.9016  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 42625, Mean R = -30.5  Std R = 7.3  Min R = -46.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.001\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.0892\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4626   2.7260  12.6533  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 42656, Mean R = -36.3  Std R = 12.9  Min R = -74.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000723\n",
      "PolicyEntropy: -3.44\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00278\n",
      "Variance: 0.0891\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6686   2.0489  11.2653  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0014   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 42687, Mean R = -31.5  Std R = 6.7  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0886\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8246   2.0523  11.8556  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 42718, Mean R = -35.6  Std R = 11.2  Min R = -69.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000696\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0882\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.3721   4.0711  20.8092  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 42749, Mean R = -31.7  Std R = 8.4  Min R = -56.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.00065\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.07e+07\n",
      "ValFuncLoss: 0.00257\n",
      "Variance: 0.0881\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1646   2.0244  10.6737  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1380    ET =    238.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.2     3.1    -0.4 |    16.9    16.6     0.2 |   -25.9   -39.0    -1.2 |    57.0    45.3    -0.0\n",
      "v_f      |   -5.05    0.90  -14.23 |    2.26    1.51    3.31 |  -11.70   -5.18  -23.05 |    0.97    6.47   -3.90\n",
      "vr_f     |     3.0 |     1.4 |     1.3 |    17.7\n",
      "r_i      |  1039.4     6.2  2350.0 |   556.6   558.9    29.1 |     7.7  -995.9  2300.4 |  1992.8   990.7  2399.8\n",
      "v_i      |  -37.58    0.72  -80.14 |   16.76   16.98    5.83 |  -69.82  -29.78  -89.94 |  -10.66   29.89  -70.00\n",
      "norm_rf  |    24.0 |    11.0 |     3.0 |    63.8\n",
      "norm_vf  |   15.29 |    3.70 |    4.09 |   23.81\n",
      "thrust   |    1130      19    9148 |    2722    2815    2266 |  -10352  -14196   -5979 |   14990   14183   15000\n",
      "norm_thrust |    9921 |    2648 |    2000 |   15000\n",
      "fuel     |     261 |      12 |     238 |     294\n",
      "rewards  |  -33.47 |    9.30 |  -74.52 |  -19.13\n",
      "fuel_rewards |   -8.98 |    0.39 |  -10.10 |   -8.17\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.49 |    0.65 |    3.54\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.67 |    9.29 |    5.58 |   58.80\n",
      "tracking_rewards |  -24.49 |    9.05 |  -64.41 |  -10.73\n",
      "steps    |     271 |      17 |     228 |     321\n",
      "***** Episode 42780, Mean R = -35.0  Std R = 9.2  Min R = -57.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.0879\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8397   2.5528  13.0947  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 42811, Mean R = -34.7  Std R = 10.4  Min R = -71.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000888\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0878\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4407   1.9108  11.9217  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 42842, Mean R = -38.7  Std R = 16.1  Min R = -95.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000863\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.0878\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6708   2.5369  11.4466  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 42873, Mean R = -39.9  Std R = 17.3  Min R = -111.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000698\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00223\n",
      "Variance: 0.0878\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9736   1.1755   7.8707  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 42904, Mean R = -37.7  Std R = 11.5  Min R = -62.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000796\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.0877\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0176   2.1435  11.6374  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 42935, Mean R = -33.5  Std R = 8.9  Min R = -54.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00214\n",
      "Variance: 0.0874\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8670   1.9366   9.6653  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 42966, Mean R = -33.7  Std R = 11.1  Min R = -71.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000631\n",
      "PolicyEntropy: -3.45\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00178\n",
      "Variance: 0.0869\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5520   3.5478  15.6516  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 42997, Mean R = -34.8  Std R = 12.6  Min R = -82.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -3.46\n",
      "PolicyLoss: -0.00227\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00177\n",
      "Variance: 0.0867\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1443   4.7323  19.2637  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 43028, Mean R = -33.0  Std R = 8.1  Min R = -54.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.00061\n",
      "PolicyEntropy: -3.47\n",
      "PolicyLoss: -0.0022\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00245\n",
      "Variance: 0.0865\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4323   3.5087  14.7783  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 43059, Mean R = -36.4  Std R = 13.1  Min R = -75.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000686\n",
      "PolicyEntropy: -3.48\n",
      "PolicyLoss: -0.00347\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00228\n",
      "Variance: 0.0862\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1532   3.7223  16.8632  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1390    ET =    223.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.4    -0.6    -0.3 |    15.3    16.7     0.2 |   -25.3   -46.7    -0.9 |    51.7    54.2    -0.0\n",
      "v_f      |   -4.81    1.06  -14.05 |    2.14    1.57    3.25 |  -11.16   -5.32  -23.96 |    0.45    7.14   -4.40\n",
      "vr_f     |     3.1 |     1.5 |     1.1 |    12.4\n",
      "r_i      |  1005.5   -20.2  2351.1 |   583.4   578.9    29.4 |     0.2  -995.4  2300.1 |  1995.2   997.4  2399.6\n",
      "v_i      |  -43.23    0.62  -79.76 |   17.37   17.05    5.86 |  -69.95  -29.92  -89.87 |  -10.26   29.63  -70.02\n",
      "norm_rf  |    22.5 |    10.9 |     0.7 |    56.5\n",
      "norm_vf  |   15.05 |    3.57 |    4.84 |   25.40\n",
      "thrust   |    1341      27    9116 |    2948    2903    2252 |  -11160  -14022   -5396 |   14988   14259   15000\n",
      "norm_thrust |    9989 |    2705 |    2000 |   15000\n",
      "fuel     |     264 |      14 |     233 |     315\n",
      "rewards  |  -36.15 |   12.99 | -111.05 |  -18.28\n",
      "fuel_rewards |   -9.08 |    0.47 |  -10.82 |   -8.00\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.48 |    0.49 |    3.56\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.53 |    8.83 |    3.21 |   51.52\n",
      "tracking_rewards |  -27.07 |   12.65 | -100.85 |  -10.05\n",
      "steps    |     272 |      19 |     227 |     333\n",
      "***** Episode 43090, Mean R = -39.1  Std R = 15.2  Min R = -94.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00118\n",
      "PolicyEntropy: -3.48\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00293\n",
      "Variance: 0.0861\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.7350   4.2548  21.5829  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 43121, Mean R = -36.7  Std R = 7.0  Min R = -54.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000668\n",
      "PolicyEntropy: -3.48\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.08e+07\n",
      "ValFuncLoss: 0.00287\n",
      "Variance: 0.086\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  16.3523   6.0849  28.6344  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 43152, Mean R = -32.3  Std R = 8.1  Min R = -60.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -3.48\n",
      "PolicyLoss: -0.00196\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00292\n",
      "Variance: 0.0859\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.3499   3.6644  17.1651  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 43183, Mean R = -34.7  Std R = 8.0  Min R = -52.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00106\n",
      "PolicyEntropy: -3.48\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0215   3.0060  12.7895  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 43214, Mean R = -36.4  Std R = 14.0  Min R = -78.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.00079\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00241\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.0854\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.5277   6.4477  24.1531  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0020   0.0079   1.6645   0.7971   0.5555\n",
      "***** Episode 43245, Mean R = -39.2  Std R = 15.7  Min R = -92.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00248\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.5330   6.0261  24.1648  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 43276, Mean R = -36.2  Std R = 8.9  Min R = -63.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000909\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.0854\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3035   2.0338  10.3787  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 43307, Mean R = -31.6  Std R = 6.3  Min R = -46.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000594\n",
      "PolicyEntropy: -3.5\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   2.4465   0.7191   4.4657  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0016   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 43338, Mean R = -34.7  Std R = 11.8  Min R = -88.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.893\n",
      "ExplainedVarOld: 0.86\n",
      "KL: 0.000647\n",
      "PolicyEntropy: -3.5\n",
      "PolicyLoss: -0.00142\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00392\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5516   1.8665   9.5758  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 43369, Mean R = -34.4  Std R = 7.4  Min R = -53.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000753\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00307\n",
      "Variance: 0.0855\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.9772   4.4417  19.5208  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0040   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1400    ET =    231.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.1     1.1    -0.3 |    17.0    16.5     0.2 |   -29.4   -48.2    -1.1 |    58.1    48.1    -0.0\n",
      "v_f      |   -4.57    0.87  -13.16 |    2.27    1.50    3.36 |  -11.33   -4.94  -22.76 |    1.79    6.22   -3.71\n",
      "vr_f     |     3.2 |     1.9 |     0.9 |    20.4\n",
      "r_i      |   957.2   -20.8  2349.7 |   605.0   554.2    27.6 |     1.4  -997.3  2300.3 |  2000.0   992.1  2399.9\n",
      "v_i      |  -40.52   -0.74  -79.91 |   18.02   17.65    5.72 |  -69.84  -29.91  -89.99 |  -10.32   29.96  -70.06\n",
      "norm_rf  |    22.6 |    11.5 |     1.5 |    58.4\n",
      "norm_vf  |   14.14 |    3.66 |    4.46 |   24.50\n",
      "thrust   |    1253      82    9159 |    2925    2902    2258 |  -10243  -14127   -5668 |   14994   14483   15000\n",
      "norm_thrust |   10018 |    2681 |    2000 |   15000\n",
      "fuel     |     262 |      12 |     235 |     310\n",
      "rewards  |  -35.32 |   10.56 |  -92.68 |  -18.33\n",
      "fuel_rewards |   -9.02 |    0.43 |  -10.66 |   -8.08\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.53 |    0.38 |    3.30\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.51 |    9.59 |    5.47 |   53.40\n",
      "tracking_rewards |  -26.31 |   10.27 |  -83.00 |   -9.73\n",
      "steps    |     269 |      20 |     223 |     324\n",
      "***** Episode 43400, Mean R = -37.0  Std R = 11.5  Min R = -67.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000715\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00412\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.5993   3.9260  15.8427  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 43431, Mean R = -35.1  Std R = 10.5  Min R = -71.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000532\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00366\n",
      "Variance: 0.0857\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5463   2.2018  10.6205  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0015   0.0066   1.6645   0.7971   0.5555\n",
      "***** Episode 43462, Mean R = -35.1  Std R = 18.2  Min R = -126.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.957\n",
      "ExplainedVarOld: 0.935\n",
      "KL: 0.000539\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1980   2.9079  14.1603  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 43493, Mean R = -34.2  Std R = 9.9  Min R = -68.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00105\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.09e+07\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.0857\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9551   1.9614  11.7113  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 43524, Mean R = -35.2  Std R = 11.6  Min R = -73.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00278\n",
      "Variance: 0.0857\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9247   2.4872  12.1220  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 43555, Mean R = -33.8  Std R = 10.7  Min R = -76.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00315\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9284   3.3509  13.5724  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 43586, Mean R = -33.1  Std R = 7.8  Min R = -53.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000767\n",
      "PolicyEntropy: -3.49\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00301\n",
      "Variance: 0.0855\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3106   1.4196   8.2087  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 43617, Mean R = -35.9  Std R = 15.7  Min R = -106.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000945\n",
      "PolicyEntropy: -3.5\n",
      "PolicyLoss: -0.00365\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.0854\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6150   1.2489   7.5800  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 43648, Mean R = -31.3  Std R = 6.6  Min R = -49.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000669\n",
      "PolicyEntropy: -3.5\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.0852\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.2713   4.5863  22.1797  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 43679, Mean R = -33.2  Std R = 10.9  Min R = -71.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.0011\n",
      "PolicyEntropy: -3.51\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.0033\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9187   1.3512   8.0303  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1410    ET =    236.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.4     2.8    -0.3 |    16.2    17.3     0.2 |   -28.3   -53.9    -0.9 |    49.6    45.0    -0.0\n",
      "v_f      |   -4.63    0.89  -13.55 |    2.23    1.72    3.13 |  -11.02   -5.47  -20.13 |    1.72    7.99   -1.17\n",
      "vr_f     |     3.1 |     1.5 |     0.8 |    16.1\n",
      "r_i      |   982.5    53.5  2350.3 |   582.6   561.5    28.4 |     0.0  -994.9  2300.1 |  1985.7   996.7  2400.0\n",
      "v_i      |  -40.23   -0.59  -79.77 |   17.43   16.81    5.76 |  -68.94  -29.95  -89.93 |  -10.02   29.94  -70.01\n",
      "norm_rf  |    22.9 |    11.5 |     1.2 |    59.5\n",
      "norm_vf  |   14.54 |    3.47 |    2.49 |   21.36\n",
      "thrust   |    1253      54    9129 |    2889    2841    2252 |  -10753  -14074   -5232 |   14991   13988   15000\n",
      "norm_thrust |    9964 |    2667 |    2000 |   15000\n",
      "fuel     |     262 |      13 |     234 |     348\n",
      "rewards  |  -34.08 |   11.56 | -126.01 |  -18.68\n",
      "fuel_rewards |   -9.01 |    0.44 |  -11.96 |   -8.05\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.49 |    0.05 |    3.66\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.73 |    9.70 |    3.29 |   54.48\n",
      "tracking_rewards |  -25.07 |   11.22 | -114.04 |  -10.12\n",
      "steps    |     271 |      19 |     224 |     327\n",
      "***** Episode 43710, Mean R = -34.0  Std R = 7.9  Min R = -60.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000717\n",
      "PolicyEntropy: -3.52\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00265\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9250   1.6468   8.3909  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 43741, Mean R = -34.7  Std R = 13.9  Min R = -83.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000632\n",
      "PolicyEntropy: -3.52\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00351\n",
      "Variance: 0.0849\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6594   2.4985  12.2194  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 43772, Mean R = -35.3  Std R = 8.1  Min R = -55.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -3.52\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00394\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0900   2.7511  12.4960  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 43803, Mean R = -34.5  Std R = 9.8  Min R = -69.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000789\n",
      "PolicyEntropy: -3.51\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00361\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.0928   5.2138  20.9197  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 43834, Mean R = -34.1  Std R = 9.5  Min R = -62.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000676\n",
      "PolicyEntropy: -3.52\n",
      "PolicyLoss: -0.0035\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00302\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7843   1.9524   9.8284  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 43865, Mean R = -30.8  Std R = 6.9  Min R = -47.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000677\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.1e+07\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.0849\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1356   3.9658  14.3622  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 43896, Mean R = -32.6  Std R = 9.3  Min R = -67.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000687\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.0847\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8378   3.6097  18.7114  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0020   0.0072   1.6645   0.7971   0.5555\n",
      "***** Episode 43927, Mean R = -35.6  Std R = 11.9  Min R = -76.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000975\n",
      "PolicyEntropy: -3.54\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00349\n",
      "Variance: 0.0846\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8574   2.0389  10.8242  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0011   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 43958, Mean R = -36.0  Std R = 14.9  Min R = -87.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.000755\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00223\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00346\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1552   4.0118  16.3294  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 43989, Mean R = -35.5  Std R = 10.7  Min R = -67.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000691\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.7e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.0024\n",
      "Variance: 0.0854\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6252   1.3400   7.5537  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1420    ET =    225.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.8     2.7    -0.3 |    14.1    16.7     0.2 |   -24.9   -55.3    -0.8 |    47.9    44.9    -0.0\n",
      "v_f      |   -4.81    0.99  -14.01 |    1.98    1.76    2.92 |  -11.08   -5.01  -21.58 |   -0.26    7.18   -3.12\n",
      "vr_f     |     3.0 |     1.8 |     1.4 |    29.5\n",
      "r_i      |  1011.0    15.3  2350.3 |   563.0   573.4    28.2 |     2.8  -995.8  2300.2 |  1988.2   998.5  2399.3\n",
      "v_i      |  -39.23    2.21  -79.48 |   17.30   17.58    5.58 |  -69.75  -29.91  -89.96 |  -10.11   29.70  -70.03\n",
      "norm_rf  |    22.7 |    10.5 |     1.2 |    59.0\n",
      "norm_vf  |   15.02 |    3.20 |    3.45 |   22.52\n",
      "thrust   |    1183     -36    9102 |    2763    2864    2225 |  -10378  -14313   -5446 |   14997   14072   15000\n",
      "norm_thrust |    9905 |    2628 |    2063 |   15000\n",
      "fuel     |     262 |      12 |     238 |     298\n",
      "rewards  |  -34.40 |   10.95 |  -87.03 |  -17.60\n",
      "fuel_rewards |   -9.01 |    0.40 |  -10.24 |   -8.19\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.47 |    0.70 |    3.73\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.48 |    8.60 |    4.22 |   54.01\n",
      "tracking_rewards |  -25.39 |   10.69 |  -77.28 |   -9.11\n",
      "steps    |     272 |      19 |     226 |     321\n",
      "***** Episode 44020, Mean R = -34.8  Std R = 10.9  Min R = -67.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000746\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.0855\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6412   2.4867  12.8007  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 44051, Mean R = -32.8  Std R = 9.5  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000741\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00241\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1695   1.0074   5.0411  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0013   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 44082, Mean R = -34.4  Std R = 14.1  Min R = -107.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000612\n",
      "PolicyEntropy: -3.52\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.086\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8894   2.9602  11.8688  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 44113, Mean R = -34.0  Std R = 12.8  Min R = -83.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000808\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00369\n",
      "Variance: 0.0857\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6249   1.5523  10.3299  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 44144, Mean R = -33.4  Std R = 12.9  Min R = -82.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000652\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00362\n",
      "Variance: 0.0854\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6354   1.8377  10.8415  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 44175, Mean R = -35.2  Std R = 15.4  Min R = -106.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00057\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00346\n",
      "Variance: 0.0858\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0157   3.2759  15.3068  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0018   0.0066   1.6645   0.7971   0.5555\n",
      "***** Episode 44206, Mean R = -36.4  Std R = 11.9  Min R = -79.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000689\n",
      "PolicyEntropy: -3.53\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00406\n",
      "Variance: 0.0858\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2313   2.4542  11.0858  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 44237, Mean R = -32.4  Std R = 9.2  Min R = -55.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000901\n",
      "PolicyEntropy: -3.54\n",
      "PolicyLoss: -0.00374\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.11e+07\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.0858\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6385   4.4474  19.4793  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 44268, Mean R = -33.3  Std R = 7.7  Min R = -58.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000827\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00321\n",
      "Variance: 0.0855\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0060   3.1528  14.4164  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 44299, Mean R = -33.6  Std R = 6.4  Min R = -50.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.0011\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00332\n",
      "Variance: 0.0855\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3154   2.7241  12.7656  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1430    ET =    235.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.6     1.5    -0.3 |    14.4    16.8     0.2 |   -25.4   -57.6    -0.9 |    46.2    38.4    -0.0\n",
      "v_f      |   -4.97    1.14  -14.09 |    2.00    1.55    3.01 |   -9.89   -4.02  -21.73 |   -0.48    8.43   -4.75\n",
      "vr_f     |     3.0 |     1.3 |     1.5 |    12.4\n",
      "r_i      |  1014.2   -51.1  2348.7 |   557.3   542.2    29.0 |    18.8  -998.3  2300.3 |  1987.4   976.2  2399.9\n",
      "v_i      |  -40.50    0.67  -80.28 |   17.58   16.50    5.65 |  -69.65  -29.99  -89.97 |  -10.01   29.80  -70.03\n",
      "norm_rf  |    22.5 |    11.0 |     1.2 |    58.8\n",
      "norm_vf  |   15.13 |    3.32 |    5.18 |   22.36\n",
      "thrust   |    1250      31    9139 |    2838    2758    2244 |  -10373  -13918   -5678 |   14996   13843   15000\n",
      "norm_thrust |    9936 |    2658 |    2000 |   15000\n",
      "fuel     |     260 |      12 |     234 |     315\n",
      "rewards  |  -33.69 |   11.15 | -107.03 |  -19.72\n",
      "fuel_rewards |   -8.95 |    0.42 |  -10.82 |   -8.04\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.54 |    0.20 |    3.87\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.61 |    8.76 |    4.37 |   53.81\n",
      "tracking_rewards |  -24.74 |   10.88 |  -96.55 |  -11.57\n",
      "steps    |     270 |      20 |     226 |     327\n",
      "***** Episode 44330, Mean R = -31.4  Std R = 6.7  Min R = -51.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000692\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00353\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1705   3.1680  13.8746  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 44361, Mean R = -31.3  Std R = 5.9  Min R = -44.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000664\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00305\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.0899   5.4066  21.6909  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 44392, Mean R = -33.2  Std R = 12.0  Min R = -86.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.0011\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.00124\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00319\n",
      "Variance: 0.0857\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  18.8580   9.0082  31.7366  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 44423, Mean R = -31.8  Std R = 9.3  Min R = -60.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00118\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.00113\n",
      "Steps: 8.30e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.0857\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.5102   3.5075  15.4839  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 44454, Mean R = -31.2  Std R = 8.2  Min R = -52.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000758\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00334\n",
      "Variance: 0.0857\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8318   3.1009  13.3827  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 44485, Mean R = -35.3  Std R = 13.8  Min R = -73.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000734\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00349\n",
      "Variance: 0.0858\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7436   2.9149  13.1007  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 44516, Mean R = -34.0  Std R = 8.2  Min R = -59.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.00088\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.0033\n",
      "Variance: 0.0858\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4818   2.6959  12.2588  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 44547, Mean R = -33.6  Std R = 6.1  Min R = -46.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.0036\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6409   3.8133  19.3371  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 44578, Mean R = -33.1  Std R = 9.3  Min R = -57.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000598\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00338\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2208   3.2190  14.1653  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 44609, Mean R = -32.5  Std R = 9.1  Min R = -61.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000889\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.12e+07\n",
      "ValFuncLoss: 0.00282\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9272   3.2568  14.3949  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1440    ET =    228.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.4     5.2    -0.3 |    14.5    16.6     0.2 |   -28.4   -36.6    -0.9 |    47.7    45.5    -0.0\n",
      "v_f      |   -5.03    0.92  -13.71 |    2.03    1.36    3.32 |  -10.40   -3.43  -22.09 |   -0.70    8.35   -2.47\n",
      "vr_f     |     2.9 |     1.0 |     0.9 |     7.2\n",
      "r_i      |   987.8    70.1  2350.8 |   549.3   565.9    27.8 |     5.0  -998.5  2300.2 |  1997.1   993.7  2399.6\n",
      "v_i      |  -39.15   -0.23  -79.87 |   16.34   16.62    5.74 |  -69.94  -29.30  -89.99 |  -10.13   29.67  -70.17\n",
      "norm_rf  |    22.5 |    10.7 |     1.2 |    62.7\n",
      "norm_vf  |   14.76 |    3.64 |    3.65 |   24.22\n",
      "thrust   |    1187       9    9145 |    2693    2783    2214 |  -10443  -14312   -5792 |   14995   13813   15000\n",
      "norm_thrust |    9906 |    2609 |    2000 |   15000\n",
      "fuel     |     262 |      13 |     234 |     309\n",
      "rewards  |  -32.94 |    9.32 |  -86.21 |  -18.97\n",
      "fuel_rewards |   -8.99 |    0.44 |  -10.64 |   -8.03\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.47 |    0.51 |    0.57 |    3.67\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.20 |    8.94 |    4.33 |   57.66\n",
      "tracking_rewards |  -23.95 |    9.05 |  -76.63 |  -10.44\n",
      "steps    |     272 |      19 |     232 |     327\n",
      "***** Episode 44640, Mean R = -33.4  Std R = 7.6  Min R = -53.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00076\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00314\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.7604   4.8048  19.8382  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0017   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 44671, Mean R = -39.9  Std R = 20.8  Min R = -118.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.8e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0858\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4771   2.2234  10.0222  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0011   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 44702, Mean R = -33.7  Std R = 9.4  Min R = -68.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.91\n",
      "ExplainedVarOld: 0.896\n",
      "KL: 0.000831\n",
      "PolicyEntropy: -3.55\n",
      "PolicyLoss: -0.00203\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00544\n",
      "Variance: 0.086\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2037   1.7644  11.5542  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 44733, Mean R = -33.5  Std R = 8.9  Min R = -61.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.95\n",
      "ExplainedVarOld: 0.932\n",
      "KL: 0.000692\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00395\n",
      "Variance: 0.0859\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9330   2.5849  11.1349  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 44764, Mean R = -32.1  Std R = 8.7  Min R = -56.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000771\n",
      "PolicyEntropy: -3.56\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00362\n",
      "Variance: 0.0856\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4987   2.8311  13.0752  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 44795, Mean R = -32.7  Std R = 8.1  Min R = -56.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000818\n",
      "PolicyEntropy: -3.57\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00324\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3728   2.4845  12.8957  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 44826, Mean R = -32.4  Std R = 7.9  Min R = -58.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00075\n",
      "PolicyEntropy: -3.57\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00336\n",
      "Variance: 0.0852\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6477   3.4507  15.6940  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0047   0.0024   0.0099   1.6645   0.7971   0.5555\n",
      "***** Episode 44857, Mean R = -38.4  Std R = 14.4  Min R = -78.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -3.57\n",
      "PolicyLoss: -0.00374\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00379\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8449   3.1158  13.3793  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 44888, Mean R = -35.7  Std R = 14.7  Min R = -77.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.00054\n",
      "PolicyEntropy: -3.57\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00397\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9189   1.2531   7.1006  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 44919, Mean R = -35.0  Std R = 8.8  Min R = -55.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000709\n",
      "PolicyEntropy: -3.57\n",
      "PolicyLoss: -0.00378\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00344\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.7925   5.6993  22.4008  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1450    ET =    226.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.1     3.8    -0.3 |    17.3    17.5     0.2 |   -31.0   -57.4    -1.0 |    47.8    44.4    -0.0\n",
      "v_f      |   -5.19    0.76  -14.01 |    2.37    1.43    3.39 |  -10.72   -3.79  -20.46 |    2.12    6.52   -3.50\n",
      "vr_f     |     3.0 |     1.4 |     1.4 |    15.2\n",
      "r_i      |  1030.2    48.4  2346.9 |   600.2   574.0    29.0 |     1.0  -988.6  2300.1 |  1997.0   989.6  2399.9\n",
      "v_i      |  -40.71    1.34  -79.99 |   17.21   17.42    5.53 |  -69.79  -29.94  -89.84 |  -10.10   29.94  -70.11\n",
      "norm_rf  |    24.7 |    11.6 |     2.0 |    60.1\n",
      "norm_vf  |   15.11 |    3.80 |    3.83 |   22.65\n",
      "thrust   |    1218     -24    9087 |    2787    2909    2245 |   -9607  -14429   -5921 |   14993   14134   14999\n",
      "norm_thrust |    9906 |    2681 |    2000 |   15000\n",
      "fuel     |     262 |      13 |     238 |     314\n",
      "rewards  |  -34.61 |   11.90 | -118.19 |  -19.87\n",
      "fuel_rewards |   -9.02 |    0.45 |  -10.79 |   -8.17\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.51 |    0.21 |    3.36\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   21.24 |    9.87 |    5.24 |   55.05\n",
      "tracking_rewards |  -25.59 |   11.60 | -108.16 |  -10.94\n",
      "steps    |     273 |      20 |     228 |     330\n",
      "***** Episode 44950, Mean R = -32.8  Std R = 6.6  Min R = -57.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000571\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.0036\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6576   1.9200  11.1986  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 44981, Mean R = -32.0  Std R = 6.9  Min R = -51.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000775\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.13e+07\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1926   3.8691  18.6776  33.4160  22.3427  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 45012, Mean R = -33.2  Std R = 5.8  Min R = -53.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.00107\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: -0.0024\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00345\n",
      "Variance: 0.0849\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  22.3892  10.3869  37.4315  37.4315  22.3892  13.6948\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0017   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 45043, Mean R = -34.6  Std R = 7.8  Min R = -51.5\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00208\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: 0.000193\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.0037\n",
      "Variance: 0.0848\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  27.8615  22.0936  49.9551  49.9551  27.8615  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 45074, Mean R = -35.7  Std R = 11.7  Min R = -79.1\n",
      "Beta: 0.0296\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.00716\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: 0.0171\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.0848\n",
      "lr_multiplier: 0.444\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  33.1512  11.6901  48.9708  49.9551  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 45105, Mean R = -32.1  Std R = 6.6  Min R = -45.1\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00522\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: 0.017\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.0849\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  29.5486   9.4369  53.4029  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 45136, Mean R = -33.9  Std R = 10.6  Min R = -70.5\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000596\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: 0.00336\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00324\n",
      "Variance: 0.0848\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  27.8886   7.3871  40.1610  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 45167, Mean R = -32.1  Std R = 6.4  Min R = -50.6\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000626\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: 0.00335\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.0037\n",
      "Variance: 0.0847\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  20.3532  10.8858  38.4635  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 45198, Mean R = -35.9  Std R = 19.4  Min R = -132.1\n",
      "Beta: 0.0296\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000324\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: 0.00155\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00393\n",
      "Variance: 0.0848\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  18.4622   8.6021  31.5985  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 45229, Mean R = -32.5  Std R = 8.6  Min R = -56.1\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000167\n",
      "PolicyEntropy: -3.58\n",
      "PolicyLoss: -0.0015\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00441\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2642   1.4799   6.8996  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1460    ET =    235.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.1     3.4    -0.3 |    16.2    16.6     0.2 |   -30.5   -59.1    -0.9 |    52.6    42.9    -0.0\n",
      "v_f      |   -5.35    1.03  -14.24 |    2.16    1.48    3.33 |  -12.28   -4.05  -21.43 |   -0.82    5.71   -2.54\n",
      "vr_f     |     2.7 |     0.9 |     1.1 |     8.0\n",
      "r_i      |  1048.5   -12.2  2346.3 |   571.6   578.8    29.6 |     4.5  -993.2  2300.2 |  1997.9   985.4  2399.6\n",
      "v_i      |  -39.13   -0.54  -79.97 |   17.69   18.00    5.71 |  -69.99  -29.99  -89.98 |  -10.03   29.99  -70.04\n",
      "norm_rf  |    23.7 |    10.8 |     2.2 |    64.2\n",
      "norm_vf  |   15.39 |    3.69 |    3.56 |   22.55\n",
      "thrust   |    1172      47    9098 |    2708    2831    2269 |  -10220  -14124   -5341 |   14982   13899   15000\n",
      "norm_thrust |    9876 |    2666 |    2000 |   15000\n",
      "fuel     |     261 |      13 |     234 |     335\n",
      "rewards  |  -33.85 |   12.09 | -152.58 |  -18.84\n",
      "fuel_rewards |   -8.99 |    0.43 |  -11.52 |   -8.05\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.54 |    0.05 |    3.50\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.25 |    9.01 |    4.33 |   59.24\n",
      "tracking_rewards |  -24.86 |   11.79 | -141.06 |  -10.48\n",
      "steps    |     272 |      19 |     226 |     333\n",
      "***** Episode 45260, Mean R = -36.5  Std R = 22.6  Min R = -152.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.989\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000299\n",
      "PolicyEntropy: -3.59\n",
      "PolicyLoss: -0.00161\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.0034\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6718   1.5749  10.0007  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 45291, Mean R = -32.5  Std R = 9.6  Min R = -65.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -3.59\n",
      "PolicyLoss: -0.00362\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00288\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9636   1.6691   8.5525  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0015   0.0056   1.6645   0.7971   0.5555\n",
      "***** Episode 45322, Mean R = -34.3  Std R = 10.0  Min R = -68.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00291\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9889   1.2204   6.0952  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 45353, Mean R = -35.6  Std R = 9.3  Min R = -62.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000806\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.14e+07\n",
      "ValFuncLoss: 0.00332\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4910   0.8091   5.6934  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 45384, Mean R = -35.5  Std R = 13.1  Min R = -99.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00326\n",
      "Variance: 0.0852\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8328   1.2360   6.1644  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0001   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 45415, Mean R = -31.4  Std R = 6.8  Min R = -48.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000757\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3094   2.1400   8.9479  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 45446, Mean R = -35.3  Std R = 9.0  Min R = -62.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000785\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00345\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3612   1.7512   9.9037  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 45477, Mean R = -35.3  Std R = 7.6  Min R = -49.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000643\n",
      "PolicyEntropy: -3.59\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00321\n",
      "Variance: 0.0853\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9182   1.2781   9.1205  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 45508, Mean R = -34.0  Std R = 12.1  Min R = -80.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000825\n",
      "PolicyEntropy: -3.59\n",
      "PolicyLoss: -0.00328\n",
      "Steps: 8.10e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.0033\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3211   1.5718   8.5034  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 45539, Mean R = -33.3  Std R = 6.8  Min R = -52.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000795\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9436   1.8001  10.0524  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0049   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1470    ET =    229.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.2     2.4    -0.4 |    16.1    16.7     0.2 |   -26.6   -55.1    -0.9 |    55.9    43.7    -0.0\n",
      "v_f      |   -5.14    0.93  -14.10 |    2.20    1.70    3.26 |  -11.11   -4.37  -20.23 |    0.40    7.77   -4.05\n",
      "vr_f     |     2.9 |     1.9 |     1.0 |    31.3\n",
      "r_i      |   995.2    29.2  2349.9 |   596.5   574.9    28.0 |     3.2  -986.7  2300.2 |  1986.8   997.6  2399.9\n",
      "v_i      |  -40.43    0.70  -80.46 |   17.13   18.31    5.59 |  -69.71  -29.97  -89.94 |  -10.14   29.79  -70.25\n",
      "norm_rf  |    23.1 |    10.8 |     1.0 |    57.8\n",
      "norm_vf  |   15.20 |    3.64 |    5.11 |   21.46\n",
      "thrust   |    1253      21    9145 |    2823    2893    2255 |  -10768  -14411   -5172 |   14982   13985   14999\n",
      "norm_thrust |    9973 |    2676 |    2000 |   15000\n",
      "fuel     |     261 |      12 |     232 |     330\n",
      "rewards  |  -34.37 |   10.16 |  -99.79 |  -19.38\n",
      "fuel_rewards |   -8.98 |    0.42 |  -11.33 |   -8.00\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.51 |    0.28 |    4.08\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.83 |    9.01 |    4.69 |   52.80\n",
      "tracking_rewards |  -25.39 |    9.88 |  -89.46 |  -10.78\n",
      "steps    |     270 |      19 |     227 |     321\n",
      "***** Episode 45570, Mean R = -36.5  Std R = 13.6  Min R = -97.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000826\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00332\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2846   2.3764  11.5686  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 45601, Mean R = -33.1  Std R = 6.9  Min R = -45.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.085\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4794   1.8665  11.0558  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 45632, Mean R = -35.7  Std R = 10.0  Min R = -62.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00335\n",
      "Variance: 0.0851\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1912   1.5703   7.6252  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 45663, Mean R = -31.1  Std R = 8.3  Min R = -66.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000879\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.00412\n",
      "Variance: 0.0848\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3298   2.8649  14.4636  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0017   0.0076   1.6645   0.7971   0.5555\n",
      "***** Episode 45694, Mean R = -33.2  Std R = 8.0  Min R = -52.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000739\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.0036\n",
      "Variance: 0.0849\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6064   2.0453  10.7122  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 45725, Mean R = -35.7  Std R = 9.3  Min R = -65.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -3.6\n",
      "PolicyLoss: -0.00352\n",
      "Steps: 8.15e+03\n",
      "TotalSteps: 1.15e+07\n",
      "ValFuncLoss: 0.0037\n",
      "Variance: 0.0848\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5431   4.8541  18.5451  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 45756, Mean R = -32.1  Std R = 6.9  Min R = -46.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000861\n",
      "PolicyEntropy: -3.61\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 8.24e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00426\n",
      "Variance: 0.0847\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3805   1.9628   8.2826  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 45787, Mean R = -34.7  Std R = 13.3  Min R = -83.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000651\n",
      "PolicyEntropy: -3.61\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.0038\n",
      "Variance: 0.0846\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7204   1.9849  11.4185  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 45818, Mean R = -32.2  Std R = 8.2  Min R = -60.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00102\n",
      "PolicyEntropy: -3.61\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00331\n",
      "Variance: 0.0845\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.1652   0.7054   4.3394  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 45849, Mean R = -31.9  Std R = 6.3  Min R = -47.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000569\n",
      "PolicyEntropy: -3.62\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00346\n",
      "Variance: 0.0842\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5506   1.5652   8.9354  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1480    ET =    228.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.9     4.7    -0.4 |    15.6    17.3     0.2 |   -24.5   -34.9    -0.9 |    52.3    57.6    -0.0\n",
      "v_f      |   -4.99    0.80  -13.50 |    2.12    1.55    3.16 |  -10.32   -3.53  -21.26 |    0.07    6.55   -2.46\n",
      "vr_f     |     2.9 |     1.2 |     0.9 |    10.2\n",
      "r_i      |   988.7     6.4  2347.2 |   569.5   575.4    28.2 |     0.5  -994.8  2300.3 |  1995.3   997.9  2399.3\n",
      "v_i      |  -40.14   -1.81  -80.07 |   17.28   17.48    5.51 |  -69.88  -29.98  -90.00 |  -10.30   28.75  -70.15\n",
      "norm_rf  |    23.5 |    11.6 |     0.7 |    61.1\n",
      "norm_vf  |   14.57 |    3.51 |    3.06 |   22.80\n",
      "thrust   |    1260      97    9174 |    2783    2887    2209 |  -10508  -14029   -5630 |   14983   13927   15000\n",
      "norm_thrust |    9987 |    2642 |    2873 |   15000\n",
      "fuel     |     261 |      12 |     231 |     303\n",
      "rewards  |  -33.37 |    8.84 |  -83.81 |  -18.73\n",
      "fuel_rewards |   -8.98 |    0.41 |  -10.41 |   -7.96\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.50 |    0.61 |    3.52\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.19 |    9.68 |    3.42 |   56.10\n",
      "tracking_rewards |  -24.39 |    8.60 |  -73.77 |  -10.02\n",
      "steps    |     269 |      19 |     225 |     323\n",
      "***** Episode 45880, Mean R = -33.9  Std R = 7.8  Min R = -54.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000668\n",
      "PolicyEntropy: -3.62\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.084\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6834   2.3322  12.9977  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 45911, Mean R = -31.7  Std R = 7.2  Min R = -49.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000776\n",
      "PolicyEntropy: -3.62\n",
      "PolicyLoss: -0.0035\n",
      "Steps: 8.63e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.0841\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1118   1.9284   9.6771  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 45942, Mean R = -31.3  Std R = 5.7  Min R = -51.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000738\n",
      "PolicyEntropy: -3.62\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00335\n",
      "Variance: 0.0842\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3611   1.7657  10.9871  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0012   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 45973, Mean R = -34.7  Std R = 15.7  Min R = -84.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000688\n",
      "PolicyEntropy: -3.62\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00312\n",
      "Variance: 0.0843\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0246   1.2108   7.0111  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0032   0.0017   0.0075   1.6645   0.7971   0.5555\n",
      "***** Episode 46004, Mean R = -32.2  Std R = 8.2  Min R = -50.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000575\n",
      "PolicyEntropy: -3.62\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00267\n",
      "Variance: 0.0843\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.4840   0.9840   6.2673  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0069   1.6645   0.7971   0.5555\n",
      "***** Episode 46035, Mean R = -40.2  Std R = 15.5  Min R = -87.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000774\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00344\n",
      "Variance: 0.0843\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1748   2.7093  11.8870  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 46066, Mean R = -36.6  Std R = 13.8  Min R = -86.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000628\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.16e+07\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.0842\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1935   2.0290  10.2618  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 46097, Mean R = -38.3  Std R = 12.9  Min R = -93.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000969\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00341\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00366\n",
      "Variance: 0.0842\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7247   1.7495   9.6962  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 46128, Mean R = -32.0  Std R = 10.6  Min R = -71.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000689\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.0839\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9941   2.2678  11.4082  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 46159, Mean R = -33.0  Std R = 6.2  Min R = -46.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000761\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00291\n",
      "Variance: 0.0837\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3158   2.7201  12.2032  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0048   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1490    ET =    230.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.7     1.6    -0.3 |    16.4    17.5     0.2 |   -25.5   -49.8    -1.0 |    51.3    45.8    -0.0\n",
      "v_f      |   -5.01    0.96  -13.64 |    2.11    1.63    3.21 |  -11.34   -5.01  -21.90 |    1.47    6.98   -3.50\n",
      "vr_f     |     3.2 |     7.0 |     1.4 |   125.8\n",
      "r_i      |   981.0   -67.1  2351.4 |   573.3   575.4    29.5 |     5.4  -996.5  2300.3 |  1997.8   994.0  2399.5\n",
      "v_i      |  -39.59   -0.65  -79.85 |   17.92   17.87    5.89 |  -69.92  -29.88  -89.98 |  -10.31   29.69  -70.02\n",
      "norm_rf  |    24.0 |    10.8 |     1.0 |    57.6\n",
      "norm_vf  |   14.72 |    3.55 |    3.50 |   23.63\n",
      "thrust   |    1203     103    9135 |    2824    2939    2259 |  -10696  -14421   -5340 |   14987   13985   15000\n",
      "norm_thrust |    9966 |    2704 |    2000 |   15000\n",
      "fuel     |     263 |      13 |     232 |     315\n",
      "rewards  |  -34.51 |   11.57 |  -93.46 |  -17.59\n",
      "fuel_rewards |   -9.03 |    0.44 |  -10.83 |   -8.01\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.50 |    0.43 |    3.34\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.26 |    9.32 |    4.92 |   52.63\n",
      "tracking_rewards |  -25.49 |   11.27 |  -83.25 |   -9.29\n",
      "steps    |     271 |      20 |     234 |     335\n",
      "***** Episode 46190, Mean R = -35.2  Std R = 10.6  Min R = -65.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000672\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.0836\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2891   1.9229   9.8158  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 46221, Mean R = -39.1  Std R = 13.6  Min R = -81.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000685\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.0837\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0813   3.4865  14.5356  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 46252, Mean R = -33.7  Std R = 9.9  Min R = -66.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000583\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00292\n",
      "Variance: 0.0837\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1774   2.6824  12.6946  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 46283, Mean R = -33.8  Std R = 12.0  Min R = -89.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000577\n",
      "PolicyEntropy: -3.63\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.0837\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6798   2.0127  11.7423  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 46314, Mean R = -35.4  Std R = 9.3  Min R = -71.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000733\n",
      "PolicyEntropy: -3.64\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.0837\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3252   1.2396   7.6207  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 46345, Mean R = -34.7  Std R = 14.4  Min R = -102.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000656\n",
      "PolicyEntropy: -3.64\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00256\n",
      "Variance: 0.0839\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7436   1.7595  10.3913  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 46376, Mean R = -34.0  Std R = 7.8  Min R = -53.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000728\n",
      "PolicyEntropy: -3.64\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0841\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9384   2.3561  13.9334  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 46407, Mean R = -28.9  Std R = 7.1  Min R = -51.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000737\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.0838\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0461   1.0686   7.4488  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0018   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 46438, Mean R = -37.2  Std R = 16.9  Min R = -117.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000618\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.17e+07\n",
      "ValFuncLoss: 0.00235\n",
      "Variance: 0.0838\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3262   1.8302  10.8099  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 46469, Mean R = -33.4  Std R = 7.7  Min R = -53.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000754\n",
      "PolicyEntropy: -3.64\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.084\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3068   2.5723  12.9791  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1500    ET =    228.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.1     5.2    -0.3 |    16.2    16.6     0.2 |   -32.5   -43.7    -0.9 |    53.4    46.9    -0.0\n",
      "v_f      |   -5.49    0.83  -14.36 |    2.18    1.54    3.16 |  -10.91   -3.32  -22.20 |   -0.01    7.30   -4.82\n",
      "vr_f     |     2.8 |     1.1 |     1.4 |    10.2\n",
      "r_i      |  1069.9    50.1  2347.8 |   587.0   578.1    29.5 |     3.4  -999.3  2300.4 |  1987.8   995.0  2399.9\n",
      "v_i      |  -40.94    0.36  -80.05 |   17.89   17.18    5.68 |  -69.65  -29.76  -89.78 |  -10.03   29.84  -70.02\n",
      "norm_rf  |    23.8 |    11.1 |     2.8 |    63.9\n",
      "norm_vf  |   15.54 |    3.54 |    5.08 |   24.23\n",
      "thrust   |    1222      15    9137 |    2764    2858    2262 |   -9677  -14220   -5220 |   14980   13978   14999\n",
      "norm_thrust |    9935 |    2681 |    2000 |   15000\n",
      "fuel     |     262 |      12 |     235 |     308\n",
      "rewards  |  -34.31 |   11.42 | -117.74 |  -18.30\n",
      "fuel_rewards |   -8.99 |    0.42 |  -10.59 |   -8.11\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.37 |    0.47 |    0.38 |    2.97\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.47 |    9.29 |    5.59 |   58.88\n",
      "tracking_rewards |  -25.32 |   11.13 | -107.66 |   -9.80\n",
      "steps    |     271 |      18 |     228 |     327\n",
      "***** Episode 46500, Mean R = -32.7  Std R = 7.8  Min R = -49.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000647\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.0839\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9095   1.4923   9.1372  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 46531, Mean R = -34.4  Std R = 8.2  Min R = -55.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000821\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0837\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1601   4.0032  15.7166  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 46562, Mean R = -34.8  Std R = 9.8  Min R = -58.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00103\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.0836\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5590   2.9871  14.0461  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 46593, Mean R = -35.5  Std R = 16.0  Min R = -101.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -3.64\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.0836\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7766   1.6191   8.3068  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 46624, Mean R = -36.8  Std R = 12.9  Min R = -82.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000817\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00287\n",
      "Variance: 0.0835\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2161   1.5192   8.2273  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 46655, Mean R = -35.7  Std R = 11.6  Min R = -70.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000567\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0832\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4410   1.9562   9.5521  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 46686, Mean R = -35.4  Std R = 23.4  Min R = -159.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.0035\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00291\n",
      "Variance: 0.0829\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9305   4.2146  14.9611  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0014   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 46717, Mean R = -32.0  Std R = 8.5  Min R = -63.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.955\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00071\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0828\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8478   4.1239  17.7070  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0012   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 46748, Mean R = -36.1  Std R = 10.6  Min R = -70.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000855\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00353\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.0032\n",
      "Variance: 0.0829\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9146   2.0607   9.3258  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 46779, Mean R = -35.6  Std R = 10.7  Min R = -78.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000596\n",
      "PolicyEntropy: -3.65\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.17e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.0829\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4403   1.9074   8.7241  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1510    ET =    234.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     5.9     0.6    -0.3 |    16.0    15.4     0.2 |   -27.2   -37.6    -0.9 |    54.4    48.1    -0.0\n",
      "v_f      |   -4.87    1.00  -13.34 |    2.11    1.53    3.12 |  -11.10   -3.20  -20.93 |    0.19    8.54   -3.20\n",
      "vr_f     |     2.9 |     1.5 |     1.4 |    19.7\n",
      "r_i      |   953.0   -75.4  2348.2 |   581.9   566.0    28.7 |     1.1  -996.3  2300.2 |  1989.7  1000.0  2399.5\n",
      "v_i      |  -40.15    0.55  -79.88 |   16.49   16.99    5.63 |  -69.80  -29.71  -89.90 |  -10.37   29.95  -70.06\n",
      "norm_rf  |    21.1 |     9.3 |     1.5 |    58.1\n",
      "norm_vf  |   14.39 |    3.47 |    4.12 |   21.89\n",
      "thrust   |    1249      24    9174 |    2885    2856    2258 |  -10561  -14305   -5862 |   14994   14300   14999\n",
      "norm_thrust |   10005 |    2684 |    2000 |   15000\n",
      "fuel     |     263 |      14 |     237 |     343\n",
      "rewards  |  -34.90 |   12.99 | -159.38 |  -17.22\n",
      "fuel_rewards |   -9.05 |    0.47 |  -11.80 |   -8.13\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.49 |    0.07 |    4.36\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.90 |    7.44 |    4.56 |   53.09\n",
      "tracking_rewards |  -25.85 |   12.66 | -147.58 |   -8.50\n",
      "steps    |     271 |      19 |     229 |     326\n",
      "***** Episode 46810, Mean R = -32.5  Std R = 10.0  Min R = -56.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.00066\n",
      "PolicyEntropy: -3.66\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.18e+07\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.0828\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7030   1.3712   7.6550  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 46841, Mean R = -37.7  Std R = 12.8  Min R = -78.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00067\n",
      "PolicyEntropy: -3.66\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00242\n",
      "Variance: 0.0827\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3030   1.8742  10.2202  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 46872, Mean R = -34.4  Std R = 9.6  Min R = -56.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -3.66\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0827\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6553   1.2349   7.6441  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 46903, Mean R = -35.0  Std R = 11.8  Min R = -71.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000822\n",
      "PolicyEntropy: -3.66\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00277\n",
      "Variance: 0.0825\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9249   1.2129   9.3966  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 46934, Mean R = -36.3  Std R = 21.3  Min R = -134.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000638\n",
      "PolicyEntropy: -3.67\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00269\n",
      "Variance: 0.0823\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4310   1.6006   8.4822  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0012   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 46965, Mean R = -36.3  Std R = 11.6  Min R = -71.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.907\n",
      "ExplainedVarOld: 0.92\n",
      "KL: 0.000856\n",
      "PolicyEntropy: -3.67\n",
      "PolicyLoss: -0.00218\n",
      "Steps: 8.71e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00316\n",
      "Variance: 0.0822\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4059   2.5603  14.7027  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 46996, Mean R = -30.8  Std R = 7.8  Min R = -53.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000616\n",
      "PolicyEntropy: -3.67\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00215\n",
      "Variance: 0.0822\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1712   2.2863  13.2138  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 47027, Mean R = -34.8  Std R = 13.1  Min R = -88.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -3.68\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00256\n",
      "Variance: 0.0817\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8544   2.5264  14.3544  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0017   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 47058, Mean R = -36.9  Std R = 12.1  Min R = -78.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000677\n",
      "PolicyEntropy: -3.68\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00272\n",
      "Variance: 0.0815\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3119   3.0763  14.2470  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 47089, Mean R = -34.1  Std R = 9.0  Min R = -55.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000683\n",
      "PolicyEntropy: -3.68\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00239\n",
      "Variance: 0.0815\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9854   3.2204  13.8016  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1520    ET =    235.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     4.1     2.0    -0.3 |    16.6    16.4     0.2 |   -35.4   -51.4    -1.0 |    44.3    41.2    -0.0\n",
      "v_f      |   -4.62    0.87  -12.70 |    2.16    1.59    3.45 |  -12.06   -3.31  -22.35 |    1.76    8.34   -3.34\n",
      "vr_f     |     3.0 |     2.2 |     1.2 |    36.5\n",
      "r_i      |   950.1     3.0  2349.3 |   601.5   566.9    27.6 |     1.4  -999.8  2300.9 |  1983.0   991.7  2399.9\n",
      "v_i      |  -39.92   -1.17  -79.72 |   16.88   16.98    5.56 |  -69.74  -29.87  -89.92 |  -10.11   29.75  -70.07\n",
      "norm_rf  |    21.6 |    10.0 |     1.8 |    57.2\n",
      "norm_vf  |   13.71 |    3.82 |    3.54 |   23.15\n",
      "thrust   |    1251      70    9109 |    2802    2894    2254 |  -10359  -14018   -5781 |   14991   14173   15000\n",
      "norm_thrust |    9931 |    2689 |    2000 |   15000\n",
      "fuel     |     264 |      13 |     238 |     315\n",
      "rewards  |  -34.71 |   12.37 | -134.73 |  -17.75\n",
      "fuel_rewards |   -9.07 |    0.43 |  -10.85 |   -8.19\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.52 |    0.04 |    3.67\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.31 |    8.39 |    4.98 |   52.23\n",
      "tracking_rewards |  -25.64 |   12.08 | -124.29 |   -8.98\n",
      "steps    |     273 |      19 |     235 |     329\n",
      "***** Episode 47120, Mean R = -30.9  Std R = 6.4  Min R = -44.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.000695\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1570   2.2300   9.6981  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 47151, Mean R = -31.8  Std R = 5.9  Min R = -43.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000826\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.00248\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.2487   1.2140   6.0279  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 47182, Mean R = -35.3  Std R = 22.0  Min R = -150.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.94\n",
      "KL: 0.000477\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00181\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.19e+07\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.0812\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8690   1.0558   5.9151  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 47213, Mean R = -32.6  Std R = 9.1  Min R = -69.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.959\n",
      "KL: 0.00132\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00424\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4935   0.8948   6.6288  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 47244, Mean R = -33.4  Std R = 9.8  Min R = -61.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.00157\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00584\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5859   4.3131  19.5969  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 47275, Mean R = -33.7  Std R = 10.8  Min R = -74.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00165\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00431\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5737   1.8104  11.0610  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 47306, Mean R = -33.8  Std R = 13.9  Min R = -90.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.00154\n",
      "PolicyEntropy: -3.7\n",
      "PolicyLoss: -0.00403\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0812\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.3815   1.4630   7.2248  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0020   0.0081   1.6645   0.7971   0.5555\n",
      "***** Episode 47337, Mean R = -38.7  Std R = 29.8  Min R = -158.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.99\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.0012\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.0815\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4050   1.6195   8.7335  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 47368, Mean R = -33.8  Std R = 15.4  Min R = -105.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.00152\n",
      "PolicyEntropy: -3.69\n",
      "PolicyLoss: -0.00516\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9187   1.2715   8.2958  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 47399, Mean R = -36.3  Std R = 9.8  Min R = -68.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00161\n",
      "PolicyEntropy: -3.7\n",
      "PolicyLoss: -0.00451\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00362\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.0764   1.1216   5.5115  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0017   0.0068   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1530    ET =    225.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     7.2     2.0    -0.3 |    15.7    18.0     0.2 |   -31.1   -59.3    -0.9 |    45.9    43.0    -0.0\n",
      "v_f      |   -4.84    0.82  -13.27 |    1.99    1.70    2.99 |  -10.55   -3.47  -23.71 |   -0.58    8.60   -3.34\n",
      "vr_f     |     2.8 |     1.1 |     1.2 |    10.8\n",
      "r_i      |  1018.0    33.8  2348.0 |   556.9   587.8    29.7 |    22.4  -997.8  2300.2 |  1979.3   989.3  2400.0\n",
      "v_i      |  -40.27    0.54  -79.62 |   16.99   17.37    5.85 |  -69.38  -29.83  -89.84 |  -10.02   29.86  -70.02\n",
      "norm_rf  |    22.6 |    10.7 |     2.5 |    62.4\n",
      "norm_vf  |   14.33 |    3.30 |    4.41 |   25.17\n",
      "thrust   |    1227      27    9146 |    2724    2863    2262 |  -10469  -14415   -5300 |   14967   14307   15000\n",
      "norm_thrust |    9936 |    2677 |    2000 |   15000\n",
      "fuel     |     264 |      13 |     237 |     347\n",
      "rewards  |  -34.41 |   15.68 | -158.81 |  -16.99\n",
      "fuel_rewards |   -9.08 |    0.44 |  -11.92 |   -8.15\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.48 |    0.05 |    3.30\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.35 |    8.84 |    6.34 |   57.37\n",
      "tracking_rewards |  -25.34 |   15.36 | -146.89 |   -8.42\n",
      "steps    |     273 |      18 |     231 |     325\n",
      "***** Episode 47430, Mean R = -34.7  Std R = 14.1  Min R = -85.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.909\n",
      "KL: 0.0014\n",
      "PolicyEntropy: -3.7\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.0813\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7604   2.5909  12.5062  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 47461, Mean R = -31.8  Std R = 11.1  Min R = -71.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00152\n",
      "PolicyEntropy: -3.7\n",
      "PolicyLoss: -0.00427\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00304\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6243   1.8045   9.6011  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 47492, Mean R = -35.7  Std R = 11.2  Min R = -65.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00159\n",
      "PolicyEntropy: -3.71\n",
      "PolicyLoss: -0.00487\n",
      "Steps: 8.66e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8639   2.3694  11.1810  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 47523, Mean R = -34.6  Std R = 13.2  Min R = -92.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.00143\n",
      "PolicyEntropy: -3.71\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.0808\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2783   1.5701   8.9791  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 47554, Mean R = -33.9  Std R = 7.8  Min R = -54.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00144\n",
      "PolicyEntropy: -3.71\n",
      "PolicyLoss: -0.00465\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.2e+07\n",
      "ValFuncLoss: 0.00265\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9946   0.9513   6.5091  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 47585, Mean R = -33.0  Std R = 8.6  Min R = -57.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00143\n",
      "PolicyEntropy: -3.71\n",
      "PolicyLoss: -0.00459\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.081\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6091   2.0057  10.0902  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 47616, Mean R = -35.6  Std R = 9.0  Min R = -60.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00209\n",
      "PolicyEntropy: -3.72\n",
      "PolicyLoss: -0.0048\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00329\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7060   2.6435  12.8191  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 47647, Mean R = -35.3  Std R = 10.2  Min R = -63.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000695\n",
      "PolicyEntropy: -3.72\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.0024\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2370   1.6988  10.2460  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 47678, Mean R = -32.9  Std R = 7.3  Min R = -52.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000918\n",
      "PolicyEntropy: -3.72\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00306\n",
      "Variance: 0.0808\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3733   2.2821  12.6399  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 47709, Mean R = -31.8  Std R = 7.6  Min R = -59.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -3.73\n",
      "PolicyLoss: -0.00361\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.0808\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4971   2.5448  12.1102  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0016   0.0059   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1540    ET =    235.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.2     4.7    -0.3 |    16.2    15.5     0.2 |   -29.2   -36.6    -0.8 |    44.9    43.0    -0.0\n",
      "v_f      |   -4.55    0.67  -13.05 |    2.15    1.25    3.10 |  -10.08   -4.03  -19.49 |    0.05    3.91   -1.27\n",
      "vr_f     |     3.4 |     3.6 |     0.8 |    55.8\n",
      "r_i      |   968.7    51.2  2348.7 |   592.7   558.7    27.7 |     1.2  -996.0  2300.3 |  1992.8   999.8  2399.8\n",
      "v_i      |  -40.31   -0.08  -79.39 |   17.25   17.55    5.71 |  -69.19  -29.48  -89.95 |  -10.03   29.96  -70.10\n",
      "norm_rf  |    21.6 |     9.9 |     1.8 |    51.7\n",
      "norm_vf  |   13.98 |    3.41 |    1.76 |   20.41\n",
      "thrust   |    1257       5    9112 |    2952    2797    2206 |  -10257  -14349   -5599 |   14990   14137   15000\n",
      "norm_thrust |    9945 |    2665 |    2444 |   15000\n",
      "fuel     |     263 |      11 |     239 |     299\n",
      "rewards  |  -34.11 |    9.95 |  -92.78 |  -18.81\n",
      "fuel_rewards |   -9.05 |    0.39 |  -10.27 |   -8.23\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.46 |    0.61 |    3.57\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.32 |    8.06 |    4.01 |   46.67\n",
      "tracking_rewards |  -25.05 |    9.70 |  -82.91 |  -10.53\n",
      "steps    |     272 |      19 |     232 |     331\n",
      "***** Episode 47740, Mean R = -36.4  Std R = 10.4  Min R = -58.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000585\n",
      "PolicyEntropy: -3.73\n",
      "PolicyLoss: -0.00257\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00302\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3961   2.8176  13.2717  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 47771, Mean R = -33.8  Std R = 9.1  Min R = -64.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -3.73\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00257\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9492   2.0384  11.9653  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 47802, Mean R = -33.9  Std R = 7.4  Min R = -52.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.00067\n",
      "PolicyEntropy: -3.73\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0813\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6634   4.3092  17.9103  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 47833, Mean R = -32.9  Std R = 7.8  Min R = -61.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000986\n",
      "PolicyEntropy: -3.73\n",
      "PolicyLoss: -0.00342\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00341\n",
      "Variance: 0.0813\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7715   1.7865   8.8095  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 47864, Mean R = -34.6  Std R = 12.2  Min R = -95.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.939\n",
      "KL: 0.00088\n",
      "PolicyEntropy: -3.73\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 8.50e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00256\n",
      "Variance: 0.0813\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.2086   6.2015  24.5407  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 47895, Mean R = -32.0  Std R = 8.3  Min R = -55.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000815\n",
      "PolicyEntropy: -3.73\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00336\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.7621   4.1838  17.7064  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 47926, Mean R = -31.6  Std R = 7.9  Min R = -60.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000834\n",
      "PolicyEntropy: -3.74\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.21e+07\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0812\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2870   3.3124  15.9017  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0014   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 47957, Mean R = -34.3  Std R = 10.8  Min R = -65.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000763\n",
      "PolicyEntropy: -3.74\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.0032\n",
      "Variance: 0.0812\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5829   2.6941  13.6589  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 47988, Mean R = -32.8  Std R = 9.9  Min R = -61.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000932\n",
      "PolicyEntropy: -3.74\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00313\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4955   3.0671  12.0369  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 48019, Mean R = -37.4  Std R = 13.8  Min R = -74.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000852\n",
      "PolicyEntropy: -3.75\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00225\n",
      "Variance: 0.081\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7461   1.5690   9.6026  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0041   0.0023   0.0095   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1550    ET =    233.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.0     5.0    -0.3 |    15.6    16.6     0.2 |   -28.6   -41.9    -0.9 |    48.7    47.7    -0.0\n",
      "v_f      |   -4.66    0.67  -12.94 |    2.01    1.44    3.12 |  -10.37   -4.59  -20.67 |    0.44    7.28   -2.73\n",
      "vr_f     |     3.0 |     1.7 |     1.1 |    21.5\n",
      "r_i      |  1023.2    -0.9  2352.0 |   577.2   563.7    28.4 |     2.7  -996.2  2300.2 |  1988.4   998.3  2399.9\n",
      "v_i      |  -39.71    0.40  -79.63 |   16.76   17.43    5.64 |  -69.88  -29.97  -89.91 |  -10.02   29.55  -70.16\n",
      "norm_rf  |    22.4 |    10.2 |     0.8 |    54.4\n",
      "norm_vf  |   13.92 |    3.43 |    2.98 |   21.24\n",
      "thrust   |    1206      14    9148 |    2710    2810    2225 |  -10584  -14443   -5686 |   14991   13948   15000\n",
      "norm_thrust |    9918 |    2638 |    2408 |   15000\n",
      "fuel     |     263 |      12 |     237 |     302\n",
      "rewards  |  -33.52 |    9.81 |  -95.01 |  -17.34\n",
      "fuel_rewards |   -9.05 |    0.41 |  -10.39 |   -8.14\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.54 |    0.54 |    4.00\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.98 |    8.45 |    4.26 |   49.40\n",
      "tracking_rewards |  -24.47 |    9.56 |  -84.92 |   -8.91\n",
      "steps    |     273 |      20 |     229 |     332\n",
      "***** Episode 48050, Mean R = -32.0  Std R = 7.3  Min R = -49.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000607\n",
      "PolicyEntropy: -3.75\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00334\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6571   5.7603  24.6924  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 48081, Mean R = -32.5  Std R = 7.8  Min R = -49.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000723\n",
      "PolicyEntropy: -3.75\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3759   1.3033   8.6861  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 48112, Mean R = -36.1  Std R = 11.0  Min R = -85.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000755\n",
      "PolicyEntropy: -3.75\n",
      "PolicyLoss: -0.00377\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00333\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4661   2.4214  13.2792  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 48143, Mean R = -34.0  Std R = 11.2  Min R = -69.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000647\n",
      "PolicyEntropy: -3.75\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.0814\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2750   3.1156  18.2498  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 48174, Mean R = -39.8  Std R = 16.7  Min R = -96.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000675\n",
      "PolicyEntropy: -3.75\n",
      "PolicyLoss: -0.0025\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00311\n",
      "Variance: 0.0815\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.8297   7.0252  27.5916  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 48205, Mean R = -31.7  Std R = 7.2  Min R = -51.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.959\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000786\n",
      "PolicyEntropy: -3.76\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0812\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.9455   4.7493  18.0754  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 48236, Mean R = -33.5  Std R = 8.2  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000698\n",
      "PolicyEntropy: -3.77\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.18e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00291\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6776   2.6193  15.1238  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 48267, Mean R = -35.5  Std R = 7.3  Min R = -54.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000925\n",
      "PolicyEntropy: -3.77\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00278\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9259   1.7376  11.0195  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 48298, Mean R = -32.2  Std R = 8.6  Min R = -56.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000587\n",
      "PolicyEntropy: -3.77\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.22e+07\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.081\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4263   1.7211   8.5752  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0050   0.0027   0.0103   1.6645   0.7971   0.5555\n",
      "***** Episode 48329, Mean R = -39.4  Std R = 19.0  Min R = -128.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000633\n",
      "PolicyEntropy: -3.76\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00346\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5637   4.1535  15.7877  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1560    ET =    230.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.8     5.0    -0.3 |    17.3    18.0     0.2 |   -37.1   -50.2    -0.9 |    51.6    49.9    -0.0\n",
      "v_f      |   -4.85    0.51  -13.21 |    2.32    1.56    3.11 |  -11.76   -3.07  -21.21 |    1.18    8.06   -2.48\n",
      "vr_f     |     3.0 |     1.9 |     1.3 |    28.7\n",
      "r_i      |   981.3     8.2  2353.1 |   591.0   571.6    28.2 |     0.1  -992.8  2301.7 |  1998.1   997.5  2399.8\n",
      "v_i      |  -39.98    1.35  -80.14 |   18.12   17.20    5.54 |  -69.95  -29.69  -89.95 |  -10.28   29.95  -70.06\n",
      "norm_rf  |    23.7 |    11.5 |     0.6 |    61.7\n",
      "norm_vf  |   14.27 |    3.49 |    2.93 |   22.69\n",
      "thrust   |    1209     -32    9191 |    2959    2855    2237 |  -10584  -14187   -5636 |   14989   14323   14999\n",
      "norm_thrust |   10033 |    2680 |    2000 |   15000\n",
      "fuel     |     263 |      13 |     240 |     322\n",
      "rewards  |  -35.15 |   12.07 | -128.74 |  -17.10\n",
      "fuel_rewards |   -9.05 |    0.43 |  -11.09 |   -8.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.47 |    0.04 |    3.37\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.29 |    9.68 |    5.96 |   56.75\n",
      "tracking_rewards |  -26.10 |   11.75 | -117.65 |   -8.62\n",
      "steps    |     270 |      19 |     231 |     320\n",
      "***** Episode 48360, Mean R = -36.7  Std R = 13.7  Min R = -89.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000852\n",
      "PolicyEntropy: -3.76\n",
      "PolicyLoss: -0.00198\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00306\n",
      "Variance: 0.081\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  15.6400   7.6689  29.8749  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 48391, Mean R = -33.1  Std R = 8.9  Min R = -64.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000785\n",
      "PolicyEntropy: -3.76\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00302\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3418   3.0092  15.3124  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 48422, Mean R = -32.3  Std R = 9.6  Min R = -65.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000793\n",
      "PolicyEntropy: -3.76\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0811\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9107   2.8299  10.0584  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 48453, Mean R = -33.8  Std R = 8.7  Min R = -54.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.952\n",
      "KL: 0.000709\n",
      "PolicyEntropy: -3.76\n",
      "PolicyLoss: -0.00307\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00355\n",
      "Variance: 0.081\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7593   3.5029  14.6032  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0003   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 48484, Mean R = -33.8  Std R = 9.0  Min R = -57.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00089\n",
      "PolicyEntropy: -3.76\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.0809\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.7922   4.2774  18.0849  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 48515, Mean R = -32.5  Std R = 8.9  Min R = -69.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000877\n",
      "PolicyEntropy: -3.77\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00307\n",
      "Variance: 0.0808\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6875   2.2572  10.5056  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0014   0.0052   1.6645   0.7971   0.5555\n",
      "***** Episode 48546, Mean R = -35.4  Std R = 11.1  Min R = -67.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000764\n",
      "PolicyEntropy: -3.77\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.0807\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.8583   5.4111  25.1009  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 48577, Mean R = -32.7  Std R = 9.2  Min R = -52.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000761\n",
      "PolicyEntropy: -3.77\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.0032\n",
      "Variance: 0.0805\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0450   3.2530  17.0461  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 48608, Mean R = -35.4  Std R = 7.8  Min R = -59.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000603\n",
      "PolicyEntropy: -3.77\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00319\n",
      "Variance: 0.0803\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3159   2.3320  11.9851  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 48639, Mean R = -31.4  Std R = 6.4  Min R = -46.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00059\n",
      "PolicyEntropy: -3.78\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00269\n",
      "Variance: 0.0803\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6519   2.3249  12.0394  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1570    ET =    228.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     7.1     5.7    -0.3 |    16.7    17.6     0.2 |   -32.4   -46.0    -0.9 |    55.7    49.3    -0.0\n",
      "v_f      |   -4.77    0.67  -13.07 |    2.16    1.49    3.36 |  -10.75   -4.22  -20.88 |   -0.42    7.44   -2.58\n",
      "vr_f     |     2.9 |     1.2 |     1.4 |    10.9\n",
      "r_i      |   973.9   -13.3  2350.2 |   573.5   596.5    28.2 |     3.1  -998.2  2300.1 |  1991.8   999.6  2399.4\n",
      "v_i      |  -38.64    1.06  -79.66 |   17.07   16.99    5.75 |  -69.27  -29.59  -89.97 |  -10.35   29.97  -70.15\n",
      "norm_rf  |    23.6 |    10.7 |     1.2 |    64.8\n",
      "norm_vf  |   14.08 |    3.73 |    2.68 |   22.51\n",
      "thrust   |    1165     -33    9161 |    2712    2883    2205 |  -11566  -13959   -5865 |   14996   14221   14998\n",
      "norm_thrust |    9948 |    2617 |    2000 |   15000\n",
      "fuel     |     261 |      12 |     235 |     307\n",
      "rewards  |  -33.28 |    9.06 |  -69.86 |  -17.88\n",
      "fuel_rewards |   -8.97 |    0.40 |  -10.56 |   -8.08\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.47 |    0.52 |    0.60 |    4.43\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.88 |    9.28 |    4.10 |   59.81\n",
      "tracking_rewards |  -24.31 |    8.80 |  -60.43 |   -9.42\n",
      "steps    |     270 |      18 |     230 |     335\n",
      "***** Episode 48670, Mean R = -32.4  Std R = 9.2  Min R = -53.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00084\n",
      "PolicyEntropy: -3.79\n",
      "PolicyLoss: -0.00381\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.23e+07\n",
      "ValFuncLoss: 0.00292\n",
      "Variance: 0.0801\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9071   3.7606  19.9379  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0002   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 48701, Mean R = -33.7  Std R = 7.4  Min R = -57.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000957\n",
      "PolicyEntropy: -3.79\n",
      "PolicyLoss: -0.00365\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.0797\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5213   1.5149   9.4143  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 48732, Mean R = -32.8  Std R = 11.1  Min R = -69.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000918\n",
      "PolicyEntropy: -3.79\n",
      "PolicyLoss: -0.00372\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00319\n",
      "Variance: 0.0796\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3726   2.1513   9.5372  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 48763, Mean R = -33.1  Std R = 10.4  Min R = -82.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.943\n",
      "KL: 0.000926\n",
      "PolicyEntropy: -3.79\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0796\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1394   1.9334  11.8799  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 48794, Mean R = -32.1  Std R = 7.4  Min R = -51.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.00083\n",
      "PolicyEntropy: -3.79\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00317\n",
      "Variance: 0.0794\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0407   1.5258   8.2155  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 48825, Mean R = -34.1  Std R = 8.5  Min R = -54.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -3.79\n",
      "PolicyLoss: -0.00337\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00361\n",
      "Variance: 0.0793\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4726   1.5639   8.6407  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 48856, Mean R = -34.1  Std R = 14.3  Min R = -100.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000674\n",
      "PolicyEntropy: -3.79\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.0793\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1193   3.7550  20.4478  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 48887, Mean R = -35.5  Std R = 12.7  Min R = -68.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000679\n",
      "PolicyEntropy: -3.8\n",
      "PolicyLoss: -0.00365\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0792\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7273   1.0121   7.0319  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0015   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 48918, Mean R = -31.9  Std R = 11.3  Min R = -64.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000603\n",
      "PolicyEntropy: -3.8\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.0791\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2875   2.8933  14.7094  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 48949, Mean R = -35.7  Std R = 11.9  Min R = -69.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -3.8\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.0791\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9088   3.9882  17.8378  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0049   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1580    ET =    234.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.9     1.6    -0.3 |    15.8    16.7     0.2 |   -30.9   -51.2    -1.0 |    42.3    44.2    -0.0\n",
      "v_f      |   -4.58    0.79  -13.06 |    2.14    1.69    3.25 |  -10.78   -3.50  -22.16 |    0.78    7.90   -3.90\n",
      "vr_f     |     3.1 |     1.7 |     1.2 |    22.1\n",
      "r_i      |   939.1   -18.5  2351.8 |   580.1   586.0    27.7 |     4.0  -996.0  2300.7 |  1999.9   997.9  2400.0\n",
      "v_i      |  -39.61    0.33  -79.64 |   16.92   17.53    5.70 |  -69.77  -29.94  -89.93 |  -10.02   29.47  -70.06\n",
      "norm_rf  |    21.9 |     9.9 |     1.1 |    53.7\n",
      "norm_vf  |   14.04 |    3.60 |    3.99 |   23.82\n",
      "thrust   |    1244      34    9160 |    2830    2886    2204 |  -10209  -14311   -6306 |   14992   14205   14999\n",
      "norm_thrust |    9984 |    2640 |    2000 |   15000\n",
      "fuel     |     262 |      12 |     235 |     306\n",
      "rewards  |  -33.80 |   10.82 | -100.50 |  -16.30\n",
      "fuel_rewards |   -9.02 |    0.41 |  -10.49 |   -8.10\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.51 |    0.63 |    3.53\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.47 |    8.27 |    4.49 |   48.71\n",
      "tracking_rewards |  -24.78 |   10.56 |  -90.70 |   -7.75\n",
      "steps    |     270 |      19 |     229 |     329\n",
      "***** Episode 48980, Mean R = -35.0  Std R = 10.3  Min R = -57.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -3.81\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.0029\n",
      "Variance: 0.0789\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0039   1.8103   9.4804  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 49011, Mean R = -30.7  Std R = 6.7  Min R = -54.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000886\n",
      "PolicyEntropy: -3.81\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.24e+07\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.0787\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4775   1.6706  10.1405  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 49042, Mean R = -33.7  Std R = 9.8  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000773\n",
      "PolicyEntropy: -3.81\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00283\n",
      "Variance: 0.0786\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3454   1.2041   7.5657  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0012   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 49073, Mean R = -36.9  Std R = 10.3  Min R = -64.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000723\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.0785\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5418   2.4998  15.6063  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 49104, Mean R = -34.3  Std R = 8.6  Min R = -54.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000992\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.0029\n",
      "Variance: 0.0785\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3800   2.5152  10.5775  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 49135, Mean R = -31.9  Std R = 11.0  Min R = -80.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000958\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00377\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00285\n",
      "Variance: 0.0785\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2910   3.7268  16.2666  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 49166, Mean R = -34.0  Std R = 11.1  Min R = -73.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000708\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00333\n",
      "Variance: 0.0784\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6163   2.4712  10.7258  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 49197, Mean R = -32.2  Std R = 10.4  Min R = -74.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000617\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0784\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9608   1.1907   6.5153  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0017   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 49228, Mean R = -30.0  Std R = 6.4  Min R = -45.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000513\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.29e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00354\n",
      "Variance: 0.0786\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1906   3.4380  18.1581  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0016   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 49259, Mean R = -34.9  Std R = 8.3  Min R = -53.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000735\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0784\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7960   1.6862  10.0271  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1590    ET =    238.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.5     5.6    -0.3 |    16.0    15.7     0.2 |   -31.3   -47.6    -0.9 |    47.1    39.7    -0.0\n",
      "v_f      |   -4.74    0.67  -13.17 |    2.09    1.40    3.16 |  -10.71   -3.85  -19.73 |    0.43    7.34   -1.40\n",
      "vr_f     |     3.0 |     1.3 |     0.9 |    15.7\n",
      "r_i      |  1008.8    33.5  2348.6 |   592.5   552.8    29.1 |     1.5  -991.5  2301.0 |  1997.0   983.4  2399.4\n",
      "v_i      |  -39.56    0.61  -80.64 |   17.06   16.44    5.74 |  -69.79  -29.95  -89.96 |  -10.18   29.47  -70.02\n",
      "norm_rf  |    22.7 |    10.6 |     0.4 |    50.7\n",
      "norm_vf  |   14.16 |    3.50 |    2.53 |   21.37\n",
      "thrust   |    1229      10    9190 |    2752    2768    2202 |  -10417  -14091   -5983 |   15000   13966   15000\n",
      "norm_thrust |    9960 |    2616 |    2608 |   15000\n",
      "fuel     |     263 |      12 |     240 |     311\n",
      "rewards  |  -33.27 |    9.82 |  -80.79 |  -18.53\n",
      "fuel_rewards |   -9.02 |    0.41 |  -10.70 |   -8.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.52 |    0.44 |    3.97\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.27 |    8.79 |    5.30 |   45.74\n",
      "tracking_rewards |  -24.25 |    9.55 |  -70.58 |   -9.91\n",
      "steps    |     271 |      18 |     229 |     320\n",
      "***** Episode 49290, Mean R = -34.3  Std R = 11.9  Min R = -78.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000657\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.0782\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9556   1.7815  10.4185  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 49321, Mean R = -35.8  Std R = 10.3  Min R = -62.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000635\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00246\n",
      "Variance: 0.0781\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5136   1.9876   9.4624  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 49352, Mean R = -33.1  Std R = 8.2  Min R = -51.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000617\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.0782\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8588   2.8325  12.9991  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0005   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 49383, Mean R = -33.2  Std R = 10.3  Min R = -64.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.25e+07\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.0782\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1723   2.4331  13.5116  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0016   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 49414, Mean R = -36.2  Std R = 12.8  Min R = -78.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.0007\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.0781\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8066   4.0209  19.5241  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0016   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 49445, Mean R = -34.3  Std R = 10.9  Min R = -71.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000776\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0782\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.9261   4.7387  21.1307  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 49476, Mean R = -30.9  Std R = 9.1  Min R = -62.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000998\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00241\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0784\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.0120   5.1651  27.3051  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 49507, Mean R = -33.8  Std R = 11.0  Min R = -74.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.71e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.0785\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7640   3.1288  15.1463  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 49538, Mean R = -33.2  Std R = 14.9  Min R = -96.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.00065\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00296\n",
      "Variance: 0.0785\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.7043   5.4716  19.7505  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 49569, Mean R = -36.1  Std R = 16.5  Min R = -110.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00128\n",
      "PolicyEntropy: -3.82\n",
      "PolicyLoss: -0.00176\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00331\n",
      "Variance: 0.0784\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.6997   6.9917  31.3700  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1600    ET =    231.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.0     5.5    -0.3 |    16.0    17.4     0.2 |   -30.5   -59.6    -1.0 |    48.4    45.9    -0.0\n",
      "v_f      |   -4.72    0.78  -13.26 |    2.00    1.53    3.19 |  -10.16   -4.13  -20.03 |    0.53    7.15   -2.49\n",
      "vr_f     |     3.0 |     1.4 |     0.8 |    14.9\n",
      "r_i      |  1001.9    24.9  2350.3 |   567.7   579.1    27.1 |     9.3  -997.2  2300.5 |  1997.5   999.9  2399.9\n",
      "v_i      |  -41.36   -1.67  -79.75 |   17.02   17.27    5.52 |  -69.89  -29.98  -89.96 |  -10.00   29.84  -70.02\n",
      "norm_rf  |    23.2 |    10.7 |     1.7 |    59.7\n",
      "norm_vf  |   14.25 |    3.49 |    3.23 |   20.55\n",
      "thrust   |    1275      90    9116 |    2750    2859    2185 |   -9713  -14125   -5798 |   14996   14071   15000\n",
      "norm_thrust |    9915 |    2636 |    2000 |   15000\n",
      "fuel     |     262 |      12 |     234 |     306\n",
      "rewards  |  -33.88 |   11.66 | -110.21 |  -16.58\n",
      "fuel_rewards |   -9.02 |    0.43 |  -10.51 |   -8.05\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.46 |    0.34 |    3.92\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.71 |    8.99 |    2.95 |   54.68\n",
      "tracking_rewards |  -24.86 |   11.35 |  -99.70 |   -8.39\n",
      "steps    |     272 |      18 |     234 |     323\n",
      "***** Episode 49600, Mean R = -32.2  Std R = 8.4  Min R = -59.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.0008\n",
      "PolicyEntropy: -3.83\n",
      "PolicyLoss: -0.00366\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00351\n",
      "Variance: 0.0781\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2405   2.2925  12.1594  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 49631, Mean R = -32.7  Std R = 6.8  Min R = -51.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000662\n",
      "PolicyEntropy: -3.83\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.0778\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.4589   5.2180  22.3259  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 49662, Mean R = -30.9  Std R = 9.1  Min R = -70.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000763\n",
      "PolicyEntropy: -3.84\n",
      "PolicyLoss: -0.00248\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.0776\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9461   4.2180  20.6474  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 49693, Mean R = -33.1  Std R = 8.6  Min R = -51.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000906\n",
      "PolicyEntropy: -3.84\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00247\n",
      "Variance: 0.0775\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0570   2.2075   9.5031  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 49724, Mean R = -30.9  Std R = 7.2  Min R = -48.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000832\n",
      "PolicyEntropy: -3.83\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.0776\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  22.1386  13.6370  47.5304  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 49755, Mean R = -32.7  Std R = 8.5  Min R = -63.1\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00415\n",
      "PolicyEntropy: -3.83\n",
      "PolicyLoss: 0.00717\n",
      "Steps: 8.2e+03\n",
      "TotalSteps: 1.26e+07\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.0776\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1672   3.7581  15.7227  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 49786, Mean R = -38.8  Std R = 21.9  Min R = -115.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000319\n",
      "PolicyEntropy: -3.84\n",
      "PolicyLoss: -0.00193\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00321\n",
      "Variance: 0.0774\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7044   3.3829  15.9313  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 49817, Mean R = -33.4  Std R = 7.1  Min R = -50.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000844\n",
      "PolicyEntropy: -3.84\n",
      "PolicyLoss: -0.00375\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0773\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8505   3.1693  19.5354  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 49848, Mean R = -31.3  Std R = 8.1  Min R = -58.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -3.84\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.0774\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6159   1.4516   8.4894  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 49879, Mean R = -30.0  Std R = 7.0  Min R = -49.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000606\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.0773\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7158   3.5817  15.7556  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1610    ET =    225.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.0     7.2    -0.3 |    15.4    16.7     0.2 |   -26.4   -62.9    -0.9 |    46.5    42.8    -0.0\n",
      "v_f      |   -4.97    0.60  -13.92 |    2.00    1.56    3.01 |  -10.22   -4.16  -21.18 |   -0.01    6.69   -4.65\n",
      "vr_f     |     3.0 |     1.4 |     1.2 |    19.0\n",
      "r_i      |  1014.5    96.3  2349.1 |   548.2   572.7    29.2 |    20.0  -989.7  2300.6 |  1993.4   993.8  2399.9\n",
      "v_i      |  -40.07   -0.08  -80.18 |   17.40   16.48    5.68 |  -69.74  -29.38  -89.86 |  -10.18   29.83  -70.08\n",
      "norm_rf  |    23.0 |    11.0 |     1.2 |    63.1\n",
      "norm_vf  |   14.94 |    3.33 |    5.28 |   22.41\n",
      "thrust   |    1230      18    9139 |    2641    2793    2214 |   -9915  -14387   -5374 |   14962   14130   15000\n",
      "norm_thrust |    9893 |    2617 |    2000 |   15000\n",
      "fuel     |     259 |      11 |     235 |     308\n",
      "rewards  |  -32.76 |   10.45 | -115.45 |  -17.33\n",
      "fuel_rewards |   -8.91 |    0.39 |  -10.60 |   -8.09\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.47 |    0.53 |    0.24 |    3.76\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.86 |    8.95 |    6.91 |   58.10\n",
      "tracking_rewards |  -23.84 |   10.19 | -105.02 |   -8.58\n",
      "steps    |     270 |      19 |     229 |     332\n",
      "***** Episode 49910, Mean R = -33.7  Std R = 8.2  Min R = -53.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000653\n",
      "PolicyEntropy: -3.84\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0773\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.4517   5.9010  21.7983  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 49941, Mean R = -36.7  Std R = 10.7  Min R = -64.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000659\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.0771\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4455   3.3842  15.6382  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 49972, Mean R = -33.5  Std R = 7.9  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000685\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.0767\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8994   3.6159  15.4712  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 50003, Mean R = -33.7  Std R = 9.7  Min R = -63.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000722\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00264\n",
      "Variance: 0.0767\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7649   2.0820   9.2239  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0023   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 50034, Mean R = -38.6  Std R = 19.2  Min R = -133.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00288\n",
      "Variance: 0.0765\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8518   1.5861  10.1989  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 50065, Mean R = -35.1  Std R = 11.0  Min R = -67.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000778\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00257\n",
      "Variance: 0.0765\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3894   2.8646  17.1900  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0020   0.0077   1.6645   0.7971   0.5555\n",
      "***** Episode 50096, Mean R = -33.5  Std R = 7.6  Min R = -51.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000976\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.19e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.003\n",
      "Variance: 0.0765\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0267   2.7211  17.6285  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 50127, Mean R = -35.0  Std R = 9.7  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.0008\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.27e+07\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.0764\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.5757   3.3775  16.7993  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 50158, Mean R = -34.2  Std R = 12.9  Min R = -92.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000785\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00314\n",
      "Variance: 0.0763\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5842   1.5596   8.8283  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 50189, Mean R = -31.6  Std R = 8.6  Min R = -60.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000733\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.0762\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0352   1.5991   9.0108  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1620    ET =    239.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.1     3.1    -0.3 |    16.3    17.1     0.2 |   -29.9   -59.2    -0.9 |    52.1    44.4    -0.0\n",
      "v_f      |   -5.00    0.60  -13.81 |    2.28    1.80    3.04 |  -11.23   -4.89  -20.72 |    1.03    6.79   -2.41\n",
      "vr_f     |     3.0 |     2.0 |     1.5 |    26.6\n",
      "r_i      |  1031.2    -9.1  2352.8 |   613.6   586.6    29.6 |     4.3  -999.7  2300.2 |  1995.0   992.5  2400.0\n",
      "v_i      |  -40.84   -0.60  -80.44 |   18.09   17.04    5.81 |  -69.78  -29.95  -89.97 |  -10.20   29.67  -70.20\n",
      "norm_rf  |    23.5 |    11.0 |     1.5 |    59.2\n",
      "norm_vf  |   14.90 |    3.41 |    2.43 |   21.79\n",
      "thrust   |    1245      41    9157 |    2860    2860    2245 |  -10104  -14277   -5955 |   14995   13929   15000\n",
      "norm_thrust |    9979 |    2687 |    2000 |   15000\n",
      "fuel     |     262 |      13 |     237 |     334\n",
      "rewards  |  -34.77 |   12.00 | -133.64 |  -18.26\n",
      "fuel_rewards |   -9.01 |    0.43 |  -11.48 |   -8.17\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.52 |    0.05 |    3.72\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.17 |    9.11 |    4.27 |   54.23\n",
      "tracking_rewards |  -25.76 |   11.69 | -122.16 |   -9.63\n",
      "steps    |     270 |      21 |     233 |     327\n",
      "***** Episode 50220, Mean R = -35.5  Std R = 15.8  Min R = -108.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.988\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000667\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00331\n",
      "Variance: 0.0761\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7042   3.7307  15.0965  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 50251, Mean R = -32.9  Std R = 8.8  Min R = -61.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000583\n",
      "PolicyEntropy: -3.85\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00287\n",
      "Variance: 0.0759\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4291   3.7030  19.3926  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 50282, Mean R = -33.2  Std R = 9.5  Min R = -60.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000863\n",
      "PolicyEntropy: -3.86\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.0756\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3565   2.9350  14.7229  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 50313, Mean R = -31.9  Std R = 9.4  Min R = -66.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.0012\n",
      "PolicyEntropy: -3.86\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00319\n",
      "Variance: 0.0754\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3931   2.0357  11.1403  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 50344, Mean R = -34.3  Std R = 12.4  Min R = -94.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.937\n",
      "KL: 0.000826\n",
      "PolicyEntropy: -3.86\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00316\n",
      "Variance: 0.0753\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7946   3.1603  14.6441  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 50375, Mean R = -34.3  Std R = 11.7  Min R = -81.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000694\n",
      "PolicyEntropy: -3.87\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00305\n",
      "Variance: 0.0754\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5220   2.6961  12.3212  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 50406, Mean R = -34.3  Std R = 14.4  Min R = -81.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000877\n",
      "PolicyEntropy: -3.87\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00313\n",
      "Variance: 0.0754\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4736   1.8657  10.2599  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 50437, Mean R = -34.9  Std R = 9.7  Min R = -59.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00059\n",
      "PolicyEntropy: -3.87\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00284\n",
      "Variance: 0.0754\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8603   2.3082  11.9047  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 50468, Mean R = -34.9  Std R = 8.9  Min R = -57.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000771\n",
      "PolicyEntropy: -3.88\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.12e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00306\n",
      "Variance: 0.0753\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3269   3.3422  17.5355  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 50499, Mean R = -34.5  Std R = 12.0  Min R = -70.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000935\n",
      "PolicyEntropy: -3.88\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.28e+07\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0752\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9893   2.5938  14.0277  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1630    ET =    232.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.8     0.7    -0.3 |    14.7    17.0     0.2 |   -30.4   -42.3    -0.9 |    45.6    39.2    -0.0\n",
      "v_f      |   -4.93    0.66  -13.40 |    2.23    1.59    2.91 |  -11.35   -4.02  -21.64 |   -0.61    6.82   -3.93\n",
      "vr_f     |     3.0 |     1.5 |     1.4 |    14.6\n",
      "r_i      |  1020.0   -19.6  2347.3 |   580.0   599.7    27.8 |     2.6  -997.6  2300.3 |  1997.9   993.8  2399.3\n",
      "v_i      |  -38.22    2.48  -80.27 |   17.15   17.55    5.68 |  -69.71  -29.71  -89.95 |  -10.14   29.96  -70.04\n",
      "norm_rf  |    21.8 |    10.3 |     2.3 |    50.3\n",
      "norm_vf  |   14.47 |    3.32 |    4.82 |   24.44\n",
      "thrust   |    1167     -53    9144 |    2717    2889    2225 |   -9635  -14366   -5065 |   14987   13895   15000\n",
      "norm_thrust |    9931 |    2651 |    2000 |   15000\n",
      "fuel     |     263 |      12 |     238 |     304\n",
      "rewards  |  -33.79 |   10.71 |  -94.22 |  -17.82\n",
      "fuel_rewards |   -9.03 |    0.42 |  -10.45 |   -8.19\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.53 |    0.43 |    3.84\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.68 |    8.52 |    6.25 |   45.27\n",
      "tracking_rewards |  -24.77 |   10.42 |  -83.98 |   -9.34\n",
      "steps    |     272 |      19 |     230 |     326\n",
      "***** Episode 50530, Mean R = -32.8  Std R = 8.1  Min R = -58.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.954\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000744\n",
      "PolicyEntropy: -3.88\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00305\n",
      "Variance: 0.0753\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8251   2.9190  15.6838  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0012   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 50561, Mean R = -34.2  Std R = 9.4  Min R = -71.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000903\n",
      "PolicyEntropy: -3.89\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00315\n",
      "Variance: 0.0752\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.9472   4.2159  18.5575  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 50592, Mean R = -32.4  Std R = 6.5  Min R = -46.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000915\n",
      "PolicyEntropy: -3.89\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.075\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6290   2.3910  12.2999  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 50623, Mean R = -34.5  Std R = 7.4  Min R = -55.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00107\n",
      "PolicyEntropy: -3.89\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00332\n",
      "Variance: 0.0751\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5910   2.4243  12.2043  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 50654, Mean R = -30.7  Std R = 9.2  Min R = -65.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000496\n",
      "PolicyEntropy: -3.9\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00316\n",
      "Variance: 0.0753\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4387   2.5651  12.9591  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 50685, Mean R = -35.1  Std R = 12.6  Min R = -86.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.00178\n",
      "PolicyEntropy: -3.9\n",
      "PolicyLoss: -0.00442\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00337\n",
      "Variance: 0.0751\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2209   3.7276  18.5551  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 50716, Mean R = -32.8  Std R = 6.5  Min R = -46.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00184\n",
      "PolicyEntropy: -3.9\n",
      "PolicyLoss: -0.00429\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00301\n",
      "Variance: 0.0749\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4275   1.6351   9.0681  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 50747, Mean R = -31.9  Std R = 8.3  Min R = -58.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00141\n",
      "PolicyEntropy: -3.91\n",
      "PolicyLoss: -0.00395\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00327\n",
      "Variance: 0.0747\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6720   2.7716  14.2790  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 50778, Mean R = -31.0  Std R = 7.0  Min R = -51.3\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00161\n",
      "PolicyEntropy: -3.91\n",
      "PolicyLoss: -0.00426\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.0747\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7016   3.9267  15.1245  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 50809, Mean R = -33.2  Std R = 9.1  Min R = -61.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00181\n",
      "PolicyEntropy: -3.92\n",
      "PolicyLoss: -0.0047\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0747\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4167   1.3254   7.8706  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0014   0.0053   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1640    ET =    231.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.0     1.5    -0.3 |    14.7    15.0     0.2 |   -24.5   -40.9    -0.8 |    46.0    47.2    -0.0\n",
      "v_f      |   -4.68    0.62  -12.66 |    2.03    1.44    2.97 |  -11.47   -3.81  -17.99 |    0.25    5.17   -2.04\n",
      "vr_f     |     3.0 |     1.8 |     0.6 |    20.8\n",
      "r_i      |  1033.0   -33.5  2349.2 |   574.2   560.2    29.2 |     2.4  -998.9  2300.4 |  1990.2   996.2  2399.5\n",
      "v_i      |  -40.67   -0.96  -79.66 |   16.92   17.89    5.71 |  -68.90  -29.77  -89.94 |  -10.14   29.66  -70.03\n",
      "norm_rf  |    20.3 |     9.8 |     2.0 |    52.5\n",
      "norm_vf  |   13.65 |    3.34 |    4.06 |   19.99\n",
      "thrust   |    1233      54    9131 |    2673    2861    2158 |  -10339  -14201   -6226 |   14999   13688   15000\n",
      "norm_thrust |    9907 |    2596 |    2921 |   15000\n",
      "fuel     |     263 |      12 |     241 |     308\n",
      "rewards  |  -32.77 |    8.65 |  -86.63 |  -18.92\n",
      "fuel_rewards |   -9.04 |    0.41 |  -10.59 |   -8.29\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.55 |    0.52 |    3.51\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.19 |    7.95 |    3.73 |   47.52\n",
      "tracking_rewards |  -23.74 |    8.38 |  -76.03 |  -10.43\n",
      "steps    |     273 |      19 |     233 |     325\n",
      "***** Episode 50840, Mean R = -31.9  Std R = 7.5  Min R = -50.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00148\n",
      "PolicyEntropy: -3.92\n",
      "PolicyLoss: -0.00458\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0745\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0233   2.7105  12.6240  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 50871, Mean R = -34.6  Std R = 9.4  Min R = -56.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.00149\n",
      "PolicyEntropy: -3.93\n",
      "PolicyLoss: -0.00373\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.29e+07\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.0743\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5661   1.4977   8.0616  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 50902, Mean R = -31.4  Std R = 8.5  Min R = -62.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00187\n",
      "PolicyEntropy: -3.93\n",
      "PolicyLoss: -0.00454\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00323\n",
      "Variance: 0.0741\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1445   1.7518   7.7409  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 50933, Mean R = -31.6  Std R = 7.9  Min R = -53.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00165\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.00414\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00345\n",
      "Variance: 0.0741\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2288   4.9772  24.5471  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0017   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 50964, Mean R = -32.5  Std R = 9.2  Min R = -69.1\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00174\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.0051\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00343\n",
      "Variance: 0.0742\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2550   1.5163   7.5930  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0018   0.0071   1.6645   0.7971   0.5555\n",
      "***** Episode 50995, Mean R = -34.5  Std R = 13.4  Min R = -91.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.0016\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.00356\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00326\n",
      "Variance: 0.0743\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1650   1.7660   8.8907  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 51026, Mean R = -30.8  Std R = 6.7  Min R = -42.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00151\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.00405\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00306\n",
      "Variance: 0.0742\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0363   2.0378  11.7642  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 51057, Mean R = -31.7  Std R = 11.0  Min R = -80.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.00185\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.00488\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00241\n",
      "Variance: 0.0739\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.2142   3.1081  14.8830  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 51088, Mean R = -33.6  Std R = 9.7  Min R = -55.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00188\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.00395\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00311\n",
      "Variance: 0.0739\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9389   2.3677  11.3472  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 51119, Mean R = -33.5  Std R = 8.9  Min R = -57.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.00149\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.00373\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00293\n",
      "Variance: 0.0739\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4996   1.1279   7.5941  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1650    ET =    237.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.7     4.5    -0.3 |    15.1    16.6     0.2 |   -26.0   -47.6    -1.0 |    47.1    50.7    -0.0\n",
      "v_f      |   -4.93    0.34  -13.18 |    2.17    1.63    2.95 |  -12.51   -5.35  -20.94 |   -0.12    4.48   -4.78\n",
      "vr_f     |     2.9 |     1.2 |     1.2 |    12.1\n",
      "r_i      |  1047.5    18.3  2349.8 |   556.8   585.2    27.4 |     6.5  -990.3  2300.5 |  1980.0   987.6  2400.0\n",
      "v_i      |  -42.20    0.49  -79.71 |   17.45   16.77    5.87 |  -69.98  -29.92  -89.81 |  -10.13   29.59  -70.04\n",
      "norm_rf  |    22.4 |    10.8 |     1.7 |    54.2\n",
      "norm_vf  |   14.25 |    3.35 |    4.91 |   22.12\n",
      "thrust   |    1305     -17    9186 |    2775    2756    2157 |   -9754  -14302   -6383 |   14954   13903   14999\n",
      "norm_thrust |    9964 |    2598 |    2828 |   15000\n",
      "fuel     |     263 |      11 |     242 |     297\n",
      "rewards  |  -32.89 |    9.68 |  -91.62 |  -18.13\n",
      "fuel_rewards |   -9.05 |    0.38 |  -10.21 |   -8.31\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.36 |    0.41 |    0.64 |    2.85\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.00 |    9.09 |    4.42 |   49.21\n",
      "tracking_rewards |  -23.85 |    9.44 |  -81.69 |   -9.43\n",
      "steps    |     272 |      19 |     231 |     330\n",
      "***** Episode 51150, Mean R = -34.9  Std R = 9.5  Min R = -65.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00194\n",
      "PolicyEntropy: -3.94\n",
      "PolicyLoss: -0.00488\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00314\n",
      "Variance: 0.0737\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4854   2.1828  11.9654  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 51181, Mean R = -36.9  Std R = 14.5  Min R = -83.5\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00149\n",
      "PolicyEntropy: -3.95\n",
      "PolicyLoss: -0.00467\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00354\n",
      "Variance: 0.0736\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4912   2.8546  14.0842  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 51212, Mean R = -32.7  Std R = 10.0  Min R = -62.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.00146\n",
      "PolicyEntropy: -3.95\n",
      "PolicyLoss: -0.00463\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00304\n",
      "Variance: 0.0736\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3384   2.0244  10.3013  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 51243, Mean R = -32.4  Std R = 7.0  Min R = -55.4\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.00169\n",
      "PolicyEntropy: -3.95\n",
      "PolicyLoss: -0.00437\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.3e+07\n",
      "ValFuncLoss: 0.00292\n",
      "Variance: 0.0735\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3078   1.1596   6.1863  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0012   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 51274, Mean R = -31.5  Std R = 9.5  Min R = -74.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.925\n",
      "ExplainedVarOld: 0.873\n",
      "KL: 0.00172\n",
      "PolicyEntropy: -3.95\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00439\n",
      "Variance: 0.0738\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1473   2.5769  11.8734  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0018   0.0069   1.6645   0.7971   0.5555\n",
      "***** Episode 51305, Mean R = -31.8  Std R = 9.3  Min R = -61.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.00176\n",
      "PolicyEntropy: -3.95\n",
      "PolicyLoss: -0.00417\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00296\n",
      "Variance: 0.0738\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4631   3.0328  16.1668  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0017   0.0067   1.6645   0.7971   0.5555\n",
      "***** Episode 51336, Mean R = -33.4  Std R = 9.7  Min R = -60.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.00109\n",
      "PolicyEntropy: -3.96\n",
      "PolicyLoss: -0.00435\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00285\n",
      "Variance: 0.0737\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9067   1.7780  11.0275  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 51367, Mean R = -35.1  Std R = 14.8  Min R = -85.0\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00192\n",
      "PolicyEntropy: -3.96\n",
      "PolicyLoss: -0.00458\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0738\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0048   1.2300   6.7795  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 51398, Mean R = -33.3  Std R = 16.7  Min R = -114.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00157\n",
      "PolicyEntropy: -3.95\n",
      "PolicyLoss: -0.00413\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.0738\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0352   1.4240   8.4872  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 51429, Mean R = -32.9  Std R = 9.0  Min R = -60.8\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.00181\n",
      "PolicyEntropy: -3.95\n",
      "PolicyLoss: -0.00524\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00272\n",
      "Variance: 0.0738\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0813   1.6435   8.5619  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1660    ET =    230.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.2     1.0    -0.3 |    14.1    16.7     0.2 |   -34.0   -48.8    -0.8 |    47.1    40.8    -0.0\n",
      "v_f      |   -4.81    0.56  -13.12 |    1.93    1.57    3.02 |   -9.06   -3.71  -23.70 |    0.66    7.07   -1.59\n",
      "vr_f     |     2.9 |     1.2 |     0.2 |    10.9\n",
      "r_i      |  1052.4   -41.9  2350.3 |   580.1   576.6    29.1 |     0.9  -997.1  2301.4 |  1998.2   996.6  2399.0\n",
      "v_i      |  -40.81   -2.44  -80.15 |   17.55   17.04    5.70 |  -69.97  -29.72  -89.97 |  -10.29   29.53  -70.07\n",
      "norm_rf  |    22.1 |     9.6 |     1.6 |    50.8\n",
      "norm_vf  |   14.13 |    3.32 |    2.47 |   24.78\n",
      "thrust   |    1271     118    9128 |    2767    2744    2218 |  -10949  -14581   -6091 |   14978   14159   15000\n",
      "norm_thrust |    9904 |    2640 |    2000 |   15000\n",
      "fuel     |     263 |      12 |     237 |     306\n",
      "rewards  |  -33.48 |   11.75 | -114.75 |  -16.41\n",
      "fuel_rewards |   -9.04 |    0.42 |  -10.54 |   -8.14\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.51 |    0.14 |    3.60\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.57 |    7.98 |    4.01 |   45.82\n",
      "tracking_rewards |  -24.44 |   11.48 | -104.33 |   -7.98\n",
      "steps    |     273 |      20 |     237 |     333\n",
      "***** Episode 51460, Mean R = -34.7  Std R = 12.1  Min R = -90.9\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00153\n",
      "PolicyEntropy: -3.96\n",
      "PolicyLoss: -0.00426\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00268\n",
      "Variance: 0.0735\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4950   2.0081  12.3475  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 51491, Mean R = -31.3  Std R = 8.4  Min R = -55.6\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.00162\n",
      "PolicyEntropy: -3.97\n",
      "PolicyLoss: -0.00402\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.0028\n",
      "Variance: 0.0733\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6106   1.6943   9.7747  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 51522, Mean R = -33.0  Std R = 12.0  Min R = -91.7\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.00161\n",
      "PolicyEntropy: -3.97\n",
      "PolicyLoss: -0.00494\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.0734\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1595   2.1921  11.7515  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 51553, Mean R = -32.6  Std R = 8.0  Min R = -58.2\n",
      "Beta: 0.1\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.00163\n",
      "PolicyEntropy: -3.97\n",
      "PolicyLoss: -0.00409\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00259\n",
      "Variance: 0.0734\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2052   1.4182   8.6486  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 51584, Mean R = -32.7  Std R = 8.9  Min R = -64.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.00202\n",
      "PolicyEntropy: -3.97\n",
      "PolicyLoss: -0.00524\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00267\n",
      "Variance: 0.0732\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4634   6.0864  23.4221  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 51615, Mean R = -33.2  Std R = 11.1  Min R = -69.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000863\n",
      "PolicyEntropy: -3.98\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.31e+07\n",
      "ValFuncLoss: 0.00259\n",
      "Variance: 0.0731\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.5091   5.9383  23.9527  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 51646, Mean R = -34.2  Std R = 9.5  Min R = -60.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000726\n",
      "PolicyEntropy: -3.98\n",
      "PolicyLoss: -0.00205\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.073\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.2699   1.2160   6.9289  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 51677, Mean R = -34.7  Std R = 21.9  Min R = -142.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.927\n",
      "KL: 0.000897\n",
      "PolicyEntropy: -3.99\n",
      "PolicyLoss: -0.00177\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00417\n",
      "Variance: 0.073\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6939   1.6987   9.3746  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 51708, Mean R = -38.0  Std R = 19.0  Min R = -124.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.952\n",
      "ExplainedVarOld: 0.913\n",
      "KL: 0.000722\n",
      "PolicyEntropy: -3.99\n",
      "PolicyLoss: -0.00184\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00449\n",
      "Variance: 0.073\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.4108   5.3340  20.9459  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0016   0.0063   1.6645   0.7971   0.5555\n",
      "***** Episode 51739, Mean R = -33.6  Std R = 13.5  Min R = -69.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000723\n",
      "PolicyEntropy: -3.99\n",
      "PolicyLoss: -0.00186\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00368\n",
      "Variance: 0.0731\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.6860   6.8332  31.6210  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0047   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1670    ET =    234.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.9     2.1    -0.3 |    14.4    16.6     0.2 |   -21.0   -53.9    -0.8 |    60.5    42.2    -0.0\n",
      "v_f      |   -4.89    0.43  -13.18 |    2.03    1.56    3.12 |  -11.34   -4.45  -20.25 |   -0.92    7.44   -4.00\n",
      "vr_f     |     2.8 |     1.0 |     1.3 |     7.4\n",
      "r_i      |  1030.0   -24.1  2353.0 |   576.2   562.2    28.5 |     0.7  -996.7  2300.4 |  1991.6   995.3  2399.8\n",
      "v_i      |  -41.88   -0.07  -79.98 |   17.36   17.65    5.81 |  -69.87  -29.95  -89.94 |  -10.58   29.89  -70.06\n",
      "norm_rf  |    22.0 |    10.9 |     0.3 |    65.2\n",
      "norm_vf  |   14.22 |    3.47 |    4.81 |   22.01\n",
      "thrust   |    1278      -5    9115 |    2786    2761    2212 |  -10881  -14271   -5539 |   14995   14018   15000\n",
      "norm_thrust |    9900 |    2643 |    2000 |   15000\n",
      "fuel     |     263 |      12 |     237 |     318\n",
      "rewards  |  -33.71 |   13.07 | -142.37 |  -17.10\n",
      "fuel_rewards |   -9.03 |    0.41 |  -10.92 |   -8.13\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.49 |    0.05 |    3.64\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.80 |    9.01 |    4.32 |   60.24\n",
      "tracking_rewards |  -24.67 |   12.76 | -131.45 |   -8.52\n",
      "steps    |     273 |      18 |     235 |     329\n",
      "***** Episode 51770, Mean R = -33.7  Std R = 9.2  Min R = -62.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000645\n",
      "PolicyEntropy: -4\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.0041\n",
      "Variance: 0.0732\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0870   2.8623  14.8684  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 51801, Mean R = -34.5  Std R = 14.2  Min R = -94.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.00115\n",
      "PolicyEntropy: -4\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.13e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00371\n",
      "Variance: 0.073\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.5148   5.7164  24.9664  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 51832, Mean R = -32.9  Std R = 11.5  Min R = -87.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000977\n",
      "PolicyEntropy: -4\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 8.27e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00389\n",
      "Variance: 0.073\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8471   2.8669  13.3403  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0015   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 51863, Mean R = -34.5  Std R = 14.0  Min R = -76.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000743\n",
      "PolicyEntropy: -4.01\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00353\n",
      "Variance: 0.073\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9093   3.6072  17.9503  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 51894, Mean R = -31.5  Std R = 6.2  Min R = -44.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.96\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.00078\n",
      "PolicyEntropy: -4.01\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00392\n",
      "Variance: 0.073\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.2195   4.1288  18.4091  53.4029  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 51925, Mean R = -33.0  Std R = 11.6  Min R = -69.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -4.01\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00405\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  23.9840  13.5202  54.4472  54.4472  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 51956, Mean R = -31.1  Std R = 9.6  Min R = -66.8\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.0053\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: 0.00922\n",
      "Steps: 8.1e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00414\n",
      "Variance: 0.0727\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  27.4440  13.1512  50.0606  54.4472  33.1512  22.0936\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0012   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 51987, Mean R = -36.2  Std R = 14.6  Min R = -92.4\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.0016\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: 0.00274\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.32e+07\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0727\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  37.9221  23.5410  61.4630  61.4630  37.9221  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 52018, Mean R = -34.4  Std R = 17.2  Min R = -114.8\n",
      "Beta: 0.0296\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.00811\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: 0.0176\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00329\n",
      "Variance: 0.0727\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  33.3199  10.5460  48.7677  61.4630  37.9221  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0017   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 52049, Mean R = -30.2  Std R = 5.4  Min R = -40.3\n",
      "Beta: 0.0296\n",
      "ExplainedVarNew: 0.966\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.00108\n",
      "PolicyEntropy: -4.01\n",
      "PolicyLoss: 0.00319\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00321\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.296\n",
      "\n",
      "\n",
      " *** BROKE ***\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  40.5062  22.3918  70.4490  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0014   0.0058   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1680    ET =    223.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.4     2.0    -0.3 |    13.8    16.2     0.2 |   -22.5   -47.6    -0.9 |    50.7    39.4    -0.0\n",
      "v_f      |   -4.85    0.44  -13.47 |    1.86    1.59    2.92 |   -9.88   -3.92  -20.31 |   -0.28    6.31   -2.81\n",
      "vr_f     |     2.8 |     1.0 |     1.2 |    10.6\n",
      "r_i      |   982.6    -7.6  2350.3 |   568.5   562.5    27.9 |     7.2  -993.0  2300.2 |  1995.0   992.8  2399.1\n",
      "v_i      |  -41.42    0.97  -80.14 |   17.26   17.24    5.85 |  -69.90  -29.96  -89.97 |  -10.26   29.79  -70.03\n",
      "norm_rf  |    21.3 |     9.4 |     1.4 |    51.2\n",
      "norm_vf  |   14.47 |    3.21 |    3.43 |   20.88\n",
      "thrust   |    1290     -20    9195 |    2761    2734    2215 |   -9999  -14466   -6187 |   14968   14287   15000\n",
      "norm_thrust |    9967 |    2622 |    2000 |   15000\n",
      "fuel     |     262 |      12 |     240 |     311\n",
      "rewards  |  -33.37 |   12.67 | -114.79 |  -18.27\n",
      "fuel_rewards |   -9.01 |    0.40 |  -10.68 |   -8.25\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.49 |    0.22 |    3.22\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.07 |    7.48 |    4.80 |   46.16\n",
      "tracking_rewards |  -24.36 |   12.37 | -104.11 |   -9.96\n",
      "steps    |     270 |      18 |     231 |     324\n",
      "***** Episode 52080, Mean R = -35.4  Std R = 15.5  Min R = -97.5\n",
      "Beta: 0.0198\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00448\n",
      "PolicyEntropy: -4.01\n",
      "PolicyLoss: 0.0174\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  32.8147  14.8703  62.1059  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0014   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 52111, Mean R = -41.6  Std R = 19.2  Min R = -106.1\n",
      "Beta: 0.0296\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000187\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: 0.000389\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00262\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.0405   4.8741  21.6104  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 52142, Mean R = -33.5  Std R = 9.3  Min R = -56.1\n",
      "Beta: 0.0444\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000152\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: -0.00126\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00317\n",
      "Variance: 0.0729\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9205   2.2008  12.3970  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 52173, Mean R = -37.1  Std R = 11.6  Min R = -69.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000467\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2602   2.2116  11.7529  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 52204, Mean R = -33.5  Std R = 7.9  Min R = -55.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: -0.00252\n",
      "Steps: 8.72e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00235\n",
      "Variance: 0.0727\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3309   2.5143  12.9539  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 52235, Mean R = -31.5  Std R = 10.4  Min R = -58.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000762\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00263\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5695   1.9736  11.7383  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0018   0.0074   1.6645   0.7971   0.5555\n",
      "***** Episode 52266, Mean R = -33.9  Std R = 8.3  Min R = -56.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000704\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5456   3.3378  16.3595  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0028   0.0017   0.0065   1.6645   0.7971   0.5555\n",
      "***** Episode 52297, Mean R = -35.5  Std R = 11.6  Min R = -65.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000545\n",
      "PolicyEntropy: -4.02\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.0728\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7068   1.5869   8.6349  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0005   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 52328, Mean R = -30.7  Std R = 8.6  Min R = -60.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000544\n",
      "PolicyEntropy: -4.03\n",
      "PolicyLoss: -0.00227\n",
      "Steps: 8.7e+03\n",
      "TotalSteps: 1.33e+07\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.0727\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8467   2.7186  13.0515  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 52359, Mean R = -37.6  Std R = 18.2  Min R = -92.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.00083\n",
      "PolicyEntropy: -4.03\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00249\n",
      "Variance: 0.0725\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6807   1.7210   9.0950  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1690    ET =    235.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.5     1.7    -0.3 |    13.4    16.6     0.2 |   -21.6   -41.0    -0.8 |    40.0    40.3    -0.0\n",
      "v_f      |   -4.73    0.49  -12.81 |    1.96    1.44    3.12 |   -9.72   -4.47  -20.38 |    0.08    5.79   -4.80\n",
      "vr_f     |     3.0 |     2.1 |     1.6 |    28.3\n",
      "r_i      |   980.5    -3.3  2352.3 |   560.5   588.2    29.9 |    19.4  -997.5  2300.1 |  1999.3   998.0  2399.6\n",
      "v_i      |  -40.32   -2.13  -79.88 |   17.72   17.69    5.53 |  -69.80  -29.88  -90.00 |  -10.14   29.87  -70.02\n",
      "norm_rf  |    21.1 |    10.0 |     1.8 |    47.0\n",
      "norm_vf  |   13.80 |    3.46 |    4.99 |   21.19\n",
      "thrust   |    1221     106    9095 |    2805    2832    2232 |   -9948  -14306   -6088 |   14988   13978   15000\n",
      "norm_thrust |    9891 |    2697 |    2258 |   15000\n",
      "fuel     |     266 |      11 |     239 |     315\n",
      "rewards  |  -34.67 |   12.52 | -106.11 |  -17.12\n",
      "fuel_rewards |   -9.16 |    0.38 |  -10.81 |   -8.22\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.46 |    0.29 |    3.02\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.97 |    8.03 |    2.99 |   42.00\n",
      "tracking_rewards |  -25.51 |   12.25 |  -96.02 |   -8.56\n",
      "steps    |     277 |      18 |     241 |     330\n",
      "***** Episode 52390, Mean R = -31.7  Std R = 9.8  Min R = -63.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000673\n",
      "PolicyEntropy: -4.03\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00272\n",
      "Variance: 0.0724\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3773   2.1529  12.3182  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 52421, Mean R = -34.4  Std R = 8.4  Min R = -55.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000707\n",
      "PolicyEntropy: -4.03\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.63e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.0723\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7993   1.9601  10.5945  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0001   0.0006   1.6645   0.7971   0.5555\n",
      "***** Episode 52452, Mean R = -30.4  Std R = 6.5  Min R = -52.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.00062\n",
      "PolicyEntropy: -4.03\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00228\n",
      "Variance: 0.0722\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4318   1.2426   7.5756  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 52483, Mean R = -35.7  Std R = 12.5  Min R = -77.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000727\n",
      "PolicyEntropy: -4.03\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.66e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.0721\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8390   5.2335  20.7203  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 52514, Mean R = -36.1  Std R = 9.8  Min R = -62.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -4.04\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.0721\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9226   2.1173  11.9734  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 52545, Mean R = -35.0  Std R = 10.6  Min R = -63.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000845\n",
      "PolicyEntropy: -4.04\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.072\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8534   1.5998   9.3416  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 52576, Mean R = -36.2  Std R = 12.7  Min R = -91.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000893\n",
      "PolicyEntropy: -4.04\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.0721\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9943   1.4807   7.6807  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 52607, Mean R = -37.6  Std R = 15.8  Min R = -93.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000621\n",
      "PolicyEntropy: -4.04\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00299\n",
      "Variance: 0.0722\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1454   2.0067  10.1145  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 52638, Mean R = -35.5  Std R = 11.0  Min R = -60.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000782\n",
      "PolicyEntropy: -4.04\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00304\n",
      "Variance: 0.0721\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.0092   0.8777   6.6843  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 52669, Mean R = -35.3  Std R = 16.1  Min R = -113.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000583\n",
      "PolicyEntropy: -4.04\n",
      "PolicyLoss: -0.00231\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00295\n",
      "Variance: 0.072\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4988   1.4679   7.9641  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0047   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1700    ET =    234.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.3     2.3    -0.3 |    16.2    18.4     0.2 |   -29.2   -53.8    -1.0 |    56.1    48.7    -0.0\n",
      "v_f      |   -4.91    0.29  -12.87 |    2.25    1.70    3.40 |  -12.39   -4.62  -21.78 |    0.43    6.28   -2.59\n",
      "vr_f     |     2.7 |     1.1 |     1.1 |     8.9\n",
      "r_i      |   972.2    20.5  2350.3 |   614.5   578.8    28.2 |     7.6  -996.8  2300.0 |  1999.2   996.1  2399.7\n",
      "v_i      |  -40.12   -0.43  -79.80 |   17.82   17.31    5.75 |  -69.89  -29.88  -89.89 |  -10.13   29.95  -70.00\n",
      "norm_rf  |    23.9 |    11.8 |     1.2 |    60.5\n",
      "norm_vf  |   13.96 |    3.78 |    3.04 |   22.32\n",
      "thrust   |    1210      49    9155 |    2928    2799    2239 |  -10341  -14005   -5841 |   14989   13917   15000\n",
      "norm_thrust |    9971 |    2699 |    2242 |   15000\n",
      "fuel     |     266 |      12 |     242 |     316\n",
      "rewards  |  -35.33 |   12.62 | -115.62 |  -19.59\n",
      "fuel_rewards |   -9.13 |    0.41 |  -10.86 |   -8.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.49 |    0.13 |    2.98\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   20.15 |   10.34 |    3.64 |   55.55\n",
      "tracking_rewards |  -26.19 |   12.31 | -104.76 |  -11.02\n",
      "steps    |     274 |      18 |     235 |     347\n",
      "***** Episode 52700, Mean R = -37.1  Std R = 16.9  Min R = -115.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000713\n",
      "PolicyEntropy: -4.05\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.34e+07\n",
      "ValFuncLoss: 0.00226\n",
      "Variance: 0.072\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7546   1.5867   9.0811  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 52731, Mean R = -31.8  Std R = 7.8  Min R = -51.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000586\n",
      "PolicyEntropy: -4.05\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00304\n",
      "Variance: 0.0719\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4024   3.2925  17.8024  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 52762, Mean R = -36.5  Std R = 13.0  Min R = -68.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000841\n",
      "PolicyEntropy: -4.05\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00303\n",
      "Variance: 0.0719\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2571   2.6543  12.1046  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 52793, Mean R = -34.4  Std R = 14.1  Min R = -98.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000608\n",
      "PolicyEntropy: -4.05\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00292\n",
      "Variance: 0.0718\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.5032   1.1282   6.4369  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 52824, Mean R = -38.0  Std R = 20.2  Min R = -127.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000564\n",
      "PolicyEntropy: -4.05\n",
      "PolicyLoss: -0.00227\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.0031\n",
      "Variance: 0.0716\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1167   1.5089   7.7434  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 52855, Mean R = -35.1  Std R = 10.2  Min R = -63.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000835\n",
      "PolicyEntropy: -4.05\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.0714\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5176   2.8474  15.2807  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 52886, Mean R = -32.7  Std R = 6.6  Min R = -50.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000762\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.0032\n",
      "Variance: 0.0714\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4679   2.2546  12.8232  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 52917, Mean R = -34.7  Std R = 13.2  Min R = -81.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000772\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0714\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2343   2.5598  11.3902  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0023   0.0090   1.6645   0.7971   0.5555\n",
      "***** Episode 52948, Mean R = -37.7  Std R = 17.2  Min R = -110.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000689\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00307\n",
      "Variance: 0.0712\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7412   2.4076  15.4554  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 52979, Mean R = -33.4  Std R = 9.5  Min R = -66.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000924\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00298\n",
      "Variance: 0.0712\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3610   1.9556   9.4686  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1710    ET =    223.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.9     4.4    -0.3 |    13.6    17.3     0.2 |   -40.8   -49.0    -0.8 |    49.6    51.5    -0.0\n",
      "v_f      |   -4.85    0.38  -13.02 |    1.91    1.64    3.02 |  -12.83   -3.99  -21.90 |   -0.07    6.93   -1.83\n",
      "vr_f     |     2.7 |     0.8 |     1.0 |     6.8\n",
      "r_i      |   985.3   -10.6  2348.1 |   591.3   566.3    29.0 |     2.9  -983.9  2300.6 |  1984.1   999.5  2399.9\n",
      "v_i      |  -40.00    0.49  -80.48 |   18.06   17.77    5.40 |  -70.00  -30.00  -89.86 |  -10.02   29.76  -70.01\n",
      "norm_rf  |    21.6 |    10.8 |     0.8 |    71.5\n",
      "norm_vf  |   14.06 |    3.32 |    2.30 |   23.99\n",
      "thrust   |    1220      -7    9165 |    2835    2867    2233 |  -10186  -14149   -6332 |   14989   14084   15000\n",
      "norm_thrust |    9976 |    2685 |    2000 |   15000\n",
      "fuel     |     264 |      12 |     239 |     312\n",
      "rewards  |  -34.79 |   12.98 | -127.27 |  -18.28\n",
      "fuel_rewards |   -9.08 |    0.41 |  -10.74 |   -8.23\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.52 |    0.04 |    3.37\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.32 |    8.95 |    5.05 |   66.51\n",
      "tracking_rewards |  -25.71 |   12.70 | -116.53 |   -9.65\n",
      "steps    |     272 |      18 |     234 |     324\n",
      "***** Episode 53010, Mean R = -33.7  Std R = 10.1  Min R = -66.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.963\n",
      "ExplainedVarOld: 0.955\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00277\n",
      "Variance: 0.0714\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7670   2.8170  14.5084  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 53041, Mean R = -32.9  Std R = 10.7  Min R = -80.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000725\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.00307\n",
      "Variance: 0.0714\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4146   2.4669  12.2958  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 53072, Mean R = -34.9  Std R = 13.7  Min R = -92.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000666\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.35e+07\n",
      "ValFuncLoss: 0.0033\n",
      "Variance: 0.0713\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3828   3.5491  13.4084  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 53103, Mean R = -33.4  Std R = 11.2  Min R = -64.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000558\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00248\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00348\n",
      "Variance: 0.0714\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.5852   5.1822  29.1926  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 53134, Mean R = -30.3  Std R = 5.9  Min R = -42.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.00059\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00306\n",
      "Variance: 0.0714\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1881   2.1090   9.7672  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 53165, Mean R = -33.4  Std R = 11.2  Min R = -59.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000625\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00345\n",
      "Variance: 0.0713\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.2636   1.5412   9.0833  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 53196, Mean R = -33.3  Std R = 7.6  Min R = -54.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000638\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.0032\n",
      "Variance: 0.0712\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0246   1.5282   8.9358  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 53227, Mean R = -32.6  Std R = 13.8  Min R = -98.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000648\n",
      "PolicyEntropy: -4.07\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00287\n",
      "Variance: 0.0712\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6397   1.2579   8.0739  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 53258, Mean R = -32.2  Std R = 9.5  Min R = -61.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.951\n",
      "KL: 0.000757\n",
      "PolicyEntropy: -4.07\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.0711\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.4933   1.3568   6.8513  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0017   0.0060   1.6645   0.7971   0.5555\n",
      "***** Episode 53289, Mean R = -34.4  Std R = 10.0  Min R = -70.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000571\n",
      "PolicyEntropy: -4.07\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00205\n",
      "Variance: 0.0709\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3458   1.5502   8.2351  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1720    ET =    238.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.4     3.5    -0.3 |    13.1    15.8     0.2 |   -28.2   -40.3    -0.8 |    50.2    52.8    -0.0\n",
      "v_f      |   -4.65    0.28  -12.19 |    1.91    1.68    3.18 |   -9.59   -5.94  -20.12 |    0.52    7.99   -3.09\n",
      "vr_f     |     2.7 |     0.9 |     1.2 |     7.5\n",
      "r_i      |   976.0   -27.8  2345.4 |   550.1   577.2    27.9 |     1.8  -997.3  2300.1 |  1989.3   990.6  2398.7\n",
      "v_i      |  -39.93    0.04  -80.20 |   16.64   17.62    5.86 |  -69.97  -29.95  -89.96 |  -10.13   29.97  -70.04\n",
      "norm_rf  |    19.3 |    10.1 |     1.2 |    63.1\n",
      "norm_vf  |   13.21 |    3.51 |    3.70 |   21.62\n",
      "thrust   |    1237      18    9161 |    2754    2782    2192 |  -10597  -14133   -5859 |   14955   14106   15000\n",
      "norm_thrust |    9932 |    2632 |    2000 |   15000\n",
      "fuel     |     264 |      11 |     242 |     306\n",
      "rewards  |  -33.13 |   11.39 | -108.80 |  -18.05\n",
      "fuel_rewards |   -9.09 |    0.39 |  -10.53 |   -8.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.44 |    0.24 |    2.92\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.33 |    8.32 |    2.09 |   58.08\n",
      "tracking_rewards |  -24.04 |   11.11 |  -98.45 |   -9.70\n",
      "steps    |     274 |      18 |     234 |     331\n",
      "***** Episode 53320, Mean R = -34.0  Std R = 16.1  Min R = -108.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000661\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.0709\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1544   4.3077  19.4487  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0012   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 53351, Mean R = -34.2  Std R = 11.5  Min R = -71.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000682\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.0709\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2854   2.6172  14.0967  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 53382, Mean R = -34.8  Std R = 16.8  Min R = -115.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000936\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00352\n",
      "Variance: 0.0708\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0447   2.9733  13.6927  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 53413, Mean R = -33.5  Std R = 8.7  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000764\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00342\n",
      "Variance: 0.0708\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0084   2.0683  12.5642  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 53444, Mean R = -35.6  Std R = 9.5  Min R = -61.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000741\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.72e+03\n",
      "TotalSteps: 1.36e+07\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0707\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5437   1.3467   6.8499  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 53475, Mean R = -29.4  Std R = 5.5  Min R = -42.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000861\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00287\n",
      "Variance: 0.0706\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0544   3.8748  18.3200  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 53506, Mean R = -33.1  Std R = 10.8  Min R = -61.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000702\n",
      "PolicyEntropy: -4.06\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00306\n",
      "Variance: 0.0706\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.2957   4.7257  22.7484  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 53537, Mean R = -32.9  Std R = 9.7  Min R = -60.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000534\n",
      "PolicyEntropy: -4.07\n",
      "PolicyLoss: -0.00279\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00297\n",
      "Variance: 0.0705\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8386   2.0391   8.8687  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 53568, Mean R = -32.0  Std R = 7.6  Min R = -57.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000658\n",
      "PolicyEntropy: -4.07\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00277\n",
      "Variance: 0.0704\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3583   1.5461  10.6071  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0019   0.0075   1.6645   0.7971   0.5555\n",
      "***** Episode 53599, Mean R = -34.5  Std R = 8.2  Min R = -54.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000766\n",
      "PolicyEntropy: -4.07\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00279\n",
      "Variance: 0.0703\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0045   2.0222   9.6299  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1730    ET =    238.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.5     1.4    -0.3 |    14.5    16.4     0.2 |   -23.8   -45.5    -0.8 |    46.6    46.8    -0.0\n",
      "v_f      |   -4.63    0.38  -12.51 |    2.03    1.58    3.16 |  -11.80   -4.73  -20.00 |    0.89    6.41   -2.55\n",
      "vr_f     |     2.9 |     1.8 |     1.5 |    23.1\n",
      "r_i      |   975.6   -44.5  2350.0 |   585.1   572.3    28.8 |     7.7  -985.6  2300.2 |  1997.8   998.2  2399.5\n",
      "v_i      |  -38.52    0.72  -79.67 |   17.40   16.71    5.69 |  -69.83  -29.75  -89.86 |  -10.11   29.73  -70.13\n",
      "norm_rf  |    20.7 |     9.7 |     1.0 |    62.1\n",
      "norm_vf  |   13.50 |    3.52 |    2.98 |   23.25\n",
      "thrust   |    1169       7    9173 |    2818    2735    2199 |   -9954  -14326   -6294 |   14993   13866   14999\n",
      "norm_thrust |    9944 |    2624 |    2000 |   15000\n",
      "fuel     |     265 |      11 |     243 |     302\n",
      "rewards  |  -33.47 |   10.46 | -115.73 |  -17.55\n",
      "fuel_rewards |   -9.10 |    0.39 |  -10.39 |   -8.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.47 |    0.35 |    2.86\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.51 |    7.67 |    5.61 |   57.12\n",
      "tracking_rewards |  -24.38 |   10.18 | -105.34 |   -9.06\n",
      "steps    |     274 |      18 |     232 |     332\n",
      "***** Episode 53630, Mean R = -34.7  Std R = 10.9  Min R = -68.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000837\n",
      "PolicyEntropy: -4.07\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.0703\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2046   2.0155  10.4289  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0018   0.0064   1.6645   0.7971   0.5555\n",
      "***** Episode 53661, Mean R = -39.5  Std R = 16.9  Min R = -112.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.961\n",
      "KL: 0.001\n",
      "PolicyEntropy: -4.08\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00256\n",
      "Variance: 0.0703\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0621   1.7338   9.5840  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 53692, Mean R = -33.3  Std R = 11.2  Min R = -71.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -4.08\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00291\n",
      "Variance: 0.0703\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8785   1.8649  10.6969  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 53723, Mean R = -30.1  Std R = 7.2  Min R = -48.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.00067\n",
      "PolicyEntropy: -4.08\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.63e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00244\n",
      "Variance: 0.0703\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7502   2.8891  14.4964  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 53754, Mean R = -30.8  Std R = 8.0  Min R = -52.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000642\n",
      "PolicyEntropy: -4.08\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.0703\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3013   1.9162  10.5656  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 53785, Mean R = -35.2  Std R = 9.7  Min R = -55.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -4.09\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.37e+07\n",
      "ValFuncLoss: 0.00268\n",
      "Variance: 0.0702\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3510   3.2873  16.3556  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 53816, Mean R = -34.5  Std R = 10.7  Min R = -72.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000532\n",
      "PolicyEntropy: -4.09\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00288\n",
      "Variance: 0.07\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4569   2.8325  15.5711  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 53847, Mean R = -31.8  Std R = 10.8  Min R = -78.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000917\n",
      "PolicyEntropy: -4.09\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.07\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.7244   3.6973  17.9366  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 53878, Mean R = -33.3  Std R = 8.2  Min R = -57.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000793\n",
      "PolicyEntropy: -4.09\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00239\n",
      "Variance: 0.0699\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1778   3.7776  15.9040  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 53909, Mean R = -36.6  Std R = 10.4  Min R = -62.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00071\n",
      "PolicyEntropy: -4.1\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00223\n",
      "Variance: 0.0699\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7736   1.4366   8.6365  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1740    ET =    225.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.8     2.3    -0.3 |    14.8    15.1     0.2 |   -28.0   -38.0    -0.9 |    39.7    38.8    -0.0\n",
      "v_f      |   -4.65    0.35  -12.72 |    2.10    1.65    3.22 |  -10.75   -5.20  -19.52 |   -0.49    6.42   -2.69\n",
      "vr_f     |     2.9 |     1.1 |     1.3 |    13.2\n",
      "r_i      |   949.2    13.1  2351.3 |   585.5   576.6    29.3 |     0.8  -999.6  2300.4 |  1998.5   999.4  2399.5\n",
      "v_i      |  -38.92   -0.81  -80.18 |   17.28   17.79    5.73 |  -69.93  -29.99  -89.95 |  -10.09   29.86  -70.02\n",
      "norm_rf  |    20.1 |     9.6 |     1.4 |    54.0\n",
      "norm_vf  |   13.71 |    3.60 |    3.38 |   20.68\n",
      "thrust   |    1179      33    9180 |    2799    2868    2181 |  -10068  -14140   -5943 |   14977   13942   15000\n",
      "norm_thrust |    9974 |    2643 |    2000 |   15000\n",
      "fuel     |     265 |      12 |     242 |     310\n",
      "rewards  |  -34.11 |   12.05 | -112.57 |  -16.52\n",
      "fuel_rewards |   -9.11 |    0.42 |  -10.67 |   -8.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.47 |    0.52 |    0.55 |    3.38\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.11 |    7.53 |    3.66 |   49.00\n",
      "tracking_rewards |  -25.00 |   11.75 | -101.91 |   -7.87\n",
      "steps    |     273 |      18 |     234 |     333\n",
      "***** Episode 53940, Mean R = -36.0  Std R = 18.8  Min R = -107.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000944\n",
      "PolicyEntropy: -4.1\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0699\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.9138   1.1973   6.2828  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0038   1.6645   0.7971   0.5555\n",
      "***** Episode 53971, Mean R = -33.5  Std R = 12.8  Min R = -72.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000616\n",
      "PolicyEntropy: -4.1\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00282\n",
      "Variance: 0.0698\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.7345   3.2318  14.5589  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0020   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 54002, Mean R = -32.6  Std R = 10.9  Min R = -61.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000871\n",
      "PolicyEntropy: -4.11\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00293\n",
      "Variance: 0.0697\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8903   1.9386  10.5177  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 54033, Mean R = -34.5  Std R = 11.1  Min R = -78.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -4.11\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00302\n",
      "Variance: 0.0696\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2108   2.2652  12.6743  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 54064, Mean R = -31.9  Std R = 8.7  Min R = -63.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000668\n",
      "PolicyEntropy: -4.11\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00311\n",
      "Variance: 0.0696\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0806   1.3158   7.5622  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 54095, Mean R = -33.7  Std R = 8.9  Min R = -62.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000639\n",
      "PolicyEntropy: -4.11\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00328\n",
      "Variance: 0.0694\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6421   2.1436  11.1302  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0013   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 54126, Mean R = -37.6  Std R = 12.2  Min R = -77.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000809\n",
      "PolicyEntropy: -4.11\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.7e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00239\n",
      "Variance: 0.0693\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.3058   4.8508  26.9621  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 54157, Mean R = -35.4  Std R = 12.9  Min R = -89.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.38e+07\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.0693\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3015   2.8816  16.1443  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 54188, Mean R = -32.2  Std R = 8.1  Min R = -54.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000555\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00253\n",
      "Variance: 0.0693\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9624   4.2258  16.6905  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 54219, Mean R = -31.5  Std R = 12.2  Min R = -72.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000715\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00245\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00228\n",
      "Variance: 0.0692\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8843   1.9694   9.6999  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1750    ET =    233.7   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.7     1.8    -0.3 |    13.6    16.7     0.2 |   -25.9   -47.0    -0.8 |    36.1    56.6    -0.0\n",
      "v_f      |   -4.55    0.47  -12.84 |    1.96    1.59    3.30 |  -10.16   -5.11  -22.87 |    0.31    6.20   -3.39\n",
      "vr_f     |     3.1 |     3.5 |     1.5 |    61.7\n",
      "r_i      |   990.7     4.6  2351.1 |   589.2   575.8    28.1 |    12.3  -998.2  2300.2 |  1995.8   996.1  2399.7\n",
      "v_i      |  -39.32    0.20  -79.82 |   16.51   17.43    6.21 |  -69.67  -29.86  -89.99 |  -10.03   29.71  -70.01\n",
      "norm_rf  |    20.6 |     9.5 |     0.7 |    59.6\n",
      "norm_vf  |   13.77 |    3.66 |    3.87 |   25.03\n",
      "thrust   |    1200       8    9129 |    2739    2761    2182 |  -10392  -14102   -5884 |   14993   14278   14999\n",
      "norm_thrust |    9891 |    2616 |    2000 |   15000\n",
      "fuel     |     265 |      11 |     240 |     308\n",
      "rewards  |  -33.52 |   11.12 |  -89.20 |  -17.64\n",
      "fuel_rewards |   -9.10 |    0.39 |  -10.57 |   -8.24\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.50 |    0.57 |    3.39\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.31 |    7.57 |    4.22 |   54.60\n",
      "tracking_rewards |  -24.42 |   10.84 |  -79.35 |   -8.91\n",
      "steps    |     275 |      18 |     236 |     324\n",
      "***** Episode 54250, Mean R = -32.2  Std R = 10.7  Min R = -77.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000668\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00226\n",
      "Variance: 0.0693\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1290   1.6814   7.6903  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0014   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 54281, Mean R = -33.3  Std R = 8.6  Min R = -63.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000596\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.0692\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9058   3.1957  17.1398  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 54312, Mean R = -32.9  Std R = 19.7  Min R = -123.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000696\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00265\n",
      "Variance: 0.0691\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4615   1.8115   9.7546  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0016   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 54343, Mean R = -38.3  Std R = 16.1  Min R = -92.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.0006\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00314\n",
      "Variance: 0.069\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3162   2.2552  11.3893  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 54374, Mean R = -33.3  Std R = 8.1  Min R = -57.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000559\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00285\n",
      "Variance: 0.0689\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9542   2.6308  14.5356  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0015   0.0059   1.6645   0.7971   0.5555\n",
      "***** Episode 54405, Mean R = -35.7  Std R = 11.6  Min R = -69.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000579\n",
      "PolicyEntropy: -4.12\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00267\n",
      "Variance: 0.0688\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8246   3.6488  14.7083  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0010   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 54436, Mean R = -32.9  Std R = 13.3  Min R = -91.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000721\n",
      "PolicyEntropy: -4.13\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.0029\n",
      "Variance: 0.0688\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0661   3.7930  17.1856  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 54467, Mean R = -33.5  Std R = 11.8  Min R = -73.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000672\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00286\n",
      "Variance: 0.0687\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9927   3.0844  15.8802  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 54498, Mean R = -34.3  Std R = 9.2  Min R = -68.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000643\n",
      "PolicyEntropy: -4.13\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.0686\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6311   2.6458  13.8870  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 54529, Mean R = -34.4  Std R = 13.3  Min R = -77.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -4.13\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.39e+07\n",
      "ValFuncLoss: 0.00262\n",
      "Variance: 0.0686\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9959   2.0854  12.6622  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1760    ET =    235.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     7.4    -0.6    -0.3 |    13.7    16.7     0.2 |   -23.7   -48.3    -0.9 |    40.9    46.0    -0.0\n",
      "v_f      |   -4.60    0.54  -13.09 |    1.95    1.52    3.15 |   -8.91   -3.58  -21.45 |    1.50    5.80   -5.27\n",
      "vr_f     |     3.0 |     1.4 |     1.6 |    20.8\n",
      "r_i      |   946.1   -26.2  2349.2 |   570.4   582.6    28.0 |    11.4  -990.6  2300.1 |  1998.5   990.2  2399.2\n",
      "v_i      |  -41.24    0.83  -79.98 |   16.74   16.82    5.77 |  -69.69  -29.33  -89.99 |  -10.04   29.90  -70.02\n",
      "norm_rf  |    20.8 |     9.5 |     1.8 |    49.7\n",
      "norm_vf  |   14.02 |    3.49 |    5.28 |   22.35\n",
      "thrust   |    1271     -12    9136 |    2826    2828    2166 |   -9913  -14293   -6490 |   14992   14099   15000\n",
      "norm_thrust |    9938 |    2645 |    2000 |   15000\n",
      "fuel     |     263 |      12 |     239 |     306\n",
      "rewards  |  -34.00 |   12.63 | -123.60 |  -17.92\n",
      "fuel_rewards |   -9.05 |    0.40 |  -10.49 |   -8.22\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.52 |    0.13 |    4.31\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.53 |    7.71 |    3.85 |   44.71\n",
      "tracking_rewards |  -24.95 |   12.35 | -113.10 |   -9.34\n",
      "steps    |     273 |      17 |     238 |     333\n",
      "***** Episode 54560, Mean R = -31.3  Std R = 8.0  Min R = -52.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000692\n",
      "PolicyEntropy: -4.13\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.0032\n",
      "Variance: 0.0686\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1084   1.9639  11.3418  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 54591, Mean R = -31.9  Std R = 5.3  Min R = -42.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000645\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.0684\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4334   1.9742  12.8919  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 54622, Mean R = -31.7  Std R = 8.3  Min R = -63.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000826\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00303\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00339\n",
      "Variance: 0.0683\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.3532   5.5228  22.7701  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0014   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 54653, Mean R = -38.1  Std R = 12.5  Min R = -85.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000969\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00239\n",
      "Variance: 0.0683\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0486   3.2755  18.3427  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 54684, Mean R = -31.1  Std R = 8.9  Min R = -56.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000657\n",
      "PolicyEntropy: -4.13\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00293\n",
      "Variance: 0.0683\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7964   1.9626  10.7167  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 54715, Mean R = -35.9  Std R = 14.6  Min R = -88.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000548\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00241\n",
      "Steps: 8.69e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0683\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1997   2.5661  14.1294  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 54746, Mean R = -32.2  Std R = 7.7  Min R = -57.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000784\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00353\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00314\n",
      "Variance: 0.0684\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2553   2.4264  12.5121  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 54777, Mean R = -36.4  Std R = 18.8  Min R = -106.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000683\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0684\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3086   1.9089  10.1714  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 54808, Mean R = -35.3  Std R = 16.7  Min R = -104.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000663\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00228\n",
      "Variance: 0.0684\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8117   3.6006  18.8652  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0015   0.0058   1.6645   0.7971   0.5555\n",
      "***** Episode 54839, Mean R = -33.9  Std R = 7.7  Min R = -60.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000711\n",
      "PolicyEntropy: -4.14\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0683\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4765   2.5028  12.4809  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1770    ET =    231.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.9     1.2    -0.3 |    14.1    16.7     0.2 |   -26.9   -47.7    -0.8 |    42.7    45.8    -0.0\n",
      "v_f      |   -4.79    0.39  -13.14 |    2.05    1.67    3.29 |  -10.66   -5.35  -18.88 |   -0.02    5.94   -4.05\n",
      "vr_f     |     2.8 |     1.0 |     1.5 |    11.0\n",
      "r_i      |   986.6    16.0  2352.5 |   593.7   568.9    28.7 |    13.5  -996.8  2300.2 |  1989.0   997.4  2400.0\n",
      "v_i      |  -40.54   -0.23  -79.54 |   17.33   17.44    5.91 |  -69.88  -29.94  -89.93 |  -10.65   29.86  -70.10\n",
      "norm_rf  |    20.8 |     9.6 |     1.3 |    48.2\n",
      "norm_vf  |   14.15 |    3.66 |    4.32 |   20.74\n",
      "thrust   |    1232      27    9098 |    2806    2788    2172 |  -10647  -14331   -5805 |   14968   14191   15000\n",
      "norm_thrust |    9885 |    2632 |    2000 |   15000\n",
      "fuel     |     263 |      11 |     242 |     300\n",
      "rewards  |  -33.74 |   11.84 | -106.30 |  -16.61\n",
      "fuel_rewards |   -9.03 |    0.39 |  -10.30 |   -8.31\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.49 |    0.59 |    3.27\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.78 |    7.68 |    5.97 |   43.22\n",
      "tracking_rewards |  -24.71 |   11.58 |  -96.35 |   -8.13\n",
      "steps    |     273 |      19 |     232 |     321\n",
      "***** Episode 54870, Mean R = -30.8  Std R = 7.0  Min R = -47.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000781\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.00275\n",
      "Variance: 0.0683\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.2362   3.9601  18.4071  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 54901, Mean R = -35.2  Std R = 17.3  Min R = -110.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000917\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.4e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0682\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3776   3.3563  15.1305  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 54932, Mean R = -32.2  Std R = 11.5  Min R = -77.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000707\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.0681\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0648   2.5851  12.6110  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 54963, Mean R = -32.0  Std R = 9.0  Min R = -53.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000649\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00341\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.0679\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5287   3.2214  14.5701  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 54994, Mean R = -32.6  Std R = 6.7  Min R = -53.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00218\n",
      "Variance: 0.0679\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2281   1.6900  11.0256  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0020   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 55025, Mean R = -37.6  Std R = 16.4  Min R = -113.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000947\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00265\n",
      "Variance: 0.0679\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0965   1.3707   9.1905  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 55056, Mean R = -34.2  Std R = 8.4  Min R = -59.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000638\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00316\n",
      "Variance: 0.0679\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5476   1.0842   8.0490  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 55087, Mean R = -32.4  Std R = 12.6  Min R = -90.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.00089\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00256\n",
      "Variance: 0.0679\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1891   2.3513  12.4598  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 55118, Mean R = -31.3  Std R = 9.0  Min R = -62.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00294\n",
      "Variance: 0.0679\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2674   4.0767  18.8448  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 55149, Mean R = -31.8  Std R = 8.2  Min R = -52.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000609\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00317\n",
      "Variance: 0.0677\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8705   2.5349  13.7877  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1780    ET =    227.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.9     0.7    -0.3 |    13.1    16.0     0.2 |   -24.4   -46.2    -0.9 |    40.1    40.0    -0.0\n",
      "v_f      |   -4.67    0.56  -13.04 |    1.91    1.59    3.10 |  -10.42   -3.93  -21.08 |    0.06    7.15   -4.54\n",
      "vr_f     |     3.1 |     3.8 |     1.5 |    66.1\n",
      "r_i      |  1002.8   -55.5  2348.9 |   557.0   592.2    28.4 |     2.2  -997.1  2300.1 |  1990.4   988.7  2399.8\n",
      "v_i      |  -39.88    0.61  -79.60 |   17.24   17.26    5.72 |  -69.99  -29.93  -89.92 |  -10.11   29.98  -70.04\n",
      "norm_rf  |    19.9 |     9.0 |     0.9 |    47.9\n",
      "norm_vf  |   14.01 |    3.44 |    5.44 |   21.64\n",
      "thrust   |    1227      -4    9134 |    2734    2781    2157 |  -10276  -14122   -5605 |   14963   14291   15000\n",
      "norm_thrust |    9900 |    2602 |    2000 |   15000\n",
      "fuel     |     264 |      11 |     242 |     309\n",
      "rewards  |  -33.14 |   11.54 | -113.44 |  -15.50\n",
      "fuel_rewards |   -9.07 |    0.39 |  -10.63 |   -8.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.49 |    0.30 |    3.09\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.93 |    6.99 |    5.32 |   42.85\n",
      "tracking_rewards |  -24.07 |   11.26 | -103.02 |   -7.04\n",
      "steps    |     274 |      17 |     240 |     341\n",
      "***** Episode 55180, Mean R = -32.3  Std R = 9.7  Min R = -62.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000779\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00284\n",
      "Variance: 0.0677\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.6725   3.3333  18.6296  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 55211, Mean R = -36.4  Std R = 12.2  Min R = -63.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -4.15\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00343\n",
      "Variance: 0.0677\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8440   2.5125  11.0894  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 55242, Mean R = -35.2  Std R = 13.2  Min R = -95.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000764\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.41e+07\n",
      "ValFuncLoss: 0.00268\n",
      "Variance: 0.0676\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3210   2.7954  14.1662  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 55273, Mean R = -36.0  Std R = 14.6  Min R = -87.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00301\n",
      "Variance: 0.0676\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3494   2.3285  12.6557  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 55304, Mean R = -31.9  Std R = 9.2  Min R = -64.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000653\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00272\n",
      "Variance: 0.0676\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2442   1.9005   9.6244  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0015   0.0055   1.6645   0.7971   0.5555\n",
      "***** Episode 55335, Mean R = -32.6  Std R = 10.7  Min R = -67.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000685\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00292\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.0676\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1281   4.2784  20.6918  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 55366, Mean R = -34.2  Std R = 12.1  Min R = -79.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000699\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0675\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9332   2.0017  12.4699  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 55397, Mean R = -31.0  Std R = 6.6  Min R = -48.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000728\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00333\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.0026\n",
      "Variance: 0.0674\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4660   1.9584  10.0145  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 55428, Mean R = -32.8  Std R = 11.8  Min R = -88.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000559\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00257\n",
      "Variance: 0.0674\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0134   2.3121  13.7216  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 55459, Mean R = -35.4  Std R = 10.0  Min R = -57.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000645\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.0674\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9735   1.8737   9.2858  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1790    ET =    228.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     7.4    -0.3    -0.3 |    13.8    15.6     0.2 |   -31.7   -51.2    -1.1 |    51.9    46.1    -0.0\n",
      "v_f      |   -4.46    0.52  -12.87 |    1.95    1.61    3.43 |  -10.81   -4.57  -23.78 |    0.13    6.46   -3.64\n",
      "vr_f     |     3.0 |     1.4 |     1.5 |    14.3\n",
      "r_i      |   949.4   -14.5  2349.6 |   575.4   580.3    28.6 |     5.3  -996.8  2300.6 |  1992.1   985.2  2400.0\n",
      "v_i      |  -40.17   -2.05  -79.57 |   17.75   17.39    5.53 |  -69.73  -29.83  -89.94 |  -10.06   29.78  -70.09\n",
      "norm_rf  |    20.0 |     9.5 |     2.3 |    53.0\n",
      "norm_vf  |   13.79 |    3.74 |    3.72 |   24.73\n",
      "thrust   |    1227     109    9109 |    2870    2864    2151 |   -9830  -14282   -6078 |   14977   13866   14999\n",
      "norm_thrust |    9928 |    2643 |    2543 |   15000\n",
      "fuel     |     265 |      12 |     241 |     308\n",
      "rewards  |  -33.99 |   11.54 |  -94.97 |  -17.12\n",
      "fuel_rewards |   -9.10 |    0.40 |  -10.59 |   -8.27\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.49 |    0.60 |    3.76\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.07 |    7.42 |    4.95 |   48.04\n",
      "tracking_rewards |  -24.89 |   11.25 |  -85.11 |   -8.61\n",
      "steps    |     274 |      19 |     238 |     332\n",
      "***** Episode 55490, Mean R = -34.4  Std R = 11.6  Min R = -70.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.00064\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00261\n",
      "Variance: 0.0674\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  15.1499   8.4269  27.4945  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0025   0.0013   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 55521, Mean R = -32.4  Std R = 7.2  Min R = -51.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000532\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00295\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.0673\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.6736   4.9390  20.3454  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 55552, Mean R = -33.5  Std R = 8.8  Min R = -64.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000811\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00215\n",
      "Variance: 0.0674\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.0345   5.5970  22.7496  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 55583, Mean R = -34.5  Std R = 11.1  Min R = -70.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000711\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.40e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00223\n",
      "Variance: 0.0676\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7907   4.0345  21.9969  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 55614, Mean R = -29.7  Std R = 6.4  Min R = -43.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000704\n",
      "PolicyEntropy: -4.16\n",
      "PolicyLoss: -0.00258\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.42e+07\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.0676\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6690   1.9443  10.1151  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 55645, Mean R = -31.4  Std R = 8.3  Min R = -56.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000798\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.0676\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2224   2.5075  11.8077  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 55676, Mean R = -37.6  Std R = 18.3  Min R = -112.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000713\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.0675\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0788   2.3661  11.0890  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 55707, Mean R = -30.9  Std R = 7.2  Min R = -53.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000697\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00236\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.0674\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9691   2.8088  17.3143  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 55738, Mean R = -32.7  Std R = 10.8  Min R = -63.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000808\n",
      "PolicyEntropy: -4.18\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00254\n",
      "Variance: 0.0672\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3161   2.6684  13.4883  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 55769, Mean R = -31.5  Std R = 10.2  Min R = -64.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000617\n",
      "PolicyEntropy: -4.18\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.0027\n",
      "Variance: 0.0672\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4771   4.6419  20.7609  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1800    ET =    233.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.8     1.7    -0.4 |    13.0    15.6     0.2 |   -16.6   -37.9    -0.8 |    43.8    44.4    -0.0\n",
      "v_f      |   -4.99    0.60  -13.66 |    1.94    1.64    2.79 |   -9.91   -4.50  -19.62 |   -0.40    5.70   -3.96\n",
      "vr_f     |     2.9 |     1.9 |     1.4 |    31.6\n",
      "r_i      |  1020.9   -23.3  2350.0 |   538.2   573.2    30.5 |    16.0  -994.2  2300.3 |  1991.4   998.0  2399.9\n",
      "v_i      |  -40.50   -0.11  -79.73 |   17.58   18.06    5.77 |  -69.96  -29.77  -89.97 |  -10.64   29.96  -70.25\n",
      "norm_rf  |    21.3 |     9.0 |     3.6 |    49.8\n",
      "norm_vf  |   14.71 |    3.13 |    4.46 |   20.90\n",
      "thrust   |    1240      44    9160 |    2662    2778    2117 |   -9393  -14265   -6160 |   14988   14244   14999\n",
      "norm_thrust |    9910 |    2554 |    2000 |   15000\n",
      "fuel     |     262 |      11 |     241 |     303\n",
      "rewards  |  -32.86 |   10.57 | -112.18 |  -16.03\n",
      "fuel_rewards |   -8.99 |    0.39 |  -10.40 |   -8.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.52 |    0.65 |    3.69\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.01 |    7.01 |    2.46 |   44.79\n",
      "tracking_rewards |  -23.87 |   10.31 | -101.93 |   -7.68\n",
      "steps    |     271 |      16 |     234 |     335\n",
      "***** Episode 55800, Mean R = -34.3  Std R = 10.1  Min R = -58.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000654\n",
      "PolicyEntropy: -4.17\n",
      "PolicyLoss: -0.00246\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00259\n",
      "Variance: 0.0672\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8982   1.9454  10.7910  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0009   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 55831, Mean R = -30.4  Std R = 7.0  Min R = -52.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -4.18\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00215\n",
      "Variance: 0.0672\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.2758   4.2564  17.0375  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 55862, Mean R = -33.1  Std R = 10.7  Min R = -79.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000699\n",
      "PolicyEntropy: -4.18\n",
      "PolicyLoss: -0.0036\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.0671\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8228   2.1954  10.7066  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 55893, Mean R = -36.2  Std R = 15.8  Min R = -96.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -4.18\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00224\n",
      "Variance: 0.067\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6060   2.7397  12.2946  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 55924, Mean R = -32.6  Std R = 7.5  Min R = -53.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000644\n",
      "PolicyEntropy: -4.19\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.0669\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9713   1.9451  10.7831  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0010   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 55955, Mean R = -30.2  Std R = 5.9  Min R = -48.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000758\n",
      "PolicyEntropy: -4.19\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.68e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00197\n",
      "Variance: 0.0668\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7242   1.0532   6.2871  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0013   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 55986, Mean R = -34.7  Std R = 11.3  Min R = -75.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000721\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.43e+07\n",
      "ValFuncLoss: 0.00255\n",
      "Variance: 0.0668\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5058   2.7524  15.4459  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 56017, Mean R = -34.8  Std R = 11.3  Min R = -73.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00315\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.0669\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0011   2.4424  12.5732  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 56048, Mean R = -32.5  Std R = 12.4  Min R = -85.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.985\n",
      "KL: 0.000933\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.0023\n",
      "Variance: 0.0669\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4442   2.2034  13.0428  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 56079, Mean R = -31.1  Std R = 7.5  Min R = -58.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00186\n",
      "Variance: 0.0668\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5178   3.6681  19.0837  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1810    ET =    233.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.0     4.0    -0.3 |    13.2    14.2     0.2 |   -22.2   -35.7    -0.8 |    40.6    41.8    -0.0\n",
      "v_f      |   -4.73    0.53  -13.23 |    1.88    1.57    2.79 |  -10.16   -4.12  -18.75 |   -0.31    5.43   -2.94\n",
      "vr_f     |     3.0 |     1.4 |     1.5 |    14.8\n",
      "r_i      |   986.4    29.8  2351.0 |   586.1   571.9    28.3 |    15.2  -999.7  2300.1 |  1995.2   991.0  2399.4\n",
      "v_i      |  -41.50   -1.21  -79.09 |   17.06   18.00    5.54 |  -69.93  -29.94  -89.72 |  -10.33   29.59  -70.01\n",
      "norm_rf  |    19.8 |     8.9 |     2.1 |    49.7\n",
      "norm_vf  |   14.21 |    3.11 |    3.46 |   19.53\n",
      "thrust   |    1302      67    9143 |    2774    2751    2146 |  -10955  -13912   -5705 |   14997   14215   14999\n",
      "norm_thrust |    9922 |    2593 |    2000 |   15000\n",
      "fuel     |     263 |      10 |     241 |     298\n",
      "rewards  |  -33.00 |   10.60 |  -96.42 |  -18.10\n",
      "fuel_rewards |   -9.04 |    0.35 |  -10.25 |   -8.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.50 |    0.56 |    3.42\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.78 |    6.93 |    5.89 |   44.70\n",
      "tracking_rewards |  -23.97 |   10.37 |  -86.28 |   -9.67\n",
      "steps    |     273 |      19 |     239 |     324\n",
      "***** Episode 56110, Mean R = -34.3  Std R = 10.9  Min R = -79.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000681\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.0667\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.2753   4.1923  22.6568  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 56141, Mean R = -33.2  Std R = 8.7  Min R = -51.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000727\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00182\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5500   1.0164   7.5606  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 56172, Mean R = -35.5  Std R = 14.7  Min R = -97.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.962\n",
      "KL: 0.000623\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00194\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00219\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3023   3.9647  19.8359  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 56203, Mean R = -33.6  Std R = 9.9  Min R = -75.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000601\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6914   2.2191  10.3130  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 56234, Mean R = -31.8  Std R = 10.3  Min R = -57.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000535\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00225\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6785   3.7965  13.9700  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 56265, Mean R = -31.3  Std R = 8.5  Min R = -52.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000617\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00298\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6500   3.6571  18.2584  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 56296, Mean R = -32.8  Std R = 8.6  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000814\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.3165   2.2566  10.7280  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 56327, Mean R = -32.4  Std R = 8.6  Min R = -56.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000682\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.00247\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.7023   1.5839   8.8789  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 56358, Mean R = -32.5  Std R = 10.3  Min R = -68.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.96\n",
      "KL: 0.000851\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00234\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.44e+07\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.0667\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0217   1.8055  11.3436  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 56389, Mean R = -33.6  Std R = 10.9  Min R = -60.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000733\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2935   2.7965  12.4978  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0016   0.0071   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1820    ET =    226.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.5     2.6    -0.3 |    14.3    15.8     0.2 |   -30.9   -49.4    -0.8 |    48.4    36.7    -0.0\n",
      "v_f      |   -4.81    0.66  -12.88 |    2.03    1.44    3.18 |  -11.37   -3.82  -21.04 |    1.05    7.00   -1.99\n",
      "vr_f     |     2.8 |     1.0 |     1.0 |     8.0\n",
      "r_i      |  1009.1    24.8  2352.4 |   554.5   569.3    28.1 |     1.6  -996.0  2300.1 |  1995.2   996.9  2399.6\n",
      "v_i      |  -39.50   -0.53  -80.21 |   16.78   17.15    5.82 |  -69.90  -29.87  -90.00 |  -10.19   29.97  -70.02\n",
      "norm_rf  |    21.6 |    10.3 |     0.6 |    54.8\n",
      "norm_vf  |   13.90 |    3.57 |    2.80 |   23.98\n",
      "thrust   |    1198      52    9128 |    2695    2776    2133 |   -9824  -14275   -5999 |   14986   14181   15000\n",
      "norm_thrust |    9875 |    2601 |    2000 |   15000\n",
      "fuel     |     264 |      11 |     238 |     304\n",
      "rewards  |  -32.99 |   10.55 |  -97.93 |  -16.61\n",
      "fuel_rewards |   -9.06 |    0.38 |  -10.43 |   -8.18\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.49 |    0.62 |    4.40\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.23 |    8.60 |    4.03 |   49.75\n",
      "tracking_rewards |  -23.93 |   10.27 |  -88.04 |   -8.42\n",
      "steps    |     275 |      17 |     237 |     325\n",
      "***** Episode 56420, Mean R = -33.1  Std R = 12.6  Min R = -71.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000543\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00191\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.3565   6.6667  26.1126  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0036   0.0020   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 56451, Mean R = -34.1  Std R = 10.2  Min R = -70.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.0665\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.1284   6.7978  26.6340  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 56482, Mean R = -31.7  Std R = 12.3  Min R = -83.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000818\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00368\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00208\n",
      "Variance: 0.0665\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4839   1.8891   9.3810  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0019   0.0070   1.6645   0.7971   0.5555\n",
      "***** Episode 56513, Mean R = -31.8  Std R = 8.0  Min R = -60.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000633\n",
      "PolicyEntropy: -4.2\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.0025\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4322   3.3432  18.8321  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 56544, Mean R = -33.5  Std R = 8.2  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000738\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0038   4.0728  17.2234  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0013   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 56575, Mean R = -29.8  Std R = 6.9  Min R = -50.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000585\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.26e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3713   2.9428  15.9851  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 56606, Mean R = -34.7  Std R = 8.8  Min R = -57.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000684\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0961   2.0117   9.9349  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 56637, Mean R = -30.2  Std R = 8.8  Min R = -54.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000815\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6835   2.7612  15.0448  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 56668, Mean R = -31.2  Std R = 8.1  Min R = -49.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000711\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1682   1.7709   9.4067  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 56699, Mean R = -33.7  Std R = 8.9  Min R = -56.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000597\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4942   2.2165  10.8231  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0006   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1830    ET =    229.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.0     2.3    -0.3 |    13.5    15.7     0.2 |   -22.9   -52.4    -0.9 |    54.7    46.6    -0.0\n",
      "v_f      |   -4.90    0.72  -13.17 |    1.96    1.57    2.86 |  -11.49   -5.08  -21.44 |    0.00    5.50   -5.10\n",
      "vr_f     |     2.8 |     1.4 |     1.3 |    13.1\n",
      "r_i      |   976.6   -25.3  2347.5 |   550.8   583.7    28.7 |     9.3  -988.5  2300.1 |  1994.9   993.2  2399.3\n",
      "v_i      |  -37.90    0.65  -80.11 |   17.41   17.07    5.84 |  -69.91  -29.78  -89.96 |  -10.09   29.91  -70.06\n",
      "norm_rf  |    21.2 |    10.3 |     1.3 |    55.2\n",
      "norm_vf  |   14.22 |    3.21 |    5.44 |   22.16\n",
      "thrust   |    1162      46    9168 |    2772    2775    2143 |  -11237  -14115   -5529 |   14982   14044   15000\n",
      "norm_thrust |    9930 |    2600 |    2000 |   15000\n",
      "fuel     |     263 |      11 |     240 |     297\n",
      "rewards  |  -32.80 |   10.30 |  -99.76 |  -17.29\n",
      "fuel_rewards |   -9.03 |    0.39 |  -10.22 |   -8.24\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.47 |    0.49 |    0.68 |    3.31\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.96 |    8.52 |    4.59 |   50.23\n",
      "tracking_rewards |  -23.77 |   10.02 |  -89.59 |   -8.82\n",
      "steps    |     272 |      17 |     238 |     323\n",
      "***** Episode 56730, Mean R = -37.3  Std R = 16.8  Min R = -99.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.987\n",
      "ExplainedVarOld: 0.989\n",
      "KL: 0.000776\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.45e+07\n",
      "ValFuncLoss: 0.00185\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.6302   4.2047  17.7819  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 56761, Mean R = -34.0  Std R = 12.5  Min R = -70.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000625\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00185\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1238   4.0948  21.1167  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 56792, Mean R = -34.3  Std R = 11.1  Min R = -63.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000699\n",
      "PolicyEntropy: -4.21\n",
      "PolicyLoss: -0.00351\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4396   2.7546  13.2928  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 56823, Mean R = -34.5  Std R = 11.2  Min R = -66.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000618\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.5838   1.8715  10.4579  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 56854, Mean R = -34.0  Std R = 8.9  Min R = -60.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00067\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.0661\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1097   2.2578  11.4897  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 56885, Mean R = -31.5  Std R = 6.6  Min R = -47.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000634\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.50e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00178\n",
      "Variance: 0.0661\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2287   2.4740  10.9789  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 56916, Mean R = -33.3  Std R = 7.9  Min R = -55.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00215\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4740   2.0038  11.0596  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0006   1.6645   0.7971   0.5555\n",
      "***** Episode 56947, Mean R = -33.6  Std R = 7.3  Min R = -51.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000994\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00206\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7859   3.2373  18.2381  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 56978, Mean R = -35.6  Std R = 13.3  Min R = -72.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000717\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00186\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8531   2.3836  14.4029  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 57009, Mean R = -32.1  Std R = 6.3  Min R = -49.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000754\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00355\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00179\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0047   1.3397   9.0893  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1840    ET =    240.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.0     2.6    -0.3 |    13.7    14.7     0.2 |   -22.9   -47.0    -0.9 |    51.8    49.2    -0.0\n",
      "v_f      |   -4.96    0.84  -12.81 |    2.11    1.50    3.11 |  -13.17   -3.31  -18.69 |   -0.27    5.84   -3.01\n",
      "vr_f     |     2.7 |     0.9 |     1.3 |     8.5\n",
      "r_i      |   990.8   -64.0  2351.9 |   588.8   590.4    28.8 |     1.8  -992.0  2301.0 |  1987.7   998.8  2400.0\n",
      "v_i      |  -39.21   -0.27  -80.14 |   17.61   17.74    5.88 |  -69.92  -29.77  -89.76 |  -10.01   29.58  -70.00\n",
      "norm_rf  |    20.3 |    10.0 |     1.2 |    54.5\n",
      "norm_vf  |   13.90 |    3.54 |    3.72 |   21.93\n",
      "thrust   |    1172      42    9185 |    2731    2844    2152 |   -9906  -14071   -5939 |   14988   14208   15000\n",
      "norm_thrust |    9957 |    2602 |    3464 |   15000\n",
      "fuel     |     265 |      11 |     240 |     304\n",
      "rewards  |  -33.44 |    9.67 |  -72.90 |  -19.10\n",
      "fuel_rewards |   -9.10 |    0.36 |  -10.47 |   -8.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.54 |    0.63 |    3.83\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.09 |    8.25 |    1.72 |   49.48\n",
      "tracking_rewards |  -24.35 |    9.43 |  -63.22 |  -10.51\n",
      "steps    |     273 |      17 |     229 |     331\n",
      "***** Episode 57040, Mean R = -31.6  Std R = 7.8  Min R = -54.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.961\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000766\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00189\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1807   1.0023   7.7854  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 57071, Mean R = -34.4  Std R = 17.0  Min R = -117.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.00078\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00265\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3093   3.2878  16.2230  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 57102, Mean R = -30.8  Std R = 7.2  Min R = -50.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000579\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00264\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.46e+07\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4071   2.5546  14.2788  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0015   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 57133, Mean R = -30.9  Std R = 7.4  Min R = -59.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000695\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.22e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00286\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.1913   3.0829  17.6640  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 57164, Mean R = -32.1  Std R = 6.3  Min R = -47.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000693\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00222\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6941   2.1190  11.3409  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 57195, Mean R = -33.9  Std R = 15.5  Min R = -100.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000649\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.0025\n",
      "Steps: 8.3e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9142   1.9920  11.2647  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0038   0.0022   0.0087   1.6645   0.7971   0.5555\n",
      "***** Episode 57226, Mean R = -34.9  Std R = 10.3  Min R = -70.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000728\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5140   2.2690  10.9853  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0020   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 57257, Mean R = -35.5  Std R = 11.0  Min R = -71.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000561\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3685   2.3384  10.5387  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 57288, Mean R = -35.1  Std R = 9.0  Min R = -59.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000674\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00266\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1108   1.4829   8.9542  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0031   0.0016   0.0066   1.6645   0.7971   0.5555\n",
      "***** Episode 57319, Mean R = -32.4  Std R = 11.8  Min R = -78.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000671\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.7e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00229\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  16.9817   7.9911  34.1559  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1850    ET =    226.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.2     3.3    -0.3 |    14.0    15.8     0.2 |   -20.6   -43.8    -0.9 |    54.5    40.0    -0.0\n",
      "v_f      |   -5.10    0.81  -13.28 |    2.03    1.63    2.98 |  -10.51   -4.03  -20.09 |   -0.43    7.18   -4.87\n",
      "vr_f     |     2.7 |     1.4 |     1.4 |    21.5\n",
      "r_i      |  1041.9   -32.7  2349.4 |   566.4   569.7    28.3 |     9.4  -994.2  2300.1 |  1990.0   964.4  2399.7\n",
      "v_i      |  -39.25    0.91  -79.89 |   16.98   17.65    5.79 |  -69.96  -29.85  -89.98 |  -10.14   29.97  -70.04\n",
      "norm_rf  |    21.3 |    10.3 |     0.4 |    58.9\n",
      "norm_vf  |   14.40 |    3.37 |    5.67 |   21.79\n",
      "thrust   |    1198     -22    9162 |    2715    2801    2144 |   -9864  -14123   -5416 |   14991   14247   15000\n",
      "norm_thrust |    9920 |    2606 |    2000 |   15000\n",
      "fuel     |     264 |      11 |     238 |     315\n",
      "rewards  |  -33.34 |   11.02 | -117.86 |  -18.26\n",
      "fuel_rewards |   -9.07 |    0.38 |  -10.85 |   -8.19\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.40 |    0.49 |    0.09 |    3.35\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.12 |    8.46 |    5.16 |   53.89\n",
      "tracking_rewards |  -24.27 |   10.76 | -107.01 |   -9.58\n",
      "steps    |     274 |      18 |     229 |     328\n",
      "***** Episode 57350, Mean R = -33.4  Std R = 8.2  Min R = -57.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000523\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00282\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00285\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5480   2.4767  12.3650  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0009   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 57381, Mean R = -37.1  Std R = 20.1  Min R = -97.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000561\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00208\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00292\n",
      "Variance: 0.0665\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.6944   2.2616  11.1563  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 57412, Mean R = -33.3  Std R = 8.0  Min R = -51.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000655\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00309\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1269   2.4862  13.3998  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 57443, Mean R = -30.2  Std R = 5.9  Min R = -50.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.47e+07\n",
      "ValFuncLoss: 0.00255\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2299   1.9707  13.2713  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 57474, Mean R = -33.5  Std R = 11.1  Min R = -68.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000594\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.0993   4.1978  19.2605  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 57505, Mean R = -34.4  Std R = 14.1  Min R = -76.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.985\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00349\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00308\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8890   3.3725  16.7227  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0034   0.0020   0.0070   1.6645   0.7971   0.5555\n",
      "***** Episode 57536, Mean R = -33.6  Std R = 7.7  Min R = -59.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000813\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.0665\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8703   2.6626  11.8107  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 57567, Mean R = -32.1  Std R = 12.9  Min R = -93.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000667\n",
      "PolicyEntropy: -4.22\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00289\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9706   3.7325  19.0106  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 57598, Mean R = -34.5  Std R = 16.4  Min R = -98.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000767\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00256\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00271\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.6012   3.7356  18.9024  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0009   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 57629, Mean R = -34.7  Std R = 12.2  Min R = -76.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000653\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00329\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7675   1.9689   9.8074  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1860    ET =    234.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     7.7     4.2    -0.3 |    12.8    14.1     0.2 |   -28.0   -39.0    -0.9 |    37.1    39.6    -0.0\n",
      "v_f      |   -4.64    0.47  -12.76 |    1.84    1.54    2.95 |   -9.82   -4.83  -20.08 |   -0.16    4.94   -1.57\n",
      "vr_f     |     2.9 |     1.5 |     1.5 |    20.2\n",
      "r_i      |   958.8    78.4  2349.8 |   540.2   578.1    29.5 |     5.8  -989.4  2300.0 |  1991.7   987.6  2399.9\n",
      "v_i      |  -39.85   -0.07  -80.07 |   17.52   16.71    5.78 |  -69.95  -29.83  -89.99 |  -10.28   29.64  -70.03\n",
      "norm_rf  |    19.0 |     8.7 |     0.2 |    46.3\n",
      "norm_vf  |   13.73 |    3.25 |    1.92 |   20.38\n",
      "thrust   |    1213     -16    9174 |    2815    2746    2145 |  -10764  -14177   -5806 |   14963   14017   14999\n",
      "norm_thrust |    9947 |    2598 |    2263 |   15000\n",
      "fuel     |     264 |      12 |     241 |     312\n",
      "rewards  |  -33.40 |   12.47 |  -98.45 |  -18.02\n",
      "fuel_rewards |   -9.06 |    0.41 |  -10.72 |   -8.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.47 |    0.52 |    0.31 |    4.64\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.08 |    6.66 |    5.62 |   41.30\n",
      "tracking_rewards |  -24.34 |   12.19 |  -88.50 |   -9.16\n",
      "steps    |     273 |      19 |     237 |     328\n",
      "***** Episode 57660, Mean R = -30.5  Std R = 7.1  Min R = -54.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000683\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00326\n",
      "Variance: 0.0667\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4518   4.8256  22.2374  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 57691, Mean R = -29.3  Std R = 6.6  Min R = -43.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000703\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00249\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00318\n",
      "Variance: 0.0667\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.3566   3.6943  18.7721  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 57722, Mean R = -33.9  Std R = 11.9  Min R = -86.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000835\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00291\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.7320   4.1045  18.1607  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 57753, Mean R = -34.3  Std R = 9.8  Min R = -66.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00273\n",
      "Variance: 0.0666\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.7690   4.2366  19.3919  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 57784, Mean R = -33.6  Std R = 11.0  Min R = -60.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -4.23\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5829   2.1525   9.9380  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 57815, Mean R = -35.6  Std R = 11.5  Min R = -67.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000786\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.48e+07\n",
      "ValFuncLoss: 0.00276\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2572   3.0314  13.4183  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 57846, Mean R = -30.8  Std R = 10.1  Min R = -65.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000612\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00259\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1053   3.7063  16.4947  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 57877, Mean R = -33.1  Std R = 11.1  Min R = -82.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000913\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00229\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.8957   6.0303  25.4475  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0009   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 57908, Mean R = -35.0  Std R = 12.3  Min R = -64.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000866\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00374\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00312\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1662   2.8222  13.8690  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 57939, Mean R = -33.5  Std R = 9.6  Min R = -66.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000628\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00267\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00223\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0244   1.9681  10.6019  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1870    ET =    237.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.2     1.4    -0.3 |    13.2    13.8     0.2 |   -26.8   -33.7    -0.9 |    39.0    42.5    -0.0\n",
      "v_f      |   -4.50    0.59  -12.53 |    1.87    1.45    3.11 |   -9.83   -5.29  -19.43 |    3.27    5.95   -4.00\n",
      "vr_f     |     2.9 |     1.2 |     1.6 |    14.3\n",
      "r_i      |   969.7    42.7  2349.9 |   560.8   579.1    29.1 |    18.0  -970.8  2300.3 |  1996.9   995.9  2400.0\n",
      "v_i      |  -39.37    0.00  -80.66 |   17.31   17.51    5.73 |  -69.93  -29.77  -90.00 |  -10.42   29.92  -70.15\n",
      "norm_rf  |    18.2 |     8.6 |     0.7 |    47.0\n",
      "norm_vf  |   13.46 |    3.40 |    4.16 |   20.42\n",
      "thrust   |    1204      40    9159 |    2802    2806    2134 |  -10089  -13950   -6388 |   14983   14250   14999\n",
      "norm_thrust |    9936 |    2625 |    2000 |   15000\n",
      "fuel     |     265 |      11 |     242 |     314\n",
      "rewards  |  -33.34 |   11.31 |  -89.59 |  -18.72\n",
      "fuel_rewards |   -9.10 |    0.39 |  -10.77 |   -8.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.47 |    0.50 |    3.51\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   15.48 |    6.44 |    4.79 |   42.04\n",
      "tracking_rewards |  -24.24 |   11.03 |  -79.73 |  -10.04\n",
      "steps    |     274 |      18 |     233 |     332\n",
      "***** Episode 57970, Mean R = -34.4  Std R = 15.7  Min R = -89.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000677\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6009   3.5154  14.8658  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0045   1.6645   0.7971   0.5555\n",
      "***** Episode 58001, Mean R = -34.2  Std R = 8.6  Min R = -54.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000609\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00246\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7564   3.1168  16.8429  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0042   1.6645   0.7971   0.5555\n",
      "***** Episode 58032, Mean R = -33.9  Std R = 12.6  Min R = -73.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000845\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3803   4.3372  18.2707  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 58063, Mean R = -35.5  Std R = 15.2  Min R = -89.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000764\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0882   1.9994  10.8374  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 58094, Mean R = -33.2  Std R = 8.6  Min R = -52.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000677\n",
      "PolicyEntropy: -4.24\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.0023\n",
      "Variance: 0.0664\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.1799   1.9334  10.3489  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0010   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 58125, Mean R = -33.4  Std R = 6.9  Min R = -50.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000595\n",
      "PolicyEntropy: -4.25\n",
      "PolicyLoss: -0.00253\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7479   2.0235  10.6324  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 58156, Mean R = -34.9  Std R = 11.8  Min R = -72.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000781\n",
      "PolicyEntropy: -4.25\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7346   2.7330  16.0110  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 58187, Mean R = -34.7  Std R = 14.9  Min R = -99.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000607\n",
      "PolicyEntropy: -4.25\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.49e+07\n",
      "ValFuncLoss: 0.00236\n",
      "Variance: 0.0663\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.4954   4.5367  21.6740  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 58218, Mean R = -30.8  Std R = 8.1  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000671\n",
      "PolicyEntropy: -4.25\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00223\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8556   1.5598  12.4178  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 58249, Mean R = -30.7  Std R = 6.8  Min R = -46.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000689\n",
      "PolicyEntropy: -4.26\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00258\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7484   1.9123   9.5958  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1880    ET =    229.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.6     2.8    -0.3 |    14.2    15.0     0.2 |   -23.9   -37.0    -1.0 |    49.0    37.3    -0.0\n",
      "v_f      |   -4.60    0.71  -12.57 |    1.83    1.51    3.15 |   -9.54   -3.37  -20.15 |    1.07    6.67   -2.63\n",
      "vr_f     |     2.8 |     0.9 |     1.4 |     8.4\n",
      "r_i      |   996.8     7.6  2347.1 |   586.9   589.1    28.1 |     0.1  -972.0  2300.1 |  1994.7   994.6  2398.6\n",
      "v_i      |  -39.86   -0.39  -80.10 |   17.23   17.32    5.77 |  -69.87  -29.86  -89.96 |  -10.19   29.93  -70.01\n",
      "norm_rf  |    20.1 |     8.7 |     1.0 |    49.0\n",
      "norm_vf  |   13.54 |    3.45 |    3.24 |   21.53\n",
      "thrust   |    1197      45    9113 |    2767    2799    2151 |  -10895  -13998   -5161 |   14980   14079   15000\n",
      "norm_thrust |    9882 |    2637 |    2191 |   15000\n",
      "fuel     |     265 |      11 |     241 |     308\n",
      "rewards  |  -33.34 |   10.78 |  -99.90 |  -17.49\n",
      "fuel_rewards |   -9.11 |    0.39 |  -10.58 |   -8.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.49 |    0.59 |    3.24\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.75 |    6.92 |    5.43 |   44.00\n",
      "tracking_rewards |  -24.23 |   10.50 |  -89.82 |   -8.92\n",
      "steps    |     276 |      19 |     237 |     335\n",
      "***** Episode 58280, Mean R = -32.1  Std R = 8.8  Min R = -57.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000602\n",
      "PolicyEntropy: -4.26\n",
      "PolicyLoss: -0.0028\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00288\n",
      "Variance: 0.0662\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8790   2.0751  12.5219  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 58311, Mean R = -34.8  Std R = 8.3  Min R = -59.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000781\n",
      "PolicyEntropy: -4.26\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.66e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.0661\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8172   3.0901  14.8798  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 58342, Mean R = -31.9  Std R = 7.1  Min R = -47.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000599\n",
      "PolicyEntropy: -4.26\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.0023\n",
      "Variance: 0.0661\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0188   2.1224  11.0287  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 58373, Mean R = -31.9  Std R = 8.7  Min R = -67.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000619\n",
      "PolicyEntropy: -4.26\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00238\n",
      "Variance: 0.0661\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.6010   4.5441  16.8993  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 58404, Mean R = -32.5  Std R = 7.4  Min R = -48.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000722\n",
      "PolicyEntropy: -4.26\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00168\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.3347   3.8959  17.9856  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0010   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 58435, Mean R = -31.2  Std R = 7.0  Min R = -49.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000908\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.0018\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.6954   4.3912  22.0843  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 58466, Mean R = -33.7  Std R = 9.3  Min R = -57.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000757\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00131\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  15.9014   7.0404  29.8227  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 58497, Mean R = -32.8  Std R = 8.2  Min R = -61.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000925\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00248\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00186\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.2499   6.5817  25.8547  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 58528, Mean R = -34.4  Std R = 10.7  Min R = -65.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000743\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.75e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6743   3.0030  14.6302  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 58559, Mean R = -29.1  Std R = 7.7  Min R = -59.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000745\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00338\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.5e+07\n",
      "ValFuncLoss: 0.00133\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7436   2.2405  12.3671  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0039   0.0019   0.0086   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1890    ET =    238.2   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.2     4.2    -0.3 |    14.9    14.2     0.2 |   -24.6   -38.8    -0.8 |    58.0    41.9    -0.0\n",
      "v_f      |   -4.78    0.45  -12.43 |    2.13    1.32    3.04 |  -12.29   -3.50  -17.91 |    0.10    4.09   -4.78\n",
      "vr_f     |     2.9 |     2.7 |     1.4 |    46.8\n",
      "r_i      |  1028.4     0.6  2351.0 |   565.2   563.4    28.6 |    14.4  -999.4  2300.0 |  1996.4   975.7  2400.0\n",
      "v_i      |  -38.61    0.98  -79.89 |   16.83   17.47    5.87 |  -69.91  -29.93  -89.91 |  -10.06   29.99  -70.05\n",
      "norm_rf  |    20.4 |     9.7 |     2.7 |    58.4\n",
      "norm_vf  |   13.45 |    3.48 |    4.93 |   21.52\n",
      "thrust   |    1144     -14    9148 |    2656    2751    2100 |  -10251  -13982   -5817 |   14998   13903   15000\n",
      "norm_thrust |    9875 |    2551 |    2000 |   15000\n",
      "fuel     |     264 |      10 |     244 |     305\n",
      "rewards  |  -32.23 |    8.37 |  -67.25 |  -16.64\n",
      "fuel_rewards |   -9.08 |    0.35 |  -10.49 |   -8.39\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.51 |    0.56 |    3.48\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.09 |    7.97 |    4.50 |   53.39\n",
      "tracking_rewards |  -23.15 |    8.12 |  -57.86 |   -8.08\n",
      "steps    |     275 |      17 |     240 |     326\n",
      "***** Episode 58590, Mean R = -30.0  Std R = 6.8  Min R = -51.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000624\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00269\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00172\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4232   4.3147  19.1559  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 58621, Mean R = -30.9  Std R = 7.0  Min R = -52.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000729\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1942   1.9391  11.2673  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 58652, Mean R = -32.8  Std R = 11.5  Min R = -78.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000693\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00168\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2989   3.1064  18.2545  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 58683, Mean R = -31.2  Std R = 10.3  Min R = -71.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000828\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00285\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00176\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6701   3.3322  17.9234  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 58714, Mean R = -32.1  Std R = 7.5  Min R = -48.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.0007\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00159\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5173   2.4029  13.5030  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0013   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 58745, Mean R = -33.4  Std R = 9.6  Min R = -62.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000689\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00148\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.6469   4.5709  22.8796  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 58776, Mean R = -29.3  Std R = 4.0  Min R = -38.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00278\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.0018\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7166   2.1816  10.7917  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0033   1.6645   0.7971   0.5555\n",
      "***** Episode 58807, Mean R = -32.9  Std R = 8.7  Min R = -64.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000842\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  15.0242   6.7037  30.4203  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 58838, Mean R = -34.0  Std R = 9.3  Min R = -58.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000899\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0712   2.5173  13.5836  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 58869, Mean R = -34.0  Std R = 12.0  Min R = -86.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000711\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3687   3.6232  15.8151  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1900    ET =    232.5   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.6     3.7    -0.3 |    14.1    15.6     0.2 |   -26.0   -39.4    -0.9 |    42.7    43.6    -0.0\n",
      "v_f      |   -4.60    0.52  -12.57 |    1.88    1.54    2.90 |  -11.02   -4.14  -20.79 |   -0.24    4.85   -3.70\n",
      "vr_f     |     2.8 |     0.9 |     1.5 |     9.1\n",
      "r_i      |  1063.9   -14.2  2350.5 |   569.8   581.9    29.5 |     0.2  -999.3  2300.2 |  1997.2   998.6  2399.1\n",
      "v_i      |  -40.88    0.13  -80.05 |   16.47   17.19    5.75 |  -69.73  -29.74  -89.99 |  -10.22   29.81  -70.00\n",
      "norm_rf  |    21.0 |     9.3 |     1.9 |    47.2\n",
      "norm_vf  |   13.54 |    3.24 |    3.79 |   21.60\n",
      "thrust   |    1229      19    9122 |    2600    2736    2122 |   -9841  -13995   -6110 |   14942   14199   15000\n",
      "norm_thrust |    9843 |    2564 |    2641 |   15000\n",
      "fuel     |     264 |      10 |     243 |     295\n",
      "rewards  |  -32.02 |    9.08 |  -86.52 |  -17.58\n",
      "fuel_rewards |   -9.07 |    0.34 |  -10.14 |   -8.36\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.39 |    0.45 |    0.67 |    2.97\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.38 |    7.81 |    4.68 |   42.15\n",
      "tracking_rewards |  -22.95 |    8.86 |  -76.72 |   -9.03\n",
      "steps    |     276 |      19 |     230 |     337\n",
      "***** Episode 58900, Mean R = -29.6  Std R = 6.3  Min R = -43.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.965\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000526\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.51e+07\n",
      "ValFuncLoss: 0.0019\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5885   3.1641  14.3242  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0044   1.6645   0.7971   0.5555\n",
      "***** Episode 58931, Mean R = -34.3  Std R = 9.2  Min R = -58.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000844\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 8.63e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.0018\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8275   3.2226  20.2753  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 58962, Mean R = -32.8  Std R = 13.6  Min R = -91.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.0007\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00369\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00148\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9096   3.6322  17.0500  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 58993, Mean R = -35.6  Std R = 10.0  Min R = -63.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000579\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00325\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00177\n",
      "Variance: 0.0655\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.9764   1.1837   7.7900  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 59024, Mean R = -32.3  Std R = 12.4  Min R = -80.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000571\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00191\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0390   2.5831  13.0054  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0013   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 59055, Mean R = -34.9  Std R = 10.7  Min R = -64.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000734\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00343\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00188\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.6449   6.4257  27.3531  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 59086, Mean R = -32.7  Std R = 7.2  Min R = -48.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000618\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00254\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.4885   5.3968  24.2634  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 59117, Mean R = -31.0  Std R = 8.2  Min R = -52.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000777\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7632   2.9224  15.9597  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 59148, Mean R = -33.4  Std R = 9.1  Min R = -67.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000757\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00385\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00216\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.6438   1.3686   9.1820  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 59179, Mean R = -34.1  Std R = 15.4  Min R = -98.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000705\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.63e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00157\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.5348   1.1284   6.5707  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0006   0.0023   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1910    ET =    236.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.9     3.5    -0.3 |    15.3    17.0     0.2 |   -22.7   -59.7    -1.1 |    55.3    37.9    -0.0\n",
      "v_f      |   -4.80    0.43  -12.74 |    2.15    1.73    3.01 |  -12.04   -4.33  -23.37 |    0.01    8.67   -3.82\n",
      "vr_f     |     2.7 |     0.9 |     1.5 |     8.4\n",
      "r_i      |  1038.1    22.4  2352.1 |   579.8   597.0    28.5 |     5.4  -999.8  2300.4 |  1979.8   999.5  2399.2\n",
      "v_i      |  -39.51    0.52  -79.74 |   16.62   17.31    5.89 |  -69.90  -29.70  -89.91 |  -10.02   29.80  -70.05\n",
      "norm_rf  |    22.8 |    10.6 |     2.2 |    60.9\n",
      "norm_vf  |   13.80 |    3.42 |    4.48 |   26.31\n",
      "thrust   |    1201      -2    9139 |    2670    2846    2149 |   -9893  -14028   -6163 |   14998   14049   15000\n",
      "norm_thrust |    9898 |    2615 |    2000 |   15000\n",
      "fuel     |     265 |      11 |     243 |     317\n",
      "rewards  |  -33.25 |   10.81 |  -98.94 |  -18.19\n",
      "fuel_rewards |   -9.10 |    0.39 |  -10.90 |   -8.35\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.38 |    0.46 |    0.24 |    3.27\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.11 |    9.02 |    4.70 |   55.87\n",
      "tracking_rewards |  -24.14 |   10.51 |  -88.84 |   -9.52\n",
      "steps    |     275 |      17 |     235 |     332\n",
      "***** Episode 59210, Mean R = -31.5  Std R = 8.5  Min R = -66.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.7e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6280   2.7825  15.7217  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 59241, Mean R = -32.4  Std R = 9.9  Min R = -66.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00193\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.4220   3.4036  15.1153  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 59272, Mean R = -32.7  Std R = 10.2  Min R = -80.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000616\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.52e+07\n",
      "ValFuncLoss: 0.00224\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  17.1801   8.3405  28.0923  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0015   1.6645   0.7971   0.5555\n",
      "***** Episode 59303, Mean R = -32.0  Std R = 9.7  Min R = -60.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000605\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00261\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.8694   7.1978  27.6296  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 59334, Mean R = -34.3  Std R = 12.2  Min R = -87.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.3074   4.4396  18.6269  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 59365, Mean R = -31.9  Std R = 7.5  Min R = -49.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000823\n",
      "PolicyEntropy: -4.27\n",
      "PolicyLoss: -0.00188\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00196\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7128   4.0951  21.1088  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 59396, Mean R = -34.2  Std R = 13.7  Min R = -89.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.985\n",
      "KL: 0.000696\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0032   2.9698  17.8472  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 59427, Mean R = -29.8  Std R = 6.2  Min R = -44.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000703\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.73e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0959   4.6623  26.5028  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 59458, Mean R = -35.3  Std R = 12.1  Min R = -76.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000625\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00204\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0307   3.9973  16.0560  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 59489, Mean R = -34.5  Std R = 12.4  Min R = -83.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000702\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.3664   5.4648  22.4770  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1920    ET =    236.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.2     1.2    -0.3 |    15.0    16.8     0.2 |   -23.1   -41.6    -0.8 |    41.9    45.3    -0.0\n",
      "v_f      |   -4.61    0.60  -12.57 |    2.04    1.60    3.11 |   -9.51   -3.61  -22.90 |   -0.45    7.67   -4.30\n",
      "vr_f     |     2.9 |     1.2 |     1.5 |    14.8\n",
      "r_i      |  1002.3   -16.3  2349.6 |   566.2   599.5    29.1 |     3.3  -995.7  2300.0 |  1987.6   999.2  2399.1\n",
      "v_i      |  -38.89   -2.32  -80.24 |   16.34   16.87    6.01 |  -69.87  -29.95  -89.96 |  -10.02   29.18  -70.13\n",
      "norm_rf  |    22.4 |     9.7 |     1.2 |    49.9\n",
      "norm_vf  |   13.56 |    3.49 |    4.62 |   23.37\n",
      "thrust   |    1179     117    9147 |    2672    2829    2151 |   -9621  -14136   -5329 |   14998   14068   15000\n",
      "norm_thrust |    9900 |    2614 |    2000 |   15000\n",
      "fuel     |     265 |      11 |     240 |     310\n",
      "rewards  |  -33.20 |   10.61 |  -89.60 |  -18.48\n",
      "fuel_rewards |   -9.09 |    0.39 |  -10.67 |   -8.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.50 |    0.65 |    4.38\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.65 |    8.22 |    3.77 |   44.85\n",
      "tracking_rewards |  -24.11 |   10.35 |  -79.71 |  -10.21\n",
      "steps    |     275 |      18 |     231 |     328\n",
      "***** Episode 59520, Mean R = -34.9  Std R = 8.4  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000841\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00221\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2113   3.8394  18.1995  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 59551, Mean R = -31.5  Std R = 9.9  Min R = -61.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000604\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.0659\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1549   2.6228  13.8823  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0005   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 59582, Mean R = -32.8  Std R = 9.8  Min R = -57.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000964\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00235\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.2599   2.2290  12.3461  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 59613, Mean R = -31.5  Std R = 8.8  Min R = -59.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000756\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00224\n",
      "Variance: 0.0658\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3582   2.8188  17.6893  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 59644, Mean R = -33.4  Std R = 10.2  Min R = -67.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -4.28\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.50e+03\n",
      "TotalSteps: 1.53e+07\n",
      "ValFuncLoss: 0.00234\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.2895   2.6391  13.7930  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 59675, Mean R = -33.1  Std R = 11.8  Min R = -80.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000644\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.9e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00209\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8543   2.6242  14.1118  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0006   1.6645   0.7971   0.5555\n",
      "***** Episode 59706, Mean R = -34.9  Std R = 12.2  Min R = -72.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.00056\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.0657\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.4675   5.9139  22.9991  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0042   0.0024   0.0095   1.6645   0.7971   0.5555\n",
      "***** Episode 59737, Mean R = -39.3  Std R = 20.1  Min R = -107.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000611\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.00226\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00281\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3404   3.3394  14.4550  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0016   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 59768, Mean R = -32.3  Std R = 9.6  Min R = -58.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.944\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00074\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.00248\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00274\n",
      "Variance: 0.0656\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.9770   3.9619  16.4544  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0010   0.0037   1.6645   0.7971   0.5555\n",
      "***** Episode 59799, Mean R = -29.7  Std R = 6.7  Min R = -47.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.964\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000968\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00232\n",
      "Variance: 0.0655\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0916   1.9220  10.2608  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0026   0.0012   0.0049   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1930    ET =    226.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.6     2.1    -0.3 |    15.2    17.6     0.2 |   -24.2   -43.3    -0.9 |    44.2    46.8    -0.0\n",
      "v_f      |   -4.71    0.64  -12.80 |    2.08    1.75    3.00 |  -10.09   -4.34  -20.73 |    0.99    7.00   -4.49\n",
      "vr_f     |     2.8 |     1.0 |     1.5 |     9.4\n",
      "r_i      |  1010.9   -32.6  2350.8 |   582.6   591.5    29.8 |     3.6  -999.6  2300.4 |  1996.2   998.7  2399.8\n",
      "v_i      |  -38.87   -0.77  -79.44 |   16.66   17.58    5.98 |  -69.33  -29.93  -89.88 |  -10.08   29.99  -70.03\n",
      "norm_rf  |    22.6 |    10.3 |     2.1 |    51.6\n",
      "norm_vf  |   13.84 |    3.39 |    4.65 |   21.94\n",
      "thrust   |    1196      60    9122 |    2681    2880    2172 |   -9965  -14343   -6178 |   14958   14051   14998\n",
      "norm_thrust |    9892 |    2645 |    2000 |   15000\n",
      "fuel     |     265 |      12 |     239 |     315\n",
      "rewards  |  -33.40 |   12.10 | -107.94 |  -15.00\n",
      "fuel_rewards |   -9.11 |    0.41 |  -10.84 |   -8.22\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.53 |    0.07 |    3.39\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.02 |    8.73 |    3.14 |   46.56\n",
      "tracking_rewards |  -24.29 |   11.82 |  -97.89 |   -6.66\n",
      "steps    |     276 |      18 |     238 |     329\n",
      "***** Episode 59830, Mean R = -35.4  Std R = 14.1  Min R = -91.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.964\n",
      "KL: 0.000724\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00205\n",
      "Variance: 0.0654\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6232   3.3628  19.1864  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0041   1.6645   0.7971   0.5555\n",
      "***** Episode 59861, Mean R = -30.7  Std R = 7.2  Min R = -49.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.00051\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00251\n",
      "Variance: 0.0654\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6972   3.2531  14.9600  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 59892, Mean R = -40.0  Std R = 20.8  Min R = -106.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.985\n",
      "KL: 0.000769\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00218\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00325\n",
      "Variance: 0.0653\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1659   4.5694  18.7301  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 59923, Mean R = -33.8  Std R = 8.2  Min R = -51.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000989\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00272\n",
      "Variance: 0.0652\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0480   2.1775  12.1361  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0022   0.0012   0.0051   1.6645   0.7971   0.5555\n",
      "***** Episode 59954, Mean R = -31.8  Std R = 9.0  Min R = -59.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000664\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.0033\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00226\n",
      "Variance: 0.0652\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8018   1.9617  11.0958  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 59985, Mean R = -32.4  Std R = 10.5  Min R = -68.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000632\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.54e+07\n",
      "ValFuncLoss: 0.00237\n",
      "Variance: 0.0653\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1024   2.6238  12.3862  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 60016, Mean R = -30.4  Std R = 7.7  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.958\n",
      "ExplainedVarOld: 0.948\n",
      "KL: 0.00064\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00252\n",
      "Steps: 8.7e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00227\n",
      "Variance: 0.0652\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6687   2.7283  13.4767  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0015   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 60047, Mean R = -34.7  Std R = 16.2  Min R = -112.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00277\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.0026\n",
      "Variance: 0.0651\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0848   1.6197   9.2487  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 60078, Mean R = -31.9  Std R = 10.9  Min R = -77.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.000645\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00235\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00286\n",
      "Variance: 0.0651\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7618   1.4225   9.4041  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 60109, Mean R = -34.7  Std R = 13.7  Min R = -98.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000735\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00313\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00246\n",
      "Variance: 0.0651\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6301   2.1922  13.4846  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1940    ET =    235.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.9     1.7    -0.3 |    15.3    16.6     0.2 |   -25.9   -51.3    -0.9 |    43.0    43.3    -0.0\n",
      "v_f      |   -4.56    0.46  -12.44 |    2.03    1.56    3.14 |  -11.02   -3.71  -19.78 |    0.07    7.55   -2.63\n",
      "vr_f     |     2.9 |     1.7 |     1.3 |    27.6\n",
      "r_i      |   965.3   -20.4  2347.0 |   564.7   586.8    28.1 |     3.5  -993.8  2300.2 |  1997.4   985.6  2399.2\n",
      "v_i      |  -39.02   -1.42  -79.90 |   16.73   16.98    5.75 |  -69.79  -29.98  -89.99 |  -10.02   29.92  -70.31\n",
      "norm_rf  |    21.4 |    10.1 |     0.9 |    51.3\n",
      "norm_vf  |   13.41 |    3.51 |    2.64 |   20.24\n",
      "thrust   |    1206      75    9145 |    2707    2762    2175 |  -10154  -13995   -5795 |   14996   13884   14999\n",
      "norm_thrust |    9894 |    2624 |    2000 |   15000\n",
      "fuel     |     264 |      10 |     243 |     307\n",
      "rewards  |  -33.36 |   12.45 | -112.01 |  -17.80\n",
      "fuel_rewards |   -9.08 |    0.36 |  -10.53 |   -8.36\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.50 |    0.36 |    3.25\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.01 |    8.41 |    4.27 |   46.30\n",
      "tracking_rewards |  -24.28 |   12.21 | -101.48 |   -9.34\n",
      "steps    |     275 |      18 |     240 |     337\n",
      "***** Episode 60140, Mean R = -33.3  Std R = 10.4  Min R = -66.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000571\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.0027\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00229\n",
      "Variance: 0.0651\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6505   4.6593  19.9716  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 60171, Mean R = -31.6  Std R = 6.9  Min R = -61.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000722\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00304\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00248\n",
      "Variance: 0.0652\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.7109   3.3626  18.2652  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 60202, Mean R = -30.0  Std R = 8.1  Min R = -48.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000844\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00227\n",
      "Variance: 0.0653\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8359   3.1090  16.9319  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0035   0.0020   0.0075   1.6645   0.7971   0.5555\n",
      "***** Episode 60233, Mean R = -33.2  Std R = 10.1  Min R = -59.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000585\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00258\n",
      "Variance: 0.0653\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.1828   2.7429  13.5798  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 60264, Mean R = -36.8  Std R = 15.0  Min R = -91.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000806\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.0652\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5636   1.8458  12.2680  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 60295, Mean R = -33.2  Std R = 8.7  Min R = -66.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000636\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.0652\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6055   3.2517  15.5159  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 60326, Mean R = -31.6  Std R = 9.3  Min R = -61.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000793\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00225\n",
      "Variance: 0.0654\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0563   4.0800  21.1195  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 60357, Mean R = -34.5  Std R = 10.1  Min R = -69.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000705\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00263\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.55e+07\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.0654\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6030   3.5247  18.3803  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 60388, Mean R = -32.3  Std R = 9.7  Min R = -73.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000615\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.52e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.0655\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.0805   3.2337  16.4159  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 60419, Mean R = -34.3  Std R = 12.5  Min R = -74.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000727\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.00275\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.0655\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8516   2.7646  15.1846  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1950    ET =    233.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     7.3     0.2    -0.3 |    15.5    15.7     0.2 |   -26.4   -46.0    -0.9 |    44.0    43.5    -0.0\n",
      "v_f      |   -4.50    0.48  -12.44 |    2.00    1.48    2.90 |   -9.58   -4.86  -20.70 |    0.53    5.52   -5.01\n",
      "vr_f     |     3.0 |     1.6 |     1.4 |    15.9\n",
      "r_i      |   967.3   -18.7  2353.6 |   566.4   586.7    29.5 |     2.8  -989.2  2301.1 |  1990.5   978.0  2400.0\n",
      "v_i      |  -39.88   -2.62  -80.15 |   17.02   16.92    5.81 |  -69.77  -29.78  -89.89 |  -10.05   29.97  -70.02\n",
      "norm_rf  |    21.1 |     9.9 |     2.1 |    47.8\n",
      "norm_vf  |   13.39 |    3.24 |    5.28 |   21.06\n",
      "thrust   |    1224     118    9152 |    2746    2833    2134 |   -9670  -14110   -6289 |   14994   13835   15000\n",
      "norm_thrust |    9927 |    2616 |    2387 |   15000\n",
      "fuel     |     266 |      11 |     244 |     307\n",
      "rewards  |  -33.40 |   10.60 |  -91.17 |  -17.53\n",
      "fuel_rewards |   -9.14 |    0.37 |  -10.57 |   -8.39\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.46 |    0.62 |    3.52\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.73 |    8.06 |    4.75 |   42.77\n",
      "tracking_rewards |  -24.26 |   10.33 |  -80.80 |   -9.14\n",
      "steps    |     276 |      18 |     243 |     332\n",
      "***** Episode 60450, Mean R = -36.6  Std R = 11.2  Min R = -68.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000658\n",
      "PolicyEntropy: -4.29\n",
      "PolicyLoss: -0.00306\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.0655\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.6937   3.5674  19.9090  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 60481, Mean R = -34.8  Std R = 8.4  Min R = -60.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000781\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00341\n",
      "Steps: 8.67e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.0653\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8188   3.3319  16.3616  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 60512, Mean R = -32.4  Std R = 11.0  Min R = -79.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000784\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00375\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.0652\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7723   2.2689  13.6471  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 60543, Mean R = -32.2  Std R = 8.2  Min R = -53.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.97\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000785\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00177\n",
      "Variance: 0.0651\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0613   2.2275  12.1992  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 60574, Mean R = -31.7  Std R = 9.2  Min R = -59.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000634\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00213\n",
      "Variance: 0.0651\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.2167   4.8316  23.1240  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 60605, Mean R = -31.6  Std R = 9.1  Min R = -68.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000946\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.66e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00166\n",
      "Variance: 0.0651\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9676   2.5382  13.9072  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 60636, Mean R = -30.5  Std R = 7.1  Min R = -48.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000607\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.065\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9579   2.8519  13.9371  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 60667, Mean R = -33.1  Std R = 9.4  Min R = -60.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000722\n",
      "PolicyEntropy: -4.3\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.065\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.8227   1.3097   7.9941  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 60698, Mean R = -34.2  Std R = 17.2  Min R = -116.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.957\n",
      "KL: 0.000617\n",
      "PolicyEntropy: -4.31\n",
      "PolicyLoss: -0.00221\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00196\n",
      "Variance: 0.0649\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   3.6363   1.6320   8.9253  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0045   0.0025   0.0101   1.6645   0.7971   0.5555\n",
      "***** Episode 60729, Mean R = -34.0  Std R = 11.3  Min R = -78.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.922\n",
      "KL: 0.000729\n",
      "PolicyEntropy: -4.31\n",
      "PolicyLoss: -0.00194\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.56e+07\n",
      "ValFuncLoss: 0.00213\n",
      "Variance: 0.0646\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.7505   4.4955  20.5163  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1960    ET =    236.9   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.9     0.7    -0.3 |    16.1    15.3     0.2 |   -32.6   -50.7    -0.8 |    43.6    42.0    -0.0\n",
      "v_f      |   -4.63    0.72  -12.65 |    2.01    1.49    2.95 |   -9.76   -4.60  -19.04 |    0.04    7.07   -4.28\n",
      "vr_f     |     3.1 |     2.7 |     1.4 |    46.3\n",
      "r_i      |  1014.7   -45.5  2350.0 |   592.1   559.2    29.1 |    31.2  -998.3  2300.3 |  1999.2   999.6  2399.9\n",
      "v_i      |  -39.16   -0.75  -79.75 |   17.40   16.31    5.81 |  -69.94  -29.80  -89.89 |  -10.04   29.99  -70.09\n",
      "norm_rf  |    21.2 |     9.6 |     1.3 |    55.2\n",
      "norm_vf  |   13.64 |    3.32 |    4.51 |   19.44\n",
      "thrust   |    1185      69    9107 |    2725    2714    2139 |   -9995  -14091   -5736 |   14994   14049   15000\n",
      "norm_thrust |    9848 |    2593 |    2103 |   15000\n",
      "fuel     |     265 |      10 |     243 |     300\n",
      "rewards  |  -32.89 |   10.96 | -116.88 |  -16.60\n",
      "fuel_rewards |   -9.11 |    0.36 |  -10.33 |   -8.34\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.52 |    0.66 |    3.31\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.74 |    7.93 |    4.83 |   50.24\n",
      "tracking_rewards |  -23.78 |   10.73 | -106.55 |   -8.09\n",
      "steps    |     277 |      18 |     239 |     326\n",
      "***** Episode 60760, Mean R = -34.2  Std R = 13.9  Min R = -74.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.00081\n",
      "PolicyEntropy: -4.31\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.0646\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.5454   3.8572  16.4991  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 60791, Mean R = -39.9  Std R = 20.1  Min R = -110.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.00072\n",
      "PolicyEntropy: -4.31\n",
      "PolicyLoss: -0.00273\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00204\n",
      "Variance: 0.0647\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2432   2.3613  11.5237  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 60822, Mean R = -30.2  Std R = 7.8  Min R = -53.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000583\n",
      "PolicyEntropy: -4.31\n",
      "PolicyLoss: -0.0023\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.0647\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.8840   2.2589  11.5317  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 60853, Mean R = -36.5  Std R = 17.9  Min R = -125.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.966\n",
      "KL: 0.000841\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00198\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00218\n",
      "Variance: 0.0645\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.2787   5.7211  22.4542  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 60884, Mean R = -33.7  Std R = 10.8  Min R = -68.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.967\n",
      "ExplainedVarOld: 0.968\n",
      "KL: 0.000696\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00207\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.0022\n",
      "Variance: 0.0644\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7557   3.1856  15.6971  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0010   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 60915, Mean R = -34.3  Std R = 10.5  Min R = -67.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000623\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.0645\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1384   2.4650  16.3235  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0012   0.0049   1.6645   0.7971   0.5555\n",
      "***** Episode 60946, Mean R = -34.8  Std R = 9.0  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.000741\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.0645\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5833   1.7634  12.8965  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 60977, Mean R = -34.3  Std R = 13.6  Min R = -93.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000603\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00219\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00219\n",
      "Variance: 0.0644\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.0277   3.1114  15.2904  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 61008, Mean R = -32.6  Std R = 6.9  Min R = -52.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.965\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.0644\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4958   4.0065  19.3444  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 61039, Mean R = -32.3  Std R = 10.4  Min R = -58.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000974\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00385\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00189\n",
      "Variance: 0.0644\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8264   4.6274  21.4160  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1970    ET =    226.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.0     2.1    -0.3 |    16.6    15.9     0.2 |   -29.2   -52.9    -1.0 |    61.9    32.3    -0.0\n",
      "v_f      |   -4.65    0.76  -12.95 |    2.22    1.67    3.17 |  -10.84   -3.72  -22.26 |    0.24    9.08   -5.04\n",
      "vr_f     |     3.0 |     1.3 |     1.5 |    11.0\n",
      "r_i      |   975.5   -31.2  2350.7 |   574.7   593.9    28.2 |     2.7  -995.9  2300.4 |  1998.9   994.7  2399.9\n",
      "v_i      |  -40.68   -1.41  -79.71 |   16.84   17.27    6.02 |  -70.00  -29.97  -89.95 |  -10.08   29.84  -70.05\n",
      "norm_rf  |    22.2 |    10.4 |     0.1 |    62.2\n",
      "norm_vf  |   13.95 |    3.62 |    5.14 |   22.67\n",
      "thrust   |    1276      87    9115 |    2761    2857    2148 |   -9384  -14128   -6099 |   14988   14144   15000\n",
      "norm_thrust |    9909 |    2632 |    2000 |   15000\n",
      "fuel     |     264 |      11 |     242 |     305\n",
      "rewards  |  -33.78 |   12.43 | -125.00 |  -17.29\n",
      "fuel_rewards |   -9.07 |    0.37 |  -10.46 |   -8.33\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.41 |    0.52 |    0.18 |    3.79\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.62 |    8.78 |    5.14 |   57.17\n",
      "tracking_rewards |  -24.71 |   12.18 | -114.96 |   -8.81\n",
      "steps    |     274 |      17 |     241 |     320\n",
      "***** Episode 61070, Mean R = -29.2  Std R = 5.3  Min R = -45.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.963\n",
      "KL: 0.000653\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.59e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00211\n",
      "Variance: 0.0643\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.0336   1.0985   7.7035  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0030   0.0015   0.0068   1.6645   0.7971   0.5555\n",
      "***** Episode 61101, Mean R = -36.1  Std R = 20.6  Min R = -140.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.944\n",
      "KL: 0.000711\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.57e+07\n",
      "ValFuncLoss: 0.00346\n",
      "Variance: 0.0642\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.7107   2.1328  12.1976  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 61132, Mean R = -34.0  Std R = 12.0  Min R = -89.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.956\n",
      "KL: 0.000778\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00244\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00313\n",
      "Variance: 0.0643\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3985   2.1654  10.7047  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 61163, Mean R = -30.1  Std R = 7.9  Min R = -53.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000772\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00332\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00291\n",
      "Variance: 0.0643\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.8235   1.5615   8.6070  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 61194, Mean R = -34.4  Std R = 9.8  Min R = -57.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000589\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00278\n",
      "Variance: 0.0642\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   4.3201   1.7055  10.7183  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 61225, Mean R = -30.6  Std R = 8.0  Min R = -58.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000627\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00284\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00224\n",
      "Variance: 0.0642\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7356   2.5979  10.6959  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 61256, Mean R = -29.7  Std R = 5.4  Min R = -41.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000631\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00346\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00252\n",
      "Variance: 0.0642\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1252   3.0195  16.9222  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 61287, Mean R = -30.6  Std R = 5.5  Min R = -42.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000506\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00253\n",
      "Variance: 0.0641\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2819   2.1255  12.1027  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 61318, Mean R = -34.1  Std R = 12.4  Min R = -90.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000803\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00243\n",
      "Variance: 0.0641\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4145   2.6174  14.6385  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 61349, Mean R = -33.4  Std R = 9.6  Min R = -73.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.00076\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00327\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.0641\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0462   3.2100  15.3482  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1980    ET =    231.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.2     3.8    -0.3 |    16.0    15.8     0.2 |   -31.0   -38.2    -0.8 |    50.6    52.9    -0.0\n",
      "v_f      |   -4.80    0.57  -13.31 |    2.18    1.56    2.80 |  -10.88   -3.73  -21.54 |    0.45    5.74   -5.15\n",
      "vr_f     |     3.1 |     1.9 |     1.4 |    22.3\n",
      "r_i      |   998.0    28.4  2348.9 |   577.1   576.9    29.6 |     2.2  -997.2  2300.2 |  1996.8   984.4  2399.2\n",
      "v_i      |  -39.30    0.90  -80.09 |   16.52   17.00    5.79 |  -69.95  -29.83  -89.97 |  -10.19   29.88  -70.03\n",
      "norm_rf  |    22.6 |    10.7 |     0.7 |    55.1\n",
      "norm_vf  |   14.32 |    3.22 |    5.16 |   22.33\n",
      "thrust   |    1195     -15    9162 |    2690    2827    2106 |   -9579  -14268   -6073 |   14991   14157   14999\n",
      "norm_thrust |    9920 |    2573 |    2000 |   15000\n",
      "fuel     |     263 |      11 |     240 |     313\n",
      "rewards  |  -32.37 |   11.15 | -140.10 |  -17.83\n",
      "fuel_rewards |   -9.05 |    0.37 |  -10.77 |   -8.26\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.52 |    0.06 |    3.79\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.29 |    8.77 |    4.74 |   50.12\n",
      "tracking_rewards |  -23.32 |   10.89 | -129.34 |   -9.35\n",
      "steps    |     273 |      17 |     240 |     325\n",
      "***** Episode 61380, Mean R = -30.7  Std R = 10.2  Min R = -66.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.97\n",
      "KL: 0.000625\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00237\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.0641\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3727   3.1844  17.1894  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0012   0.0050   1.6645   0.7971   0.5555\n",
      "***** Episode 61411, Mean R = -31.9  Std R = 9.9  Min R = -70.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000896\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.0642\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0405   2.4570  13.7360  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0008   0.0036   1.6645   0.7971   0.5555\n",
      "***** Episode 61442, Mean R = -34.9  Std R = 13.5  Min R = -88.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000755\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00301\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.58e+07\n",
      "ValFuncLoss: 0.00202\n",
      "Variance: 0.0643\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9080   1.9260  12.5124  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 61473, Mean R = -30.7  Std R = 10.3  Min R = -78.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000542\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00252\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00201\n",
      "Variance: 0.0643\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3922   2.1305  12.5842  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0011   0.0046   1.6645   0.7971   0.5555\n",
      "***** Episode 61504, Mean R = -32.4  Std R = 6.9  Min R = -50.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000765\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00214\n",
      "Variance: 0.0643\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4814   4.2148  20.4517  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0021   1.6645   0.7971   0.5555\n",
      "***** Episode 61535, Mean R = -36.3  Std R = 13.1  Min R = -82.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.00063\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00296\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00218\n",
      "Variance: 0.0643\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.0446   1.5390   9.2765  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0027   0.0014   0.0062   1.6645   0.7971   0.5555\n",
      "***** Episode 61566, Mean R = -33.6  Std R = 14.9  Min R = -98.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000708\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00293\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00241\n",
      "Variance: 0.0642\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8508   2.4455  13.4163  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 61597, Mean R = -34.1  Std R = 11.7  Min R = -71.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000789\n",
      "PolicyEntropy: -4.32\n",
      "PolicyLoss: -0.00309\n",
      "Steps: 8.64e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00203\n",
      "Variance: 0.0641\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.5195   4.3989  20.8487  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 61628, Mean R = -31.8  Std R = 10.4  Min R = -79.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000619\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00198\n",
      "Variance: 0.064\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3843   2.1112  10.9914  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 61659, Mean R = -33.8  Std R = 10.7  Min R = -71.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000877\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00331\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00199\n",
      "Variance: 0.064\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6945   2.4748  15.4794  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0024   0.0013   0.0049   1.6645   0.7971   0.5555\n",
      "Update Cnt = 1990    ET =    235.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.7    -0.5    -0.3 |    15.1    14.7     0.2 |   -34.8   -42.2    -0.8 |    41.3    41.1    -0.0\n",
      "v_f      |   -4.84    0.87  -12.88 |    2.09    1.51    2.94 |   -9.67   -3.97  -19.79 |    1.18    6.90   -2.90\n",
      "vr_f     |     2.8 |     1.1 |     1.4 |    13.5\n",
      "r_i      |  1029.2   -61.5  2347.8 |   569.5   558.3    29.1 |     9.4  -999.9  2300.4 |  1957.9   997.7  2399.5\n",
      "v_i      |  -41.10   -0.70  -79.10 |   16.91   17.75    5.70 |  -69.83  -29.77  -90.00 |  -10.51   29.57  -70.04\n",
      "norm_rf  |    21.5 |     9.8 |     1.1 |    49.2\n",
      "norm_vf  |   13.94 |    3.37 |    3.01 |   21.04\n",
      "thrust   |    1239      68    9080 |    2652    2831    2095 |  -10519  -14044   -5441 |   14995   13982   14999\n",
      "norm_thrust |    9838 |    2578 |    2000 |   15000\n",
      "fuel     |     263 |      11 |     241 |     323\n",
      "rewards  |  -33.10 |   11.26 |  -98.82 |  -16.88\n",
      "fuel_rewards |   -9.04 |    0.36 |  -11.11 |   -8.28\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.42 |    0.50 |    0.06 |    3.78\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.15 |    7.85 |    5.09 |   44.17\n",
      "tracking_rewards |  -24.06 |   10.99 |  -87.71 |   -8.34\n",
      "steps    |     275 |      16 |     237 |     322\n",
      "***** Episode 61690, Mean R = -31.3  Std R = 7.1  Min R = -50.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.969\n",
      "KL: 0.000697\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00198\n",
      "Variance: 0.064\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.0935   4.9187  22.2906  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0011   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 61721, Mean R = -33.4  Std R = 11.4  Min R = -88.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.00076\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00217\n",
      "Variance: 0.0641\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.4603   2.2533  11.9821  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0008   0.0035   1.6645   0.7971   0.5555\n",
      "***** Episode 61752, Mean R = -32.4  Std R = 7.1  Min R = -50.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.969\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000646\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00329\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.064\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.1570   2.0165  12.1232  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0026   1.6645   0.7971   0.5555\n",
      "***** Episode 61783, Mean R = -29.9  Std R = 6.8  Min R = -54.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000751\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.064\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.4391   4.0397  16.4157  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 61814, Mean R = -30.2  Std R = 6.6  Min R = -47.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000621\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.59e+07\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.064\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.3014   2.5320  12.8123  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 61845, Mean R = -32.1  Std R = 9.2  Min R = -57.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000702\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00336\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00231\n",
      "Variance: 0.0639\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2505   2.2572  10.5072  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0017   0.0010   0.0040   1.6645   0.7971   0.5555\n",
      "***** Episode 61876, Mean R = -32.4  Std R = 8.1  Min R = -48.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000521\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00172\n",
      "Variance: 0.0638\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  15.2377   7.2398  27.8367  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0011   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 61907, Mean R = -34.3  Std R = 11.6  Min R = -77.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000908\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00268\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00217\n",
      "Variance: 0.0637\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.5378   5.0436  20.3363  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 61938, Mean R = -32.8  Std R = 7.7  Min R = -50.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000661\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.002\n",
      "Variance: 0.0637\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8360   2.0317  13.5830  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 61969, Mean R = -33.9  Std R = 13.3  Min R = -85.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.0031\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00167\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5004   2.7564  12.5629  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0020   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2000    ET =    230.8   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    11.8     1.1    -0.3 |    16.4    15.0     0.2 |   -26.3   -40.4    -0.9 |    54.4    43.4    -0.0\n",
      "v_f      |   -4.90    0.86  -13.25 |    2.16    1.63    2.97 |  -10.57   -4.38  -22.36 |    0.11    6.52   -4.50\n",
      "vr_f     |     2.9 |     1.2 |     1.5 |    11.7\n",
      "r_i      |  1031.9   -41.3  2351.3 |   592.6   572.7    29.8 |     3.5  -998.6  2300.4 |  1993.6   998.2  2399.9\n",
      "v_i      |  -39.51    1.98  -79.98 |   17.45   17.14    5.66 |  -69.52  -29.83  -89.95 |  -10.07   29.99  -70.01\n",
      "norm_rf  |    22.7 |    10.9 |     0.6 |    54.6\n",
      "norm_vf  |   14.31 |    3.40 |    4.88 |   22.56\n",
      "thrust   |    1190     -42    9134 |    2668    2794    2086 |  -10239  -14205   -5515 |   14993   13939   15000\n",
      "norm_thrust |    9880 |    2550 |    2147 |   15000\n",
      "fuel     |     262 |      11 |     237 |     300\n",
      "rewards  |  -32.32 |    9.39 |  -88.80 |  -17.71\n",
      "fuel_rewards |   -9.01 |    0.37 |  -10.30 |   -8.17\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.52 |    0.61 |    3.49\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   19.34 |    9.07 |    5.02 |   49.58\n",
      "tracking_rewards |  -23.31 |    9.13 |  -78.74 |   -9.20\n",
      "steps    |     273 |      18 |     237 |     333\n",
      "***** Episode 62000, Mean R = -31.8  Std R = 8.4  Min R = -55.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000738\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.00322\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00182\n",
      "Variance: 0.0634\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7083   2.0995  12.7784  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 62031, Mean R = -33.6  Std R = 14.8  Min R = -107.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000656\n",
      "PolicyEntropy: -4.33\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00186\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.2063   4.4566  21.0451  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 62062, Mean R = -30.5  Std R = 6.9  Min R = -51.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000663\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.51e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.0018\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.8413   3.3263  14.9489  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0006   1.6645   0.7971   0.5555\n",
      "***** Episode 62093, Mean R = -34.1  Std R = 11.4  Min R = -73.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000673\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.00276\n",
      "Steps: 8.57e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00186\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.5670   5.6636  24.1917  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 62124, Mean R = -30.9  Std R = 7.3  Min R = -51.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000746\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00187\n",
      "Variance: 0.0636\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.6801   5.0142  20.9065  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "***** Episode 62155, Mean R = -36.6  Std R = 14.0  Min R = -77.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000626\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00165\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5057   3.1196  16.1946  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 62186, Mean R = -34.3  Std R = 12.9  Min R = -75.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000757\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.6e+07\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6472   3.5013  19.9448  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 62217, Mean R = -32.0  Std R = 9.6  Min R = -64.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000781\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.25e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00226\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8716   3.0508  15.7212  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0011   0.0043   1.6645   0.7971   0.5555\n",
      "***** Episode 62248, Mean R = -33.6  Std R = 10.0  Min R = -57.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000725\n",
      "PolicyEntropy: -4.34\n",
      "PolicyLoss: -0.0034\n",
      "Steps: 8.43e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00207\n",
      "Variance: 0.0635\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  14.2103   5.7011  25.2052  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0014   0.0057   1.6645   0.7971   0.5555\n",
      "***** Episode 62279, Mean R = -31.3  Std R = 6.7  Min R = -47.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.968\n",
      "ExplainedVarOld: 0.967\n",
      "KL: 0.00075\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00323\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00152\n",
      "Variance: 0.0634\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.8587   3.8392  19.5154  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0005   0.0025   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2010    ET =    232.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |    10.3     1.0    -0.3 |    16.1    15.7     0.2 |   -27.7   -53.4    -0.9 |    50.4    38.1    -0.0\n",
      "v_f      |   -4.82    0.86  -13.01 |    2.19    1.56    3.07 |   -9.96   -3.46  -25.30 |   -0.17    7.25   -5.05\n",
      "vr_f     |     2.9 |     1.1 |     1.4 |    11.0\n",
      "r_i      |  1000.4   -26.7  2348.2 |   591.5   593.3    29.4 |     0.6  -991.6  2300.5 |  1999.6   997.5  2399.5\n",
      "v_i      |  -40.19    0.09  -80.20 |   16.68   17.16    5.81 |  -69.92  -29.75  -89.98 |  -10.16   29.88  -70.13\n",
      "norm_rf  |    22.3 |    10.6 |     1.4 |    53.7\n",
      "norm_vf  |   14.06 |    3.48 |    5.49 |   26.21\n",
      "thrust   |    1215      30    9156 |    2756    2811    2123 |  -11943  -13916   -5687 |   14995   13894   14999\n",
      "norm_thrust |    9929 |    2596 |    2000 |   15000\n",
      "fuel     |     263 |      11 |     240 |     313\n",
      "rewards  |  -32.91 |   10.77 | -107.80 |  -17.62\n",
      "fuel_rewards |   -9.05 |    0.39 |  -10.77 |   -8.24\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.54 |    0.19 |    3.82\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.89 |    8.85 |    4.18 |   48.70\n",
      "tracking_rewards |  -23.86 |   10.49 |  -97.40 |   -9.11\n",
      "steps    |     273 |      18 |     237 |     325\n",
      "***** Episode 62310, Mean R = -32.2  Std R = 9.0  Min R = -64.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000566\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00266\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00188\n",
      "Variance: 0.0634\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.3295   3.9883  19.2838  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0018   0.0073   1.6645   0.7971   0.5555\n",
      "***** Episode 62341, Mean R = -29.2  Std R = 7.0  Min R = -54.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000749\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00294\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00212\n",
      "Variance: 0.0633\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2369   2.6231  10.9501  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0014   0.0054   1.6645   0.7971   0.5555\n",
      "***** Episode 62372, Mean R = -30.2  Std R = 7.8  Min R = -53.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00259\n",
      "Steps: 8.47e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00181\n",
      "Variance: 0.0632\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.2786   2.7621  11.2535  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 62403, Mean R = -32.2  Std R = 10.0  Min R = -58.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000793\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00175\n",
      "Variance: 0.0632\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4791   2.5613  13.2524  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0015   0.0008   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 62434, Mean R = -32.3  Std R = 7.7  Min R = -53.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000567\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00302\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00199\n",
      "Variance: 0.0632\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.5889   4.2945  24.0606  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0007   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 62465, Mean R = -34.7  Std R = 9.6  Min R = -66.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000859\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.74e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00133\n",
      "Variance: 0.0633\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.9949   2.5824  13.7683  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0009   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 62496, Mean R = -30.5  Std R = 7.7  Min R = -50.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000606\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00286\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00123\n",
      "Variance: 0.0632\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4503   2.6604  14.3927  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 62527, Mean R = -32.6  Std R = 6.8  Min R = -54.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000794\n",
      "PolicyEntropy: -4.35\n",
      "PolicyLoss: -0.00319\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00143\n",
      "Variance: 0.0631\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6354   2.8325  15.2445  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 62558, Mean R = -34.0  Std R = 10.9  Min R = -67.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.986\n",
      "ExplainedVarOld: 0.985\n",
      "KL: 0.000849\n",
      "PolicyEntropy: -4.36\n",
      "PolicyLoss: -0.00297\n",
      "Steps: 8.31e+03\n",
      "TotalSteps: 1.61e+07\n",
      "ValFuncLoss: 0.00141\n",
      "Variance: 0.0629\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8017   2.3802  13.0997  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 62589, Mean R = -32.4  Std R = 10.7  Min R = -62.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000808\n",
      "PolicyEntropy: -4.36\n",
      "PolicyLoss: -0.00344\n",
      "Steps: 8.5e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00166\n",
      "Variance: 0.0628\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0193   1.5136  10.4368  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0005   0.0022   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2020    ET =    230.0   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.9     2.7    -0.3 |    14.4    13.1     0.2 |   -26.5   -47.7    -0.8 |    51.9    31.5    -0.0\n",
      "v_f      |   -4.56    0.65  -12.60 |    2.03    1.47    2.77 |  -10.83   -5.03  -19.06 |   -0.32    5.99   -4.71\n",
      "vr_f     |     3.1 |     3.1 |     1.5 |    51.7\n",
      "r_i      |  1001.7    16.4  2350.1 |   555.2   551.3    29.5 |     8.3  -998.5  2300.8 |  1993.1   994.8  2399.8\n",
      "v_i      |  -41.19   -0.55  -80.10 |   17.24   17.30    5.56 |  -69.99  -29.73  -89.78 |  -10.27   29.74  -70.03\n",
      "norm_rf  |    19.4 |     9.4 |     1.3 |    52.3\n",
      "norm_vf  |   13.57 |    3.15 |    4.80 |   21.45\n",
      "thrust   |    1291      48    9162 |    2765    2744    2055 |  -10023  -14116   -5194 |   14948   14047   14998\n",
      "norm_thrust |    9926 |    2550 |    3145 |   15000\n",
      "fuel     |     263 |      11 |     239 |     311\n",
      "rewards  |  -32.22 |    9.38 |  -72.69 |  -16.89\n",
      "fuel_rewards |   -9.04 |    0.39 |  -10.68 |   -8.23\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.46 |    0.51 |    0.53 |    3.36\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.38 |    7.43 |    4.59 |   47.33\n",
      "tracking_rewards |  -23.18 |    9.11 |  -62.91 |   -8.46\n",
      "steps    |     273 |      18 |     230 |     322\n",
      "***** Episode 62620, Mean R = -34.0  Std R = 12.3  Min R = -72.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000739\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00299\n",
      "Steps: 8.36e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.0628\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.7713   3.2775  15.3593  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 62651, Mean R = -31.0  Std R = 6.7  Min R = -50.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000762\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00335\n",
      "Steps: 8.6e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00146\n",
      "Variance: 0.0627\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4571   4.2062  23.1985  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0006   1.6645   0.7971   0.5555\n",
      "***** Episode 62682, Mean R = -33.5  Std R = 8.0  Min R = -54.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000752\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.73e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00125\n",
      "Variance: 0.0626\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4274   2.7352  15.5652  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 62713, Mean R = -31.2  Std R = 6.6  Min R = -47.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.975\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000722\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00314\n",
      "Steps: 8.71e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00145\n",
      "Variance: 0.0626\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.0072   3.2605  14.7926  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0031   1.6645   0.7971   0.5555\n",
      "***** Episode 62744, Mean R = -30.0  Std R = 7.9  Min R = -52.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000649\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00339\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00171\n",
      "Variance: 0.0626\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.2747   6.1055  31.0691  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 62775, Mean R = -31.7  Std R = 8.1  Min R = -53.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000726\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00154\n",
      "Variance: 0.0625\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.5678   2.3404  13.7449  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0012   1.6645   0.7971   0.5555\n",
      "***** Episode 62806, Mean R = -32.5  Std R = 7.4  Min R = -52.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000773\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00372\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00148\n",
      "Variance: 0.0624\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.7591   2.3000  13.8496  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 62837, Mean R = -36.5  Std R = 16.3  Min R = -104.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000625\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.23e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00184\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.6468   4.6096  21.0958  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0020   0.0011   0.0047   1.6645   0.7971   0.5555\n",
      "***** Episode 62868, Mean R = -33.5  Std R = 7.6  Min R = -50.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000688\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00162\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.9477   3.5682  14.9247  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 62899, Mean R = -31.7  Std R = 8.3  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000804\n",
      "PolicyEntropy: -4.36\n",
      "PolicyLoss: -0.00348\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.9425   3.0839  13.7603  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0020   0.0078   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2030    ET =    240.6   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.5     3.5    -0.3 |    14.8    14.9     0.2 |   -27.7   -44.4    -0.8 |    46.1    41.3    -0.0\n",
      "v_f      |   -4.51    0.55  -12.41 |    1.97    1.60    2.77 |   -9.89   -5.44  -20.63 |   -0.25    5.33   -5.66\n",
      "vr_f     |     2.9 |     1.4 |     1.5 |    16.9\n",
      "r_i      |   998.2    -4.0  2347.9 |   559.4   585.2    28.9 |    17.5  -997.3  2300.1 |  1986.1   999.2  2399.8\n",
      "v_i      |  -39.77    0.11  -79.63 |   17.49   17.35    5.83 |  -69.62  -29.65  -89.90 |  -10.04   29.89  -70.02\n",
      "norm_rf  |    20.6 |    10.0 |     0.5 |    49.6\n",
      "norm_vf  |   13.37 |    3.15 |    5.67 |   21.34\n",
      "thrust   |    1214      17    9131 |    2697    2811    2078 |  -10130  -14085   -5193 |   14998   13910   15000\n",
      "norm_thrust |    9888 |    2562 |    2105 |   15000\n",
      "fuel     |     264 |      11 |     242 |     299\n",
      "rewards  |  -32.46 |    9.21 | -104.86 |  -17.16\n",
      "fuel_rewards |   -9.06 |    0.37 |  -10.29 |   -8.31\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.55 |    0.53 |    3.83\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.36 |    8.08 |    4.73 |   44.64\n",
      "tracking_rewards |  -23.40 |    8.95 |  -94.57 |   -8.69\n",
      "steps    |     274 |      19 |     237 |     331\n",
      "***** Episode 62930, Mean R = -33.0  Std R = 9.4  Min R = -60.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000612\n",
      "PolicyEntropy: -4.36\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.33e+03\n",
      "TotalSteps: 1.62e+07\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.0624\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.7924   3.5342  16.7506  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0028   1.6645   0.7971   0.5555\n",
      "***** Episode 62961, Mean R = -33.8  Std R = 14.3  Min R = -96.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000731\n",
      "PolicyEntropy: -4.36\n",
      "PolicyLoss: -0.00252\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.0624\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8219   2.8877  12.8645  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 62992, Mean R = -31.7  Std R = 6.5  Min R = -45.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00068\n",
      "PolicyEntropy: -4.36\n",
      "PolicyLoss: -0.003\n",
      "Steps: 8.69e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00142\n",
      "Variance: 0.0624\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.5440   2.3522  13.9028  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 63023, Mean R = -31.9  Std R = 7.1  Min R = -55.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000619\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.66e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.0624\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  13.5289   4.8230  24.8055  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 63054, Mean R = -35.2  Std R = 13.5  Min R = -94.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.984\n",
      "KL: 0.000747\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.0029\n",
      "Steps: 8.65e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00101\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2315   2.5246  11.1613  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0003   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 63085, Mean R = -30.5  Std R = 6.4  Min R = -49.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000707\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.0032\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1588   4.4764  17.1827  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0009   0.0004   0.0019   1.6645   0.7971   0.5555\n",
      "***** Episode 63116, Mean R = -32.7  Std R = 11.1  Min R = -79.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000926\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00255\n",
      "Steps: 8.32e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00117\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  18.4735   8.0435  32.5365  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0016   1.6645   0.7971   0.5555\n",
      "***** Episode 63147, Mean R = -29.4  Std R = 5.3  Min R = -42.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.00145\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00117\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00103\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  16.5727   9.0700  38.3535  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 63178, Mean R = -29.0  Std R = 6.2  Min R = -51.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.971\n",
      "KL: 0.000657\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.0013\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8206   2.1467  11.2891  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0007   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 63209, Mean R = -33.9  Std R = 12.1  Min R = -74.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.985\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000617\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00305\n",
      "Steps: 8.39e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00135\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.6928   4.1240  18.3018  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0023   0.0011   0.0050   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2040    ET =    233.3   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     8.9     3.5    -0.3 |    15.4    14.0     0.2 |   -22.1   -48.9    -1.1 |    47.9    48.2    -0.0\n",
      "v_f      |   -4.42    0.47  -12.11 |    2.10    1.55    3.05 |  -10.02   -3.42  -23.59 |    0.19    7.34   -4.84\n",
      "vr_f     |     2.9 |     1.5 |     1.4 |    17.8\n",
      "r_i      |   973.9    47.1  2348.0 |   582.4   573.1    27.9 |     1.6  -990.8  2301.0 |  1999.8   995.4  2399.3\n",
      "v_i      |  -38.84    0.32  -79.34 |   16.81   16.69    5.94 |  -69.90  -29.87  -89.99 |  -10.11   29.33  -70.02\n",
      "norm_rf  |    20.7 |     9.9 |     3.1 |    61.7\n",
      "norm_vf  |   13.06 |    3.43 |    5.01 |   24.05\n",
      "thrust   |    1185      -6    9097 |    2663    2773    2087 |   -9722  -13996   -5215 |   14949   13905   14999\n",
      "norm_thrust |    9836 |    2562 |    2000 |   15000\n",
      "fuel     |     263 |      10 |     243 |     305\n",
      "rewards  |  -32.07 |    9.84 |  -96.84 |  -18.61\n",
      "fuel_rewards |   -9.05 |    0.36 |  -10.49 |   -8.35\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.50 |    0.54 |    0.46 |    3.46\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   17.17 |    8.34 |    5.31 |   56.66\n",
      "tracking_rewards |  -23.02 |    9.61 |  -86.80 |   -9.96\n",
      "steps    |     275 |      18 |     237 |     330\n",
      "***** Episode 63240, Mean R = -32.7  Std R = 8.9  Min R = -59.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000876\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00271\n",
      "Steps: 8.7e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00121\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.9158   5.2507  22.7090  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0003   0.0017   1.6645   0.7971   0.5555\n",
      "***** Episode 63271, Mean R = -30.7  Std R = 6.0  Min R = -49.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000571\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00321\n",
      "Steps: 8.45e+03\n",
      "TotalSteps: 1.63e+07\n",
      "ValFuncLoss: 0.00109\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.4702   3.0970  13.2751  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0004   0.0020   1.6645   0.7971   0.5555\n",
      "***** Episode 63302, Mean R = -31.1  Std R = 7.1  Min R = -49.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.971\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000606\n",
      "PolicyEntropy: -4.37\n",
      "PolicyLoss: -0.00239\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4153   2.4191  11.9284  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 63333, Mean R = -33.3  Std R = 9.7  Min R = -54.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000676\n",
      "PolicyEntropy: -4.38\n",
      "PolicyLoss: -0.00251\n",
      "Steps: 8.68e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00107\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   5.9429   2.5210  11.2924  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0008   0.0004   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 63364, Mean R = -33.7  Std R = 17.1  Min R = -111.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.982\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000758\n",
      "PolicyEntropy: -4.38\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.62e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.000997\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6791   2.4736  14.8527  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 63395, Mean R = -32.4  Std R = 6.8  Min R = -49.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000639\n",
      "PolicyEntropy: -4.38\n",
      "PolicyLoss: -0.00318\n",
      "Steps: 8.42e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00133\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.6727   2.2259  10.7504  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0024   0.0102   1.6645   0.7971   0.5555\n",
      "***** Episode 63426, Mean R = -37.5  Std R = 15.1  Min R = -82.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000736\n",
      "PolicyEntropy: -4.38\n",
      "PolicyLoss: -0.00291\n",
      "Steps: 8.55e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00128\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.0584   4.2437  19.9170  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0009   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 63457, Mean R = -34.3  Std R = 11.8  Min R = -85.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.973\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000632\n",
      "PolicyEntropy: -4.38\n",
      "PolicyLoss: -0.00238\n",
      "Steps: 8.4e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00183\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.2440   3.4502  16.3756  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0006   0.0029   1.6645   0.7971   0.5555\n",
      "***** Episode 63488, Mean R = -32.3  Std R = 11.6  Min R = -81.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000822\n",
      "PolicyEntropy: -4.38\n",
      "PolicyLoss: -0.00367\n",
      "Steps: 8.34e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00194\n",
      "Variance: 0.062\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.1792   4.5431  18.7260  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0032   1.6645   0.7971   0.5555\n",
      "***** Episode 63519, Mean R = -30.7  Std R = 7.2  Min R = -53.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000642\n",
      "PolicyEntropy: -4.38\n",
      "PolicyLoss: -0.0026\n",
      "Steps: 8.67e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00155\n",
      "Variance: 0.0619\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.0267   5.5513  20.9647  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2050    ET =    251.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.8     2.5    -0.3 |    15.8    14.5     0.2 |   -24.1   -43.4    -0.9 |    48.3    57.4    -0.0\n",
      "v_f      |   -4.64    0.61  -12.30 |    2.07    1.61    2.84 |   -9.73   -4.66  -21.77 |    1.12    5.99   -4.80\n",
      "vr_f     |     2.8 |     1.1 |     1.4 |     8.9\n",
      "r_i      |  1006.9   -20.1  2352.0 |   584.9   580.5    27.4 |     3.9  -994.8  2300.7 |  1995.6   998.3  2399.9\n",
      "v_i      |  -39.62    1.46  -79.87 |   17.29   17.09    5.92 |  -69.77  -29.93  -89.87 |  -10.04   29.89  -70.01\n",
      "norm_rf  |    21.7 |     9.7 |     0.8 |    58.8\n",
      "norm_vf  |   13.33 |    3.24 |    4.84 |   22.62\n",
      "thrust   |    1211      -8    9128 |    2727    2772    2102 |   -9950  -14075   -5260 |   14996   13826   14998\n",
      "norm_thrust |    9883 |    2581 |    2000 |   15000\n",
      "fuel     |     264 |      11 |     238 |     312\n",
      "rewards  |  -32.99 |   10.96 | -111.79 |  -17.59\n",
      "fuel_rewards |   -9.08 |    0.39 |  -10.74 |   -8.16\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.43 |    0.51 |    0.37 |    4.02\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   18.00 |    8.16 |    4.13 |   53.80\n",
      "tracking_rewards |  -23.90 |   10.70 | -101.21 |   -9.31\n",
      "steps    |     275 |      18 |     223 |     316\n",
      "***** Episode 63550, Mean R = -34.0  Std R = 9.6  Min R = -64.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000883\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00377\n",
      "Steps: 8.61e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00173\n",
      "Variance: 0.0619\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.3683   5.5198  21.9074  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0021   0.0012   0.0048   1.6645   0.7971   0.5555\n",
      "***** Episode 63581, Mean R = -33.4  Std R = 11.7  Min R = -67.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000674\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.50e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00133\n",
      "Variance: 0.0618\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1980   4.3840  24.1708  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 63612, Mean R = -32.8  Std R = 8.9  Min R = -65.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.981\n",
      "KL: 0.000626\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00283\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00169\n",
      "Variance: 0.0619\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6477   3.0793  17.1099  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0001   0.0007   1.6645   0.7971   0.5555\n",
      "***** Episode 63643, Mean R = -33.9  Std R = 10.4  Min R = -63.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000795\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 8.35e+03\n",
      "TotalSteps: 1.64e+07\n",
      "ValFuncLoss: 0.00157\n",
      "Variance: 0.0619\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.5588   2.6068  14.4331  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 63674, Mean R = -31.8  Std R = 6.2  Min R = -47.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000669\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.0016\n",
      "Variance: 0.062\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.6825   3.1980  16.6058  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 63705, Mean R = -29.5  Std R = 4.7  Min R = -38.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000664\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00287\n",
      "Steps: 8.46e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00135\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.1422   3.4334  14.2000  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0013   1.6645   0.7971   0.5555\n",
      "***** Episode 63736, Mean R = -31.3  Std R = 10.0  Min R = -70.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.00077\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00317\n",
      "Steps: 8.44e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00125\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.3919   2.6580  14.8108  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0014   0.0006   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 63767, Mean R = -29.4  Std R = 8.2  Min R = -51.2\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.983\n",
      "KL: 0.000627\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00324\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.000962\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.1325   6.6738  25.5663  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0016   0.0008   0.0034   1.6645   0.7971   0.5555\n",
      "***** Episode 63798, Mean R = -32.3  Std R = 10.9  Min R = -74.5\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.975\n",
      "KL: 0.000998\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00288\n",
      "Steps: 8.63e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00151\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.2958   5.3017  26.1419  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0003   0.0018   1.6645   0.7971   0.5555\n",
      "***** Episode 63829, Mean R = -32.5  Std R = 9.1  Min R = -49.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.978\n",
      "ExplainedVarOld: 0.972\n",
      "KL: 0.000933\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00392\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00141\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.6160   1.9364  11.2639  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0018   0.0009   0.0038   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2060    ET =    250.4   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     9.3     4.7    -0.3 |    15.9    12.6     0.2 |   -25.6   -40.3    -0.8 |    54.6    39.4    -0.0\n",
      "v_f      |   -4.72    0.44  -12.25 |    2.22    1.53    3.08 |  -10.14   -5.95  -18.16 |   -0.49    5.46   -1.72\n",
      "vr_f     |     2.8 |     1.0 |     0.7 |     8.5\n",
      "r_i      |  1020.1    52.8  2348.0 |   611.8   538.7    28.7 |     3.0  -994.6  2300.0 |  1995.0   994.3  2399.7\n",
      "v_i      |  -39.99    0.24  -79.80 |   16.77   17.28    5.64 |  -69.81  -29.70  -89.96 |  -10.62   29.96  -70.10\n",
      "norm_rf  |    20.5 |    10.0 |     1.5 |    54.9\n",
      "norm_vf  |   13.29 |    3.54 |    3.59 |   20.24\n",
      "thrust   |    1217     -10    9135 |    2776    2733    2085 |  -10485  -14032   -5595 |   14986   13766   14999\n",
      "norm_thrust |    9892 |    2568 |    2413 |   15000\n",
      "fuel     |     264 |      11 |     242 |     312\n",
      "rewards  |  -31.93 |    9.19 |  -74.48 |  -16.69\n",
      "fuel_rewards |   -9.06 |    0.37 |  -10.71 |   -8.30\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.44 |    0.55 |    0.56 |    3.81\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.93 |    8.55 |    4.39 |   49.93\n",
      "tracking_rewards |  -22.87 |    8.93 |  -64.74 |   -8.28\n",
      "steps    |     274 |      18 |     234 |     333\n",
      "***** Episode 63860, Mean R = -32.6  Std R = 8.6  Min R = -62.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.98\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000698\n",
      "PolicyEntropy: -4.39\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.58e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00168\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   8.3413   2.9205  17.3539  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0027   1.6645   0.7971   0.5555\n",
      "***** Episode 63891, Mean R = -34.1  Std R = 11.7  Min R = -69.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.974\n",
      "KL: 0.000848\n",
      "PolicyEntropy: -4.4\n",
      "PolicyLoss: -0.00358\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00151\n",
      "Variance: 0.062\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.1071   2.6551  16.8188  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 63922, Mean R = -32.3  Std R = 8.9  Min R = -68.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.983\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000706\n",
      "PolicyEntropy: -4.4\n",
      "PolicyLoss: -0.00312\n",
      "Steps: 8.54e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.0015\n",
      "Variance: 0.0619\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.7518   2.7499  15.0338  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0013   0.0007   0.0030   1.6645   0.7971   0.5555\n",
      "***** Episode 63953, Mean R = -31.6  Std R = 8.3  Min R = -56.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.973\n",
      "KL: 0.000714\n",
      "PolicyEntropy: -4.4\n",
      "PolicyLoss: -0.00308\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00165\n",
      "Variance: 0.062\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.4020   2.6384  14.1903  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0003   0.0014   1.6645   0.7971   0.5555\n",
      "***** Episode 63984, Mean R = -31.1  Std R = 10.8  Min R = -68.3\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.978\n",
      "KL: 0.000717\n",
      "PolicyEntropy: -4.4\n",
      "PolicyLoss: -0.00274\n",
      "Steps: 8.28e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00192\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.0378   2.9161  15.8089  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0043   0.0020   0.0097   1.6645   0.7971   0.5555\n",
      "***** Episode 64015, Mean R = -34.0  Std R = 9.8  Min R = -61.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.976\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000712\n",
      "PolicyEntropy: -4.4\n",
      "PolicyLoss: -0.00243\n",
      "Steps: 8.21e+03\n",
      "TotalSteps: 1.65e+07\n",
      "ValFuncLoss: 0.00182\n",
      "Variance: 0.0621\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  15.3278   6.9884  27.1910  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0033   0.0019   0.0078   1.6645   0.7971   0.5555\n",
      "***** Episode 64046, Mean R = -33.4  Std R = 8.8  Min R = -58.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.979\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.00104\n",
      "PolicyEntropy: -4.4\n",
      "PolicyLoss: -0.00164\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00166\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  12.0843   4.7277  19.6600  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0029   0.0016   0.0061   1.6645   0.7971   0.5555\n",
      "***** Episode 64077, Mean R = -33.6  Std R = 11.1  Min R = -68.4\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.974\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.000836\n",
      "PolicyEntropy: -4.4\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00195\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.8730   2.1483  12.5794  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0004   0.0002   0.0008   1.6645   0.7971   0.5555\n",
      "***** Episode 64108, Mean R = -34.1  Std R = 7.6  Min R = -55.0\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.981\n",
      "ExplainedVarOld: 0.98\n",
      "KL: 0.000748\n",
      "PolicyEntropy: -4.41\n",
      "PolicyLoss: -0.00326\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00233\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  16.4810   7.1547  28.0247  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0003   0.0011   1.6645   0.7971   0.5555\n",
      "***** Episode 64139, Mean R = -36.0  Std R = 15.6  Min R = -83.9\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.99\n",
      "ExplainedVarOld: 0.987\n",
      "KL: 0.0009\n",
      "PolicyEntropy: -4.41\n",
      "PolicyLoss: -0.00227\n",
      "Steps: 8.37e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.0021\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  10.4153   2.1984  14.7924  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0007   0.0004   0.0016   1.6645   0.7971   0.5555\n",
      "Update Cnt = 2070    ET =    289.1   Stats:  Mean, Std, Min, Max\n",
      "r_f      |     6.7     2.8    -0.3 |    14.5    13.5     0.2 |   -27.6   -33.7    -0.8 |    48.7    35.2    -0.0\n",
      "v_f      |   -4.65    0.62  -12.73 |    1.97    1.47    2.85 |  -10.20   -3.18  -21.84 |   -0.46    5.88   -4.24\n",
      "vr_f     |     2.9 |     1.3 |     1.4 |    15.1\n",
      "r_i      |  1010.6   -29.2  2352.0 |   579.0   580.5    28.4 |    14.4  -987.1  2300.5 |  1999.8   987.6  2399.7\n",
      "v_i      |  -40.91   -1.14  -80.59 |   17.78   17.71    5.89 |  -69.85  -29.78  -89.95 |  -10.14   29.62  -70.04\n",
      "norm_rf  |    19.3 |     8.5 |     1.8 |    49.1\n",
      "norm_vf  |   13.70 |    3.22 |    4.51 |   22.22\n",
      "thrust   |    1259      80    9166 |    2747    2884    2075 |  -10418  -14037   -5286 |   14991   13488   15000\n",
      "norm_thrust |    9954 |    2586 |    2746 |   15000\n",
      "fuel     |     263 |      12 |     238 |     309\n",
      "rewards  |  -33.27 |   10.47 |  -83.93 |  -18.85\n",
      "fuel_rewards |   -9.05 |    0.40 |  -10.63 |   -8.16\n",
      "glideslope_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "glideslope |    1.45 |    0.54 |    0.59 |    3.40\n",
      "sc_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_penalty |    0.00 |    0.00 |    0.00 |    0.00\n",
      "sc_margin |  100.00 |    0.00 |  100.00 |  100.00\n",
      "range_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_rewards |    0.00 |    0.00 |    0.00 |    0.00\n",
      "landing_margin |   16.28 |    6.45 |    5.70 |   44.13\n",
      "tracking_rewards |  -24.21 |   10.18 |  -74.24 |  -10.45\n",
      "steps    |     272 |      18 |     239 |     329\n",
      "***** Episode 64170, Mean R = -32.4  Std R = 9.0  Min R = -53.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.977\n",
      "KL: 0.00101\n",
      "PolicyEntropy: -4.41\n",
      "PolicyLoss: -0.00281\n",
      "Steps: 8.49e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00218\n",
      "Variance: 0.0622\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   6.2058   3.0827  16.1057  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0010   0.0006   0.0024   1.6645   0.7971   0.5555\n",
      "***** Episode 64201, Mean R = -34.1  Std R = 9.7  Min R = -66.1\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.984\n",
      "ExplainedVarOld: 0.982\n",
      "KL: 0.000666\n",
      "PolicyEntropy: -4.41\n",
      "PolicyLoss: -0.00272\n",
      "Steps: 8.48e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00217\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  20.5131  12.9269  41.1908  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0006   0.0002   0.0010   1.6645   0.7971   0.5555\n",
      "***** Episode 64232, Mean R = -29.8  Std R = 6.7  Min R = -44.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.00183\n",
      "PolicyEntropy: -4.41\n",
      "PolicyLoss: 0.00038\n",
      "Steps: 8.38e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00187\n",
      "Variance: 0.0623\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  15.1187   7.1495  30.8486  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0006   0.0025   1.6645   0.7971   0.5555\n",
      "***** Episode 64263, Mean R = -30.9  Std R = 5.6  Min R = -43.6\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.972\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000833\n",
      "PolicyEntropy: -4.42\n",
      "PolicyLoss: -0.00311\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00161\n",
      "Variance: 0.0624\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   9.5894   2.6939  15.8710  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0012   0.0005   0.0023   1.6645   0.7971   0.5555\n",
      "***** Episode 64294, Mean R = -31.4  Std R = 8.3  Min R = -55.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000788\n",
      "PolicyEntropy: -4.41\n",
      "PolicyLoss: -0.00262\n",
      "Steps: 8.41e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00189\n",
      "Variance: 0.0625\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :  11.5409   5.3042  21.8416  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0005   0.0002   0.0009   1.6645   0.7971   0.5555\n",
      "***** Episode 64325, Mean R = -30.5  Std R = 8.1  Min R = -55.8\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.977\n",
      "ExplainedVarOld: 0.979\n",
      "KL: 0.000589\n",
      "PolicyEntropy: -4.41\n",
      "PolicyLoss: -0.00289\n",
      "Steps: 8.53e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.0017\n",
      "Variance: 0.0625\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n",
      "Policy  Gradients: u/sd/Max/C Max/Max u/Max sd :   7.8131   2.0194  11.8538  70.4490  40.5062  23.5410\n",
      "ValFun  Gradients: u/sd/Max/C Max/Max u/Max sd :   0.0019   0.0010   0.0039   1.6645   0.7971   0.5555\n",
      "***** Episode 64356, Mean R = -34.9  Std R = 11.5  Min R = -69.7\n",
      "Beta: 0.0667\n",
      "ExplainedVarNew: 0.962\n",
      "ExplainedVarOld: 0.976\n",
      "KL: 0.000686\n",
      "PolicyEntropy: -4.42\n",
      "PolicyLoss: -0.00316\n",
      "Steps: 8.56e+03\n",
      "TotalSteps: 1.66e+07\n",
      "ValFuncLoss: 0.00164\n",
      "Variance: 0.0624\n",
      "lr_multiplier: 0.198\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-66e144938d8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/RL_lib/Agents/PPO/agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_episodes, train_samples, warmup_updates)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtrain_episodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mtrajectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mepisode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/RL_lib/Agents/PPO/agent.py\u001b[0m in \u001b[0;36mrun_policy\u001b[0;34m(self, episode_cnt, warmup)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mtrajectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0me_cnt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_episodes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mtraj\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rewards1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rewards2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'observes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/RL_lib/Agents/PPO/agent.py\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_timestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mpadded_traj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/RL_lib/Agents/PPO/arch_policy_gtvf.py\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(self, env, policy, val_func, model, recurrent_steps, use_timestep, add_padding)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mvpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mnobserves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mgt_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/Mars3dof_env/env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_to_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/Mars3dof_env/dynamics_model.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, t, thrust_cmd, lander)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_dynamics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meqom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrk4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_next\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Study/Subjects/MachineLearning/Projects/RL_Meta-Learning-master/Mars3dof_env/env_utils.py\u001b[0m in \u001b[0;36mrk4\u001b[0;34m(t, x, xdot, h)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mk4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m   \u001b[0;34m,\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mk3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from env import Env\n",
    "import env_utils as envu\n",
    "from dynamics_model import Dynamics_model\n",
    "from lander_model import Lander_model\n",
    "from ic_gen2 import Landing_icgen\n",
    "import rl_utils\n",
    "\n",
    "from arch_policy_gtvf import Arch\n",
    "\n",
    "from policy import Policy\n",
    "from value_function import Value_function\n",
    "\n",
    "import policy_nets as policy_nets\n",
    "import valfunc_nets as valfunc_nets\n",
    "\n",
    "from agent import Agent\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from flat_constraint import Flat_constraint\n",
    "from glideslope_constraint import Glideslope_constraint\n",
    "from reward_terminal_mdr import Reward\n",
    "\n",
    "\n",
    "logger = rl_utils.Logger()\n",
    "dynamics_model = Dynamics_model()\n",
    "lander_model = Lander_model(apf_tau1=22,apf_tau2=100,apf_vf1=-2,apf_vf2=-1,apf_v0=70,apf_atarg=15)\n",
    "lander_model.get_state_agent = lander_model.get_state_agent_po\n",
    "lander_model.apf_pot = lander_model.apf_pot2\n",
    "obs_dim = 3\n",
    "gt_dim = 5\n",
    "act_dim = 3\n",
    "recurrent_steps = 60\n",
    "\n",
    "reward_object = Reward()\n",
    "\n",
    "glideslope_constraint = Glideslope_constraint(gs_limit=-1.0)\n",
    "shape_constraint = Flat_constraint()\n",
    "env = Env(lander_model,dynamics_model,logger,\n",
    "          reward_object=reward_object,\n",
    "          glideslope_constraint=glideslope_constraint,\n",
    "          shape_constraint=shape_constraint,\n",
    "          tf_limit=100.0,print_every=10)\n",
    "\n",
    "env.ic_gen = Landing_icgen(mass_uncertainty=0.05, \n",
    "                           g_uncertainty=(0.05,0.05),\n",
    "                           adjust_apf_v0=True,\n",
    "                          downrange = (0,2000 , -70, -10), \n",
    "                           crossrange = (-1000,1000 , -30,30),  \n",
    "                           altitude = (2300,2400,-90,-70))\n",
    "env.ic_gen.show()\n",
    "\n",
    "arch = Arch()\n",
    "\n",
    "policy = Policy(policy_nets.GRU(obs_dim, act_dim, recurrent_steps=recurrent_steps), shuffle=False,\n",
    "                kl_targ=0.001,epochs=20, beta=0.1, servo_kl=True, max_grad_norm=30,\n",
    "                init_func=rl_utils.xn_init)\n",
    "value_function = Value_function(valfunc_nets.GRU(gt_dim, recurrent_steps=recurrent_steps), \n",
    "                                shuffle=False, batch_size=9999999, max_grad_norm=30,obs_key='muxed_observes')\n",
    "\n",
    "agent = Agent(arch, policy, value_function, None, env, logger,\n",
    "              policy_episodes=30, policy_steps=3000, gamma1=0.95, gamma2=0.995, lam=0.98, \n",
    "              recurrent_steps=recurrent_steps, monitor=env.rl_stats)\n",
    "\n",
    "\n",
    "agent.train(90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"recurrent_policy-60step\"\n",
    "policy.save_params(fname)\n",
    "value_function.save_params(fname)\n",
    "np.save(fname + \"_history\",env.rl_stats.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9776.44 |2346.96 |2000.00 |15000.00 |    64\n",
      "glideslope | 5.413 |22.923 | 0.594 |1435.687 |    94\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.216 |   0.074 |   1.078 |   1.411\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     0.8\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.4    -0.5    -0.1 |     0.8     0.4    -0.0\n",
      "velocity |   0.023  -0.056  -1.213 |   0.042   0.037   0.074 |  -0.049  -0.134  -1.411 |   0.118   0.009  -1.072\n",
      "fuel     |287.54 | 14.57 |260.57 |333.25\n",
      "glideslope | 34.63 | 26.64 | 15.55 |152.63\n",
      "i :  200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9807.88 |2355.55 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.338 |21.262 | 0.554 |1435.687 |    94\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.217 |   0.074 |   1.078 |   1.411\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     0.8\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     0.8     0.4    -0.0\n",
      "velocity |   0.025  -0.053  -1.214 |   0.042   0.039   0.073 |  -0.065  -0.134  -1.411 |   0.118   0.016  -1.072\n",
      "fuel     |286.99 | 13.68 |260.57 |333.25\n",
      "glideslope | 36.79 | 36.72 | 14.19 |338.70\n",
      "i :  300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9836.55 |2373.17 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.445 |24.862 | 0.553 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.215 |   0.075 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     0.8     1.0    -0.0\n",
      "velocity |   0.026  -0.052  -1.213 |   0.042   0.039   0.075 |  -0.065  -0.134  -1.566 |   0.118   0.023  -1.042\n",
      "fuel     |287.26 | 14.42 |251.78 |333.25\n",
      "glideslope | 36.40 | 36.79 | 13.42 |338.70\n",
      "i :  400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9844.82 |2375.46 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.464 |25.333 | 0.553 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.217 |   0.075 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.027  -0.051  -1.215 |   0.043   0.039   0.075 |  -0.080  -0.143  -1.566 |   0.118   0.025  -1.042\n",
      "fuel     |288.12 | 14.65 |251.78 |333.25\n",
      "glideslope | 38.83 | 46.86 | 12.79 |621.24\n",
      "i :  500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9850.17 |2375.55 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.434 |23.547 | 0.553 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.077 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.028  -0.050  -1.216 |   0.043   0.040   0.076 |  -0.080  -0.143  -1.566 |   0.118   0.025  -1.042\n",
      "fuel     |288.25 | 14.98 |251.78 |344.68\n",
      "glideslope | 38.58 | 45.05 | 12.79 |621.24\n",
      "i :  600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9852.83 |2374.96 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.537 |22.729 | 0.553 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.076 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.028  -0.051  -1.216 |   0.043   0.039   0.076 |  -0.080  -0.143  -1.566 |   0.118   0.025  -1.042\n",
      "fuel     |287.90 | 14.87 |251.78 |344.68\n",
      "glideslope | 38.22 | 42.88 | 12.79 |621.24\n",
      "i :  700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.23 |2370.23 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.536 |22.242 | 0.553 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.075 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.028  -0.051  -1.218 |   0.043   0.039   0.075 |  -0.080  -0.143  -1.566 |   0.118   0.025  -1.042\n",
      "fuel     |287.79 | 14.73 |251.78 |344.68\n",
      "glideslope | 38.44 | 42.92 | 12.79 |621.24\n",
      "i :  800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9883.68 |2376.47 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.512 |21.529 | 0.450 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.075 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.028  -0.052  -1.219 |   0.043   0.039   0.074 |  -0.080  -0.143  -1.566 |   0.118   0.025  -1.042\n",
      "fuel     |287.61 | 14.64 |251.78 |344.68\n",
      "glideslope | 38.30 | 42.57 | 12.79 |621.24\n",
      "i :  900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9890.67 |2376.94 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.501 |20.865 | 0.450 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.027  -0.053  -1.219 |   0.043   0.039   0.074 |  -0.080  -0.143  -1.566 |   0.132   0.025  -1.042\n",
      "fuel     |287.63 | 14.76 |251.78 |344.68\n",
      "glideslope | 37.56 | 41.04 | 12.79 |621.24\n",
      "i :  1000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9893.51 |2379.20 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.508 |20.796 | 0.450 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.075 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.027  -0.053  -1.219 |   0.043   0.039   0.075 |  -0.080  -0.143  -1.566 |   0.132   0.025  -1.041\n",
      "fuel     |287.89 | 14.65 |251.78 |344.68\n",
      "glideslope | 37.54 | 40.52 | 12.79 |621.24\n",
      "i :  1100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9887.58 |2376.06 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.571 |20.889 | 0.450 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.075 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.027  -0.053  -1.218 |   0.043   0.039   0.075 |  -0.080  -0.143  -1.566 |   0.132   0.025  -1.041\n",
      "fuel     |287.95 | 14.70 |251.78 |344.68\n",
      "glideslope | 38.27 | 45.87 | 12.40 |792.33\n",
      "i :  1200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9882.40 |2375.03 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.585 |21.058 | 0.450 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.075 |   1.043 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.0\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     0.9     1.0    -0.0\n",
      "velocity |   0.027  -0.052  -1.218 |   0.043   0.039   0.075 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.041\n",
      "fuel     |287.70 | 14.69 |249.75 |344.68\n",
      "glideslope | 38.41 | 45.79 | 12.22 |792.33\n",
      "i :  1300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.47 |2373.22 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.574 |20.803 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.075 |   1.030 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.027  -0.053  -1.217 |   0.043   0.039   0.075 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.024\n",
      "fuel     |287.53 | 14.75 |249.75 |344.68\n",
      "glideslope | 37.62 | 44.30 | 12.22 |792.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  1400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.44 |2373.93 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.568 |20.724 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.075 |   1.030 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.027  -0.054  -1.217 |   0.043   0.039   0.074 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.024\n",
      "fuel     |287.44 | 14.95 |249.75 |344.68\n",
      "glideslope | 37.38 | 43.57 | 12.22 |792.33\n",
      "i :  1500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9882.18 |2377.61 |2000.00 |15000.00 |   163\n",
      "glideslope | 5.580 |20.481 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.075 |   1.030 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.027  -0.054  -1.218 |   0.043   0.038   0.075 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.024\n",
      "fuel     |287.34 | 15.00 |246.79 |344.68\n",
      "glideslope | 37.17 | 43.94 | 12.22 |792.33\n",
      "i :  1600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9877.36 |2374.56 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.592 |20.601 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.075 |   1.030 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.027  -0.054  -1.218 |   0.043   0.038   0.075 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.024\n",
      "fuel     |287.46 | 15.00 |246.79 |344.68\n",
      "glideslope | 38.00 | 51.92 | 12.22 |1189.63\n",
      "i :  1700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.12 |2370.22 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.654 |20.985 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.043   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.019\n",
      "fuel     |287.46 | 15.03 |246.79 |344.68\n",
      "glideslope | 38.24 | 51.35 | 12.22 |1189.63\n",
      "i :  1800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.86 |2369.91 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.672 |21.301 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.043   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.019\n",
      "fuel     |287.44 | 15.05 |246.79 |344.68\n",
      "glideslope | 38.58 | 51.65 | 12.22 |1189.63\n",
      "i :  1900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9874.00 |2370.23 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.690 |21.311 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.019\n",
      "fuel     |287.48 | 15.15 |246.79 |344.68\n",
      "glideslope | 38.50 | 50.65 | 12.22 |1189.63\n",
      "i :  2000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.40 |2368.22 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.668 |21.045 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.019\n",
      "fuel     |287.46 | 15.05 |246.79 |344.68\n",
      "glideslope | 38.25 | 49.80 | 12.22 |1189.63\n",
      "i :  2100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.15 |2368.66 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.671 |21.203 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.019\n",
      "fuel     |287.50 | 15.10 |246.79 |344.68\n",
      "glideslope | 38.33 | 49.67 | 12.22 |1189.63\n",
      "i :  2200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.82 |2367.22 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.769 |23.061 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.132   0.025  -1.019\n",
      "fuel     |287.48 | 15.13 |246.79 |344.68\n",
      "glideslope | 38.34 | 49.40 | 12.22 |1189.63\n",
      "i :  2300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.15 |2364.89 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.786 |23.058 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.134   0.025  -1.019\n",
      "fuel     |287.43 | 15.17 |246.79 |344.68\n",
      "glideslope | 38.99 | 50.25 | 12.22 |1189.63\n",
      "i :  2400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.47 |2364.08 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.788 |23.666 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.022 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.134   0.025  -1.019\n",
      "fuel     |287.44 | 15.17 |246.79 |344.68\n",
      "glideslope | 38.91 | 49.59 | 12.22 |1189.63\n",
      "i :  2500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.62 |2363.92 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.785 |23.488 | 0.427 |4633.066 |   291\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.134   0.026  -1.016\n",
      "fuel     |287.45 | 15.16 |246.79 |344.68\n",
      "glideslope | 38.84 | 49.02 | 12.22 |1189.63\n",
      "i :  2600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9862.05 |2363.30 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.794 |25.959 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.026  -1.016\n",
      "fuel     |287.46 | 15.21 |246.79 |344.68\n",
      "glideslope | 38.78 | 48.86 | 12.22 |1189.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  2700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9862.05 |2362.08 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.805 |25.805 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.026  -1.016\n",
      "fuel     |287.44 | 15.21 |246.79 |344.68\n",
      "glideslope | 39.00 | 48.96 | 12.22 |1189.63\n",
      "i :  2800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.12 |2361.64 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.798 |25.545 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.026  -1.016\n",
      "fuel     |287.48 | 15.23 |246.79 |344.68\n",
      "glideslope | 38.90 | 48.59 | 12.22 |1189.63\n",
      "i :  2900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.82 |2360.58 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.781 |25.344 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.026  -1.016\n",
      "fuel     |287.51 | 15.20 |246.79 |344.68\n",
      "glideslope | 38.95 | 50.48 | 12.22 |1189.63\n",
      "i :  3000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9860.87 |2359.62 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.771 |25.105 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.026  -1.016\n",
      "fuel     |287.54 | 15.19 |246.79 |344.68\n",
      "glideslope | 38.88 | 50.01 | 12.22 |1189.63\n",
      "i :  3100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.25 |2358.59 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.793 |25.159 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.026  -1.016\n",
      "fuel     |287.49 | 15.18 |246.79 |344.68\n",
      "glideslope | 38.76 | 49.44 | 12.22 |1189.63\n",
      "i :  3200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.50 |2359.08 |2000.00 |15000.00 |  1539\n",
      "glideslope | 5.776 |24.907 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.054  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.45 | 15.16 |246.79 |344.68\n",
      "glideslope | 38.88 | 50.07 | 12.22 |1189.63\n",
      "i :  3300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.13 |2361.54 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.777 |24.876 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.54 | 15.22 |246.79 |344.68\n",
      "glideslope | 38.83 | 49.53 | 12.22 |1189.63\n",
      "i :  3400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.25 |2361.74 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.777 |24.787 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.48 | 15.24 |246.79 |344.68\n",
      "glideslope | 38.89 | 49.68 | 12.22 |1189.63\n",
      "i :  3500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.64 |2361.24 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.773 |24.703 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.44 | 15.27 |246.79 |344.68\n",
      "glideslope | 38.90 | 49.47 | 12.22 |1189.63\n",
      "i :  3600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.89 |2361.66 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.774 |24.559 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.074 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.39 | 15.26 |246.79 |344.68\n",
      "glideslope | 38.92 | 49.18 | 12.22 |1189.63\n",
      "i :  3700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.94 |2360.55 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.778 |24.435 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.34 | 15.24 |246.79 |344.68\n",
      "glideslope | 38.95 | 49.03 | 12.22 |1189.63\n",
      "i :  3800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.25 |2359.83 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.767 |24.318 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.074 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.39 | 15.29 |246.79 |344.68\n",
      "glideslope | 38.77 | 48.52 | 12.22 |1189.63\n",
      "i :  3900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.14 |2359.28 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.762 |24.362 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.36 | 15.28 |246.79 |344.68\n",
      "glideslope | 38.82 | 48.43 | 12.22 |1189.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  4000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.94 |2359.91 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.753 |24.294 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.41 | 15.29 |246.79 |344.68\n",
      "glideslope | 38.75 | 48.02 | 12.22 |1189.63\n",
      "i :  4100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.18 |2360.81 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.753 |24.135 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.220 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.42 | 15.27 |246.79 |344.68\n",
      "glideslope | 38.78 | 47.88 | 12.22 |1189.63\n",
      "i :  4200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.74 |2360.26 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.779 |24.638 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.40 | 15.22 |246.79 |344.68\n",
      "glideslope | 38.98 | 48.27 | 12.22 |1189.63\n",
      "i :  4300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9874.34 |2361.05 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.787 |24.506 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.40 | 15.23 |246.79 |344.68\n",
      "glideslope | 38.90 | 47.92 | 12.22 |1189.63\n",
      "i :  4400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.42 |2361.31 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.793 |24.352 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.40 | 15.23 |246.79 |344.68\n",
      "glideslope | 38.80 | 47.50 | 12.22 |1189.63\n",
      "i :  4500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.99 |2361.27 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.795 |24.325 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.38 | 15.23 |246.79 |344.68\n",
      "glideslope | 38.95 | 47.85 | 12.22 |1189.63\n",
      "i :  4600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9874.85 |2361.28 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.791 |24.275 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.33 | 15.23 |246.79 |344.68\n",
      "glideslope | 39.21 | 50.99 | 12.22 |1272.67\n",
      "i :  4700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.95 |2361.01 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.790 |24.239 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.28 | 15.22 |246.79 |344.68\n",
      "glideslope | 39.18 | 50.64 | 12.22 |1272.67\n",
      "i :  4800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9874.20 |2361.81 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.791 |24.308 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.25 | 15.21 |246.79 |344.68\n",
      "glideslope | 39.07 | 50.24 | 12.22 |1272.67\n",
      "i :  4900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.23 |2361.93 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.788 |24.391 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.32 | 15.25 |246.79 |346.41\n",
      "glideslope | 38.97 | 49.86 | 12.22 |1272.67\n",
      "i :  5000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.26 |2362.13 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.779 |24.239 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.29 | 15.25 |246.79 |346.41\n",
      "glideslope | 38.85 | 49.48 | 12.22 |1272.67\n",
      "i :  5100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.10 |2360.58 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.794 |24.753 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.24 | 15.23 |246.79 |346.41\n",
      "glideslope | 38.81 | 49.17 | 12.22 |1272.67\n",
      "i :  5200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.17 |2359.74 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.795 |24.641 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.28 | 15.23 |246.79 |346.41\n",
      "glideslope | 38.83 | 48.95 | 12.22 |1272.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  5300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.80 |2358.30 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.787 |24.520 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.026  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.25 | 15.24 |246.79 |346.41\n",
      "glideslope | 38.72 | 48.63 | 12.22 |1272.67\n",
      "i :  5400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.39 |2359.23 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.787 |24.497 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.29 | 15.30 |246.79 |346.41\n",
      "glideslope | 38.80 | 48.54 | 12.22 |1272.67\n",
      "i :  5500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.91 |2360.56 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.781 |24.394 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.26 | 15.28 |246.79 |346.41\n",
      "glideslope | 38.69 | 48.27 | 12.22 |1272.67\n",
      "i :  5600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.70 |2360.59 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.779 |24.278 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.26 | 15.30 |246.79 |346.41\n",
      "glideslope | 38.71 | 48.25 | 12.22 |1272.67\n",
      "i :  5700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.17 |2361.59 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.779 |24.399 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.30 | 15.30 |246.79 |346.41\n",
      "glideslope | 38.70 | 47.95 | 12.01 |1272.67\n",
      "i :  5800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.16 |2361.63 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.780 |24.386 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.33 | 15.32 |246.79 |346.41\n",
      "glideslope | 38.90 | 48.93 | 12.01 |1272.67\n",
      "i :  5900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.83 |2361.49 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.776 |24.340 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.32 | 15.32 |246.79 |346.41\n",
      "glideslope | 38.83 | 48.64 | 12.01 |1272.67\n",
      "i :  6000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.07 |2361.22 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.773 |24.330 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.33 | 15.30 |246.79 |346.41\n",
      "glideslope | 38.79 | 48.45 | 12.01 |1272.67\n",
      "i :  6100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.33 |2360.53 |2000.00 |15000.00 |  3249\n",
      "glideslope | 5.773 |24.231 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.30 | 15.30 |246.79 |346.41\n",
      "glideslope | 38.78 | 48.26 | 12.01 |1272.67\n",
      "i :  6200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.92 |2361.04 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.774 |24.176 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.29 | 15.29 |246.79 |346.41\n",
      "glideslope | 38.76 | 48.01 | 12.01 |1272.67\n",
      "i :  6300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.97 |2360.93 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.777 |24.192 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.24 | 15.27 |246.79 |346.41\n",
      "glideslope | 38.90 | 48.76 | 12.01 |1272.67\n",
      "i :  6400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.60 |2361.65 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.790 |24.294 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.23 | 15.31 |246.79 |346.41\n",
      "glideslope | 38.95 | 48.71 | 12.01 |1272.67\n",
      "i :  6500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.07 |2362.05 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.797 |24.594 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.19 | 15.28 |246.79 |346.41\n",
      "glideslope | 38.94 | 48.52 | 12.01 |1272.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  6600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.15 |2360.98 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.792 |24.632 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.054  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.18 | 15.26 |246.79 |346.41\n",
      "glideslope | 38.87 | 48.27 | 12.01 |1272.67\n",
      "i :  6700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.78 |2361.64 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.817 |24.723 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.16 | 15.24 |246.79 |346.41\n",
      "glideslope | 38.91 | 48.07 | 12.01 |1272.67\n",
      "i :  6800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.46 |2361.20 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.824 |24.696 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.16 | 15.25 |246.79 |346.41\n",
      "glideslope | 38.97 | 48.37 | 12.01 |1272.67\n",
      "i :  6900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.23 |2361.44 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.838 |25.322 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.16 | 15.24 |246.79 |346.41\n",
      "glideslope | 39.14 | 49.38 | 12.01 |1272.67\n",
      "i :  7000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.31 |2360.81 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.841 |25.375 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.14 | 15.24 |246.79 |346.41\n",
      "glideslope | 39.18 | 49.25 | 12.01 |1272.67\n",
      "i :  7100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.60 |2360.61 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.849 |25.479 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.2\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.0    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.13 | 15.25 |246.79 |346.41\n",
      "glideslope | 39.25 | 49.57 | 12.01 |1272.67\n",
      "i :  7200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.02 |2360.45 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.853 |25.524 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.072 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.11 | 15.25 |246.79 |346.41\n",
      "glideslope | 39.18 | 49.43 | 12.01 |1272.67\n",
      "i :  7300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.79 |2360.23 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.851 |25.458 | 0.427 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.11 | 15.28 |246.79 |346.41\n",
      "glideslope | 39.20 | 49.29 | 12.01 |1272.67\n",
      "i :  7400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.79 |2359.89 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.844 |25.369 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.11 | 15.29 |246.79 |346.41\n",
      "glideslope | 39.09 | 49.01 | 11.90 |1272.67\n",
      "i :  7500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.38 |2359.92 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |25.259 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.12 | 15.29 |246.79 |346.41\n",
      "glideslope | 39.10 | 48.99 | 11.90 |1272.67\n",
      "i :  7600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9863.61 |2358.81 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.848 |25.266 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.09 | 15.29 |246.79 |346.41\n",
      "glideslope | 39.18 | 49.28 | 11.90 |1272.67\n",
      "i :  7700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.15 |2359.07 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.844 |25.318 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.09 | 15.29 |246.79 |346.41\n",
      "glideslope | 39.24 | 49.43 | 11.90 |1272.67\n",
      "i :  7800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.50 |2358.97 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.845 |25.331 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.08 | 15.30 |246.79 |346.41\n",
      "glideslope | 39.29 | 49.34 | 11.90 |1272.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  7900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.03 |2358.38 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.848 |25.285 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.07 | 15.30 |246.79 |346.41\n",
      "glideslope | 39.34 | 49.23 | 11.90 |1272.67\n",
      "i :  8000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9863.70 |2358.43 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.840 |25.192 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.09 | 15.28 |246.79 |346.41\n",
      "glideslope | 39.27 | 49.02 | 11.90 |1272.67\n",
      "i :  8100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9863.27 |2358.42 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.842 |25.244 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.09 | 15.27 |246.79 |346.41\n",
      "glideslope | 39.40 | 49.87 | 11.90 |1272.67\n",
      "i :  8200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.75 |2358.90 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.841 |25.282 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.08 | 15.26 |246.79 |346.41\n",
      "glideslope | 39.44 | 49.91 | 11.90 |1272.67\n",
      "i :  8300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.05 |2358.92 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.840 |25.243 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.09 | 15.25 |246.79 |346.41\n",
      "glideslope | 39.50 | 50.07 | 11.90 |1272.67\n",
      "i :  8400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.82 |2358.90 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.836 |25.168 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.09 | 15.26 |246.79 |346.41\n",
      "glideslope | 39.51 | 49.95 | 11.90 |1272.67\n",
      "i :  8500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.61 |2359.25 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |25.096 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.08 | 15.25 |246.79 |346.41\n",
      "glideslope | 39.55 | 49.94 | 11.90 |1272.67\n",
      "i :  8600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.53 |2359.10 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.835 |25.071 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.06 | 15.26 |246.79 |346.41\n",
      "glideslope | 39.57 | 49.98 | 11.90 |1272.67\n",
      "i :  8700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.36 |2359.56 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.833 |25.017 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.07 | 15.27 |246.79 |346.41\n",
      "glideslope | 39.52 | 49.76 | 11.90 |1272.67\n",
      "i :  8800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.95 |2359.98 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.830 |24.942 | 0.404 |10011.119 |  2523\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.072 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.05 | 15.26 |246.79 |346.41\n",
      "glideslope | 39.51 | 49.59 | 11.90 |1272.67\n",
      "i :  8900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.56 |2359.62 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.834 |27.519 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.03 | 15.24 |246.79 |346.41\n",
      "glideslope | 39.49 | 49.54 | 11.90 |1272.67\n",
      "i :  9000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.05 |2360.01 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |27.463 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.03 | 15.25 |246.79 |346.41\n",
      "glideslope | 39.52 | 49.49 | 11.90 |1272.67\n",
      "i :  9100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.98 |2359.56 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.833 |27.376 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.02 | 15.23 |246.79 |346.41\n",
      "glideslope | 39.50 | 49.80 | 11.90 |1272.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  9200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.52 |2359.64 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.835 |27.336 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.03 | 15.23 |246.79 |346.41\n",
      "glideslope | 39.52 | 49.78 | 11.90 |1272.67\n",
      "i :  9300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.14 |2359.37 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |27.284 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.03 | 15.23 |246.79 |346.41\n",
      "glideslope | 39.63 | 50.24 | 11.90 |1272.67\n",
      "i :  9400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.73 |2359.25 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |27.351 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.02 | 15.22 |246.79 |346.41\n",
      "glideslope | 39.59 | 50.11 | 11.90 |1272.67\n",
      "i :  9500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.46 |2358.99 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.834 |27.291 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.04 | 15.24 |246.79 |348.45\n",
      "glideslope | 39.56 | 49.93 | 11.90 |1272.67\n",
      "i :  9600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.74 |2358.42 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |27.274 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.02 | 15.25 |246.79 |348.45\n",
      "glideslope | 39.66 | 50.08 | 11.90 |1272.67\n",
      "i :  9700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.65 |2358.58 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |27.241 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.02 | 15.27 |246.79 |348.45\n",
      "glideslope | 39.68 | 50.29 | 11.90 |1272.67\n",
      "i :  9800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9865.79 |2358.91 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.837 |27.165 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.02 | 15.28 |246.79 |348.45\n",
      "glideslope | 39.66 | 50.18 | 11.90 |1272.67\n",
      "i :  9900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9866.45 |2359.04 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.838 |27.177 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.03 | 15.28 |246.79 |348.45\n",
      "glideslope | 39.70 | 50.21 | 11.90 |1272.67\n",
      "\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.25 |2359.81 |2000.00 |15000.00 |  6155\n",
      "glideslope | 5.838 |27.116 | 0.404 |19265.421 |  8843\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.222 |   0.073 |   1.016 |   1.566\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.3\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.7    -0.1 |     1.1     1.2    -0.0\n",
      "velocity |   0.025  -0.053  -1.219 |   0.042   0.038   0.073 |  -0.082  -0.143  -1.566 |   0.134   0.032  -1.016\n",
      "fuel     |287.04 | 15.29 |246.79 |348.45\n",
      "glideslope | 39.69 | 50.20 | 11.90 |1272.67\n",
      "\n",
      "Initial Stats (mean,std,min,max)\n",
      "norm_vf  |  92.221 |   9.151 |  71.035 | 115.870\n",
      "norm_rf  |  2670.5 |   226.8 |  2302.7 |  3250.0\n",
      "position |   991.3     6.3  2349.9 |   582.3   581.7    28.6 |     0.1 -1000.0  2300.0 |  1999.9  1000.0  2400.0\n",
      "velocity | -39.686   0.118 -79.882 |  17.277  17.335   5.769 | -69.999 -29.997 -89.997 | -10.001  29.987 -70.004\n",
      "fuel     |  0.00 |  0.00 |  0.00 |  0.00\n",
      "glideslope |  2.18 |  1.07 |  0.94 |  8.50\n"
     ]
    }
   ],
   "source": [
    "policy.test_mode=True\n",
    "  \n",
    "env.test_policy_batch(agent,10000,print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lander_model.trajectory_list)\n",
    "traj_list = lander_model.trajectory_list[0:100]\n",
    "len(traj_list)\n",
    "np.save('recurrent_policy-rkill-60step_100traj',traj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9932.68 |2381.93 |2000.00 |15000.00 |    28\n",
      "glideslope | 5.951 |19.713 | 0.552 |1071.393 |    61\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.070 |   1.074 |   1.400\n",
      "norm_rf  |     0.3 |     0.2 |     0.1 |     0.9\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.5    -0.4    -0.1 |     0.9     0.4    -0.0\n",
      "velocity |   0.027  -0.053  -1.217 |   0.042   0.034   0.070 |  -0.054  -0.136  -1.397 |   0.133   0.016  -1.073\n",
      "fuel     |286.89 | 12.85 |261.19 |326.79\n",
      "glideslope | 39.98 | 43.45 | 14.03 |326.35\n",
      "i :  200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9851.14 |2359.94 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.529 |17.332 | 0.552 |1071.393 |    61\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.217 |   0.069 |   1.056 |   1.400\n",
      "norm_rf  |     0.3 |     0.1 |     0.0 |     0.9\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.5    -0.4    -0.1 |     0.9     0.4    -0.0\n",
      "velocity |   0.026  -0.054  -1.215 |   0.042   0.036   0.068 |  -0.058  -0.136  -1.397 |   0.133   0.016  -1.052\n",
      "fuel     |287.05 | 14.77 |255.93 |335.89\n",
      "glideslope | 39.15 | 44.90 | 13.57 |410.06\n",
      "i :  300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.68 |2358.65 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.776 |18.647 | 0.403 |1071.393 |    61\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.056 |   1.435\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.5    -0.5    -0.1 |     1.7     0.4    -0.0\n",
      "velocity |   0.027  -0.052  -1.219 |   0.041   0.036   0.072 |  -0.058  -0.136  -1.432 |   0.133   0.021  -1.052\n",
      "fuel     |286.92 | 14.53 |250.88 |335.89\n",
      "glideslope | 39.95 | 42.18 | 13.02 |410.06\n",
      "i :  400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.83 |2360.56 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.758 |18.618 | 0.403 |1071.393 |    61\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.072 |   1.056 |   1.435\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.5    -0.5    -0.1 |     1.7     0.4    -0.0\n",
      "velocity |   0.027  -0.052  -1.217 |   0.041   0.037   0.071 |  -0.064  -0.136  -1.432 |   0.133   0.021  -1.052\n",
      "fuel     |286.97 | 14.98 |250.88 |335.89\n",
      "glideslope | 39.50 | 39.21 | 13.02 |410.06\n",
      "i :  500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9858.14 |2351.77 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.839 |21.907 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.072 |   1.056 |   1.435\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.5    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.052  -1.217 |   0.041   0.037   0.071 |  -0.064  -0.136  -1.432 |   0.133   0.021  -1.052\n",
      "fuel     |287.43 | 14.97 |250.88 |335.89\n",
      "glideslope | 40.25 | 40.83 | 12.66 |410.06\n",
      "i :  600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9848.27 |2360.33 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.819 |21.532 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.051 |   1.435\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.024  -0.053  -1.217 |   0.041   0.037   0.072 |  -0.075  -0.136  -1.432 |   0.133   0.021  -1.051\n",
      "fuel     |287.65 | 15.05 |250.88 |339.61\n",
      "glideslope | 39.74 | 38.92 | 12.66 |410.06\n",
      "i :  700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9862.24 |2356.38 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.851 |21.852 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.071 |   1.051 |   1.435\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.024  -0.053  -1.218 |   0.041   0.037   0.071 |  -0.075  -0.136  -1.432 |   0.133   0.021  -1.051\n",
      "fuel     |287.52 | 14.88 |250.88 |339.61\n",
      "glideslope | 39.71 | 41.74 | 12.66 |536.97\n",
      "i :  800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9860.53 |2359.33 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.799 |21.833 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.071 |   1.051 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.024  -0.054  -1.218 |   0.041   0.037   0.071 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.051\n",
      "fuel     |287.80 | 15.23 |250.86 |339.61\n",
      "glideslope | 39.75 | 46.12 | 12.66 |677.97\n",
      "i :  900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9858.45 |2359.43 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.806 |21.544 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.072 |   1.046 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.054  -1.217 |   0.042   0.037   0.071 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.045\n",
      "fuel     |287.49 | 15.18 |250.86 |339.61\n",
      "glideslope | 40.21 | 52.76 | 12.66 |809.47\n",
      "i :  1000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9853.95 |2356.79 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.840 |21.501 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.071 |   1.046 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.053  -1.216 |   0.042   0.037   0.070 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.045\n",
      "fuel     |287.18 | 15.10 |250.86 |339.61\n",
      "glideslope | 39.73 | 50.70 | 12.66 |809.47\n",
      "i :  1100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.21 |2358.55 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.896 |21.424 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.071 |   1.046 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.037   0.071 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.045\n",
      "fuel     |287.20 | 15.17 |250.86 |339.61\n",
      "glideslope | 39.75 | 49.38 | 12.66 |809.47\n",
      "i :  1200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9860.36 |2358.50 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.926 |21.222 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.072 |   1.046 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.5    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.037   0.071 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.045\n",
      "fuel     |287.18 | 15.03 |250.86 |339.61\n",
      "glideslope | 39.61 | 48.22 | 12.66 |809.47\n",
      "i :  1300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9856.79 |2357.14 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.952 |21.361 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.072 |   1.046 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.054  -1.217 |   0.042   0.038   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.045\n",
      "fuel     |287.01 | 15.10 |250.86 |339.61\n",
      "glideslope | 39.60 | 47.82 | 12.66 |809.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  1400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9862.38 |2354.62 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.921 |21.277 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.072 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.054  -1.218 |   0.042   0.038   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.94 | 15.05 |250.86 |339.61\n",
      "glideslope | 39.17 | 46.61 | 12.66 |809.47\n",
      "i :  1500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9858.78 |2353.55 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.964 |22.088 | 0.403 |3702.969 |   481\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.5    -0.0\n",
      "velocity |   0.025  -0.054  -1.217 |   0.042   0.037   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.83 | 15.05 |250.86 |339.61\n",
      "glideslope | 39.37 | 46.45 | 12.66 |809.47\n",
      "i :  1600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9858.01 |2356.43 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.977 |24.975 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.072 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.054  -1.217 |   0.042   0.037   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.80 | 15.02 |250.86 |339.61\n",
      "glideslope | 40.20 | 54.90 | 12.66 |1219.08\n",
      "i :  1700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9862.74 |2357.02 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.963 |24.537 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.072 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.053  -1.216 |   0.042   0.038   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.82 | 14.98 |250.86 |339.61\n",
      "glideslope | 39.96 | 54.08 | 12.66 |1219.08\n",
      "i :  1800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9864.98 |2355.29 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.955 |24.424 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.072 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.054  -1.216 |   0.042   0.038   0.071 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.80 | 14.92 |250.86 |339.61\n",
      "glideslope | 40.46 | 61.44 | 12.66 |1322.71\n",
      "i :  1900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.79 |2354.59 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.951 |24.121 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.219 |   0.072 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.053  -1.217 |   0.042   0.037   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.69 | 14.82 |250.86 |339.61\n",
      "glideslope | 40.39 | 60.80 | 12.66 |1322.71\n",
      "i :  2000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.20 |2354.98 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.937 |23.986 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.072 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.217 |   0.042   0.037   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.62 | 14.84 |250.86 |339.61\n",
      "glideslope | 40.18 | 59.75 | 12.66 |1322.71\n",
      "i :  2100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.74 |2354.72 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.914 |23.696 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.072 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.217 |   0.042   0.037   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.63 | 14.85 |250.86 |339.61\n",
      "glideslope | 39.97 | 58.65 | 12.66 |1322.71\n",
      "i :  2200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.39 |2355.79 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.933 |23.603 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.217 |   0.042   0.038   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.57 | 14.86 |250.86 |339.61\n",
      "glideslope | 39.91 | 57.74 | 12.64 |1322.71\n",
      "i :  2300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9874.28 |2355.83 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.933 |23.329 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.73 | 15.02 |250.86 |339.61\n",
      "glideslope | 39.73 | 56.88 | 12.64 |1322.71\n",
      "i :  2400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.56 |2354.63 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.906 |23.217 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.042 |   1.490\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.072 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.041\n",
      "fuel     |286.77 | 15.09 |250.86 |339.61\n",
      "glideslope | 39.75 | 57.18 | 12.64 |1322.71\n",
      "i :  2500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.76 |2356.07 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.907 |22.998 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.037   0.073 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.60 | 15.05 |250.86 |339.61\n",
      "glideslope | 39.68 | 56.57 | 12.64 |1322.71\n",
      "i :  2600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9874.31 |2356.76 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.895 |22.833 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.6    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.136  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.61 | 15.03 |250.86 |339.61\n",
      "glideslope | 39.65 | 56.38 | 12.64 |1322.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  2700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.50 |2355.14 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.895 |23.430 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.57 | 14.99 |250.86 |339.61\n",
      "glideslope | 39.80 | 57.75 | 12.64 |1322.71\n",
      "i :  2800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.21 |2354.27 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.901 |23.501 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.66 | 15.08 |250.86 |341.23\n",
      "glideslope | 39.98 | 57.24 | 12.64 |1322.71\n",
      "i :  2900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9873.65 |2353.50 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.894 |23.339 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.61 | 15.11 |250.86 |341.23\n",
      "glideslope | 40.16 | 57.99 | 12.64 |1322.71\n",
      "i :  3000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.93 |2353.66 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.891 |23.168 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.054  -1.217 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.65 | 15.10 |250.86 |341.23\n",
      "glideslope | 40.33 | 58.68 | 12.64 |1322.71\n",
      "i :  3100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9869.75 |2354.14 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.886 |23.114 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.220 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.054  -1.217 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.72 | 15.14 |250.86 |341.23\n",
      "glideslope | 40.24 | 58.03 | 12.64 |1322.71\n",
      "i :  3200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.64 |2355.36 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.864 |22.996 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1    -0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.025  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.82 | 15.17 |250.86 |345.33\n",
      "glideslope | 40.27 | 57.65 | 12.64 |1322.71\n",
      "i :  3300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.94 |2355.60 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.867 |22.995 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.074 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.133   0.027  -1.039\n",
      "fuel     |286.78 | 15.22 |250.86 |345.33\n",
      "glideslope | 40.49 | 59.28 | 12.64 |1322.71\n",
      "i :  3400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.24 |2355.54 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.870 |22.929 | 0.403 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.135   0.027  -1.039\n",
      "fuel     |286.71 | 15.26 |248.55 |345.33\n",
      "glideslope | 40.44 | 58.75 | 12.64 |1322.71\n",
      "i :  3500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.09 |2355.09 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.887 |22.825 | 0.396 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.135   0.028  -1.039\n",
      "fuel     |286.70 | 15.31 |248.55 |345.33\n",
      "glideslope | 40.30 | 58.06 | 12.64 |1322.71\n",
      "i :  3600\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.07 |2355.51 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.889 |23.114 | 0.396 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.6    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.135   0.028  -1.039\n",
      "fuel     |286.72 | 15.32 |248.55 |345.33\n",
      "glideslope | 40.37 | 57.84 | 12.64 |1322.71\n",
      "i :  3700\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.64 |2355.55 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.875 |22.938 | 0.396 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.135   0.028  -1.039\n",
      "fuel     |286.73 | 15.33 |248.55 |345.33\n",
      "glideslope | 40.12 | 57.22 | 12.64 |1322.71\n",
      "i :  3800\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9872.73 |2356.47 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.870 |22.818 | 0.396 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.075  -0.141  -1.490 |   0.135   0.028  -1.039\n",
      "fuel     |286.73 | 15.31 |248.55 |345.33\n",
      "glideslope | 40.25 | 56.92 | 12.64 |1322.71\n",
      "i :  3900\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9871.66 |2355.39 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.870 |22.814 | 0.396 |7897.179 |  1514\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.083  -0.141  -1.490 |   0.135   0.028  -1.039\n",
      "fuel     |286.70 | 15.28 |248.55 |345.33\n",
      "glideslope | 40.33 | 56.82 | 12.11 |1322.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :  4000\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.03 |2355.32 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.879 |25.110 | 0.396 |11579.283 |  3914\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.041 |   1.491\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.038   0.073 |  -0.083  -0.141  -1.490 |   0.135   0.028  -1.039\n",
      "fuel     |286.73 | 15.31 |248.55 |345.33\n",
      "glideslope | 40.45 | 57.63 | 12.11 |1322.71\n",
      "i :  4100\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9867.98 |2355.25 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.877 |24.983 | 0.396 |11579.283 |  3914\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.040 |   1.506\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.025  -0.053  -1.218 |   0.042   0.038   0.073 |  -0.083  -0.141  -1.501 |   0.135   0.028  -1.039\n",
      "fuel     |286.70 | 15.32 |246.23 |345.33\n",
      "glideslope | 40.65 | 58.47 | 12.11 |1322.71\n",
      "i :  4200\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9870.10 |2355.56 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.874 |24.882 | 0.396 |11579.283 |  3914\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.040 |   1.506\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.025  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.083  -0.141  -1.501 |   0.135   0.028  -1.039\n",
      "fuel     |286.69 | 15.35 |246.23 |345.33\n",
      "glideslope | 40.43 | 57.91 | 12.11 |1322.71\n",
      "i :  4300\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.31 |2355.34 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.862 |24.731 | 0.396 |11579.283 |  3914\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.040 |   1.506\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.026  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.083  -0.141  -1.501 |   0.135   0.028  -1.039\n",
      "fuel     |286.70 | 15.33 |246.23 |345.33\n",
      "glideslope | 40.41 | 57.70 | 12.11 |1322.71\n",
      "i :  4400\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.27 |2356.24 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.865 |24.661 | 0.396 |11579.283 |  3914\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.040 |   1.506\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.025  -0.054  -1.218 |   0.042   0.038   0.073 |  -0.083  -0.141  -1.501 |   0.135   0.028  -1.039\n",
      "fuel     |286.69 | 15.37 |246.23 |345.33\n",
      "glideslope | 40.44 | 57.46 | 12.11 |1322.71\n",
      "i :  4500\n",
      "Cumulative Stats (mean,std,max,argmax)\n",
      "thrust   |9868.25 |2356.10 |2000.00 |15000.00 |   145\n",
      "glideslope | 5.861 |24.582 | 0.396 |11579.283 |  3914\n",
      "sc_margin |100.000 | 0.000 |100.000 |100.000 |     0\n",
      "\n",
      "Final Stats (mean,std,min,max)\n",
      "norm_vf  |   1.221 |   0.073 |   1.040 |   1.506\n",
      "norm_rf  |     0.3 |     0.2 |     0.0 |     1.7\n",
      "position |     0.1     0.0    -0.0 |     0.3     0.2     0.0 |    -0.7    -0.6    -0.1 |     1.7     0.9    -0.0\n",
      "velocity |   0.026  -0.053  -1.218 |   0.042   0.038   0.073 |  -0.083  -0.141  -1.501 |   0.135   0.028  -1.039\n",
      "fuel     |286.65 | 15.39 |246.23 |345.33\n",
      "glideslope | 40.59 | 57.57 | 12.11 |1322.71\n"
     ]
    }
   ],
   "source": [
    "env.lander.sensor_pos_bias_range=(-0.05,0.05)\n",
    "env.lander.sensor_vel_bias_range=(-0.05,0.05)\n",
    "env.test_policy_batch(agent,10000,print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
